<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>go-context</title>
      <link href="/posts/4e29148d.html"/>
      <url>/posts/4e29148d.html</url>
      
        <content type="html"><![CDATA[<h1 id="go-上下文context">Go-上下文Context</h1><h2 id="上下文context">上下文context</h2><p>上下文context是Go中较独特的设计，其他编程语言中较为少见，主要用于在Goroutine之间传递请求的截止时间、取消信号和其他跨API边界的值。</p><p><img src="/posts/4e29148d/image-18.png"></p><p><code>context.Context</code>是Go在1.7版本中引入的标准库接口，定义了4个待实现的方法：</p><ol type="1"><li><p><code>Deadline</code>：返回 <a href="https://draven.co/golang/tree/context.Context"><code>context.Context</code></a>被取消的时间，也就是完成工作的截止日期（如果<code>Context</code>设置了截止时间，则返回<code>ok=true</code>，<code>deadline</code>返回该时间；如果没有设置截止时间，则返回<code>ok=false</code>，<code>deadline</code>为空）</p></li><li><p><code>Done</code>：返回一个<code>Channel</code>（在<strong>当前工作完成或者上下文被取消后关闭</strong>），<strong>作为对<code>Context</code>关联函数的取消信号</strong>。当<code>Channel</code>关闭时，关联函数终止工作并返回。</p><ul><li><p>多次调用 <code>Done</code> 方法会返回同一个Channel；（可以通过<code>select</code>监听该通道，在取消信号到来时，实现优雅退出）</p><blockquote><p>为什么<code>Context</code>不设置<code>Cancel</code>函数呢？</p><p>与<code>Done</code>通道设置为只读的原因一致：收到取消信号的函数callee，通常不是发送取消信号的函数caller。特别地，当一个父操作启动goroutines以执行子操作时，子操作不应该具备取消父操作的权力。</p><p>caller 不应该去关心、干涉 callee 的情况，决定如何以及何时 return 是callee 的责任。caller 只需发送取消信号，callee根据收到的信息来做进一步的决策，因此接口并没有定义 cancel方法，而是在canceler中定义。</p></blockquote></li></ul></li><li><p><code>Err</code>：返回 <a href="https://draven.co/golang/tree/context.Context"><code>context.Context</code></a>结束的原因，只会<strong>在 <code>Done</code> 方法对应的 Channel关闭时返回非空的值</strong>：</p><ol type="1"><li>如果 <a href="https://draven.co/golang/tree/context.Context"><code>context.Context</code></a>被取消，会返回 <code>Canceled</code> 错误；</li><li>如果 <a href="https://draven.co/golang/tree/context.Context"><code>context.Context</code></a>超时，会返回 <code>DeadlineExceeded</code> 错误；</li></ol></li><li><p><code>Value</code>：从 <a href="https://draven.co/golang/tree/context.Context"><code>context.Context</code></a>中获取键对应的值，对于同一个上下文来说，多次调用 <code>Value</code>并传入相同的 <code>Key</code>会返回相同的结果，该方法可以用来传递请求特定的数据；</p></li></ol><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> Context <span class="keyword">interface</span> &#123;</span><br><span class="line">Deadline() (deadline time.Time, ok <span class="type">bool</span>)</span><br><span class="line">Done() &lt;-<span class="keyword">chan</span> <span class="keyword">struct</span>&#123;&#125;</span><br><span class="line">Err() <span class="type">error</span></span><br><span class="line">Value(key <span class="keyword">interface</span>&#123;&#125;) <span class="keyword">interface</span>&#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>Context</code>是线程安全的，可以被多个goroutine同时使用。</p><p>再来看看另一个接口<code>canceler</code>：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> canceler <span class="keyword">interface</span> &#123;</span><br><span class="line">cancel(removeFromParent <span class="type">bool</span>, err <span class="type">error</span>)</span><br><span class="line">Done() &lt;-<span class="keyword">chan</span> <span class="keyword">struct</span>&#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>源码中<code>*cancelCtx</code>和<code>*timerCtx</code>实现了<code>canceler</code>接口：对应的Context时可取消的。</p><h3 id="设计原理">设计原理</h3><p>目的：在Goroutine构成的树形结构中，对信号进行同步处理，以减少计算资源的浪费。</p><blockquote><p><a href="https://go.dev/blog/context">Go Concurrency Patterns:Context</a></p><p>Go 服务的每一个请求都是通过单独的 Goroutine 处理的，HTTP/RPC请求的处理器会启动新的 Goroutine访问数据库和其他服务。当一个请求被取消或者超时，所有面向该请求工作的goroutine将快速退出，以便系统回收资源。</p></blockquote><p>如下图所示，我们可能会创建多个 Goroutine 来处理一次请求，而 <a href="https://draven.co/golang/tree/context.Context"><code>context.Context</code></a>的作用是在不同 Goroutine之间同步请求特定数据、取消信号以及处理请求的截止日期。</p><p><img src="/posts/4e29148d/image-19.png"></p><p>每一个 <a href="https://draven.co/golang/tree/context.Context"><code>context.Context</code></a>都会从最顶层的 Goroutine 一层一层传递到最下层。<a href="https://draven.co/golang/tree/context.Context"><code>context.Context</code></a>可以在上层 Goroutine执行出现错误时，将信号及时同步给下层，停掉无用的工作以减少额外资源的消耗：</p><p><img src="/posts/4e29148d/image-20.png"></p><h3 id="核心接口与类">核心接口与类</h3><h4 id="context.cancelctx"><code>context.cancelCtx</code></h4><p><a href="https://draven.co/golang/tree/context.cancelCtx"><code>context.cancelCtx</code></a>结构体实现了接口<code>canceler</code>：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> cancelCtx <span class="keyword">struct</span> &#123;</span><br><span class="line">Context</span><br><span class="line"></span><br><span class="line">mu       sync.Mutex            <span class="comment">// 保护之后的字段</span></span><br><span class="line">done     <span class="keyword">chan</span> <span class="keyword">struct</span>&#123;&#125;         <span class="comment">// 懒汉式创建（调用Done方法时才创建），被第一个取消信号关闭</span></span><br><span class="line">children <span class="keyword">map</span>[canceler]<span class="keyword">struct</span>&#123;&#125; <span class="comment">// 第一个取消信号到来时，设置为nil</span></span><br><span class="line">err      <span class="type">error</span>                 <span class="comment">// 第一个取消信号到来时，设置为non-nil的值</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// cancel closes c.done, cancels each of c&#x27;s children, and, if</span></span><br><span class="line"><span class="comment">// removeFromParent is true, removes c from its parent&#x27;s children.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *cancelCtx)</span></span> cancel(removeFromParent <span class="type">bool</span>, err <span class="type">error</span>) &#123;</span><br><span class="line"><span class="keyword">if</span> err == <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="built_in">panic</span>(<span class="string">&quot;context: internal error: missing cancel error&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line">  <span class="comment">// 1. 加锁，保证修改cancelCtx内部字段时的并发安全</span></span><br><span class="line">c.mu.Lock()</span><br><span class="line"><span class="keyword">if</span> c.err != <span class="literal">nil</span> &#123;</span><br><span class="line">c.mu.Unlock()</span><br><span class="line"><span class="keyword">return</span> <span class="comment">// 该Context已经被其他协程取消，直接返回</span></span><br><span class="line">&#125;</span><br><span class="line">c.err = err</span><br><span class="line">  <span class="comment">// 2. 关闭done通道，通知其他协程</span></span><br><span class="line"><span class="keyword">if</span> c.done == <span class="literal">nil</span> &#123;</span><br><span class="line">c.done = closedchan</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line"><span class="built_in">close</span>(c.done)</span><br><span class="line">&#125;</span><br><span class="line">  <span class="comment">// 3. 遍历所有子Context：</span></span><br><span class="line"><span class="keyword">for</span> child := <span class="keyword">range</span> c.children &#123;</span><br><span class="line"><span class="comment">// <span class="doctag">NOTE:</span> acquiring the child&#x27;s lock while holding parent&#x27;s lock.</span></span><br><span class="line">child.cancel(<span class="literal">false</span>, err)<span class="comment">// 递归地取消所有子Context</span></span><br><span class="line">&#125;</span><br><span class="line">c.children = <span class="literal">nil</span><span class="comment">// 子Context置空</span></span><br><span class="line">  <span class="comment">// 4. 解锁</span></span><br><span class="line">c.mu.Unlock()</span><br><span class="line"><span class="comment">// 5. 从父Context的children列表中，移除当前Context</span></span><br><span class="line"><span class="keyword">if</span> removeFromParent &#123;</span><br><span class="line">removeChild(c.Context, c)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 调用了 Done() 方法的时候才会创建done通道</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *cancelCtx)</span></span> Done() &lt;-<span class="keyword">chan</span> <span class="keyword">struct</span>&#123;&#125; &#123;</span><br><span class="line">d := c.done.Load()</span><br><span class="line"><span class="keyword">if</span> d != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> d.(<span class="keyword">chan</span> <span class="keyword">struct</span>&#123;&#125;)</span><br><span class="line">&#125;</span><br><span class="line">c.mu.Lock()</span><br><span class="line"><span class="keyword">defer</span> c.mu.Unlock()</span><br><span class="line">d = c.done.Load()</span><br><span class="line"><span class="keyword">if</span> d == <span class="literal">nil</span> &#123;</span><br><span class="line">d = <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">struct</span>&#123;&#125;)</span><br><span class="line">c.done.Store(d)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> d.(<span class="keyword">chan</span> <span class="keyword">struct</span>&#123;&#125;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>有一个关键问题：调用<code>cancel</code>方法时，如何设置参数<code>removeFromParent</code>呢？也即：什么时候传<code>true</code>？什么时候传<code>false</code>？</p><p>看看<code>removeChild</code>函数：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// removeChild 将当前Context从它的父Context的children列表中删除</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">removeChild</span><span class="params">(parent Context, child canceler)</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> s, ok := parent.(stopCtx); ok &#123;</span><br><span class="line">s.stop()</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">&#125;</span><br><span class="line">p, ok := parentCancelCtx(parent)</span><br><span class="line"><span class="keyword">if</span> !ok &#123;</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">&#125;</span><br><span class="line">p.mu.Lock()</span><br><span class="line"><span class="keyword">if</span> p.children != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="built_in">delete</span>(p.children, child)</span><br><span class="line">&#125;</span><br><span class="line">p.mu.Unlock()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>什么时候会传<code>true</code>呢？<strong>调用<code>WithCancel()</code>时。</strong></p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">return</span> &amp;c, <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123; c.cancel(<span class="literal">true</span>, Canceled) &#125;</span><br></pre></td></tr></table></figure><p>当新创建一个可取消的<code>Context</code>时，返回的<code>cancelFunc</code>需要传入<code>true</code>：当调用返回的<code>cancelFunc</code>时，将调用<code>removeChild</code>函数，将该<code>Context</code>从其父<code>Context</code>的<code>children</code>列表中删除。</p><blockquote><p>以下是一棵Context树：</p><p><img src="/posts/4e29148d/image-21.png"></p><p>当调用标红<code>Context</code>的<code>cancel</code>方法后，该<code>Context</code>将从它的父<code>Context</code>的<code>children</code>列表中删除，实线变成虚线；虚线框内的<code>Context</code>也均被取消，父子关系消失。</p></blockquote><h3 id="派生的-context">派生的 <code>Context</code></h3><p><code>context</code> 包提供了从现有的 <code>Context</code> 值派生新<code>Context</code> 值的函数。这些派生的 <code>Context</code>形成了一棵树：<strong>当一个 <code>Context</code>被取消时，所有从它派生的 <code>Context</code> 也会被取消。</strong></p><h4 id="默认上下文context.background">默认上下文：<code>context.Background</code></h4><p><code>Background</code>是任何<code>Context</code>树的根，永远不会被取消，也没有<code>Value</code>和<code>Deadline</code>。（通常用于main,init和测试函数，或者作为传入请求的顶级<code>Context</code>）</p><p><a href="https://github.com/golang/go/tree/master/src/context"><code>context</code></a>包中最常用的方法还是 <a href="https://draven.co/golang/tree/context.Background"><code>context.Background</code></a>、<a href="https://draven.co/golang/tree/context.TODO"><code>context.TODO</code></a>，这两个方法都会返回预先初始化好的私有变量<code>background</code> 和 <code>todo</code>，它们会在同一个 Go程序中被复用：</p><blockquote><p>这两个私有变量都是通过 <code>new(emptyCtx)</code>语句初始化的，它们是指向私有结构体 <a href="https://draven.co/golang/tree/context.emptyCtx"><code>context.emptyCtx</code></a>的指针，这是最简单、最常用的上下文类型：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> emptyCtx <span class="type">int</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(*emptyCtx)</span></span> Deadline() (deadline time.Time, ok <span class="type">bool</span>) &#123;</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(*emptyCtx)</span></span> Done() &lt;-<span class="keyword">chan</span> <span class="keyword">struct</span>&#123;&#125; &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(*emptyCtx)</span></span> Err() <span class="type">error</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(*emptyCtx)</span></span> Value(key <span class="keyword">interface</span>&#123;&#125;) <span class="keyword">interface</span>&#123;&#125; &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><a href="https://draven.co/golang/tree/context.emptyCtx"><code>context.emptyCtx</code></a>通过空方法实现了 <a href="https://draven.co/golang/tree/context.Context"><code>context.Context</code></a>接口中的所有方法，它没有任何功能。</p><p><img src="/posts/4e29148d/image-22.png"></p></blockquote><p>从源代码看，<a href="https://draven.co/golang/tree/context.Background"><code>context.Background</code></a>和 <a href="https://draven.co/golang/tree/context.TODO"><code>context.TODO</code></a>只是互为别名，没有太大的差别，只是在使用和语义上稍有不同：</p><ul><li><a href="https://draven.co/golang/tree/context.Background"><code>context.Background</code></a>是上下文的默认值，所有其他的上下文都应该从它衍生出来；</li><li><a href="https://draven.co/golang/tree/context.TODO"><code>context.TODO</code></a>应该仅在不确定应该使用哪种上下文时使用；</li></ul><h4 id="取消信号context.withcancel">取消信号：<code>context.WithCancel()</code></h4><p><a href="https://draven.co/golang/tree/context.WithCancel"><code>context.WithCancel</code></a>函数用于从父<code>Context</code>中衍生出一个新的子<code>Context</code>，并返回父<code>Context</code>的副本。一旦我们父<code>Context</code>的<code>Done</code>通道关闭/cancel被调用，父<code>Context</code>以及它的子<code>Context</code>都会被取消，所有的Goroutine 都会同步收到这一取消信号。</p><p><img src="/posts/4e29148d/image-23.png"></p><p>看看<a href="https://draven.co/golang/tree/context.WithCancel"><code>context.WithCancel</code></a>函数的实现：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">WithCancel</span><span class="params">(parent Context)</span></span> (ctx Context, cancel CancelFunc) &#123;</span><br><span class="line">c := newCancelCtx(parent)<span class="comment">// 传入一个父Context（通常是一个background，作为根节点）；返回新建的父Context副本</span></span><br><span class="line">propagateCancel(parent, &amp;c)</span><br><span class="line"><span class="keyword">return</span> &amp;c, <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123; c.cancel(<span class="literal">true</span>, Canceled) &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">newCancelCtx</span><span class="params">(parent Context)</span></span> cancelCtx &#123;</span><br><span class="line"><span class="keyword">return</span> cancelCtx&#123;Context: parent&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol type="1"><li><a href="https://draven.co/golang/tree/context.newCancelCtx"><code>context.newCancelCtx</code></a>将传入的<code>Context</code>包装成私有结构体 <a href="https://draven.co/golang/tree/context.cancelCtx"><code>context.cancelCtx</code></a>；</li><li><a href="https://draven.co/golang/tree/context.propagateCancel"><code>context.propagateCancel</code></a>会构建父子<code>Context</code>之间的关联，当父<code>Context</code>被取消时，子<code>Context</code>也会被取消；共包含3种情况：<ol type="1"><li>当<code>parent.Done()==nil</code>时，也即<code>parent</code>不会触发取消信号时，当前函数直接返回；</li><li>当<code>child</code>的继承链包含可以取消的<code>Context</code>时，判断<code>parent</code>是否已经触发取消信号：<ul><li>如果已经被取消，<code>child</code> 会立刻被取消；</li><li>如果没有被取消，<code>child</code> 会被加入 <code>parent</code> 的<code>children</code> 列表中，等待 <code>parent</code>释放取消信号；</li></ul></li><li>在默认情况下：<ul><li>运行一个新的 Goroutine 同时监听 <code>parent.Done()</code> 和<code>child.Done()</code> 两个 Channel：在 <code>parent.Done()</code>关闭时调用 <code>child.cancel</code> 取消子上下文；</li></ul></li></ol></li></ol><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">propagateCancel</span><span class="params">(parent Context, child canceler)</span></span> &#123;</span><br><span class="line">done := parent.Done()</span><br><span class="line"><span class="keyword">if</span> done == <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="comment">// 1. 父Context不会触发取消信号</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">select</span> &#123;</span><br><span class="line"><span class="keyword">case</span> &lt;-done:</span><br><span class="line">    <span class="comment">// 如果父Context已经被取消，则取消子Context的任务</span></span><br><span class="line">child.cancel(<span class="literal">false</span>, parent.Err()) </span><br><span class="line"><span class="keyword">return</span></span><br><span class="line"><span class="keyword">default</span>:</span><br><span class="line">    <span class="comment">// 如果父Context没有取消信号，继续执行</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 2. 寻找需要取消的父Context：</span></span><br><span class="line"><span class="keyword">if</span> p, ok := parentCancelCtx(parent); ok &#123;</span><br><span class="line">    <span class="comment">// 获取父Context的取消信息，并加锁</span></span><br><span class="line">p.mu.Lock()</span><br><span class="line"><span class="keyword">if</span> p.err != <span class="literal">nil</span> &#123;</span><br><span class="line">      <span class="comment">// 如果父Context已被取消，传递取消信号给子Context</span></span><br><span class="line">child.cancel(<span class="literal">false</span>, p.err)</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// 如果父Context没有被取消，将子Context挂到父Context的children列表中</span></span><br><span class="line">p.children[child] = <span class="keyword">struct</span>&#123;&#125;&#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line">p.mu.Unlock()</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// 3. 没有找到需要取消的父Context：启动一个goroutine同时监听父Context和子Context的取消信号</span></span><br><span class="line"><span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="keyword">select</span> &#123;</span><br><span class="line"><span class="keyword">case</span> &lt;-parent.Done():</span><br><span class="line">        <span class="comment">// 如果父Context被取消，则取消子Context</span></span><br><span class="line">child.cancel(<span class="literal">false</span>, parent.Err())</span><br><span class="line"><span class="keyword">case</span> &lt;-child.Done():</span><br><span class="line">        <span class="comment">// 如果子Context自己取消，直接返回</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;()</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol type="1"><li><code>propagateCancel</code>方法的意义是什么呢？</li></ol><p>​不断向上寻找可以“挂靠”的“可取消”<code>Context</code>，并“挂靠”上去。这样，调用上层<code>cancel</code>方法的时候，就可以层层传递，将那些挂靠的子<code>Context</code>同时取消。看看查找的关键函数：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">parentCancelCtx</span><span class="params">(parent Context)</span></span> (*cancelCtx, <span class="type">bool</span>) &#123;</span><br><span class="line">done := parent.Done()</span><br><span class="line"><span class="keyword">if</span> done == closedchan || done == <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, <span class="literal">false</span></span><br><span class="line">&#125;</span><br><span class="line">  <span class="comment">// 查找 parent.Value(&amp;cancelCtxKey) 来获取最内层包裹的 *cancelCtx：验证parent.Done() 返回的 channel 是否与该 *cancelCtx 的 channel 匹配</span></span><br><span class="line">  <span class="comment">// 如果不匹配，说明 *cancelCtx 被提供了不同 done channel 的自定义实现所包裹，这种情况下我们不应该绕过该包装层。</span></span><br><span class="line">p, ok := parent.Value(&amp;cancelCtxKey).(*cancelCtx)</span><br><span class="line"><span class="keyword">if</span> !ok &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, <span class="literal">false</span></span><br><span class="line">&#125;</span><br><span class="line">pdone, _ := p.done.Load().(<span class="keyword">chan</span> <span class="keyword">struct</span>&#123;&#125;)</span><br><span class="line"><span class="keyword">if</span> pdone != done &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, <span class="literal">false</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> p, <span class="literal">true</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="2" type="1"><li>如果没有找到可“挂靠”的<code>Context</code>（第3种情况），那理论上<code>case &lt;-parent.Done()</code>永远不会发生，岂非有些多余？</li></ol><p>​进入<code>Value</code>函数看看：从context链中查找<code>key</code>对应的值：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *valueCtx)</span></span> Value(key any) any &#123;</span><br><span class="line"><span class="keyword">if</span> c.key == key &#123;</span><br><span class="line"><span class="keyword">return</span> c.val</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> value(c.Context, key)</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">value</span><span class="params">(c Context, key any)</span></span> any &#123;</span><br><span class="line"><span class="keyword">for</span> &#123;</span><br><span class="line"><span class="keyword">switch</span> ctx := c.(<span class="keyword">type</span>) &#123;</span><br><span class="line"><span class="keyword">case</span> *valueCtx:<span class="comment">// 1. 值上下文</span></span><br><span class="line"><span class="keyword">if</span> key == ctx.key &#123;</span><br><span class="line"><span class="keyword">return</span> ctx.val</span><br><span class="line">&#125;</span><br><span class="line">c = ctx.Context<span class="comment">// 未找到，继续向上层查找</span></span><br><span class="line"><span class="keyword">case</span> *cancelCtx:<span class="comment">// 可取消上下文</span></span><br><span class="line"><span class="keyword">if</span> key == &amp;cancelCtxKey &#123;</span><br><span class="line"><span class="keyword">return</span> c</span><br><span class="line">&#125;</span><br><span class="line">c = ctx.Context</span><br><span class="line"><span class="keyword">case</span> withoutCancelCtx:<span class="comment">// 无取消上下文</span></span><br><span class="line"><span class="keyword">if</span> key == &amp;cancelCtxKey &#123;</span><br><span class="line"><span class="comment">// This implements Cause(ctx) == nil</span></span><br><span class="line"><span class="comment">// when ctx is created using WithoutCancel.</span></span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line">c = ctx.c</span><br><span class="line"><span class="keyword">case</span> *timerCtx:<span class="comment">// 定时器上下文</span></span><br><span class="line"><span class="keyword">if</span> key == &amp;cancelCtxKey &#123;</span><br><span class="line"><span class="keyword">return</span> &amp;ctx.cancelCtx<span class="comment">// 返回内嵌的 cancelCtx</span></span><br><span class="line">&#125;</span><br><span class="line">c = ctx.Context</span><br><span class="line"><span class="keyword">case</span> backgroundCtx, todoCtx:</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line"><span class="keyword">default</span>:</span><br><span class="line"><span class="keyword">return</span> c.Value(key)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>​发现<code>Value</code>只能识别一些原生的<code>Context</code>类型，如果采用自定义的<code>Context</code>类型作为父<code>Context</code>，不能匹配。此时Go会新启动一个协程来监控取消信号。</p><ol start="3" type="1"><li><p>为啥第3种情况里<code>select</code>语句的两个<code>case</code>都不能删？</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> &#123;</span><br><span class="line"><span class="keyword">case</span> &lt;-parent.Done():</span><br><span class="line">child.cancel(<span class="literal">false</span>, parent.Err())</span><br><span class="line"><span class="keyword">case</span> &lt;-child.Done():</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><pre><code>1. 第一个`case`如果去掉，那么父`Context`的取消信号无法传递给子`Context`了；2. 第二个`case`是说如果子`Context`自行取消，则退出该`select`，不用再等父`Context`的取消信号（否则父`Context`一直不取消，造成goroutine泄漏）</code></pre></li></ol><h4 id="定时取消信号context.withtimeout">定时取消信号：<code>context.WithTimeout()</code></h4><p><a href="https://draven.co/golang/tree/context.WithDeadline"><code>context.WithDeadline</code></a>在创建 <a href="https://draven.co/golang/tree/context.timerCtx"><code>context.timerCtx</code></a>的过程中判断了父<code>Context</code>的<code>Deadline</code>当前<code>Deadline</code>（新的<code>Context</code> 的 <code>Deadline</code>是当前时间加上超时时间，与父<code>Context</code>的<code>Deadline</code>做比较，取更早的一个）；并通过<a href="https://draven.co/golang/tree/time.AfterFunc"><code>time.AfterFunc</code></a>创建定时器，当时间超过了截止日期后会调用 <a href="https://draven.co/golang/tree/context.timerCtx.cancel"><code>context.timerCtx.cancel</code></a>同步取消信号。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">WithTimeout</span><span class="params">(parent Context, timeout time.Duration)</span></span> (Context, CancelFunc) &#123;</span><br><span class="line">  <span class="comment">// 将当前时间与超时时间相加，形成一个绝对的截止时间</span></span><br><span class="line"><span class="keyword">return</span> WithDeadline(parent, time.Now().Add(timeout))</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">WithDeadline</span><span class="params">(parent Context, d time.Time)</span></span> (Context, CancelFunc) &#123;</span><br><span class="line">  <span class="comment">// 1. 检查父Context是否已设置截止时间cur：</span></span><br><span class="line"><span class="keyword">if</span> cur, ok := parent.Deadline(); ok &amp;&amp; cur.Before(d) &#123;</span><br><span class="line">    <span class="comment">// 1.1 cur早于当前设置的截止时间d，直接调用WithCancel返回一个可取消的Context，无需使用定时器；</span></span><br><span class="line"><span class="keyword">return</span> WithCancel(parent)</span><br><span class="line">&#125;</span><br><span class="line">  <span class="comment">// 1.2 cur晚于d：创建一个带有截止时间d的新Context</span></span><br><span class="line">c := &amp;timerCtx&#123;</span><br><span class="line">cancelCtx: newCancelCtx(parent),</span><br><span class="line">deadline:  d,</span><br><span class="line">&#125;</span><br><span class="line">  <span class="comment">// 将parent的取消信号，传播给新创建的timerCtx</span></span><br><span class="line">propagateCancel(parent, c)</span><br><span class="line">  <span class="comment">// 2. 处理截止时间：计算当前时间到截止时间d的持续时间dur</span></span><br><span class="line">dur := time.Until(d)</span><br><span class="line"><span class="keyword">if</span> dur &lt;= <span class="number">0</span> &#123;</span><br><span class="line">c.cancel(<span class="literal">true</span>, DeadlineExceeded) <span class="comment">// 2.1 已经过了截止日期：立即取消Context</span></span><br><span class="line"><span class="keyword">return</span> c, <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123; c.cancel(<span class="literal">false</span>, Canceled) &#125;</span><br><span class="line">&#125;</span><br><span class="line">  <span class="comment">// 2.2 尚未过截止时间：设置定时器，在dur后调用cancel，取消Context</span></span><br><span class="line">c.mu.Lock()</span><br><span class="line"><span class="keyword">defer</span> c.mu.Unlock()</span><br><span class="line"><span class="keyword">if</span> c.err == <span class="literal">nil</span> &#123;</span><br><span class="line">c.timer = time.AfterFunc(dur, <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">c.cancel(<span class="literal">true</span>, DeadlineExceeded)</span><br><span class="line">&#125;)</span><br><span class="line">&#125;</span><br><span class="line">  <span class="comment">// 3. 返回Context和取消函数</span></span><br><span class="line"><span class="keyword">return</span> c, <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123; c.cancel(<span class="literal">true</span>, Canceled) &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p><a href="https://draven.co/golang/tree/context.timerCtx"><code>context.timerCtx</code></a>内部不仅通过嵌入 <a href="https://draven.co/golang/tree/context.cancelCtx"><code>context.cancelCtx</code></a>结构体继承了相关的变量和方法，还通过持有的定时器 <code>timer</code>和截止时间 <code>deadline</code> 实现了定时取消的功能：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> timerCtx <span class="keyword">struct</span> &#123;</span><br><span class="line">cancelCtx</span><br><span class="line">timer *time.Timer <span class="comment">// Under cancelCtx.mu.</span></span><br><span class="line"></span><br><span class="line">deadline time.Time</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *timerCtx)</span></span> Deadline() (deadline time.Time, ok <span class="type">bool</span>) &#123;</span><br><span class="line"><span class="keyword">return</span> c.deadline, <span class="literal">true</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *timerCtx)</span></span> cancel(removeFromParent <span class="type">bool</span>, err <span class="type">error</span>) &#123;</span><br><span class="line">c.cancelCtx.cancel(<span class="literal">false</span>, err)</span><br><span class="line"><span class="keyword">if</span> removeFromParent &#123;</span><br><span class="line">removeChild(c.cancelCtx.Context, c)</span><br><span class="line">&#125;</span><br><span class="line">c.mu.Lock()</span><br><span class="line"><span class="keyword">if</span> c.timer != <span class="literal">nil</span> &#123;</span><br><span class="line">c.timer.Stop()</span><br><span class="line">c.timer = <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line">c.mu.Unlock()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></blockquote><p><code>WithTimeout</code>非常适用于设置与后端服务器的请求超时。当希望在一定时间内没有响应就取消请求时，可以使用<code>WithTimeout</code>。</p><h4 id="传值context.withvalue">传值：<code>context.WithValue()</code></h4><p><a href="https://github.com/golang/go/tree/master/src/context"><code>context</code></a>包中的 <a href="https://draven.co/golang/tree/context.WithValue"><code>context.WithValue</code></a>能从父<code>Context</code>中创建一个子<code>Context</code>，传值的子<code>Context</code>使用<a href="https://draven.co/golang/tree/context.valueCtx"><code>context.valueCtx</code></a>类型：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// WithValue 返回父 Context 的副本，父 Context 的 Value 方法对于 key 返回 val</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">WithValue</span><span class="params">(parent Context, key, val <span class="keyword">interface</span>&#123;&#125;)</span></span> Context &#123;</span><br><span class="line"><span class="keyword">if</span> key == <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="built_in">panic</span>(<span class="string">&quot;nil key&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> !reflectlite.TypeOf(key).Comparable() &#123;</span><br><span class="line"><span class="built_in">panic</span>(<span class="string">&quot;key is not comparable&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> &amp;valueCtx&#123;parent, key, val&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p><a href="https://draven.co/golang/tree/context.valueCtx"><code>context.valueCtx</code></a>结构体会将除了 <code>Value</code> 之外的<code>Err</code>、<code>Deadline</code>等方法代理到父上下文中，它只会响应 <a href="https://draven.co/golang/tree/context.valueCtx.Value"><code>context.valueCtx.Value</code></a>方法：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> valueCtx <span class="keyword">struct</span> &#123;</span><br><span class="line">Context<span class="comment">// 父Context</span></span><br><span class="line">key, val <span class="keyword">interface</span>&#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *valueCtx)</span></span> Value(key <span class="keyword">interface</span>&#123;&#125;) <span class="keyword">interface</span>&#123;&#125; &#123;</span><br><span class="line"><span class="keyword">if</span> c.key == key &#123;</span><br><span class="line"><span class="keyword">return</span> c.val</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> c.Context.Value(key)<span class="comment">// 向父Context中不断回溯查找</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果 <a href="https://draven.co/golang/tree/context.valueCtx"><code>context.valueCtx</code></a>中存储的键值对与 <a href="https://draven.co/golang/tree/context.valueCtx.Value"><code>context.valueCtx.Value</code></a>方法中传入的参数不匹配，就会从父<code>Context</code>中查找该键对应的值，直到某个父<code>Context</code>中返回<code>nil</code> 或者查找到对应的值。</p></blockquote><p><code>WithValue</code> 允许将值与 <code>Context</code>关联，这些值在请求的生命周期内是有效的，并且线程安全地共享。通常在 web服务中，<code>WithValue</code>被用来在请求处理中传递用户信息或其他与请求相关的数据。</p><h3 id="一个栗子">一个栗子</h3><p>创建一个过期时间为1s的<code>Context</code>，并传入<code>handle</code>函数，该方法使用500ms处理传入的请求：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">ctx, cancel := context.WithTimeout(context.Background(), <span class="number">1</span>*time.Second)<span class="comment">// 创建一个1s超时的Context</span></span><br><span class="line"><span class="keyword">defer</span> cancel()</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 启动一个新的goroutine：执行handle函数</span></span><br><span class="line"><span class="keyword">go</span> handle(ctx, <span class="number">500</span>*time.Millisecond)</span><br><span class="line"><span class="keyword">select</span> &#123;</span><br><span class="line"><span class="keyword">case</span> &lt;-ctx.Done():</span><br><span class="line">    <span class="comment">// 等待Context的取消信号</span></span><br><span class="line">fmt.Println(<span class="string">&quot;main&quot;</span>, ctx.Err())</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">handle</span><span class="params">(ctx context.Context, duration time.Duration)</span></span> &#123;</span><br><span class="line"><span class="keyword">select</span> &#123;</span><br><span class="line">  <span class="comment">// 监听父Context（main中的ctx）：如果父Context被取消，handle函数退出</span></span><br><span class="line"><span class="keyword">case</span> &lt;-ctx.Done():</span><br><span class="line">fmt.Println(<span class="string">&quot;handle&quot;</span>, ctx.Err())</span><br><span class="line">  <span class="comment">// 监听duration，等待500ms后打印消息</span></span><br><span class="line"><span class="keyword">case</span> &lt;-time.After(duration):</span><br><span class="line">fmt.Println(<span class="string">&quot;process request with&quot;</span>, duration)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol type="1"><li><p>由于超时时间1s&gt;处理时间500ms，因此打印内容为：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ go run context.go</span><br><span class="line">process request with 500ms</span><br><span class="line">main context deadline exceeded</span><br></pre></td></tr></table></figure><p><code>handle</code> 函数没有进入超时的 <code>select</code> 分支，但是<code>main</code> 函数的 <code>select</code> 却会等待 <a href="https://draven.co/golang/tree/context.Context"><code>context.Context</code></a>超时并打印出 <code>main context deadline exceeded</code>。</p></li><li><p>如果设置处理时间=1500ms&gt;超时时间1s，整个程序将因Contxt终止而终止，打印内容为：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="keyword">go</span> run context.<span class="keyword">go</span></span><br><span class="line">main context deadline exceeded</span><br><span class="line">handle context deadline exceeded</span><br></pre></td></tr></table></figure><p>注：有几率不打印"handle context deadline exceeded"，因为main协程已经退出了，handle被强制退出了。此时需要main中sleep一会儿。</p></li></ol><h3 id="一些官方文档的建议">一些官方文档的建议</h3><ol type="1"><li>不要将 <code>Context</code> 塞到结构体里。直接将<code>Context</code> 类型作为函数的第一参数，而且一般都命名为 ctx；</li><li>不要向函数传入一个 nil 的context，如果你实在不知道传什么，标准库准备好了一个context：<code>todo</code>；</li><li>不要把本应该作为函数参数的类型塞到 context 中，context存储的应该是一些共同的数据。例如：登陆的 session、cookie 等；</li><li>同一个 context 可能会被传递到多个 goroutine，别担心，context是并发安全的。</li></ol><h2 id="参考">参考</h2><p><a href="https://draven.co/golang/docs/part3-runtime/ch06-concurrency/golang-context/">Go语言设计与实现</a></p><p><a href="https://www.cnblogs.com/qcrao-2018/p/11007503.html">深度解密Go语言之context</a></p>]]></content>
      
      
      <categories>
          
          <category> Go </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Transformer系列：2. Attention机制，MHA，MQA和GQA</title>
      <link href="/posts/1e6a04d4.html"/>
      <url>/posts/1e6a04d4.html</url>
      
        <content type="html"><![CDATA[<h2 id="scaled-dot-product-attention">Scaled Dot-Product Attention</h2><p>只使用一个注意力头计算权重。</p><p>假设有输入序列<span class="math inline">\(X=(x_1, x_2,...,x_n)\)</span>，<strong>对于每个词<span class="math inline">\(x_i\)</span>（维度为<span class="math inline">\(d\)</span>），计算其与所有其他词的相关性，并赋予不同的权重</strong>，最后对这些信息加权求和，得到新的表示。输入矩阵：<span class="math inline">\(X\in\mathbb{R^{n\timesd}}\)</span>. <span class="math display">\[Attention(Q, K, V)=softmax(\frac{QK^{T}}{\sqrt{d_k}})V\]</span> 这里，<span class="math inline">\(Q\in\mathbb{R^{n\timesd_k}}, K\in\mathbb{R^{m\times d_k}, V\in\mathbb{R^{m\timesd_v}}}\)</span>。实质上，一个Attention层是：将<span class="math inline">\([n, d_k]\)</span>的序列<span class="math inline">\(Q\)</span>编码成一个新的<span class="math inline">\(n\times d_v\)</span>序列。</p><p>从向量角度看： <span class="math display">\[Attention(q_t, K, V)=\sum_{s=1}^m \frac{1}{Z}\exp(\frac{&lt;q_t,k_s&gt;}{\sqrt{d_k}})v_s\]</span> 其中，<span class="math inline">\(Z\)</span>是归一化因子。上式意为：通过<span class="math inline">\(q_t\)</span>这个query，通过与各个<span class="math inline">\(k_s\)</span>内积再softmax的方式，得到<span class="math inline">\(q_t\)</span>与各个<span class="math inline">\(v_s\)</span>的相似度；再加权求和，得到一个<span class="math inline">\(d_v\)</span>维的向量。</p><p><img src="/posts/1e6a04d4/image-18.png"></p><p>分为以下几个步骤：</p><ol type="1"><li><p><strong>计算Query, Key,Value矩阵</strong>：每个输入token被映射为三个不同的向量：</p><ul><li>Q：当前需要关注的内容，例如在机器翻译中，查询可能是目标语言句子中的一个token；</li><li>K：与查询进行匹配的内容，例如源语言句子中的token；</li><li>V：最终要提取的信息，通常与键对应。</li></ul><p>转换矩阵： <span class="math display">\[Q=XW_Q, K=XW_K, V=XW_V\]</span> 其中，<span class="math inline">\(W_Q, W_K,W_V\)</span>是可学习的参数矩阵。</p><p><strong>输入：维度<span class="math inline">\(d_k\)</span>的queries和keys</strong>；<strong>输出：维度为<span class="math inline">\(d_v\)</span>的values</strong></p><blockquote><p>查询矩阵Q的维度：[<span class="math inline">\(n, d_k\)</span>]，<span class="math inline">\(n\)</span>为queries的数量；<span class="math inline">\(d_k\)</span>是每个query的维度</p><p>键矩阵K的维度：[<span class="math inline">\(m, d_k\)</span>]，<span class="math inline">\(n\)</span>为keys的数量；<span class="math inline">\(d_k\)</span>是每个key的维度</p><p>值矩阵V的维度：[<span class="math inline">\(m, d_v\)</span>]，<span class="math inline">\(m\)</span>为queries的数量；<span class="math inline">\(d_v\)</span>是每个value的维度</p><ol type="1"><li><strong>Q和K的维度必须一致</strong>：V和Q/K的维度可以不一致；</li><li><strong>K和V的长度必须一致</strong>：K和V本质上对应同一个sequence在不同空间的表达。</li></ol><p>Attention得到的output：[<span class="math inline">\(n, d_v\)</span>].Attention层的本质：<strong>将<span class="math inline">\([n,d_k]\)</span>的序列<span class="math inline">\(Q\)</span>编码成一个新的<span class="math inline">\([n, d_v]\)</span>的序列。</strong></p></blockquote></li><li><p><strong>计算点积</strong>：得到注意力分数矩阵 <span class="math display">\[scores=QK^{T}\]</span></p></li><li><p><strong>缩放</strong>：将点积除以<span class="math inline">\(\sqrt{d_k}\)</span>，其中：<span class="math inline">\(\sqrt{d_k}\)</span>是Key向量的维度，<span class="math inline">\(\sqrt{d_k}\)</span>是缩放因子，避免数值过大导致梯度消失。</p><blockquote><p><strong>为什么要使用缩放因子<span class="math inline">\(\sqrt{d_k}\)</span>？</strong><strong>归一化</strong></p><p>假设<span class="math inline">\(Q,K\)</span>里的元素均值为0，方差为1，那么：<span class="math inline">\(A=QK^{T}\)</span>中元素均值为0，方差为<span class="math inline">\(d\)</span>。当d变得很大时，<span class="math inline">\(A\)</span>中的元素方差也变得很大，导致<span class="math inline">\(softmax(A)\)</span>的分布也趋于陡峭（分布的方差大，分布集中在绝对值大的区域）。</p><p><span class="math inline">\(A\)</span>中每一个元素乘上<span class="math inline">\(\frac{1}{\sqrt{d_k}}\)</span>后，方差又回到1，使得：<span class="math inline">\(softmax(A)\)</span>的分布陡峭程度与<span class="math inline">\(d\)</span>解耦，从而使得训练过程中，梯度值保持稳定。</p></blockquote></li><li><p><strong>softmax归一化</strong>：对缩放后的点积结果，应用softmax函数，得到注意力权重矩阵A：<span class="math display">\[A=softmax(\frac{QK^{T}}{\sqrt{d_k}})\]</span></p></li><li><p><strong>加权求和</strong>：将注意力权重矩阵<span class="math inline">\(A\)</span>与值矩阵<span class="math inline">\(V\)</span>相乘，得到加权求和的结果。</p></li></ol><p>单头注意力机制代码实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SingleHeadAttention</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, embed_dim</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        单头注意力机制的初始化。</span></span><br><span class="line"><span class="string">        :param embed_dim: 嵌入维度，Query、Key 和 Value 的维度</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>(SingleHeadAttention, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.embed_dim = embed_dim</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 定义线性层，将输入映射到 Query、Key 和 Value</span></span><br><span class="line">        <span class="variable language_">self</span>.query_linear = nn.Linear(embed_dim, embed_dim)</span><br><span class="line">        <span class="variable language_">self</span>.key_linear = nn.Linear(embed_dim, embed_dim)</span><br><span class="line">        <span class="variable language_">self</span>.value_linear = nn.Linear(embed_dim, embed_dim)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 缩放因子，用于防止点积结果过大</span></span><br><span class="line">        <span class="variable language_">self</span>.scale = torch.sqrt(torch.FloatTensor($embed_dim]))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, query, key, value</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        单头注意力的前向传播。</span></span><br><span class="line"><span class="string">        :param query: 查询张量，形状为 $batch_size, seq_len_q, embed_dim]</span></span><br><span class="line"><span class="string">        :param key: 键张量，形状为 $batch_size, seq_len_k, embed_dim]</span></span><br><span class="line"><span class="string">        :param value: 值张量，形状为 $batch_size, seq_len_k, embed_dim]</span></span><br><span class="line"><span class="string">        :return: 输出张量，形状为 $batch_size, seq_len_q, embed_dim]</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 将输入映射到 Query、Key 和 Value</span></span><br><span class="line">        Q = <span class="variable language_">self</span>.query_linear(query)</span><br><span class="line">        K = <span class="variable language_">self</span>.key_linear(key)</span><br><span class="line">        V = <span class="variable language_">self</span>.value_linear(value)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算点积注意力分数</span></span><br><span class="line">        attention_scores = torch.matmul(Q, K.transpose(-<span class="number">2</span>, -<span class="number">1</span>)) / <span class="variable language_">self</span>.scale</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 应用 Softmax 函数，得到注意力权重</span></span><br><span class="line">        attention_weights = F.softmax(attention_scores, dim=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 加权求和，得到最终输出</span></span><br><span class="line">        output = torch.matmul(attention_weights, V)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> output, attention_weights</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例输入</span></span><br><span class="line"><span class="comment"># 假设我们有以下输入张量：</span></span><br><span class="line"><span class="comment"># - query: $batch_size, seq_len_q, embed_dim]</span></span><br><span class="line"><span class="comment"># - key: $batch_size, seq_len_k, embed_dim]</span></span><br><span class="line"><span class="comment"># - value: $batch_size, seq_len_k, embed_dim]</span></span><br><span class="line">batch_size = <span class="number">2</span></span><br><span class="line">seq_len_q = <span class="number">3</span><span class="comment"># query的序列长度</span></span><br><span class="line">seq_len_k = <span class="number">4</span><span class="comment">#k,v的序列长度，注意这里K、V是成对存在的</span></span><br><span class="line">embed_dim = <span class="number">6</span><span class="comment"># 假设embedding的维度为6</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机生成输入数据</span></span><br><span class="line">query = torch.randn(batch_size, seq_len_q, embed_dim)</span><br><span class="line">key = torch.randn(batch_size, seq_len_k, embed_dim)</span><br><span class="line">value = torch.randn(batch_size, seq_len_k, embed_dim)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化单头注意力模块</span></span><br><span class="line">attention = SingleHeadAttention(embed_dim)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 前向传播</span></span><br><span class="line">output, attention_weights = attention(query, key, value)</span><br></pre></td></tr></table></figure><h2 id="mha">MHA</h2><p>单头注意力中，模型只能通过一个注意力头来捕捉输入数据中的特征，这限制了模型对复杂关系的建模能力。而多头注意力（Multi-HeadAttention）是Transformer架构的核心组件，它的核心思想是：<strong>将输入数据分解为多个子空间，每个子空间通过一个独立的注意力“头”（heads）进行处理，最后将所有heads的输出合并</strong>，从而能够捕捉到输入数据中不同子空间的特征；同时其复杂度并无增加。</p><p><img src="/posts/1e6a04d4/image-19.png"></p><p>这里对<span class="math inline">\(W^Q, W^K,W^V\)</span>进行拆分，有： <span class="math display">\[head\]</span></p><p>步骤如下：</p><ol type="1"><li><p><strong>计算Query，Key，Value矩阵</strong>： <span class="math display">\[Q=XW_Q, K=XW_K, V=XW_V\]</span></p></li><li><p><strong>分割多个heads</strong>：假设有<span class="math inline">\(h\)</span>个heads，每个head的维度为<span class="math inline">\(d_k\)</span>，则有： <span class="math display">\[d_k=\frac{d_{dim}}{h}\]</span> 其中，<span class="math inline">\(d_{dim}\)</span>是模型的嵌入维度。</p><p>分割后的Q，K，V如下： <span class="math display">\[Q_i=split(Q, i),  \\K_i=split(K, i),  \\V_i=split(V, i)\]</span> 其中，<span class="math inline">\(i\)</span>表示第<span class="math inline">\(i\)</span>个头。</p></li><li><p><strong>计算每个head的注意力</strong>：</p><ol type="1"><li><p><strong>计算点积注意力分数</strong>： <span class="math display">\[A_i=Q_i\times K_i^{T}\]</span></p></li><li><p><strong>缩放</strong>： <span class="math display">\[S_i=\frac{A_i}{\sqrt{d_k}}\]</span></p></li><li><p><strong>SoftMax</strong>： <span class="math display">\[W_i=softmax(S_i)\]</span></p></li><li><p><strong>加权求和</strong>： <span class="math display">\[O_i=W_i\times V_i\]</span></p></li></ol></li><li><p><strong>合并所有head的输出</strong>： <span class="math display">\[O=concat(O_1,O_2,...,O_h)W^{O}\]</span> 其中，<span class="math inline">\(W_O\)</span>是另一个可学习的权重矩阵，用于将合并后的输出映射回原始维度。</p></li></ol><p>用一些示意图辅助理解：</p><ol type="1"><li><p>假设输入序列的seq_len=4，hidden_size=8，使用2头注意力。弱化batch_size（假设为1）.</p><blockquote><p><span class="math inline">\(Q=XW_Q\)</span>：<span class="math inline">\([s, h]\times [h, h]]\rightarrow [s,h]\)</span></p></blockquote><p><img src="/posts/1e6a04d4/image-20.png"></p></li><li><p><strong>每个head</strong>：对于每个<span class="math inline">\(Q_i, K_i,V_i\)</span>，分别计算attention，最后得到一个[2, 4,4]的矩阵，即<strong><span class="math inline">\([h, s,d_i]\)</span></strong>.（<strong>引入head，切分hidden_size</strong>，设每个head的hidden_size为<span class="math inline">\(d_i\)</span>）</p><blockquote><p><span class="math inline">\(QK^T=[h, s, d_i]\times [h, d_i,s]\rightarrow [h, s, s]\)</span></p></blockquote><p><img src="/posts/1e6a04d4/image-21.png"></p></li><li><p>重新拼接为[8,4]的矩阵，即<span class="math inline">\([s,d]\)</span>；再经过<span class="math inline">\(W_O\)</span>，得到<span class="math inline">\(O\)</span>矩阵，即输出。</p><p><img src="/posts/1e6a04d4/image-22.png"></p></li></ol><p>MHA代码实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MultiHeadAttention</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, embed_dim, num_heads</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        多头注意力机制的初始化。</span></span><br><span class="line"><span class="string">        :param embed_dim: 嵌入维度</span></span><br><span class="line"><span class="string">        :param num_heads: 头的数量</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>(MultiHeadAttention, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.embed_dim = embed_dim</span><br><span class="line">        <span class="variable language_">self</span>.num_heads = num_heads</span><br><span class="line">        <span class="variable language_">self</span>.head_dim = embed_dim // num_heads</span><br><span class="line"></span><br><span class="line">        <span class="keyword">assert</span> <span class="variable language_">self</span>.head_dim * num_heads == embed_dim, <span class="string">&quot;Embed size needs to be divisible by heads&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 定义线性层，将输入映射到 Query、Key 和 Value</span></span><br><span class="line">        <span class="variable language_">self</span>.query_linear = nn.Linear(embed_dim, embed_dim)</span><br><span class="line">        <span class="variable language_">self</span>.key_linear = nn.Linear(embed_dim, embed_dim)</span><br><span class="line">        <span class="variable language_">self</span>.value_linear = nn.Linear(embed_dim, embed_dim)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 定义输出的线性层</span></span><br><span class="line">        <span class="variable language_">self</span>.out = nn.Linear(embed_dim, embed_dim)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 缩放因子</span></span><br><span class="line">        <span class="variable language_">self</span>.scale = torch.sqrt(torch.FloatTensor([<span class="variable language_">self</span>.head_dim]))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, query, key, value</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        多头注意力的前向传播。</span></span><br><span class="line"><span class="string">        :param query: 查询张量，形状为 [batch_size, seq_len_q, embed_dim]</span></span><br><span class="line"><span class="string">        :param key: 键张量，形状为 [batch_size, seq_len_k, embed_dim]</span></span><br><span class="line"><span class="string">        :param value: 值张量，形状为 [batch_size, seq_len_k, embed_dim]</span></span><br><span class="line"><span class="string">        :return: 输出张量，形状为 [batch_size, seq_len_q, embed_dim]</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        batch_size = query.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将输入映射到 Query、Key 和 Value</span></span><br><span class="line">        Q = <span class="variable language_">self</span>.query_linear(query)  <span class="comment"># [batch_size, seq_len_q, embed_dim]</span></span><br><span class="line">        K = <span class="variable language_">self</span>.key_linear(key)      <span class="comment"># [batch_size, seq_len_k, embed_dim]</span></span><br><span class="line">        V = <span class="variable language_">self</span>.value_linear(value)  <span class="comment"># [batch_size, seq_len_k, embed_dim]</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 分割成多个头</span></span><br><span class="line">        Q = Q.view(batch_size, -<span class="number">1</span>, <span class="variable language_">self</span>.num_heads, <span class="variable language_">self</span>.head_dim).transpose(<span class="number">1</span>, <span class="number">2</span>)  <span class="comment"># [batch_size, num_heads, seq_len_q, head_dim]</span></span><br><span class="line">        K = K.view(batch_size, -<span class="number">1</span>, <span class="variable language_">self</span>.num_heads, <span class="variable language_">self</span>.head_dim).transpose(<span class="number">1</span>, <span class="number">2</span>)  <span class="comment"># [batch_size, num_heads, seq_len_k, head_dim]</span></span><br><span class="line">        V = V.view(batch_size, -<span class="number">1</span>, <span class="variable language_">self</span>.num_heads, <span class="variable language_">self</span>.head_dim).transpose(<span class="number">1</span>, <span class="number">2</span>)  <span class="comment"># [batch_size, num_heads, seq_len_k, head_dim]</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算点积注意力分数</span></span><br><span class="line">        attention_scores = torch.matmul(Q, K.transpose(-<span class="number">2</span>, -<span class="number">1</span>)) / <span class="variable language_">self</span>.scale  <span class="comment"># [batch_size, num_heads, seq_len_q, seq_len_k]</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 应用 Softmax 函数，得到注意力权重</span></span><br><span class="line">        attention_weights = F.softmax(attention_scores, dim=-<span class="number">1</span>)  <span class="comment"># [batch_size, num_heads, seq_len_q, seq_len_k]</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 加权求和，得到每个头的输出</span></span><br><span class="line">        output = torch.matmul(attention_weights, V)  <span class="comment"># [batch_size, num_heads, seq_len_q, head_dim]</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 合并所有头的输出</span></span><br><span class="line">        output = output.transpose(<span class="number">1</span>, <span class="number">2</span>).contiguous().view(batch_size, -<span class="number">1</span>, <span class="variable language_">self</span>.embed_dim)  <span class="comment"># [batch_size, seq_len_q, embed_dim]</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 通过输出的线性层</span></span><br><span class="line">        output = <span class="variable language_">self</span>.out(output)  <span class="comment"># [batch_size, seq_len_q, embed_dim]</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> output, attention_weights</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例输入</span></span><br><span class="line">batch_size = <span class="number">2</span></span><br><span class="line">seq_len_q = <span class="number">3</span></span><br><span class="line">seq_len_k = <span class="number">4</span></span><br><span class="line">embed_dim = <span class="number">16</span></span><br><span class="line">num_heads = <span class="number">4</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机生成输入数据</span></span><br><span class="line">query = torch.randn(batch_size, seq_len_q, embed_dim)</span><br><span class="line">key = torch.randn(batch_size, seq_len_k, embed_dim)</span><br><span class="line">value = torch.randn(batch_size, seq_len_k, embed_dim)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化多头注意力模块</span></span><br><span class="line">attention = MultiHeadAttention(embed_dim, num_heads)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 前向传播</span></span><br><span class="line">output, attention_weights = attention.forward(query, key, value)</span><br></pre></td></tr></table></figure><h2 id="kv-cache">KV Cache</h2><p>大模型在<strong>decode阶段采用自回归的方式</strong>。即：<strong>最新的token输出依赖于先前生成或者预先填入的Token</strong>。</p><p>假如我们输入“窗前明月光下一句是”：decode过程如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">step0: 输入=[BOS]窗前明月光下一句是；输出=疑</span><br><span class="line">step1: 输入=[BOS]窗前明月光下一句是疑；输出=是</span><br><span class="line">step2: 输入=[BOS]窗前明月光下一句是疑是；输出=地</span><br><span class="line">step3: 输入=[BOS]窗前明月光下一句是疑是地；输出=上</span><br><span class="line">step4: 输入=[BOS]窗前明月光下一句是疑是地上；输出=霜</span><br><span class="line">step5: 输入=[BOS]窗前明月光下一句是疑是地上霜；输出=[EOS]</span><br></pre></td></tr></table></figure><p>在生成“疑”字时，用的是<strong>输入序列中“是”字的最后一层hiddenstate</strong>，再通过最后的分类头预测。可以注意到：下一个step的输入包含了上一个step的内容，而且只在最后面多一个token；因此下一个step的计算也包含了上一个step的计算。</p><p>由于<strong>decoder是casual的（一个token的attention只依赖于之前的token，得益于maskattention）</strong>。因此在自回归生成的过程中，每一步会重复计算之前所有tokens的attention，可简化为：只计算新token的attention。</p><p>如下图：空的方块代表可以以前的steps中重用的计算部分：</p><p><img src="/posts/1e6a04d4/image-23.png"></p><h3 id="key-cache">Key Cache</h3><p>维护一个密钥缓存，存储：在每次迭代中计算的键向量。当前step的流程如下：</p><ol type="1"><li><p>只计算一个Query向量和一个Key向量：</p><p><img src="/posts/1e6a04d4/image-24.png"></p></li><li><p>从Key Cache中提取先前steps计算的Key Vectors，计算AttentionScore的最后一行，即新的Query Vector与所有Key Vectors的点积：</p><p><img src="/posts/1e6a04d4/image-25.png"></p></li></ol><h3 id="value-cache">Value Cache</h3><p>与Key Vector类似，每个step只需要计算最新的Value Vector；其他ValueVectors可以从Value Cache中提取并重复使用：</p><p><img src="/posts/1e6a04d4/image-26.png"></p><h2 id="mqa">MQA</h2><p>KVCache虽然可以解决kv重复计算的问题，但面对长上下文时，显存占用量巨大。</p><blockquote><p>以llama3-8B模型为例：模型序列长度<span class="math inline">\(L=8192\)</span>(8K)；Transformer层数<span class="math inline">\(N=32\)</span>，注意力头数<span class="math inline">\(H=32\)</span>，每个注意力头的维度<span class="math inline">\(D=128\)</span>，batch按照1算，数据类型为BF16（2个字节），需要的缓存为：<span class="math display">\[token_{kv}=2\times 1\times 32\times 8192\times 128\times 32\times2=4294967296\]</span> 即4GB。</p></blockquote><p>MQA的核心思想是：<strong>所有注意力头共享一份Key和Value矩阵，仅保留Query的多头性质</strong>。即：Key和Value的计算是唯一的，而Query则根据不同的头进行独立转换。</p><blockquote><p>在下图中：</p><p>当 batch size=1时，图中红色、绿色、蓝色虚线圈处的乘法全部为矩阵乘向量，是MemoryBound，算术强度不到 1。</p><p>当 batch size&gt;1 时（比如 Continuous Batching）：</p><ul><li>红色和蓝色部分：<strong>线性层计算是权重乘以激活</strong>，<strong>不同请求之间可以共享权重</strong>，因此是矩阵乘矩阵，并且Batch Size 越大，算术强度越大，越趋近于计算密集型（FFN 层也类似）；</li><li>绿色部分：<strong>注意力计算是激活乘以激活</strong>。因为<strong>不同的请求之间没有任何相关性</strong>，即使Batching，此处也是 Batched矩阵乘向量，并且因为序列长度可能不同，这里不同请求的矩阵乘向量是不规则的。即，这里算术强度始终不到1，是Memory Bound。</li></ul><p>因此绿色部分较难优化，输入序列越长，瓶颈越大。</p></blockquote><p><img src="/posts/1e6a04d4/image-29.png"></p><blockquote><p>与MHA对比：</p><p><strong>MHA</strong>：输入分别经过<span class="math inline">\(W_Q,W_K, W_V\)</span>的变换，切成<span class="math inline">\(n\)</span>份（n为头数），维度从<span class="math inline">\(d_{model}\)</span>降到<span class="math inline">\(d_{head}\)</span>，分别进行attention计算再拼接；</p><p><strong>MQA</strong>：只对<span class="math inline">\(Q\)</span>切分，而<span class="math inline">\(K,V\)</span>直接在线形变换时将维度降至<span class="math inline">\(d_{head}\)</span>（而不是切分变小）</p></blockquote><p><img src="/posts/1e6a04d4/image-27.png"></p><p>假设输入的维度为：<span class="math inline">\([b, s,d]\)</span>，其中<span class="math inline">\(b\)</span>为batchsize，<span class="math inline">\(s\)</span>为sequence length，<span class="math inline">\(d\)</span>为hidden size。</p><ol type="1"><li><p><strong>线性变换</strong>：得到的<span class="math inline">\(Q\)</span>为<span class="math inline">\([b, s,d]\)</span>；<span class="math inline">\(K, V\)</span>为<span class="math inline">\([b, s, d_head]\)</span>.</p></li><li><p><strong>多头切分</strong>：</p><ul><li><p>将<span class="math inline">\(Q\)</span>按head切分：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Q = Q.view(batch_size, -<span class="number">1</span>, <span class="variable language_">self</span>.num_heads, <span class="variable language_">self</span>.head_dim).transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br></pre></td></tr></table></figure></li><li><p>拓展<span class="math inline">\(K, V\)</span>以匹配<span class="math inline">\(Q\)</span>的维度：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">K = K.unsqueeze(<span class="number">1</span>).expand(-<span class="number">1</span>, <span class="variable language_">self</span>.num_heads, -<span class="number">1</span>, -<span class="number">1</span>)                      </span><br><span class="line">V = V.unsqueeze(<span class="number">1</span>).expand(-<span class="number">1</span>, <span class="variable language_">self</span>.num_heads, -<span class="number">1</span>, -<span class="number">1</span>)</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>注意力计算</strong>：计算<span class="math inline">\(Q,V\)</span>之间的点积： <span class="math display">\[scores=\frac{Q_{split}K_{split}^T}{\sqrt{d_{head}}}\]</span> ​ 应用softmax获取注意力权重： <span class="math display">\[W=softmax(scores)\]</span> ​ 使用注意力权重，对Value加权求和： <span class="math display">\[context=WV_{split}\]</span></p></li><li><p><strong>多头合并</strong>：使用矩阵乘法matmul广播，使得每个头都乘以这同一个张量，以此来实现KV参数共享。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">output = torch.matmul(attn, V)  </span><br><span class="line"><span class="comment"># (batch_size, num_heads, seq_len, head_dim)</span></span><br><span class="line">output = output.transpose(<span class="number">1</span>, <span class="number">2</span>).contiguous().view(batch_size, -<span class="number">1</span>, <span class="variable language_">self</span>.d_model) <span class="comment"># (batch_size, seq_len, d_model)</span></span><br></pre></td></tr></table></figure></li></ol><p>数学公式：</p><p><img src="/posts/1e6a04d4/image-28.png"></p><p>MQA代码实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MultiQueryAttention</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, d_model, num_heads</span>):</span><br><span class="line">        <span class="built_in">super</span>(MultiQueryAttention, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.num_heads = num_heads</span><br><span class="line">        <span class="variable language_">self</span>.d_model = d_model</span><br><span class="line">        <span class="variable language_">self</span>.head_dim = d_model // num_heads</span><br><span class="line"></span><br><span class="line">        <span class="keyword">assert</span> (</span><br><span class="line">            <span class="variable language_">self</span>.head_dim * num_heads == d_model</span><br><span class="line">        ), <span class="string">&quot;d_model must be divisible by num_heads&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.query_linear = nn.Linear(d_model, d_model)</span><br><span class="line">        <span class="variable language_">self</span>.key_linear = nn.Linear(d_model, <span class="variable language_">self</span>.head_dim)</span><br><span class="line">        <span class="variable language_">self</span>.value_linear = nn.Linear(d_model, <span class="variable language_">self</span>.head_dim)</span><br><span class="line">        <span class="variable language_">self</span>.out_linear = nn.Linear(d_model, d_model)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, queries, keys, values, mask=<span class="literal">None</span></span>):</span><br><span class="line">        batch_size = queries.size(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 线性变换</span></span><br><span class="line">        Q = <span class="variable language_">self</span>.query_linear(queries)  <span class="comment"># (batch_size, seq_len, d_model)</span></span><br><span class="line">        K = <span class="variable language_">self</span>.key_linear(keys)       <span class="comment"># (batch_size, seq_len, head_dim)</span></span><br><span class="line">        V = <span class="variable language_">self</span>.value_linear(values)   <span class="comment"># (batch_size, seq_len, head_dim)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 分割为多个头</span></span><br><span class="line">        Q = Q.view(batch_size, -<span class="number">1</span>, <span class="variable language_">self</span>.num_heads, <span class="variable language_">self</span>.head_dim).transpose(<span class="number">1</span>, <span class="number">2</span>)  <span class="comment"># (batch_size, num_heads, seq_len, head_dim)</span></span><br><span class="line">        K = K.unsqueeze(<span class="number">1</span>).expand(-<span class="number">1</span>, <span class="variable language_">self</span>.num_heads, -<span class="number">1</span>, -<span class="number">1</span>)                      <span class="comment"># (batch_size, num_heads, seq_len, head_dim)</span></span><br><span class="line">        V = V.unsqueeze(<span class="number">1</span>).expand(-<span class="number">1</span>, <span class="variable language_">self</span>.num_heads, -<span class="number">1</span>, -<span class="number">1</span>)                      <span class="comment"># (batch_size, num_heads, seq_len, head_dim)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算注意力得分</span></span><br><span class="line">        scores = torch.matmul(Q, K.transpose(-<span class="number">2</span>, -<span class="number">1</span>)) / torch.sqrt(torch.tensor(<span class="variable language_">self</span>.head_dim, dtype=torch.float32))</span><br><span class="line">        <span class="keyword">if</span> mask isnotNone:</span><br><span class="line">            scores = scores.masked_fill(mask == <span class="number">0</span>, -<span class="number">1e9</span>)</span><br><span class="line">        attn = F.softmax(scores, dim=-<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 计算注意力输出</span></span><br><span class="line">        output = torch.matmul(attn, V)  <span class="comment"># (batch_size, num_heads, seq_len, head_dim)</span></span><br><span class="line">    </span><br><span class="line">        output = output.transpose(<span class="number">1</span>, <span class="number">2</span>).contiguous().view(batch_size, -<span class="number">1</span>, <span class="variable language_">self</span>.d_model)  <span class="comment"># (batch_size, seq_len, d_model)</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.out_linear(output)</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">1</span></span><br><span class="line">seq_len = <span class="number">3</span></span><br><span class="line">d_model = <span class="number">4</span></span><br><span class="line">num_heads = <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机生成输入张量</span></span><br><span class="line">queries = torch.rand(batch_size, seq_len, d_model)</span><br><span class="line">keys = torch.rand(batch_size, seq_len, d_model)</span><br><span class="line">values = torch.rand(batch_size, seq_len, d_model)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化 MQA 模型</span></span><br><span class="line">mqa = MultiQueryAttention(d_model, num_heads)</span><br><span class="line"></span><br><span class="line">mask = torch.tril(torch.ones(seq_len, seq_len)).unsqueeze(<span class="number">0</span>).unsqueeze(<span class="number">0</span>)  <span class="comment"># (1, 1, seq_len, seq_len)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;mask:&#x27;</span>,mask)</span><br><span class="line"><span class="comment"># 前向传播</span></span><br><span class="line">output = mqa(queries, keys, values,mask)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;输出张量：&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(output)</span><br></pre></td></tr></table></figure><h3 id="内存">内存</h3><p>MQA所需要缓存的KV值，从所有头减为一个头，KV Cache减少为之前的<span class="math inline">\(\frac{1}{h}\)</span>。</p><p>性能测试如下：</p><p><img src="/posts/1e6a04d4/image-30.png"></p><ol type="1"><li>训练速度基本不变；</li><li>推理时间和beam-search时间大幅缩短；</li><li>推理过程中：Encoder推理速度基本不变；Decoder推理大幅加速。</li></ol><p><strong>MQA不改变计算量，但大幅降低了显存使用（降低KVCache）</strong>：</p><ol type="1"><li>降低KVCache的空间占用率；节省的显存空间可用于增加批次大小、提升吞吐量；</li><li>头数量的减少，导致从显存中读取的数据量减少，减少了计算单元的等待时间，从内存密集型趋近于计算密集型。</li></ol><h3 id="表征能力">表征能力</h3><p>共享K，V可能导致模型捕捉上下文的能力下降，限制模型的表征能力，导致任务效果相比MHA略有损失。</p><h3 id="通信">通信</h3><p>在多卡并行情况下，<strong>MQA减少了访存，但是增加了并行通信开销</strong>。由于<strong>K和V张量在所有头部之间共享，每个GPU上都需要有自己的备份</strong>。与下图(a)中MHA并行策略相比，<strong>MQA需要使用all-to-all对进行输入输出激活张量resharding，从而产生额外的通信成本</strong>。具体如下图(b)所示。另外，因为每个卡上都有备份，这可能会导致MQA的内存成本节省将会丧失。</p><p><img src="/posts/1e6a04d4/image-31.png"></p><h2 id="gqa">GQA</h2><p>MHA和MQA的折中方案：采用<strong>分组</strong>机制，<strong>让多个Query 共享少量的 Key 和Value</strong>，减少自注意力计算的复杂度，同时保持 Transformer的表达能力。</p><p><img src="/posts/1e6a04d4/image-32.png"></p><ol type="1"><li><p><strong>Query多头计算</strong>：Query依然是<strong>每个头独立计算</strong>。假设有<span class="math inline">\(h\)</span>个注意力头，计算方式如下： <span class="math display">\[Q_i=XW_Q^i, i=1,2,...,h\]</span> 其中：<span class="math inline">\(W_Q^i\)</span>是第<span class="math inline">\(i\)</span>个头的Query投影矩阵；计算出的<span class="math inline">\(Q_i\)</span>形状为<span class="math inline">\([b,s, d_{head}]\)</span>.（<span class="math inline">\(d_head=\frac{d}{h}\)</span>）</p></li><li><p><strong>共享分组：Key和Value计算</strong>。将Key和Value分成<span class="math inline">\(g\)</span>组，其中<span class="math inline">\(g&lt;h\)</span>，即： <span class="math display">\[K_j=XW_K^j, V_j=XW_V^j, j=1,2,...,g\]</span> 计算出的<span class="math inline">\(K_j,V_j\)</span>形状为<span class="math inline">\([b, s,d_g]\)</span>（<span class="math inline">\(d_g=\frac{d}{g}\)</span>）</p></li><li><p><strong>计算注意力分数</strong>： <span class="math display">\[A_i=softmax(\frac{Q_iK_j^T}{\sqrt{d_g}})\]</span> 其中：<span class="math inline">\(Q_i\)</span>来自每个Query头；<span class="math inline">\(K_j\)</span>来自共享的Key组。计算得到的<span class="math inline">\(A_i\)</span>形状为<span class="math inline">\([b,s, s]\)</span>.</p></li><li><p><strong>计算加权Value</strong>： <span class="math display">\[Z_i=A_iV_j\]</span></p></li></ol><p>​ 其中：<span class="math inline">\(V_j\)</span>是共享的Value组。计算得到的<span class="math inline">\(Z_i\)</span>形状为<span class="math inline">\([b,s, d_{head}]\)</span></p><ol start="5" type="1"><li><strong>输出计算</strong>：拼接所有注意力头计算的结果<span class="math inline">\(Z_i\)</span>会被拼接： <span class="math display">\[Z=[Z_1, Z_2, ..., Z_h]W_O\]</span> 其中，<span class="math inline">\(W_O\)</span>是输出投影矩阵，最终得到形状为<span class="math inline">\([b, s, d]\)</span>的输出。</li></ol><p>GQA代码实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GQA</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, d_model, num_heads, num_groups</span>):</span><br><span class="line">        <span class="built_in">super</span>(GQA, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="keyword">assert</span> num_heads % num_groups == <span class="number">0</span>, <span class="string">&quot;Heads should be evenly divisible by groups&quot;</span></span><br><span class="line">        <span class="variable language_">self</span>.num_heads = num_heads</span><br><span class="line">        <span class="variable language_">self</span>.num_groups = num_groups</span><br><span class="line">        <span class="variable language_">self</span>.d_model = d_model</span><br><span class="line">        <span class="variable language_">self</span>.d_head = d_model // num_heads</span><br><span class="line">        <span class="variable language_">self</span>.d_group = d_model // num_groups  <span class="comment"># Key-Value 分组维度</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Query 仍然是独立的</span></span><br><span class="line">        <span class="variable language_">self</span>.W_q = nn.Linear(d_model, d_model, bias=<span class="literal">False</span>)</span><br><span class="line">        <span class="comment"># Key 和 Value 共享</span></span><br><span class="line">        <span class="variable language_">self</span>.W_k = nn.Linear(d_model, d_model // num_groups * num_heads, bias=<span class="literal">False</span>)</span><br><span class="line">        <span class="variable language_">self</span>.W_v = nn.Linear(d_model, d_model // num_groups * num_heads, bias=<span class="literal">False</span>)</span><br><span class="line">        <span class="variable language_">self</span>.W_o = nn.Linear(d_model, d_model, bias=<span class="literal">False</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        batch_size, seq_len, _ = x.shape</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算 Query, Key, Value</span></span><br><span class="line">        Q = <span class="variable language_">self</span>.W_q(x).view(batch_size, seq_len, <span class="variable language_">self</span>.num_heads, <span class="variable language_">self</span>.d_head)</span><br><span class="line">        K = <span class="variable language_">self</span>.W_k(x).view(batch_size, seq_len, <span class="variable language_">self</span>.num_groups, <span class="variable language_">self</span>.d_group)</span><br><span class="line">        V = <span class="variable language_">self</span>.W_v(x).view(batch_size, seq_len, <span class="variable language_">self</span>.num_groups, <span class="variable language_">self</span>.d_group)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算注意力分数</span></span><br><span class="line">        attention_scores = torch.einsum(<span class="string">&quot;bqhd,bkgd-&gt;bhqk&quot;</span>, Q, K) / (<span class="variable language_">self</span>.d_group ** <span class="number">0.5</span>)</span><br><span class="line">        attention_weights = torch.softmax(attention_scores, dim=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算注意力加权值</span></span><br><span class="line">        Z = torch.einsum(<span class="string">&quot;bhqk,bkgd-&gt;bqhd&quot;</span>, attention_weights, V)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 重新 reshape 并输出</span></span><br><span class="line">        Z = Z.reshape(batch_size, seq_len, <span class="variable language_">self</span>.d_model)</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.W_o(Z)</span><br></pre></td></tr></table></figure><p>MHA，MLA，MQA对比：</p><p><img src="/posts/1e6a04d4/image-33.png"></p><p>在MHA下，对于所有输入批次和序列中的每个token，KV Cache的总大小为：<span class="math display">\[2\times b\times l\times h\times d\times n\]</span> 其中，<span class="math inline">\(b\)</span>为batchsize，<span class="math inline">\(l\)</span>为总序列长度（输入+输出序列），<span class="math inline">\(h\)</span>为注意力头数量，<span class="math inline">\(d\)</span>为每个head的维度，<span class="math inline">\(n\)</span>为层数。</p><p><img src="/posts/1e6a04d4/image-34.png"></p><p>上图中，<span class="math inline">\(g\)</span>为KV头的组数。当<span class="math inline">\(g=h\)</span>时是MLA；当<span class="math inline">\(g=1\)</span>时是MQA；当<span class="math inline">\(1&lt;g&lt;h\)</span>时，只将KV Cache压缩到<span class="math inline">\(\frac{g}{h}\)</span>。</p><p>GQA和MQA的性能收益主要来源于KVCache的减少，支持放入更多tokens；但GQA和MQA的性能容易受到并行策略的影响。</p><p><strong>GQA和MQA的瓶颈主要在于加载 KV</strong>。如果GQA kernel在Qhead维度上做并行（一个Q head对应一个block），则会导致共享一个KVhead的block被调度在不同的SM上，每个SM 都会对同一份KV head做重复加载。则内存减少的收益会大大降低。因此需要减少Q head的并行度。</p><blockquote><p>在llama2/3-70B中，GQA中<span class="math inline">\(g=8\)</span>，其他用了GQA的同体量模型基本上也保持了这个设置，这是出于对推理效率的考虑。70B体量的模型，如果不进行极端的量化，不可能部署到单卡（A100/H10080G）上；一般情况下一台机可以装8张卡，而Attention的每个Head实际上是独立运算然后拼接起来的，因此，正好可以<strong>每张卡负责计算一组K、V对应的AttentionHead</strong>。这样可以在尽可能保证K、V多样性的同时最大程度上减少卡间通信。</p></blockquote><h2 id="参考">参考</h2><p><a href="http://nlp.seas.harvard.edu/annotated-transformer/">TheAnnotated Transformer</a></p><p><a href="https://arxiv.org/abs/2406.09297">MLKV: Multi-LayerKey-Value Heads for Memory Efficient Transformer Decoding</a></p><p><a href="https://arxiv.org/abs/2302.14017">Full Stack Optimization ofTransformer Inference: a Survey</a></p><p><a href="https://arxiv.org/abs/1911.02150">Fast Transformer Decoding:One Write-Head is All You Need</a></p><p><a href="https://arxiv.org/abs/2211.05102">Efficiently ScalingTransformer Inference</a></p><p><a href="https://www.zhihu.com/column/c_1889336819960743598">探秘Transformer系列之（27）---MQA &amp; GQA</a></p><p><a href="https://zhuanlan.zhihu.com/p/700588653">缓存与效果的极限拉扯：从MHA、MQA、GQA到MLA</a></p>]]></content>
      
      
      <categories>
          
          <category> Transformer </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Transformer系列：1. 从RNN到Transformer</title>
      <link href="/posts/42e930ef.html"/>
      <url>/posts/42e930ef.html</url>
      
        <content type="html"><![CDATA[<p>场景：</p><ul><li>图像信息：任务为理解图像内容，采用卷积神经网络；</li><li><strong>序列信息</strong>：任务为理解语音/文字/视频，采用<strong>循环神经网络</strong>。</li></ul><p>对于序列信息，由于按时序输入的数据之间非独立，<strong>前后数据之间具备相关性</strong>，因此网络需要存储信息的能力。</p><h2 id="rnn">RNN</h2><h3 id="网络结构">网络结构</h3><ul><li><p>RNN通过使用<strong>带自反馈的神经元</strong>，能够处理<strong>任意长度的序列</strong></p></li><li><p><img src="/posts/42e930ef/image-18.png"></p></li><li><p><strong>时序</strong>sequence：RNN能建模序列数据，序列指的是前、后输入数据<span class="math inline">\((x^{(t)},x^{(t+1)})\)</span>不独立，相互影响；</p></li><li><p><strong>循环</strong>recurrent：<strong>对每个输入的操作都是一样的</strong>，循环往复地重复这些相同操作，<strong>每时刻有相同参数W和U（参数共享）</strong>；</p></li><li><p><strong>记忆</strong>memory： 隐藏层<span class="math inline">\(h_{(t)}\)</span>中捕捉了所有时刻t之前的信息，理论上<span class="math inline">\(h_{(t)}\)</span>记忆的内容可以无限长，然而实际上记忆还是有限的；</p></li></ul><h3 id="正向计算">正向计算</h3><p><img src="/posts/42e930ef/image-19.png"></p><h3 id="反向传播bptt">反向传播BPTT</h3><p><img src="/posts/42e930ef/image-20.png"></p><h3 id="梯度消失-梯度爆炸">梯度消失 / 梯度爆炸</h3><p>循环神经网络的<strong>递归结构</strong>，导致梯度消失/梯度爆炸现象更明显</p><p>梯度爆炸：可采用梯度截断解决</p><p><strong>由于梯度消失，RNN无法处理长期依赖关系。</strong></p><blockquote><p>比如，考虑一个语言模型，试图根据之前单词预测下一个；</p><p>如果要预测“The clouds are in thesky”中最后一个单词，不需要更多的上下文即可知道下一个单词会是“sky”。在这种情况下，相关信息与预测位置的间隔比较小，RNNs可以学会使用之前的信息；</p><p>考虑试图预测“I grew up in <strong>Italy</strong>… I speak fluentItalian.”中最后一个，则需要用到包含“Italy”的上下文，从前面的信息推断后面的单词。相关信息与预测位置的间隔可能会很大。随着这种间隔的拉长，RNNs就会无法学习连接信息。</p></blockquote><h3 id="发展历程">发展历程</h3><p>Simple RNN -&gt; Contextualize RNN -&gt; Contextualized RNN withattention -&gt; Transformer(2017)</p><h4 id="simple-rnn">Simple RNN</h4><p><img src="/posts/42e930ef/image-21.png"></p><blockquote><p><strong>RNN Encoder-Decoder</strong>：</p><p>出现背景：传统RNN架构仅适用于输入输出等长的任务；RNNEncoder-Decoder使用一个<strong>定长状态机</strong>作为输入输出桥梁，以实现对<strong>输入输出都是变长序列</strong>的处理。</p><p><img src="/posts/42e930ef/image-22.png"></p><p>处理过程：</p><ul><li><strong>Encoder</strong>：</li></ul><ol type="1"><li><strong>逐个读取</strong>输入序列的token，计算隐状态：</li></ol><p><span class="math display">\[h_{&lt;t&gt;}=f(h_{&lt;t-1&gt;}, x_t)\]</span></p><ol start="2" type="1"><li>从输入序列的第二个token开始，Encoder每个时刻的输入包括：<strong>上一个时刻的隐状态+当前token</strong></li><li>Encoder最后一个时刻的隐状态为：一个固定长度的高维特征向量<strong><span class="math inline">\(C=(z_1, ...,z_T)\)</span>，编码了整个输入序列的语义上下文</strong>。</li></ol><ul><li><strong>Decoder</strong>：通过给定的隐状态<span class="math inline">\(h_{&lt;t&gt;}\)</span>，预测下一个token <span class="math inline">\(y_t\)</span>，最后生成输出序列。</li></ul><ol type="1"><li><p>计算当前时间<span class="math inline">\(t\)</span>时的隐状态：<span class="math display">\[h_{&lt;t&gt;}=f(h_{&lt;t-1&gt;}, y_{t-1}, c)\]</span></p></li><li><p>下一个token的条件概率分布为： <span class="math display">\[P(y_t|y_{t-1}, y_{t-2}, ..., y_1, c)=g(h_{&lt;t-1&gt;}, y_{t-1}, c)\]</span></p></li></ol><p>Encoder-Decoder联合训练，最大化条件对数似然函数： <span class="math display">\[\max\limits_{\theta} \frac{1}{N}\sum_{n=1}^{N}\log p_{\theta}(y_n|x_n)\]</span> 其中，<span class="math inline">\(\theta\)</span>为模型参数的集合，每个<span class="math inline">\((x_n,y_n)\)</span>是训练集中的（输入序列，输出序列）对。</p></blockquote><p>思想：<strong>将长序列的上下文，压缩到一个较小的状态中</strong></p><p>有两个问题：</p><ol type="1"><li><strong>encoder将整个源端序列（不论长度）压缩为一个固定维度的向量（encoderoutput）</strong>：并且这个向量中包含的信息中，关于源端序列末尾的token的信息更多，因此<strong>如果序列很长，最终可能基本上“遗忘”了序列开头的token的信息</strong>；</li><li><strong>随着decoder timestep的信息的增加，initial hiddenstates中包含的encoderoutput相关信息也会衰减</strong>：decoder会逐渐“遗忘”源端序列的信息，而更多地关注目标序列中在该timestep之前的token的信息。</li></ol><h4 id="contextualized-rnn">Contextualized RNN</h4><p>为了解决上述第2个问题：encoder output随着decodertimestep增加而信息衰减。提出以下模型：</p><p><strong>decoder在每个timestep的input上都会加上一个context</strong>：在decoder的每一步，都把源端的整个句子的信息和target端当前的token一起输入到RNN中，防止源端的context信息随着timestep的增长而衰减。</p><p><img src="/posts/42e930ef/image-23.png"></p><p>但是还有一个问题：<strong>context对于每个timestep都是静态的</strong>(encoder端的finalhiddenstates，或者是所有timestep的output的平均值)。但是每个decoder端的token在解码时，用到的context真的应该是一样的吗？</p><h4 id="contextualized-rnn-with-soft-align-attention">Contextualized RNNwith soft align (Attention)</h4><p><img src="/posts/42e930ef/image-24.png"></p><h3 id="rnn的优缺点">RNN的优缺点</h3><p>RNN优点如下：</p><ol type="1"><li><strong>权重共享</strong>：<strong>不同的timestep采用相同的权重</strong>，可以减少模型参数量，降低过拟合风险；</li><li><strong>速度快</strong>：Encoder每个时刻的输入仅依赖于上一个隐状态和当前token，Decoder通过给定的隐状态预测下一个token，因此<strong>所有token推理消耗基本相同</strong>；<strong>整体推理速度和context长度线形相关</strong>。</li></ol><p>RNN缺点如下：</p><ol type="1"><li><p><strong>表达能力缺失</strong>：</p><ul><li><strong>有损压缩，隐状态长度固定</strong>：隐向量保存context能力有限；</li><li><strong>RNN偏序</strong>：整个语序并不完全满足偏序结构，通常有定语后置、补语和各种从句等附加方式，因此RNN处理长距离关联复杂语法结构的能力有限；</li><li><strong>Decoder解码时，每个timestep的隐状态来源于Encoder生成的同一个隐向量</strong>：不同位置的单词可能需要不同程度和不同方面的信息；</li><li><strong>权重共享</strong>：对输入中的每个单词赋予同样权重，无法对单词的重要程度进行区分。</li></ul></li><li><p><strong>信息遗失</strong>：</p><ul><li><strong>序列早期部分的记忆，随着距离的增加产生传播衰减</strong>；</li><li><strong>难以捕捉过长距离依赖关系</strong></li></ul></li><li><p><strong>难以并行</strong>：RNN需要对序列内容进行逐步处理，每一步的输出取决于先前的隐状态和当前输入。RNN的串行计算阻碍了训练时的并行计算，导致训练效率较低，训练时间过长。</p></li><li><p><strong>难以训练</strong>：RNN用于信息传输通路只有一条，并且该通路上的计算包含多次非线性激活操作；当RNN处理长序列时，因为timestep增加带来的多层激活函数的嵌套，将导致梯度反传时指数级地消失或爆炸。</p><ul><li>梯度消失：前面的梯度信息无法有效地传递到后面，所以RNN网络难以学习远距离依赖关系；</li><li>梯度爆炸：网络的权重会变得极大，导致网络不稳定；</li></ul><p>当面对长序列时，RNN需要大量内存来维持长序列的隐状态，比如需要完整理解整个句子乃至整篇文章才能做出判断，这些内存负担对训练也造成了很大挑战。</p></li></ol><h2 id="长短期记忆模型lstm">长短期记忆模型（LSTM）</h2><p><img src="/posts/42e930ef/image-25.png"> <img src="/posts/42e930ef/image-26.png"> <img src="/posts/42e930ef/image-27.png"></p><h2 id="transformer">Transformer</h2><h3 id="通用结构">通用结构</h3><ul><li><p><strong>特征模型</strong>：假设矩阵X为任务模型的输入，矩阵的列可能是句子之中的单词。任务模型使用特征模型把X转换为特征向量F。特征模型可能是<strong>RNN、CNN、嵌入层或者其他模型</strong>；</p></li><li><p><strong>查询模型</strong>：q是查询向量，用来确定任务模型需要关注X中的哪些向量、提取哪些信息。或者说，q可以被解释为一个一般问题：<strong>哪个特征向量包含对q最重要的信息?</strong></p></li><li><p><strong>注意力模型</strong>：<strong>输入</strong>为<strong>特征向量F</strong>和<strong>查询向量q</strong>，<strong>输出</strong>是<strong>上下文向量c</strong>；</p></li><li><p><strong>输出模型</strong>：使用上下文向量c，将各个部分组合成最终的高级特征向量y（例如输出模型可以是softmax层，输出一个预测）</p></li></ul><figure><img src="https://github.com/user-attachments/assets/bb2b2db9-50d3-4a5c-ba33-d8a1c434f085" alt="image"><figcaption aria-hidden="true">image</figcaption></figure><h3 id="注意力模型">注意力模型</h3><ol type="1"><li>从输入生成的<strong>特征向量F</strong>开始：生成<strong>键矩阵K，值矩阵V</strong>；</li><li>使用矩阵K和查询向量q作为输入：计算<strong>注意力得分向量e</strong>；q表示对信息的请求，<span class="math inline">\(e_l\)</span>表示矩阵K的第<span class="math inline">\(l\)</span>列对于q的重要性；</li><li>通过对齐层（比如softmax函数）进一步处理注意力分数，进而得到<strong>注意力权重a</strong>；</li><li>利用注意力权重a和值矩阵V进行计算：得到<strong>上下文向量c</strong>。</li></ol><blockquote><p>QKV的形象理解：</p><ul><li>Q：<strong>目标序列</strong>的<strong>每个token将自己关注的信息</strong>总结到一个向量query之中，向其它token发出询问。目标序列所有token的query构成了查询矩阵Q；</li><li>K：<strong>源序列</strong>的<strong>每个token将自己的特征</strong>总结到一个向量key之中，根据该特征回答其他token的询问。目标序列所有token的key构成了键矩阵K；</li><li>V：<strong>源序列</strong>的<strong>每个token的实际值（最终提供的信息）</strong>是向量value。源序列所有token的value构成了值矩阵V。</li></ul><p>在查找中，目标序列中每个token用自己的query，去和源序列每个token的key计算得到<strong>对齐系数</strong>，代表token之间的相似度或者相关性：<strong>query和key越相似，就代表value对query的影响力越大，query越需要吸收value的信息</strong>。随后query会根据两个词之间的亲密关系，来决定从V中提取出多少信息出来融入到自身。</p></blockquote><p><img src="/posts/42e930ef/image-29.png"></p><h3 id="计算流程">计算流程</h3><ol type="1"><li><strong>生成隐状态向量</strong>：源序列依次输入Encoder，<strong>对于每个输入token，Encoder输出一个对应的隐状态向量，表示当前token及其context</strong>；</li><li><strong>计算对齐系数a</strong>：在Decoder输出每一个预测值<span class="math inline">\(y\)</span>之前，运用Encoder输出的所有隐状态向量计算注意力分数a；（反映：<strong>源序列的所有token，和目标序列当前token的相关性大小</strong>）</li><li><strong>计算概率分布</strong>：<strong>注意力分数a进行softmax归一化，得到注意力权重w</strong>，表示：<strong>每个输入token对当前输出token的重要程度</strong>（softmax：放大高分隐藏状态，抑制低分隐藏状态）</li><li><strong>计算当前时刻的context</strong>：使用注意力权重w对Encoder所有隐状态向量加权求和，得到<strong>Decoder当前时刻的上下文语义向量Context</strong>，表示：<strong>当前输出token所需的源语言信息</strong>；</li><li><strong>更新Decoder的隐状态</strong>；</li><li>Decoder计算输出预测token：<strong>输入为Decoder前一次的输出、Decoder当前状态和Decoder当前时刻的Context</strong>，输出为一个概率分布，表示：<strong>每个可能的token作为当前输出的概率</strong>。</li></ol><p><img src="/posts/42e930ef/image-30.png"></p><h3 id="思想">思想</h3><ol type="1"><li><p><strong>增大信息含量</strong>：</p><p><img src="/posts/42e930ef/image-31.png"></p><ul><li><strong>RNN</strong>：Decoder将所有context压缩到一个固定大小隐向量，不同阶段均使用相同的隐向量。上下文较长时，表达能力有限；</li><li><strong>TTT</strong>：context压缩到模型权重中，增强了表达能力；</li><li><strong>self-attention</strong>：使用一个列表（<strong>KVCache</strong>）存储所有context，<strong>无压缩</strong>。不像RNN只传递一个Decoder最终的隐状态，而是<strong>传入所新token就可以和过去所有context进行交互</strong>。</li></ul></li><li><p><strong>缩短token间距</strong>：任意两个token之间<strong>建立了distance= 1的平行关系，从而解决RNN的长路径依赖问题(distance =N)</strong>，平等地看待每一个token，无前后偏好；取消RNN的递归限制，支持并行。</p></li><li><p><strong>动态生成权重</strong>：CNN/全连接层使用静态权重，在训练时候固定，在推理时<strong>注意力机制使用动态权重，由输入的query、key通过相似度计算而得</strong>，是一种自适应操作。</p></li><li><p><strong>对齐</strong>：注意力机制应用在序列转换的源序列和目标序列之间。</p></li><li><p><strong>双向context融合</strong>：可以同时从左到右和从右到左读取输入序列，并将每个时间步的隐状态拼接起来作为输出；允许Encoder同时考虑输入序列中，每个单词的前后上下文信息。（在此之前只有BiLSTM，但是其本质只是两个单向建模的叠加，而不是Transformer这种彻底的context融合）</p></li></ol><h3 id="不足">不足</h3><ol type="1"><li><strong>算力需求大</strong>：需要计算序列中每个token对其他每个token的关系，因此<strong>计算量随输入序列长度的增加，呈平方级增长</strong>。这限制了LLM的最大序列长度N的大小；RNN只要考虑之前的隐状态和当前输入。</li><li><strong>内存消耗大</strong>：KV Cache</li></ol><h2 id="参考">参考</h2><p><a href="https://arxiv.org/abs/1406.1078">Learning PhraseRepresentations using RNN Encoder-Decoder for Statistical MachineTranslation</a></p><p><a href="https://arxiv.org/abs/2203.14263">A General Survey onAttention Mechanisms in Deep Learning</a></p><p><a href="https://arxiv.org/abs/2407.04620">Learning to (Learn at TestTime): RNNs with Expressive Hidden States</a></p><p><a href="https://zhuanlan.zhihu.com/p/104393915">【经典精读】万字长文解读Transformer模型和Attention机制</a></p><p><a href="https://blog.csdn.net/weixin_42110638/article/details/134016569">一文搞定自注意力机制（Self-Attention）</a></p><p><a href="https://zhuanlan.zhihu.com/p/22502842848">探秘Transformer系列之（1）：注意力机制</a></p>]]></content>
      
      
      <categories>
          
          <category> Transformer </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Transformer的KV Cache</title>
      <link href="/posts/76aa9d6e.html"/>
      <url>/posts/76aa9d6e.html</url>
      
        <content type="html"><![CDATA[<h2 id="problems">Problems</h2><p>对于LLMs，每次矩阵乘法都由若干个浮点运算组成，因此其性能受限于GPU的FLOPS；随着输入的token长度增加，<strong>Transformer的自注意力机制与输入序列长度呈平方关系增长</strong>，产生最大的延迟开销。</p><p>为了解决推理延迟和吞吐量问题，当前的大模型服务系统通常采用KVCache：通过缓存已计算的Key和Value矩阵，以避免在解码阶段重复计算键和值的投影（空间换时间）。然而在以下场景中KVCache占用内存较大，影响推理性能：</p><ol type="1"><li>处理长序列或多轮对话；</li><li>对于多个客户端请求，每个请求分别保留各自的KV Cache。</li></ol><p>KVCache的核心问题在于：占用大量内存和访存带宽；在生成阶段引入大量重复计算。本篇博客探讨KVCache压缩技术。</p><h2 id="backgrounds">Backgrounds</h2><p>推理加速的衡量指标如下：</p><ol type="1"><li><strong>吞吐量</strong>：每生成一个token，服务商需要支付的算力成本。可以通过<strong>tokenspersecond(tps)</strong>衡量，即推理服务器单位时间内能处理针对所有用户和请求生成的输出token数。</li><li><strong>延迟</strong>：包括两个指标：<ul><li><strong>TTFT（Time To FirstToken）</strong>：在用户输入查询的内容后，<strong>模型生成第一个输出token所需的时间</strong>。</li><li><strong>TPOT（Time Per OutputToken）</strong>：<strong>单个输出token的生成时间</strong>，即：总生成时间/总生成token数。</li><li>额外：<strong>TBT（Token之间的时间）</strong>：两个token生成间的延迟。</li></ul></li></ol><p><strong>prefill阶段</strong>：负责处理输入prompt的完整内容，计算量大、并行性高，生成第一个token，因此主要使用<strong>TTFT</strong>衡量；</p><p><strong>decode阶段</strong>：通过自回归方式，逐个生成后续的token，尽管单步计算量小，但生成每个新token都需要反复访问之前生成的所有token对应的KVCache。主要使用<strong>TBT/TPOT</strong>衡量。</p><p>下图展示了推理过程中，KV Cache对显存的占用情况：</p><p><img src="/posts/76aa9d6e/image-29.png"></p><h2 id="parameter-analysis-of-transformer">Parameter Analysis ofTransformer</h2><p>当前主流的LLMs均基于transformer模型，按模型结构可划分为两大类：encoder-decoder和decoder-only。<strong>decoder-only</strong>结构又可以分为<strong>CausalLM</strong>（代表模型是GPT系列）和<strong>PrefixLM</strong>（代表模型是GLM）。这里分析decoder-only框架transformer模型的模型参数量、计算量、中间激活值、KVcache。</p><blockquote><p>为什么现在的LLMs基本采用Decoder-Only结构呢？</p><ul><li>相同参数量的训练效率：Decoder-Only &gt; Encoder-Only &gt;Encoder-Decoder</li><li>现行分布式并行策略下，可扩展的<strong>参数量上限</strong>和<strong>分布式集群规模上限</strong>：Decoder-Only,Encoder-Only &gt;&gt; Encoder-Decoder</li></ul><p><strong>PipelineParallelism</strong>是模型参数达到千亿、集群扩展到千卡以上时<strong>最重要的特性</strong>。为什么呢？</p><p>流水并行的核心优势是：用较少的 Pipeline Bubble 代价 （当 gradientaccumulation step 很大时可以忽略不计），较少的 Tensor Buffer显存代价，以及非常低的通信开销，将大模型的不同层拆分到不同节点上。大幅减少了单张 GPU 上的 weight tensor 大小（数量） 和 Activation tensor大小（数量）。</p><ul><li>与TP相比：<strong>对于大型模型（如70B+），仅仅模型权重的大小就足以超出单节点上4-8个GPU的限制</strong>；然而<strong>当尝试将TP扩展到超出单节点内GPU数量（通常为4或8）时，性能会受到一个低带宽网络——“节点间连接”的强烈影响</strong>。即极高的通信频率和通信量使得TP只能在机器内8 张卡用 NVLink 等高速互联来实现，跨机的 TP 会严重拖慢速度。</li><li>与DP相比：DP 所需的 AllReduce 通信会随着机器数量增多而变慢；但PP将DP的模型更新限定在一个很小的范围内（比如六台机器）， 同时PP 也让DP所需同步的模型梯度大小变小了，大大减缓了模型更新对于训练速度的影响。</li></ul><p>然而，PP有一个重要约束条件：<strong>需要一个规整对称的、线性顺序的网络结构。</strong></p><ul><li>GPT 就是这样一个典型的网络结构： 完全一样的 Transformer Layer顺序堆叠，没有分叉和不对称情况，当均匀切分 Layer 时，各个 Stage的前向/反向计算时间均一致。</li><li>T5 是 Encoder-Decoder 架构：整个网络分为两大块，且 Encoder 和Decoder 的 Transformer Layer 参数大小、Attention 计算量、Context Length等均不一致；另外， T5 Encoder 的输出要发给每个 DecoderLayer，<strong>导致流水并行中，各个 Stage之间会产生大量的、非对称的、间隔跨多个 Stage的数据依赖</strong>,更加剧了流水并行的 load balance 问题。</li></ul></blockquote><p>假设：Transformer模型层数为<span class="math inline">\(l\)</span>，隐藏层维度为<span class="math inline">\(h\)</span>，注意力头数为<span class="math inline">\(a\)</span>；词表大小为<span class="math inline">\(V\)</span>，训练数据的批次大小为<span class="math inline">\(b\)</span>，序列长度为<span class="math inline">\(s\)</span>。</p><h3 id="参数量估计">参数量估计</h3><p>Transformer模型由<span class="math inline">\(l\)</span>个相同的层组成，每个层分为两个部分：<strong>self-attention模块</strong>和<strong>MLP模块</strong>。</p><ol type="1"><li><strong>self-attention模块</strong>：模型参数包括<span class="math inline">\(Q, K, V\)</span>的权重矩阵<span class="math inline">\(W_Q, W_K, W_V\)</span>和偏置，以及输出矩阵<span class="math inline">\(W_O\)</span>和偏置。其中，4个权重矩阵形状为<span class="math inline">\([h, h]\)</span>，4个偏置形状为<span class="math inline">\([h]\)</span>。self-attention块的参数量为：<strong><span class="math inline">\(4h^2+4h\)</span></strong>.</li><li><strong>MLP模块</strong>：包含2个线性层，第一个先将维度从<span class="math inline">\(h\)</span>映射到<span class="math inline">\(4h\)</span>，权重矩阵<span class="math inline">\(W_1\)</span>形状为<span class="math inline">\([h,4h]\)</span>，偏置形状为<span class="math inline">\([4h]\)</span>；第二个将维度从<span class="math inline">\(4h\)</span>映射到<span class="math inline">\(h\)</span>，权重矩阵<span class="math inline">\(W_2\)</span>形状为<span class="math inline">\([4h,h]\)</span>，偏置形状为<span class="math inline">\([h]\)</span>。MLP块的参数量为：<strong><span class="math inline">\(8h^2+5h\)</span></strong>.</li></ol><p>self-attention块和MLP块各有1个<strong>LayerNorm</strong>，包含2个可训练模型参数：缩放参数<span class="math inline">\(\gamma\)</span>和平移参数<span class="math inline">\(\beta\)</span>，形状都是<span class="math inline">\([h]\)</span>；参数量共为<span class="math inline">\(4h\)</span>.</p><p>因此，<strong>每个transformer层的参数量为<span class="math inline">\(12h^2+13h\)</span></strong>.</p><p>词向量维度通常等于隐藏层维度<span class="math inline">\(h\)</span>，因此<strong>词嵌入矩阵的参数量为<span class="math inline">\(Vh\)</span></strong>.</p><h4 id="training显存占用">Training显存占用</h4><p>显存占用主要包括4个部分：<strong>模型参数</strong>，前向计算产生的<strong>激活值</strong>，反向传播计算得到的<strong>梯度</strong>，<strong>优化器状态</strong>。训练时常常采用Adam优化器。</p><p>传统FP32训练中，每个参数对应1个梯度（4字节）和2个优化器状态（动量和方差，各4字节）。因此共<span class="math inline">\(4*N+4*N+(4+4)*N=16*N\)</span>.</p><p>若使用高低混合精度训练，则：使用BF16进行大部分计算（每个参数、梯度分别需要2字节），额外复制一份模型权重和梯度为FP32；因此每个参数总共需要 12 字节。总参数量为<span class="math inline">\(2*N+2*N+4*N+4*N+(4+4)*N=20*N\)</span>.</p><h4 id="inference显存占用">Inference显存占用</h4><p>推理阶段没有梯度和优化器状态，也无需保存中间激活值。因此显存占用主要来源是<strong>模型参数</strong>。</p><p>如果使用BF16推理，显存占用为<span class="math inline">\(2N\)</span>；如果采用KVCache加速推理，需要额外占用显存，下文详细分析。</p><h3 id="计算量flops估计">计算量FLOPs估计</h3><p>假设输入数据的形状为<span class="math inline">\([b, s]\)</span>.</p><ol type="1"><li><strong>self-attention模块</strong>： <span class="math display">\[Q=xW_Q, K=xW_K, V=xW_V \\x_{out}=softmax(\frac{QK^T}{\sqrt{h}})·V·W_{o}+x\]</span><ul><li>计算<span class="math inline">\(Q, K, V\)</span>：矩阵乘法为<span class="math inline">\([b,s,h]\times[h,h]\rightarrow[b,s,h]\)</span>，计算量为<span class="math inline">\(2*2bsh^2=6bsh^2\)</span>.</li><li><span class="math inline">\(QK^T\)</span>：矩阵乘法为<span class="math inline">\([b,headnum,s,perheadhiddensize]\times[b,headnum,perheadhiddensize,s]\rightarrow[b,headnum,s,s]\)</span>，计算量为：<span class="math inline">\(2bs^2h\)</span>.</li><li>计算在<span class="math inline">\(V\)</span>上的加权<span class="math inline">\(score·V\)</span>：矩阵乘法为<span class="math inline">\([b,headnum,s,s]\times[b,headnum,s,perheadhiddensize]\rightarrow[b,headnum,s,perheadhiddensize]\)</span>，计算量为：<span class="math inline">\(2bs^2h\)</span>.</li><li>attention后的线形映射：矩阵乘法为<span class="math inline">\([b,s,h]\times[h,h]\rightarrow[b,s,h]\)</span>，计算量为<span class="math inline">\(2bsh^2\)</span>.</li></ul></li><li><strong>MLP模块</strong>： <span class="math display">\[s=f_{gelu}(x_{out}W_1)W_2+x_{out}\]</span><ul><li>第一个线形层：<span class="math inline">\([b,s,h]\times[h,4h]\rightarrow[b,s,4h]\)</span>，计算量为<span class="math inline">\(8bsh^2\)</span>.</li><li>第二个线形层：<span class="math inline">\([b,s,4h]\times[4h,h]\rightarrow[b,s,h]\)</span>，计算量为<span class="math inline">\(8bsh^2\)</span>.</li></ul></li></ol><p>将上述计算量累加，得到：**每个transformer层的计算量为<span class="math inline">\(24bsh^2+4bs^2h\)</span>.</p><p>logits计算：将隐藏向量映射为词表大小，矩阵乘法为：<span class="math inline">\([b,s,h]\times[h,V]\rightarrow[b,s,V]\)</span>，计算量为<span class="math inline">\(2bshV\)</span>.</p><p>综上，<strong>对于一个<span class="math inline">\(l\)</span>层的Transformer模型，若输入形状为<span class="math inline">\([b,s]\)</span>，一次训练迭代的计算量为<span class="math inline">\(l*(24bsh^2+4bs^2h)+2bshV\)</span></strong>.</p><h4 id="计算量与参数量的关联">计算量与参数量的关联</h4><p>当隐藏层维度<span class="math inline">\(h\)</span>&gt;&gt;序列长度<span class="math inline">\(s\)</span>时：计算量近似为<span class="math inline">\(24bsh^2*l\)</span>（模型参数量为12lh^2<span class="math inline">\(，输入tokens数为\)</span>b*s$）。可近似认为：<strong>在一次前向计算中，对于每个token，每个模型参数需要进行2次浮点数运算（1次加法+1次乘法）</strong>；</p><p><strong>反向传播的计算量是前向传播的2倍</strong>，也即：<strong>1次训练迭代中，对于每个token，每个模型参数需要<span class="math inline">\(2*3=6\)</span>次浮点数计算</strong>。</p><p>如果采用<strong>激活值重计算</strong>以减小中间激活显存，需要一次额外的前向传递，那么：在一次训练迭代中，对于每个token，每个模型参数需要<span class="math inline">\(2*4=8\)</span>次浮点数计算。</p><h4 id="训练时间估计">训练时间估计</h4><p>给定<strong>训练tokens数、模型参数、训练硬件配置</strong>的情况下，训练transformer模型的计算时间为：<span class="math display">\[训练时间=\frac{8\times tokens数\times 模型参数量}{GPU数\timesGPU峰值FLOPs\times GPU利用率}\]</span></p><h3 id="中间激活值估计">中间激活值估计</h3><p>激活值：<strong>前向传播过程中计算，在后向传播中需要使用的全部张量</strong>。不包括模型参数和优化器状态，包括dropout所需的mask矩阵。</p><p>假设：中间激活值采用F16或BF16格式保存，每个元素占用2个字节。（dropout的mask矩阵例外，每个元素只占用1个字节）</p><ol type="1"><li><p><strong>self-attention模块</strong>：</p><ul><li><span class="math inline">\(Q, K, V\)</span>：需要保存共同输入<span class="math inline">\(x\)</span>，<span class="math inline">\(x\)</span>的形状为<span class="math inline">\([b,s,h]\)</span>，显存占用为<span class="math inline">\(2bsh\)</span>.</li><li><span class="math inline">\(QK^T\)</span>：需要保存中间激活<span class="math inline">\(Q,K\)</span>，<span class="math inline">\(Q,K\)</span>的形状均为<span class="math inline">\([b,s,h]\)</span>，显存占用为<span class="math inline">\(4bsh\)</span>.</li><li><span class="math inline">\(softmax\)</span>函数：保存输入<span class="math inline">\(QK^T\)</span>，若注意力头数为<span class="math inline">\(a\)</span>，<span class="math inline">\(QK^T\)</span>形状为<span class="math inline">\([b,a,s,s]\)</span>，显存占用为<span class="math inline">\(2bs^2a\)</span>.</li><li><strong>计算完<span class="math inline">\(softmax\)</span>函数后，进行dropout</strong>：<strong>需要保存一个mask矩阵</strong>，形状与<span class="math inline">\(QK^T\)</span>相同，显存占用为<span class="math inline">\(bs^2a\)</span>.</li><li>计算在<span class="math inline">\(V\)</span>伤的加权<span class="math inline">\(score·V\)</span>：需要保存<span class="math inline">\(score\)</span>，显存占用为<span class="math inline">\(2bs^2a\)</span>；需要保存<span class="math inline">\(V\)</span>，显存占用为<span class="math inline">\(2bsh\)</span>。合计显存占用为<span class="math inline">\(2bs^2a+2bsh\)</span>.</li><li>计算输出映射，进行dropout：保存输入映射<span class="math inline">\(2bsh\)</span>；dropout保存mask矩阵<span class="math inline">\(bsh\)</span>。合计显存占用为<span class="math inline">\(3bsh\)</span>.</li></ul><p>综上，self-attention模块中间激活值显存占用为：<span class="math inline">\(11bsh+5bs^2a\)</span>.</p></li><li><p><strong>MLP模块</strong>：</p><ul><li>第一个线形层：保存输入，显存占用为<span class="math inline">\(2bsh\)</span>；</li><li>激活函数：保存输入，显存占用为<span class="math inline">\(8bsh\)</span>；</li><li>第二个线形层：保存输入，显存占用为<span class="math inline">\(8bsh\)</span>；</li><li>dropout操作：保存mask矩阵，显存占用为<span class="math inline">\(bsh\)</span>.</li></ul><p>综上，MLP模块中间激活值显存占用为：<span class="math inline">\(19bsh\)</span>.</p></li></ol><p>Self-attention和MLP各对应一个LayerNorm，每个均需保存其输入，大小为<span class="math inline">\(2bsh\)</span>，总显存占用为<span class="math inline">\(4bsh\)</span>.</p><p>综上，<strong>对于<span class="math inline">\(l\)</span>层的transformer模型，中间激活值显存占用近似为<span class="math inline">\((34bsh+5bs^2a)l\)</span></strong>.</p><h4 id="对比模型参数和中间激活值的显存占用">对比：模型参数和中间激活值的显存占用</h4><p><strong>对于<span class="math inline">\(l\)</span>层的transformer模型：模型参数量为<span class="math inline">\((12h^2+13h)*l\)</span>；中间激活值为<span class="math inline">\((34bsh+5bs^2a)*l\)</span></strong>.</p><p>可以发现：模型参数显存占用量与输入数据大小无关；中间激活值显存占用<strong>与输入数据大小（批次大小b和序列长度s）成正相关</strong>。</p><p>随着批次增大或序列变长，中间激活值成为显存占用的主要来源。若采用<strong>激活重计算</strong>，理论上可将其显存占用从<span class="math inline">\(O(n)\)</span>降至<span class="math inline">\(O(\sqrt{n})\)</span>.</p><h2 id="kv-cache-for-inference">KV Cache for Inference</h2><p>由于每层decoderlayer的attention计算独立，因此每一层都需要单独缓存<span class="math inline">\(K,V\)</span>。代码中体现为：在<code>Attention</code>类中创建<span class="math inline">\(kv_cache\)</span>张量：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Attention</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, args: ModelArgs</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.args = args</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.cache_k = torch.zeros((args.max_batch_size, args.max_seq_len, <span class="variable language_">self</span>.n_kv_heads, <span class="variable language_">self</span>.head_dim), device=args.device)</span><br><span class="line">        <span class="variable language_">self</span>.cache_v = torch.zeros((args.max_batch_size, args.max_seq_len, <span class="variable language_">self</span>.n_kv_heads, <span class="variable language_">self</span>.head_dim), device=args.device)</span><br></pre></td></tr></table></figure><p><img src="/posts/76aa9d6e/image-30.png"></p><h3 id="prefill">prefill</h3><p><strong>prefill阶段</strong>：输入一个prompt序列，<strong>每个transformer层的MHA模块生成KV键值对并存储在KVCache中</strong>，最终生成第一个token，可采用并行计算加速。</p><p>用户输入prompt的token均需参与计算，因此<span class="math inline">\(Q\)</span>的形状为：<span class="math inline">\([b,s,h]\)</span>。</p><p>设输入到 Transformer 层的输入为 <span class="math inline">\(x_{pre}\in \mathbb{R}^{s\times h}\)</span>，其中<span class="math inline">\(h\)</span> 是隐藏维度，<span class="math inline">\(s\)</span> 是提示词 token 序列的长度。MHA 模块的<span class="math inline">\(4\)</span> 个线性层权重用 <span class="math inline">\(W_Q\)</span>，<span class="math inline">\(W_K\)</span>，<span class="math inline">\(W_V\)</span> 和 <span class="math inline">\(W_o\)</span>表示。查询、键和值（Q、K、V）的计算过程如下：</p><p><span class="math display">\[Q_{pre}=x_{pre}W_Q, K_{pre}=x_{pre}W_K, V_{pre}=x_{pre}W_V \\x_{out}=softmax(\frac{Q_{pre}K_{pre}^T}{\sqrt{h}})·V_{pre}·W_{o}+x_{pre}\]</span></p><p>生成的 <span class="math inline">\(K_{pre}\)</span> 和 <span class="math inline">\(V_{pre}\)</span> 被存储在 KV Cache中，每个transformer layer 都独立的存储 KV 键值对。</p><p>MHA 的输出 <span class="math inline">\(x_{out}\in \mathbb{R}^{s\timesh}\)</span> 将传递到 MLP。MLP 的输出作为下一个 Transformerlayer的输入。</p><h3 id="decode">decode</h3><p><strong>decode阶段</strong>：使用并更新 KVcache，<strong>逐个生成后续的token（无并行性），当前生成的token依赖于之前已经生成的所有tokens</strong>。该阶段的推理计算分两部分：<strong>更新KV cache</strong> 和<strong>计算 decoder layers 的输出</strong>。</p><p>只有新生成的 token 作为下一次迭代过程的输入，所以此时 <span class="math inline">\(Q\)</span> 的维度为 <span class="math inline">\([b, 1, h]\)</span>，即只有新 token 作为 Q。</p><ol type="1"><li>MHA加载先前存储的KVCache，计算新生成token对应的KV键值对，并拼接到原有KV Cache： <span class="math display">\[Q_{dec}=x_{dec}W_{Q} \\K_{cat}=[K_{cache }, x_{dec}W_{K}] \\V_{cat}=[V_{cache }, x_{dec}W_{V}]\]</span></li><li>MHA剩余计算： <span class="math display">\[x_{out}=softmax(\frac{Q_{cat}K_{pre}^T}{\sqrt{h}})·V_{cat}·W_{o}+x_{dec}\]</span> <img src="/posts/76aa9d6e/image-31.png"></li></ol><p>其中MHA的输出<span class="math inline">\(x_{out}\)</span>被传递到MLP；最后一个 Transformer 层的输出被发送到最终的预测层，以预测下一个token。</p><h3 id="kv-cache显存占用">KV Cache显存占用</h3><p>单轮对话的KV Cache优化在decode阶段应用，加入KVCache前后区别如下：</p><p>在B方案中，使用输出token替换查询嵌入中的输入token，且KVCache存储之前生成的 token。因此在计算attentionscore时，只需要使用一个查询token，再加上KV Cache中的已有 token就可以了，节省了矩阵乘法的计算量。在处理大规模序列和大批量数据时，显著降低计算开销。</p><p><img src="/posts/76aa9d6e/image-32.png"></p><p><strong>MHA模块中：生成单个token的KV键值对，矩阵计算开销为<span class="math inline">\(4*l*h^2\)</span></strong>.</p><p>假设输入序列的长度为<span class="math inline">\(s\)</span>，输出序列的长度为<span class="math inline">\(o\)</span>，decoder layer的层数为<span class="math inline">\(l\)</span>。若以F16保存KVCache，那么其峰值显存占用为： <span class="math display">\[2*2*l*h*b*(s+o)=4lhb(s+o)\]</span> 其中，第一个 <code>2</code> 表示 K/V cache，第二个<code>2</code>表示 float16 占 2 个 bytes.</p><h2 id="references">References</h2><p><a href="https://zhuanlan.zhihu.com/p/1889619251880494812">探秘Transformer系列之（20）---KV Cache</a></p><p><a href="https://www.zhihu.com/question/588325646/answer/3422090041">为什么现在的LLM都是Decoderonly的架构？ - 成诚的回答 - 知乎</a></p><p><a href="https://zhuanlan.zhihu.com/p/720230227">LLM参数量&amp;计算量- 唐旺的文章 - 知乎</a></p><p><a href="https://www.armcvai.cn/2024-11-01/kv-cache-optimize.html">kv-cache原理及优化概述</a></p><p><a href="https://mp.weixin.qq.com/s?__biz=MzAxOTU5NTU4MQ==&amp;mid=2247492972&amp;idx=1&amp;sn=f7e8d2952eac2f06cc3cd077cf597220&amp;chksm=9a61e9290e09c13596b2717aab8211534984736404c4868df46a76f94184907ac95c7e83d529&amp;mpshare=1&amp;scene=1&amp;srcid=0303h7gisstQrJCmywCfl8Ee&amp;sharer_shareinfo=238e76c6cd310aac8cdc2f870c2dff18&amp;sharer_shareinfo_first=238e76c6cd310aac8cdc2f870c2dff18#rd">图解KVCache：解锁LLM推理效率的关键</a></p>]]></content>
      
      
      <categories>
          
          <category> Transformer </category>
          
      </categories>
      
      
        <tags>
            
            <tag> KV Cache </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>verl框架：2. 对比OpenRLHF+colocate思路解析</title>
      <link href="/posts/2ac460b1.html"/>
      <url>/posts/2ac460b1.html</url>
      
        <content type="html"><![CDATA[<h2 id="spmd-mpmd">SPMD-&gt;MPMD</h2><p>SPMD设计范式：单程序多数据，<strong>所有进程/线程执行同一个程序的拷贝</strong>，通过环境变量差异自主确定行为模式，<strong>无需中心调度节点</strong>。主流并行框架（DDP/DeepSpeed/Megatron）均基于SPMD范式。</p><p>优点：SPMD由于没有controller，完全由worker自驱，在运行时更为高效；</p><p>缺点：由于各个worker上需要运行相同程序，灵活性不如single-controller模式；需要考虑各个rank之间的通信，增加编程复杂度。</p><p>经典代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(os.environ[<span class="string">&#x27;RANK&#x27;</span>], os.environ[<span class="string">&#x27;WORLD_SIZE&#x27;</span>], os.environ[<span class="string">&#x27;MASTER_ADDR&#x27;</span>], os.environ[<span class="string">&#x27;MASTER_PORT&#x27;</span>])</span><br><span class="line">torch.distributed.init_process_group(backend=<span class="string">&quot;nccl&quot;</span>)</span><br><span class="line">torch.cuda.set_device(torch.distributed.get_rank())</span><br></pre></td></tr></table></figure><ol type="1"><li><strong><code>torchrun</code>执行以上脚本，启动多个进程</strong>；每个进程不同的环境变量，标识其所属的机器号和端口号，以及进程号和进程总数。</li><li><strong><code>torch.distributed.init_process_group</code>根据环境变量构建通信组</strong>（一个阻塞操作，所有进程必须完成后才开始执行）</li><li><code>set_device</code>将当前进程绑定在一块GPU上。</li></ol><p>OpenRLHF SPMDppo的系统架构如下：<strong>PPOTrainer负责整个PPO算法的控制逻辑</strong>。此时，<strong>不同的模型在同一组卡和同一组进程上，按照不同的时间片运行SPMD</strong>。这些共享同一组计算资源并按时间交替使用的模型被称为<strong>colocatemodels</strong>。</p><p><img src="/posts/2ac460b1/image-18.png"></p><p>然而，SPMD要求不同的模型串行执行，即使没有数据依赖的模型也难以实现并发。如果模型不需要占用全部计算卡，就会导致部分计算资源的闲置；此外，SPMD需要将多个模型的参数同时加载到一张计算卡上，如果不结合offload等技术，很容易引发显存OOM问题。</p><p><img src="/posts/2ac460b1/image-19.png"></p><p>那么如何实现这一点呢？OpenRLHF的方案是：<strong>使用ray拉起</strong>。在Ray 的抽象下，各个模块都可以看成是独立的 multi-process training /generate，通过配置不同的placementgroup，从而使模块绑定到不同的卡上；模块之间的交互通过 Object Store 和Object Ref 做数据收发来实现。</p><h2 id="openrlhf的ray流程">OpenRLHF的Ray流程</h2><p>OpenRLHF与Ray相关的架构图如下：</p><p><img src="/posts/2ac460b1/image-20.png"></p><h3 id="driver-process">Driver Process</h3><ol type="1"><li>在<strong>Driver process中实例化多个<a href="https://github.com/OpenRLHF/OpenRLHF/blob/v0.5.9.post1/openrlhf/trainer/ray/launcher.py#L143">PPORayActorGroup</a></strong>：<strong>每一个Group 实例代表着一个PPO模块，包含1个Master Ray-Actor，多个WorkerRay-Actor；每个 Worker Ray-Actor是这个完整模型的 DP 分片。</strong></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PPORayActorGroup</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        num_nodes,<span class="comment"># 节点数量（物理机器）</span></span></span><br><span class="line"><span class="params">        num_gpus_per_node,<span class="comment"># 每个节点上的GPU数量</span></span></span><br><span class="line"><span class="params">        ray_actor_type: <span class="type">Type</span>[BasePPORole],<span class="comment"># 每个Actor类型</span></span></span><br><span class="line"><span class="params">        pg: PlacementGroup = <span class="literal">None</span>,<span class="comment"># Ray 的 PlacementGroup，控制 Actor 的调度策略</span></span></span><br><span class="line"><span class="params">        num_gpus_per_actor=<span class="number">1</span>,<span class="comment"># 每个 Actor 分配的 GPU 数量</span></span></span><br><span class="line"><span class="params">        resources: <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="built_in">float</span>] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">        num_resources_per_node: <span class="built_in">int</span> = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">    </span>) -&gt; <span class="literal">None</span>:</span><br><span class="line"> ......</span><br><span class="line">        <span class="variable language_">self</span>._initiate_actors(pg, num_gpus_per_actor)</span><br><span class="line">解释</span><br></pre></td></tr></table></figure><p>创建<code>PPORayActorGroup</code>实例时，其<code>__init__</code>函数包括创建RayActor集群，过程如下：</p><blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_initiate_actors</span>(<span class="params">self, pg, num_gpus_per_actor</span>):</span><br><span class="line">world_size = <span class="variable language_">self</span>._num_nodes * <span class="variable language_">self</span>._num_gpus_per_node<span class="comment"># 总GPU数量</span></span><br><span class="line"><span class="comment"># 1. 创建 Placement Group（每个节点上GPU数量多于1个）：默认每个Actor需要1GPU+1CPU</span></span><br><span class="line"> <span class="keyword">if</span> <span class="variable language_">self</span>._num_gpus_per_node &gt; <span class="number">1</span> <span class="keyword">and</span> pg <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">     bundles = [&#123;<span class="string">&quot;GPU&quot;</span>: <span class="number">1</span>, <span class="string">&quot;CPU&quot;</span>: <span class="number">1</span>&#125; <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>._num_nodes * <span class="variable language_">self</span>._num_gpus_per_node)]</span><br><span class="line">     <span class="keyword">if</span> <span class="variable language_">self</span>._resources:</span><br><span class="line">         ......</span><br><span class="line">     pg = placement_group(bundles, strategy=<span class="string">&quot;PACK&quot;</span>)</span><br><span class="line">     ray.get(pg.ready())</span><br><span class="line"> <span class="comment"># 2. 创建Master Ray-Actor（rank=0）：</span></span><br><span class="line"> <span class="keyword">if</span> pg:</span><br><span class="line">     master_actor = <span class="variable language_">self</span>.ray_actor_type.options(</span><br><span class="line">         ......</span><br><span class="line">     ).remote(world_size, <span class="number">0</span>, <span class="literal">None</span>, <span class="literal">None</span>)<span class="comment"># None, None：Master 的地址和端口</span></span><br><span class="line"> <span class="keyword">else</span>:</span><br><span class="line">     master_actor = <span class="variable language_">self</span>.ray_actor_type.options(</span><br><span class="line">         ......</span><br><span class="line">     ).remote(world_size, <span class="number">0</span>, <span class="literal">None</span>, <span class="literal">None</span>)</span><br><span class="line"> <span class="variable language_">self</span>._actor_handlers = [master_actor]</span><br><span class="line"> <span class="comment"># 3. 创建 Worker Ray-Actor（rank=1 到 world_size-1）</span></span><br><span class="line"> <span class="keyword">if</span> world_size &gt; <span class="number">1</span>:</span><br><span class="line"> master_addr,master_port=ray.get(master_actor.get_master_addr_port.remote())</span><br><span class="line"> <span class="keyword">for</span> rank <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, world_size):</span><br><span class="line">     <span class="keyword">if</span> pg:</span><br><span class="line">         worker_actor = <span class="variable language_">self</span>.ray_actor_type.options(</span><br><span class="line">            ......</span><br><span class="line">             ),</span><br><span class="line">         ).remote(world_size, rank, master_addr, master_port)</span><br><span class="line">     <span class="keyword">else</span>:</span><br><span class="line">         worker_actor = <span class="variable language_">self</span>.ray_actor_type.options(</span><br><span class="line">            ......</span><br><span class="line">         ).remote(world_size, rank, master_addr, master_port)</span><br><span class="line">     <span class="variable language_">self</span>._actor_handlers.append(worker_actor)</span><br></pre></td></tr></table></figure></blockquote><ul><li><p><code>PPORayActorGroup</code>中维护列表<code>self._actor_handlers</code>，是一个<code>List[ray.actor.ActorHandle]</code>，列表中每个元素表示<strong>某个远端Ray-Actor的引用</strong>（对应PPO-Actor/Ref/Critic/RM实例）。可以在Ray集群中的任何位置调用这个handler，来对相应的远端Ray-Actor执行操作。</p></li><li><p><code>ActorModelRayActor</code>：<strong>创建在远端worker进程上，是Ray-Actor</strong>。它包含了设置ds_zero分布式环境、加载模型权重、数据集准备、optimizer/scheduler准备、训练等一系列操作。</p></li></ul><p>注意：<code>PPORayActorGroup</code>在DriverProcess中完成实例化，但主进程中并不包括控制逻辑；算法逻辑在模块对应的<code>PPORayActorGroup</code>中，通过远程调用<code>ActorPPOTrainer</code>实现。</p><h3 id="ray远程调用fit开始训练">Ray远程调用fit，开始训练</h3><p>完成参数初始化、各个模块建立和模型初始化后，控制逻辑交给了隶属于Actor 的 Group，调用<a href="https://link.zhihu.com/?target=https%3A//github.com/OpenRLHF/OpenRLHF/blob/273422305ea17362319f5569c6f9ef5a16b49cb0/openrlhf/trainer/ray/launcher.py%23L242">async_fit_actor_model</a>，这个方法内会调用所有Actor worker 的 <code>fit</code>方法，本质上是调用了<a href="https://github.com/OpenRLHF/OpenRLHF/blob/c438a86ab5981e40f12299c7da4e64468deb7a28/openrlhf/trainer/ppo_trainer.py#L125">PPOTrainer.fit</a>。使得所有worker同时开始训练。</p><p><img src="/posts/2ac460b1/image-29.png"></p><blockquote><p>异步调用的实现方式：<code>async_run_method</code>函数通过<code>self._actor_handlers</code>，实现在相应的远端Ray-Actor上异步调用任意指定的方法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">async_run_method</span>(<span class="params">self, method_name, *args, **kwargs</span>):</span><br><span class="line"> refs = []</span><br><span class="line"> <span class="keyword">for</span> actor <span class="keyword">in</span> <span class="variable language_">self</span>._actor_handlers:</span><br><span class="line">     method = <span class="built_in">getattr</span>(actor, method_name)</span><br><span class="line">     refs.append(method.remote(*args, **kwargs))</span><br><span class="line"> <span class="keyword">return</span> refs</span><br></pre></td></tr></table></figure></blockquote><ol type="1"><li><p><strong>初始化阶段</strong>：初始化训练参数，设置评估和模型保存频率。若未指定，默认每个epoch评估一次，且不自动保存检查点。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        args = <span class="variable language_">self</span>.args</span><br><span class="line">        <span class="comment"># 加载数据集</span></span><br><span class="line">        num_rollouts_per_episodes = <span class="built_in">len</span>(<span class="variable language_">self</span>.prompts_dataloader)</span><br></pre></td></tr></table></figure></li><li><p><strong>检查点加载与vLLM引擎唤醒</strong>：</p><ul><li>检查检查点路径是否存在，若存在则加载；</li><li>若使用vLLM引擎且启用睡眠模式：先唤醒引擎再广播参数，完成后恢复睡眠以节省资源。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 广播初始检查点到vLLM引擎</span></span><br><span class="line">ckpt_path = os.path.join(args.ckpt_path, <span class="string">&quot;_actor&quot;</span>)</span><br><span class="line"><span class="keyword">if</span> args.load_checkpoint <span class="keyword">and</span> os.path.exists(ckpt_path) <span class="keyword">and</span> <span class="keyword">not</span> <span class="variable language_">self</span>.vllm_engines <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">    <span class="comment"># 若启用vLLM睡眠模式，先唤醒引擎</span></span><br><span class="line">    <span class="keyword">if</span> <span class="variable language_">self</span>.strategy.args.vllm_enable_sleep:</span><br><span class="line">        <span class="keyword">from</span> openrlhf.trainer.ray.vllm_engine <span class="keyword">import</span> batch_vllm_engine_call</span><br><span class="line">        batch_vllm_engine_call(<span class="variable language_">self</span>.vllm_engines, <span class="string">&quot;wake_up&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 异步广播模型参数到vLLM</span></span><br><span class="line">    ref = <span class="variable language_">self</span>.actor_model_group.async_run_method(method_name=<span class="string">&quot;broadcast_to_vllm&quot;</span>)</span><br><span class="line">    ray.get(ref)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 广播完成后重新进入睡眠模式</span></span><br><span class="line">    <span class="keyword">if</span> <span class="variable language_">self</span>.strategy.args.vllm_enable_sleep:</span><br><span class="line">        batch_vllm_engine_call(<span class="variable language_">self</span>.vllm_engines, <span class="string">&quot;sleep&quot;</span>)</span><br></pre></td></tr></table></figure></li><li><p><strong>恢复训练状态</strong>：从断点恢复训练进度，计算当前所处的episode和step</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取已消耗的样本数和当前步数</span></span><br><span class="line">consumed_samples = ray.get(<span class="variable language_">self</span>.actor_model_group.async_run_method(method_name=<span class="string">&quot;get_consumed_samples&quot;</span>))[<span class="number">0</span>]</span><br><span class="line">steps = consumed_samples // args.rollout_batch_size + <span class="number">1</span></span><br><span class="line">start_episode = consumed_samples // args.rollout_batch_size // num_rollouts_per_episodes</span><br><span class="line">consumed_samples = consumed_samples % (num_rollouts_per_episodes * args.rollout_batch_size)</span><br></pre></td></tr></table></figure></li><li><p><strong>训练主循环</strong>：</p><ol type="1"><li>设置数据加载器的epoch和样本偏移，使用<code>tqdm</code>显示当前episode进度条；</li><li>核心步骤：<ul><li><strong>经验生成</strong>：根据输入prompts生成交互经验；</li><li><strong>数据分发</strong>：将经验数据异步发送给Actor和Critic模型；</li><li><strong>PPO训练</strong>：调用<code>ppo_train</code>更新模型参数；</li></ul></li><li>KL控制与日志记录：<ul><li><strong>KL控制</strong>：动态调整KL散度惩罚系数；</li><li><strong>保存日志/检查点内容</strong>：日志包括生成样本、奖励值、训练状态等；检查点按配置频率保存模型和训练状态。</li></ul></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> episode <span class="keyword">in</span> <span class="built_in">range</span>(start_episode, args.num_episodes):</span><br><span class="line">    <span class="comment"># 设置数据加载器的epoch和样本偏移</span></span><br><span class="line">    <span class="variable language_">self</span>.prompts_dataloader.sampler.set_epoch(</span><br><span class="line">        episode, consumed_samples=<span class="number">0</span> <span class="keyword">if</span> episode &gt; start_episode <span class="keyword">else</span> consumed_samples</span><br><span class="line">    )</span><br><span class="line">    pbar = tqdm(<span class="built_in">range</span>(<span class="variable language_">self</span>.prompts_dataloader.__len__()), desc=<span class="string">f&quot;Episode [<span class="subst">&#123;episode + <span class="number">1</span>&#125;</span>/<span class="subst">&#123;args.num_episodes&#125;</span>]&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> _, rand_prompts, labels <span class="keyword">in</span> <span class="variable language_">self</span>.prompts_dataloader:</span><br><span class="line">    <span class="comment"># 生成经验数据（状态-动作-奖励序列）</span></span><br><span class="line">    experiences = <span class="variable language_">self</span>.experience_maker.make_experience_list(rand_prompts, labels, **<span class="variable language_">self</span>.generate_kwargs)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 解码示例样本（用于日志）</span></span><br><span class="line">    sample0 = <span class="variable language_">self</span>.tokenizer.batch_decode(experiences[<span class="number">0</span>].sequences[<span class="number">0</span>].unsqueeze(<span class="number">0</span>), skip_special_tokens=<span class="literal">True</span>)</span><br><span class="line">    <span class="built_in">print</span>(sample0)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 异步将经验数据分发到Actor和Critic模型组</span></span><br><span class="line">    refs = <span class="variable language_">self</span>.actor_model_group.async_run_method_batch(method_name=<span class="string">&quot;append&quot;</span>, experience=experiences)</span><br><span class="line">    <span class="keyword">if</span> <span class="variable language_">self</span>.critic_model_group <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        refs.extend(<span class="variable language_">self</span>.critic_model_group.async_run_method_batch(method_name=<span class="string">&quot;append&quot;</span>, experience=experiences))</span><br><span class="line">    ray.get(refs)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 执行PPO训练步骤</span></span><br><span class="line">    status = <span class="variable language_">self</span>.ppo_train(steps)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 更新KL散度控制器</span></span><br><span class="line">    <span class="keyword">if</span> <span class="string">&quot;kl&quot;</span> <span class="keyword">in</span> status:</span><br><span class="line">        <span class="variable language_">self</span>.kl_ctl.update(status[<span class="string">&quot;kl&quot;</span>], args.rollout_batch_size * args.n_samples_per_prompt)</span><br><span class="line">    pbar.set_postfix(status)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#记录生成样本和奖励</span></span><br><span class="line">    status[<span class="string">&quot;generated_samples&quot;</span>] = [sample0[<span class="number">0</span>], experiences[<span class="number">0</span>].info[<span class="string">&quot;reward&quot;</span>][<span class="number">0</span>]]</span><br><span class="line">    <span class="comment"># 保存日志和检查点</span></span><br><span class="line">    client_states = &#123;<span class="string">&quot;consumed_samples&quot;</span>: steps * args.rollout_batch_size&#125;</span><br><span class="line">    <span class="variable language_">self</span>.save_logs_and_checkpoints(args, steps, pbar, status, client_states)</span><br><span class="line"></span><br><span class="line">    pbar.update()</span><br><span class="line">    steps = steps + <span class="number">1</span></span><br></pre></td></tr></table></figure></li><li><p><strong>训练终止</strong>：训练结束后关闭WandB/TensorBoard日志连接。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="variable language_">self</span>._wandb <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="variable language_">self</span>._wandb.finish()</span><br><span class="line">    <span class="keyword">if</span> <span class="variable language_">self</span>._tensorboard <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="variable language_">self</span>._tensorboard.close()</span><br></pre></td></tr></table></figure></li></ol><h4 id="step1.-样本生成将这个-batch-的-prompts-输入给-actorrollout-得到-responses">Step1.<strong>样本生成</strong>：将这个 batch 的 prompts 输入给 Actor，rollout得到 responses</h4><p>从<code>make_experience_list</code>进入，调用链为：<a href="https://github.com/OpenRLHF/OpenRLHF/blob/0b530f1119147ba1241632b123032e228ad2636b/openrlhf/trainer/ppo_utils/experience_maker.py#L223"><code>make_experience_list</code></a>-&gt;<a href="https://github.com/OpenRLHF/OpenRLHF/blob/0b530f1119147ba1241632b123032e228ad2636b/openrlhf/trainer/ppo_utils/experience_maker.py#L625"><code>generate_samples</code></a>-&gt;<a href="https://github.com/OpenRLHF/OpenRLHF/blob/bb46342711a203c457df2fbca5967fd0549557e0/openrlhf/trainer/ppo_utils/experience_maker.py#L627"><code>_generate_vllm</code></a></p><ol type="1"><li><p><strong>初始化采样参数</strong>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sampling_params = SamplingParams(</span><br><span class="line">    temperature=kwargs.get(<span class="string">&quot;temperature&quot;</span>, <span class="number">1.0</span>),</span><br><span class="line">    top_p=kwargs.get(<span class="string">&quot;top_p&quot;</span>, <span class="number">1.0</span>),</span><br><span class="line">    max_tokens=kwargs.get(<span class="string">&quot;max_new_tokens&quot;</span>, <span class="number">1024</span>),</span><br><span class="line">    ...</span><br><span class="line">)</span><br></pre></td></tr></table></figure></li><li><p><strong>扩展prompts</strong>：采用数据增强，每个提示生成多份样本</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">n_samples_per_prompt = kwargs.pop(<span class="string">&quot;n_samples_per_prompt&quot;</span>, args.n_samples_per_prompt)</span><br><span class="line">all_prompts = <span class="built_in">sum</span>([[prompt] * n_samples_per_prompt <span class="keyword">for</span> prompt <span class="keyword">in</span> all_prompts], [])</span><br></pre></td></tr></table></figure></li><li><p><strong>分布式请求分发</strong>：异步调用每个vllm引擎上的<code>add_requests</code>方法</p><blockquote><p>Vllm engine上的<a href="https://github.com/OpenRLHF/OpenRLHF/blob/0b530f1119147ba1241632b123032e228ad2636b/openrlhf/trainer/ray/vllm_engine.py#L83"><code>add_requests</code></a>：收集所有Ray-Actor上的请求，统一生成responses</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">add_requests</span>(<span class="params">self, actor_rank, *, sampling_params, prompt_token_ids</span>):</span><br><span class="line">......</span><br><span class="line">    <span class="comment"># 批量生成</span></span><br><span class="line">    responses = <span class="variable language_">self</span>.llm.generate(prompts=requests, sampling_params=sampling_params)</span><br><span class="line">    <span class="comment"># 结果分发</span></span><br><span class="line">    offset = <span class="number">0</span></span><br><span class="line">    <span class="variable language_">self</span>.responses = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> actor_rank, num <span class="keyword">in</span> num_requests:</span><br><span class="line">        <span class="variable language_">self</span>.response_queues[actor_rank].put(responses[offset : offset + num])</span><br><span class="line">        offset += num</span><br><span class="line">    <span class="variable language_">self</span>.requests = &#123;&#125;<span class="comment"># 状态重置</span></span><br></pre></td></tr></table></figure><p>调用<a href="https://github.com/OpenRLHF/OpenRLHF/blob/0b530f1119147ba1241632b123032e228ad2636b/openrlhf/models/actor.py#L136"><code>generate</code></a>函数，完成基于PyTorch的文本生成：调用Pytorch的<a href="https://docs.pytorch.org/torchtune/0.3/generated/torchtune.generation.generate.html"><code>generate</code></a>函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@torch.no_grad()</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate</span>(<span class="params">self, input_ids: torch.Tensor, **kwargs</span>) -&gt; <span class="type">Union</span>[</span><br><span class="line">    <span class="type">Tuple</span>[torch.LongTensor, torch.LongTensor],</span><br><span class="line">    <span class="type">Tuple</span>[torch.LongTensor, torch.LongTensor, torch.BoolTensor],</span><br><span class="line">]:</span><br><span class="line">    ......</span><br><span class="line">    <span class="comment"># Call generate</span></span><br><span class="line">    sequences = <span class="variable language_">self</span>.model.generate(**generate_args)</span><br><span class="line">    <span class="comment"># Prepare mask tensor</span></span><br><span class="line">    eos_token_id = generate_args[<span class="string">&quot;eos_token_id&quot;</span>]</span><br><span class="line">    pad_token_id = generate_args[<span class="string">&quot;pad_token_id&quot;</span>]</span><br><span class="line">    <span class="keyword">return</span> process_sequences(sequences, input_ids.size(<span class="number">1</span>), eos_token_id, pad_token_id)</span><br></pre></td></tr></table></figure></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">batch_size = (<span class="built_in">len</span>(all_prompt_token_ids) + <span class="built_in">len</span>(llms) - <span class="number">1</span>) // <span class="built_in">len</span>(llms)</span><br><span class="line"><span class="keyword">for</span> i, llm <span class="keyword">in</span> <span class="built_in">enumerate</span>(llms):</span><br><span class="line">    prompt_token_ids = all_prompt_token_ids[i*batch_size : (i+<span class="number">1</span>)*batch_size]</span><br><span class="line">    refs.append(llm.add_requests.remote(...))</span><br><span class="line">ray.get(refs)</span><br></pre></td></tr></table></figure></li><li><p><strong>收集结果，进行批处理和标准化</strong>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">all_outputs = <span class="built_in">sum</span>(ray.get(all_output_refs), [])</span><br><span class="line">sequences, attention_mask, action_mask = process_sequences(</span><br><span class="line">    sequences, batch_max_input_len, eos_token_id, pad_token_id</span><br><span class="line">)</span><br></pre></td></tr></table></figure></li></ol><p>最后封装样本的数据结构如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Samples(</span><br><span class="line">    sequences: Tensor        <span class="comment"># [batch, seq_len] 完整序列</span></span><br><span class="line">    attention_mask: Tensor   <span class="comment"># [batch, seq_len] 有效token位置</span></span><br><span class="line">    action_mask: Tensor      <span class="comment"># [batch, seq_len] 需优化的token位置</span></span><br><span class="line">    response_length: Tensor  <span class="comment"># [batch] 每个响应的实际长度</span></span><br><span class="line">    prompts: <span class="type">List</span>[<span class="built_in">str</span>]       <span class="comment"># 原始提示</span></span><br><span class="line">    labels: <span class="type">List</span>             <span class="comment"># 对应标签</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><h4 id="step2.-收集experiences从refrewardcritic上收集并处理exps">Step2.收集experiences：从Ref/Reward/Critic上收集并处理exps</h4><p>从<code>make_experience_list</code>进入，调用链为：<a href="https://github.com/OpenRLHF/OpenRLHF/blob/0b530f1119147ba1241632b123032e228ad2636b/openrlhf/trainer/ppo_utils/experience_maker.py#L223"><code>make_experience_list</code></a>-&gt;<a href="https://github.com/OpenRLHF/OpenRLHF/blob/bb46342711a203c457df2fbca5967fd0549557e0/openrlhf/trainer/ppo_utils/experience_maker.py#L492"><code>make_experience</code></a></p><ol type="1"><li><p><strong>数据准备</strong>：在一遍inference后，收集所有样本信息，为批处理做准备</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sequences_list = [s.sequences <span class="keyword">for</span> s <span class="keyword">in</span> samples_list]</span><br><span class="line">attention_mask_list = [s.attention_mask <span class="keyword">for</span> s <span class="keyword">in</span> samples_list]</span><br><span class="line">......</span><br></pre></td></tr></table></figure></li><li><p><strong>计算Reward模型</strong>：</p><ul><li><strong>本地模式</strong>：直接调用模型组进行计算</li><li><strong>远程模式</strong>：通过Ray分发到远程服务</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">r_refs = <span class="literal">None</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> <span class="variable language_">self</span>.remote_rm_url:<span class="comment"># 本地奖励模型：</span></span><br><span class="line">    r_refs = <span class="variable language_">self</span>.reward_model_group.async_run_method_batch(</span><br><span class="line">        ......</span><br><span class="line">    )</span><br><span class="line"><span class="keyword">else</span>:<span class="comment"># 远程奖励服务</span></span><br><span class="line">    queries_list = <span class="built_in">sum</span>(</span><br><span class="line">        [<span class="variable language_">self</span>.tokenizer.batch_decode(seq, skip_special_tokens=<span class="literal">False</span>) <span class="keyword">for</span> seq <span class="keyword">in</span> sequences_list], []</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">if</span> <span class="variable language_">self</span>.custom_reward_func:<span class="comment"># 自定义奖励模型</span></span><br><span class="line">        ......</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_chunks):</span><br><span class="line">           ......</span><br><span class="line">            r = <span class="variable language_">self</span>.custom_reward_func.remote(</span><br><span class="line">                queries_list[start_idx:end_idx],</span><br><span class="line">                prompts_list[start_idx:end_idx],</span><br><span class="line">                labels_list[start_idx:end_idx],</span><br><span class="line">            )</span><br><span class="line">            r_refs.append(r)</span><br><span class="line">    <span class="keyword">else</span>:<span class="comment"># 将数据分布在不同的远程奖励模型服务器上</span></span><br><span class="line">        num_servers = <span class="built_in">len</span>(<span class="variable language_">self</span>.remote_rm_url)</span><br><span class="line">        batch_size = (<span class="built_in">len</span>(queries_list) + num_servers - <span class="number">1</span>) // num_servers</span><br><span class="line">        r_refs = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_servers):</span><br><span class="line">            ......</span><br><span class="line">            r = remote_rm_fn_ray.remote(</span><br><span class="line">                rm,</span><br><span class="line">                queries=queries_list[start_idx:end_idx],</span><br><span class="line">                prompts=prompts_list[start_idx:end_idx],</span><br><span class="line">                labels=labels_list[start_idx:end_idx],</span><br><span class="line">            )</span><br><span class="line">            r_refs.append(r)</span><br></pre></td></tr></table></figure></li><li><p><strong>从Ref/Critic上收集exps</strong>：</p><ul><li><code>action_log_probs</code>: 当前策略的动作概率</li><li><code>value</code>: 状态价值估计</li><li><code>base_action_log_probs</code>:参考策略的动作概率（用于KL散度计算）</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Actor模型（当前策略）</span></span><br><span class="line">action_log_probs_ref = <span class="variable language_">self</span>.actor_model_group.async_run_method_batch(...)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Critic模型（价值函数）</span></span><br><span class="line">value_ref = <span class="variable language_">self</span>.critic_model_group.async_run_method_batch(...)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始模型（参考策略）</span></span><br><span class="line">base_action_log_probs_ref = <span class="variable language_">self</span>.initial_model_group.async_run_method_batch(...)</span><br></pre></td></tr></table></figure></li><li><p><strong>结果整合</strong>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">experience = Experience(</span><br><span class="line">    sequences,                <span class="comment"># 输入序列</span></span><br><span class="line">    action_log_probs,         <span class="comment"># 当前策略logprobs</span></span><br><span class="line">    base_action_log_probs,    <span class="comment"># 参考策略logprobs</span></span><br><span class="line">    value,                    <span class="comment"># 价值函数输出</span></span><br><span class="line">    <span class="literal">None</span>,                     <span class="comment"># 初始化为空的advantage</span></span><br><span class="line">    <span class="literal">None</span>,                     <span class="comment"># 初始化为空的return</span></span><br><span class="line">    attention_mask,           <span class="comment"># 注意力掩码</span></span><br><span class="line">    samples.action_mask,      <span class="comment"># 动作掩码</span></span><br><span class="line">    info,                     <span class="comment"># 元信息</span></span><br><span class="line">    kl                        <span class="comment"># KL散度</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></li><li><p><strong>计算KL散度</strong>：衡量当前策略与参考策略的差异</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kl = compute_approx_kl(action_log_probs, base_action_log_probs)</span><br><span class="line">kl_mean = masked_mean(kl, samples.action_mask)</span><br></pre></td></tr></table></figure></li></ol><h4 id="step3.-确保将处理后的exps传送给critic并行执行actor和critic的训练">Step3.确保将处理后的exps传送给Critic，并行执行Actor和Critic的训练</h4><p>从<code>PPOTrainer.ppo_train</code>开始：这里<code>critic_model_group</code>，<code>actor_model_group</code>均为<code>PPORayActorGroup</code>，通过<code>async_run_method</code>远程调用Ray-Actor上的<code>fit</code>方法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">ppo_train</span>(<span class="params">self, global_steps</span>):</span><br><span class="line">    status = &#123;&#125;</span><br><span class="line">    <span class="comment"># 1. Critic模型训练</span></span><br><span class="line">    <span class="keyword">if</span> <span class="variable language_">self</span>.critic_model_group <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        ......</span><br><span class="line">        <span class="comment"># 异步启动Critic模型训练(fit方法)</span></span><br><span class="line">        critic_status_ref = <span class="variable language_">self</span>.critic_model_group.async_run_method(method_name=<span class="string">&quot;fit&quot;</span>)</span><br><span class="line">......</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># 2. Actor模型训练</span></span><br><span class="line">    <span class="keyword">if</span> global_steps &gt; <span class="variable language_">self</span>.freezing_actor_steps:</span><br><span class="line">      <span class="comment"># 当全局步数超过冻结步数时才执行：异步启动actor模型训练</span></span><br><span class="line">      ......</span><br><span class="line">        actor_status_ref = <span class="variable language_">self</span>.actor_model_group.async_run_method(method_name=<span class="string">&quot;fit&quot;</span>, kl_ctl=<span class="variable language_">self</span>.kl_ctl.value)</span><br><span class="line">        status.update(ray.get(actor_status_ref)[<span class="number">0</span>])<span class="comment"># 获取并记录actor训练状态</span></span><br><span class="line">...... </span><br><span class="line">        <span class="comment"># 2.1 如果有vLLM引擎：广播actor模型权重到vLLM引擎</span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.vllm_engines <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">              ......</span><br><span class="line">  ray.get(<span class="variable language_">self</span>.actor_model_group.async_run_method(method_name=<span class="string">&quot;broadcast_to_vllm&quot;</span>))</span><br><span class="line">......</span><br><span class="line">    <span class="comment"># 3. 等待Critic训练完成，更新其状态</span></span><br><span class="line">    <span class="keyword">if</span> <span class="variable language_">self</span>.critic_model_group <span class="keyword">and</span> <span class="keyword">not</span> <span class="variable language_">self</span>.strategy.args.colocate_all_models:</span><br><span class="line">        status.update(ray.get(critic_status_ref)[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> status</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><code>ppo_critic</code>，<code>ppo_actor</code>在Ray上分别有各自的<code>ppo_train</code>函数：</p><ol type="1"><li><p><a href="https://github.com/OpenRLHF/OpenRLHF/blob/bb46342711a203c457df2fbca5967fd0549557e0/openrlhf/trainer/ppo_utils/experience_maker.py#L470"><strong>将exps传送给Critic</strong></a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="variable language_">self</span>.critic <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">    <span class="keyword">for</span> experience <span class="keyword">in</span> experiences:</span><br><span class="line">        <span class="comment"># send experience to critic</span></span><br><span class="line">        experience_cpu = deepcopy(experience)</span><br><span class="line">        experience_cpu.to_device(<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">        <span class="variable language_">self</span>._ref = <span class="variable language_">self</span>.critic.append.remote(experience_cpu)</span><br></pre></td></tr></table></figure></li><li><p><strong>Actor训练</strong>：调用链为：<a href="https://github.com/OpenRLHF/OpenRLHF/blob/ebe9b6fdd0753c248e51593186c7420fc751e44d/openrlhf/trainer/ppo_trainer.py#L204"><code>PPOTrainer.ppo_train</code></a>-&gt;<a href="https://github.com/OpenRLHF/OpenRLHF/blob/ebe9b6fdd0753c248e51593186c7420fc751e44d/openrlhf/trainer/ray/ppo_actor.py#L454">‎<code>ActorModelRayActor.fit‎</code></a>-&gt;<a href="https://github.com/OpenRLHF/OpenRLHF/blob/ebe9b6fdd0753c248e51593186c7420fc751e44d/openrlhf/trainer/ray/ppo_actor.py#L143">`<code>ActorModelRayActor.ppo_train</code></a></p></li><li><p><strong>Critic训练</strong>：调用链为：<a href="https://github.com/OpenRLHF/OpenRLHF/blob/ebe9b6fdd0753c248e51593186c7420fc751e44d/openrlhf/trainer/ppo_trainer.py#L204"><code>PPOTrainer.ppo_train</code></a>-&gt;<a href="https://github.com/OpenRLHF/OpenRLHF/blob/ebe9b6fdd0753c248e51593186c7420fc751e44d/openrlhf/trainer/ray/ppo_critic.py#L246">‎<code>CriticModelRayActor.fit‎</code></a>-&gt;<a href="https://github.com/OpenRLHF/OpenRLHF/blob/ebe9b6fdd0753c248e51593186c7420fc751e44d/openrlhf/trainer/ray/ppo_critic.py#L59">``<code>CriticModelRayActor.ppo_train</code></a></p></li></ol><h4 id="step4.-vllm_engine权重更新">Step4. vllm_engine权重更新</h4><h3 id="总流程">总流程</h3><p>最后看看总流程：<a href="https://github.com/OpenRLHF/OpenRLHF/tree/main">OpenRLHF</a>/<a href="https://github.com/OpenRLHF/OpenRLHF/tree/main/openrlhf">openrlhf</a>/<a href="https://github.com/OpenRLHF/OpenRLHF/tree/main/openrlhf/cli">cli</a>/<a href="https://github.com/OpenRLHF/OpenRLHF/blob/main/openrlhf/cli/train_ppo_ray.py">train_ppo_ray.py</a></p><p><img src="/posts/2ac460b1/image-21.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">args</span>):</span><br><span class="line">  <span class="string">&#x27;&#x27;&#x27;1. 初始化阶段&#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># 1.1 分布式策略配置</span></span><br><span class="line">    strategy = get_strategy(args)</span><br><span class="line">    strategy.<span class="built_in">print</span>(args)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 1.2 Placement Group初始化</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;1.2 如果采用colocate_actor_ref或colocate_all_models策略：创建Placement Group</span></span><br><span class="line"><span class="string">    将 Actor 和 Reference 模型部署在相同的 GPU 上，减少跨节点通信&#x27;&#x27;&#x27;</span></span><br><span class="line">    pg = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">if</span> args.colocate_actor_ref <span class="keyword">or</span> args.colocate_all_models:</span><br><span class="line">        <span class="keyword">if</span> args.init_kl_coef &gt; <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">assert</span> (</span><br><span class="line">                args.actor_num_nodes == args.ref_num_nodes</span><br><span class="line">                <span class="keyword">and</span> args.actor_num_gpus_per_node == args.ref_num_gpus_per_node</span><br><span class="line">            ), <span class="string">f&quot;num_nodes and num_gpus_per_node must be the same when colocate actor and ref model.&quot;</span></span><br><span class="line"></span><br><span class="line">        bundles = [&#123;<span class="string">&quot;GPU&quot;</span>: <span class="number">1</span>, <span class="string">&quot;CPU&quot;</span>: <span class="number">1</span>&#125; <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(args.actor_num_nodes * args.actor_num_gpus_per_node)]</span><br><span class="line">        pg = placement_group(bundles, strategy=<span class="string">&quot;PACK&quot;</span>)</span><br><span class="line">        ray.get(pg.ready())</span><br><span class="line"></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;2. 核心组件初始化&#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># 2.1 初始化vLLM引擎（用于文本生成）</span></span><br><span class="line">    vllm_engines = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">if</span> args.vllm_num_engines <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> args.vllm_num_engines &gt; <span class="number">0</span>:</span><br><span class="line">        max_len = args.max_len <span class="keyword">if</span> args.max_len <span class="keyword">else</span> args.prompt_max_len + args.generate_max_len</span><br><span class="line">        <span class="keyword">if</span> args.colocate_all_models:</span><br><span class="line">            <span class="keyword">assert</span> (</span><br><span class="line">                args.actor_num_nodes * args.actor_num_gpus_per_node</span><br><span class="line">                == args.vllm_num_engines * args.vllm_tensor_parallel_size</span><br><span class="line">            ), (</span><br><span class="line">                <span class="string">f&quot;actor_num_nodes * actor_num_gpus_per_node must be equal to &quot;</span></span><br><span class="line">                <span class="string">f&quot;vllm_num_engines * vllm_tensor_parallel_size, got <span class="subst">&#123;args.actor_num_nodes * args.actor_num_gpus_per_node&#125;</span> &quot;</span></span><br><span class="line">                <span class="string">f&quot;and <span class="subst">&#123;args.vllm_num_engines * args.vllm_tensor_parallel_size&#125;</span>&quot;</span></span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        vllm_engines = create_vllm_engines(</span><br><span class="line">            args.vllm_num_engines,</span><br><span class="line">            args.vllm_tensor_parallel_size,<span class="comment"># Tensor 并行度（GPU 数量）</span></span><br><span class="line">            args.pretrain,</span><br><span class="line">            args.seed,</span><br><span class="line">            args.full_determinism,</span><br><span class="line">            args.enable_prefix_caching,<span class="comment"># 启用 KV Cache 复用</span></span><br><span class="line">            args.enforce_eager,</span><br><span class="line">            max_len,</span><br><span class="line">            pg <span class="keyword">if</span> args.colocate_all_models <span class="keyword">else</span> <span class="literal">None</span>,</span><br><span class="line">            args.vllm_gpu_memory_utilization,</span><br><span class="line">            args.vllm_enable_sleep,</span><br><span class="line">        )</span><br><span class="line">    <span class="comment"># 2.2 Actor / Critic / Reward / Reference 模型初始化</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;num_gpus_per_actor：</span></span><br><span class="line"><span class="string">如果使用PlacementGroup，则允许5个Actor共享1个GPU；否则每个Actor独占1个GPU&#x27;&#x27;&#x27;</span></span><br><span class="line">    actor_model = PPORayActorGroup(</span><br><span class="line">        args.actor_num_nodes,</span><br><span class="line">        args.actor_num_gpus_per_node,</span><br><span class="line">        ActorModelRayActor,</span><br><span class="line">        pg=pg,</span><br><span class="line">        num_gpus_per_actor=<span class="number">0.2</span> <span class="keyword">if</span> pg <span class="keyword">else</span> <span class="number">1</span>,</span><br><span class="line">        duplicate_actors=args.ring_attn_size * args.ds_tensor_parallel_size,</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">if</span> args.init_kl_coef &lt;= <span class="number">0</span>:</span><br><span class="line">        ref_model = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        ref_model = PPORayActorGroup(</span><br><span class="line">            args.ref_num_nodes,</span><br><span class="line">            args.ref_num_gpus_per_node,</span><br><span class="line">            ReferenceModelRayActor,</span><br><span class="line">            pg=pg,</span><br><span class="line">            num_gpus_per_actor=<span class="number">0.2</span> <span class="keyword">if</span> pg <span class="keyword">else</span> <span class="number">1</span>,</span><br><span class="line">            duplicate_actors=args.ring_attn_size * args.ds_tensor_parallel_size,</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> args.colocate_all_models:</span><br><span class="line">        pg = <span class="literal">None</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> args.critic_pretrain <span class="keyword">and</span> args.colocate_critic_reward:</span><br><span class="line">        <span class="keyword">assert</span> (</span><br><span class="line">            args.critic_num_nodes == args.reward_num_nodes</span><br><span class="line">            <span class="keyword">and</span> args.critic_num_gpus_per_node == args.reward_num_gpus_per_node</span><br><span class="line">        ), <span class="string">f&quot;num_nodes and num_gpus_per_node must be the same when colocate critic and reward model.&quot;</span></span><br><span class="line"></span><br><span class="line">        bundles = [&#123;<span class="string">&quot;GPU&quot;</span>: <span class="number">1</span>, <span class="string">&quot;CPU&quot;</span>: <span class="number">1</span>&#125; <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(args.critic_num_nodes * args.critic_num_gpus_per_node)]</span><br><span class="line">        pg = placement_group(bundles, strategy=<span class="string">&quot;PACK&quot;</span>)</span><br><span class="line">        ray.get(pg.ready())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> args.critic_pretrain:</span><br><span class="line">        critic_model = PPORayActorGroup(</span><br><span class="line">            args.critic_num_nodes,</span><br><span class="line">            args.critic_num_gpus_per_node,</span><br><span class="line">            CriticModelRayActor,</span><br><span class="line">            pg=pg,</span><br><span class="line">            num_gpus_per_actor=<span class="number">0.2</span> <span class="keyword">if</span> pg <span class="keyword">else</span> <span class="number">1</span>,</span><br><span class="line">            duplicate_actors=args.ring_attn_size * args.ds_tensor_parallel_size,</span><br><span class="line">        )</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        critic_model = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> args.remote_rm_url:</span><br><span class="line">        reward_pretrain = args.reward_pretrain</span><br><span class="line">        reward_model = PPORayActorGroup(</span><br><span class="line">            args.reward_num_nodes,</span><br><span class="line">            args.reward_num_gpus_per_node,</span><br><span class="line">            RewardModelRayActor,</span><br><span class="line">            pg=pg,</span><br><span class="line">            num_gpus_per_actor=<span class="number">0.2</span> <span class="keyword">if</span> pg <span class="keyword">else</span> <span class="number">1</span>,</span><br><span class="line">            duplicate_actors=args.ring_attn_size * args.ds_tensor_parallel_size,</span><br><span class="line">        )</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        reward_model = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;3. 训练流程&#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># 3.1 初始化训练控制器PPOTrainer</span></span><br><span class="line">    ppo_trainer = PPOTrainer.remote(</span><br><span class="line">        args.pretrain,</span><br><span class="line">        strategy,</span><br><span class="line">        actor_model,</span><br><span class="line">        critic_model,</span><br><span class="line">        reward_model,</span><br><span class="line">        ref_model,</span><br><span class="line">        vllm_engines,</span><br><span class="line">        prompt_split=args.prompt_split,</span><br><span class="line">        eval_split=args.eval_split,</span><br><span class="line">        <span class="comment"># generate kwargs</span></span><br><span class="line">        do_sample=<span class="literal">True</span>,</span><br><span class="line">        prompt_max_len=args.prompt_max_len,</span><br><span class="line">        max_new_tokens=args.generate_max_len,</span><br><span class="line">        max_length=args.max_len,</span><br><span class="line">        temperature=args.temperature,</span><br><span class="line">        top_p=args.top_p,</span><br><span class="line">    )</span><br><span class="line">    max_steps = ray.get(ppo_trainer.get_max_steps.remote())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3.2 分阶段初始化</span></span><br><span class="line">    <span class="comment"># 第一阶段：初始化Actor/Ref/Reward</span></span><br><span class="line">    refs = []</span><br><span class="line">    <span class="keyword">if</span> ref_model <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        refs.extend(ref_model.async_init_model_from_pretrained(strategy, args.pretrain))</span><br><span class="line">    refs.extend(actor_model.async_init_model_from_pretrained(strategy, args.pretrain, max_steps, vllm_engines))</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> args.remote_rm_url:</span><br><span class="line">        refs.extend(reward_model.async_init_model_from_pretrained(strategy, reward_pretrain))</span><br><span class="line">    ray.get(refs)<span class="comment"># 同步等待</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 第二阶段：初始化Critic（Critic需要等Actor确定max_steps后才能初始化）</span></span><br><span class="line">    <span class="keyword">if</span> args.critic_pretrain:</span><br><span class="line">        refs.extend(critic_model.async_init_model_from_pretrained(strategy, args.critic_pretrain, max_steps))</span><br><span class="line">        ray.get(refs)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3.3 训练执行</span></span><br><span class="line">    ray.get(ppo_trainer.fit.remote())</span><br><span class="line"></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;4. 收尾阶段&#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># 4.1 模型保存：Actor必保存；Critic可选保存</span></span><br><span class="line">    ray.get(actor_model.async_save_model())</span><br><span class="line">    <span class="keyword">if</span> args.critic_pretrain <span class="keyword">and</span> args.save_value_network:</span><br><span class="line">        ray.get(critic_model.async_save_model())</span><br></pre></td></tr></table></figure><h2 id="openrlhf的colocate策略">OpenRLHF的Colocate策略</h2><h3 id="原理">原理</h3><p>在进入colocate策略的分析前，先回顾一下PPO的工作流：</p><ol type="1"><li><p>准备一个batch的prompts；</p></li><li><p>将这个 batch 的 prompts 输入给 Actor，rollout 得到responses；</p></li><li><p>将 prompt + responses 输入给 Critic/Reward/Reference，进行inference，分别计算得得到 values、reward 和 log probs，将这些整合称为experiences；</p><p><img src="/posts/2ac460b1/image-22.png"></p></li><li><p>根据 experiences 多轮计算 actor loss 和 critic loss 并更新 Actor和 Critic。</p><p><img src="/posts/2ac460b1/image-23.png"></p></li></ol><p>再纵向整理一次各个模块的工作流：</p><ol type="1"><li><p>Actor：需要 training engine 和 rollout engine。前者使用现代training engine，比如 Megatron 或者 FSDP，后者得用现代推理引擎，比如SGLang 或者 vllm 作为 rollout engine。有一个小问题，为什么不能拿着training engine 得到的 logits 做 sampling 然后 decode，貌似也可以用去rollout？简单来说，太慢了，用训练引擎做 decode的效果自然不如专用的推理引擎。</p></li><li><p>Critic：需要 training engine 和 inferenceengine。前者还是是现代的训练引擎，但是后者，可以用现代的推理引擎的高效prefill 来得到 value 么？其实不能，critic model 的 inference 会直接复用training engine 的 forward 来得到 value，所以 critic 的 inference engine和 training engine 其实是同一个。</p></li><li><p>Reference 和 Reward：只需要inference，因为二者不需要训练，但是用现代推理引擎得到的 log probs 和reward 的精度不如用现代训练引擎得到的精度，所以这里选择用 trainingengine 的 forward 来做 inference，得到 log probs 和 reward。</p></li></ol><p>collocate 策略：</p><ol type="1"><li>将 actor 的 training engine 和 reference 的 inference engine放置在同一个资源组上；</li><li>将 critic 的 training/inference engine 和 reward 的 inference engine放置在同一个资源组上；</li><li>最后单独放置 actor 的 rollout engine。</li></ol><h3 id="部署actorrefcriticrm实例">部署Actor/Ref/Critic/RM实例</h3><h4 id="非共同部署">非共同部署</h4><p><img src="/posts/2ac460b1/image-24.png"></p><p>一个部署示例如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">actor_model = PPORayActorGroup(</span><br><span class="line">    args.actor_num_nodes,<span class="comment"># 部署想用的节点数</span></span><br><span class="line">    args.actor_num_gpus_per_node,<span class="comment"># 部署后每个节点上想用的gpu数</span></span><br><span class="line">    ActorModelRayActor,<span class="comment"># Actor/Critic/Reward/ReferenceRayActor</span></span><br><span class="line">    pg=pg,</span><br><span class="line">    num_gpus_per_actor=<span class="number">0.2</span> <span class="keyword">if</span> pg <span class="keyword">else</span> <span class="number">1</span>,<span class="comment"># </span></span><br><span class="line">    duplicate_actors=args.ring_attn_size * args.ds_tensor_parallel_size,</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>其中，<code>num_gpus_per_actor</code>等于1说明每个实例占满一张gpu，即“非共同部署”；小于1说明每个实例只占部分gpu，即“共同部署”。</p><h4 id="共同部署">共同部署</h4><p><img src="/posts/2ac460b1/image-25.png"></p><p>这里展示PPO-Actor和PPO-Reference的colocate策略：</p><ol type="1"><li><p>创建一个PlacementGroup，接下来Actor和Reference实例均使用这个配置方案：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bundles = [&#123;<span class="string">&quot;GPU&quot;</span>: <span class="number">1</span>, <span class="string">&quot;CPU&quot;</span>: <span class="number">1</span>&#125; <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(args.actor_num_nodes * args.actor_num_gpus_per_node)]</span><br><span class="line">pg = placement_group(bundles, strategy=<span class="string">&quot;PACK&quot;</span>)</span><br></pre></td></tr></table></figure></li><li><p>PPO-Actor和PPO-Reference分别创建一个PPORayActorGroup。<strong>为了实现模块之间的colocate，往两个Group中传入同一个pg</strong>：</p><p><strong>在Group内部，通过<code>num_gpus_per_actor</code>分配每个worker的bundle</strong></p></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">......</span><br><span class="line">actor_model = PPORayActorGroup(</span><br><span class="line">    args.actor_num_nodes,</span><br><span class="line">    args.actor_num_gpus_per_node,</span><br><span class="line">    ActorModelRayActor,</span><br><span class="line">    pg=pg,</span><br><span class="line">    num_gpus_per_actor=<span class="number">0.2</span> <span class="keyword">if</span> pg <span class="keyword">else</span> <span class="number">1</span>,</span><br><span class="line">    duplicate_actors=args.ring_attn_size * args.ds_tensor_parallel_size,</span><br><span class="line">)</span><br><span class="line"><span class="keyword">if</span> args.init_kl_coef &lt;= <span class="number">0</span>:</span><br><span class="line">    ref_model = <span class="literal">None</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    ref_model = PPORayActorGroup(</span><br><span class="line">        args.ref_num_nodes,</span><br><span class="line">        args.ref_num_gpus_per_node,</span><br><span class="line">        ReferenceModelRayActor,</span><br><span class="line">        pg=pg,</span><br><span class="line">        num_gpus_per_actor=<span class="number">0.2</span> <span class="keyword">if</span> pg <span class="keyword">else</span> <span class="number">1</span>,</span><br><span class="line">        duplicate_actors=args.ring_attn_size * args.ds_tensor_parallel_size,</span><br><span class="line">    )</span><br></pre></td></tr></table></figure><h3 id="部署vllm_engines实例">部署vllm_engines实例</h3><p><img src="/posts/2ac460b1/image-26.png"></p><p>对于<strong>Rollout模块</strong>：</p><ol type="1"><li>Driver process中创建一个或多个<a href="https://github.com/OpenRLHF/OpenRLHF/blob/c438a86ab5981e40f12299c7da4e64468deb7a28/openrlhf/trainer/ray/vllm_engine.py#L26">LLMRayActor</a>（worker端的Ray-Actor），每个代表一个vLLM engine（一个完整的 DP 模型），由<a href="https://github.com/OpenRLHF/OpenRLHF/blob/c438a86ab5981e40f12299c7da4e64468deb7a28/openrlhf/trainer/ray/vllm_engine.py#L111">create_vllm_engines</a>创建。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># create_vllm_engines函数部分代码：</span></span><br><span class="line">vllm_engines.append(</span><br><span class="line">    LLMRayActor.options(</span><br><span class="line">        num_cpus=num_gpus,</span><br><span class="line">        num_gpus=num_gpus,</span><br><span class="line">        scheduling_strategy=scheduling_strategy,</span><br><span class="line">    ).remote(</span><br><span class="line">        model=pretrain,</span><br><span class="line"> ......</span><br><span class="line">    )</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>每个 engine 内部通过 Ray 启动 TP Ray-Actor（这个 Ray-Actor 会 attach到已有的 cluster，不会新建一个）。</p><h3 id="ds_rank0与vllm_ranks之间的通信">ds_rank0与vllm_ranks之间的通信</h3><p>假设DP分组如下：</p><ul><li>Actor0 / Ref0 / RM0 / Critic0 / vllm_engine0为一组</li><li>Actor1 / Ref1 / RM1 / Critic1 / vllm_engine1为一组</li><li>Actor2 / Ref2 / RM2 / Critic2 / vllm_engine2为一组</li><li>Actor3 / Ref3 / RM3 / Critic3 / vllm_engine3为一组</li></ul><p>每一组负责一个micro-batch的训练（一个DP分片）。</p><p>在OpenRLHF中，<strong>Actor和Rollout是两个独立的模块，前者放在deepseed训练引擎，后者放在vLLM中，需要保持权重同步</strong>。因此，当PPO-Actor更新时，ds_rank0需要和all_vllm_ranks进行通讯，最新的权重broadcast给所有vllm_ranks：</p><p><img src="/posts/2ac460b1/image-27.png"></p><p>分成以下几个步骤：</p><h4 id="创建通信组">创建通信组</h4><p><img src="/posts/2ac460b1/image-28.png"></p><ol type="1"><li><p><strong>PPO-Actor0（ds_rank0）所在的worker进程</strong>：<strong>通过handler引用，触发远端每个vllm_engine上的init_process_group操作，并将ds_rank0纳入通讯组</strong>。<a href="https://github.com/OpenRLHF/OpenRLHF/blob/bb46342711a203c457df2fbca5967fd0549557e0/openrlhf/trainer/ray/ppo_actor.py#L58">code</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create torch group with deepspeed rank 0 and all vllm ranks</span></span><br><span class="line"><span class="comment"># to update vllm engine&#x27;s weights after each training stage.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Say we have 3 vllm engines and eache of them has 4 GPUs,</span></span><br><span class="line"><span class="comment"># then the torch group is:</span></span><br><span class="line"><span class="comment"># [    0,      1, 2, 3, 4,  5, 6, 7, 8,  9, 10, 11, 12]</span></span><br><span class="line"><span class="comment"># |ds rank 0 |  engine-0  |  engine-1  |   engine-2   |</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># For ZeRO-1/2:</span></span><br><span class="line"><span class="comment">#   1. Broadcast parameters from rank 0 to all vllm engines</span></span><br><span class="line"><span class="comment"># For ZeRO-3:</span></span><br><span class="line"><span class="comment">#   1. AllGather paramters to rank 0</span></span><br><span class="line"><span class="comment">#   2. Broadcast parameters from rank 0 to all vllm engines</span></span><br><span class="line"><span class="keyword">if</span> <span class="variable language_">self</span>.vllm_engines <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> torch.distributed.get_rank() == <span class="number">0</span>:</span><br><span class="line">    ...</span><br><span class="line">    <span class="comment"># world_size = num_of_all_vllm_ranks + 1 ds_rank0</span></span><br><span class="line">    world_size = vllm_num_engines * vllm_tensor_parallel_size + <span class="number">1</span></span><br><span class="line">    ...</span><br><span class="line">    <span class="comment"># =====================================================================</span></span><br><span class="line">    <span class="comment"># 遍历每个vllm_engines，将其下的每个vllm_rank添加进通讯组中，这里又分成两步：</span></span><br><span class="line">    <span class="comment"># 1. engine.init_process_group.remote(...)：</span></span><br><span class="line">    <span class="comment">#    首先，触发远程vllm_engine的init_process_group方法</span></span><br><span class="line">    <span class="comment"># 2. 远程vllm_engine是一个包装过的vllm实例，它的init_process_group</span></span><br><span class="line">    <span class="comment">#    方法将进一步触发这个vllm实例下的各个worker进程（见4.4图例），</span></span><br><span class="line">    <span class="comment">#    最终是在这些worker进程上执行“将每个vllm_rank&quot;添加进ds_rank0通讯组的工作</span></span><br><span class="line">    <span class="comment"># =====================================================================</span></span><br><span class="line">    refs = [</span><br><span class="line">        engine.init_process_group.remote(</span><br><span class="line">            <span class="comment"># ds_rank0所在node addr</span></span><br><span class="line">            master_address, </span><br><span class="line">            <span class="comment"># ds_rank0所在node port</span></span><br><span class="line">            master_port,</span><br><span class="line">            <span class="comment"># 该vllm_engine的第一个rank在&quot;ds_rank0 + all_vllm_ranks“中的global_rank，</span></span><br><span class="line">            <span class="comment"># 该值将作为一个offset，以该值为起点，可以推算出该vllm_engine中其余vllm_rank的global_rank</span></span><br><span class="line">            i * vllm_tensor_parallel_size + <span class="number">1</span>, </span><br><span class="line">            world_size,</span><br><span class="line">            <span class="string">&quot;openrlhf&quot;</span>,</span><br><span class="line">            backend=backend,</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">for</span> i, engine <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="variable language_">self</span>.vllm_engines)</span><br><span class="line">    ]</span><br><span class="line">    <span class="comment"># =====================================================================</span></span><br><span class="line">    <span class="comment"># 将ds_rank0添加进通讯组中</span></span><br><span class="line">    <span class="comment"># =====================================================================</span></span><br><span class="line">    <span class="variable language_">self</span>._model_update_group = init_process_group(</span><br><span class="line">        backend=backend,</span><br><span class="line">        init_method=<span class="string">f&quot;tcp://<span class="subst">&#123;master_address&#125;</span>:<span class="subst">&#123;master_port&#125;</span>&quot;</span>,</span><br><span class="line">        world_size=world_size,</span><br><span class="line">        rank=<span class="number">0</span>,</span><br><span class="line">        group_name=<span class="string">&quot;openrlhf&quot;</span>,</span><br><span class="line">    )</span><br><span class="line">    <span class="comment"># =====================================================================</span></span><br><span class="line">    <span class="comment"># 确保all_vllm_ranks都已添加进通讯组中</span></span><br><span class="line">    <span class="comment"># =====================================================================</span></span><br><span class="line">    ray.get(refs)</span><br></pre></td></tr></table></figure></li><li><p><strong>每个vllm_engine（即每个包装后的vllm实例）下的worker进程</strong>：<a href="https://github.com/OpenRLHF/OpenRLHF/blob/bb46342711a203c457df2fbca5967fd0549557e0/openrlhf/trainer/ray/vllm_worker_wrap.py#L11">code</a></p><ul><li><strong>例如tp_size=2，那么每个vllm实例下就有2个worker进程，这两个worker进程都会运行这段代码。</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">WorkerWrap</span>(<span class="title class_ inherited__">Worker</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">init_process_group</span>(<span class="params">self, master_address, master_port, rank_offset, world_size, group_name, backend=<span class="string">&quot;nccl&quot;</span></span>):</span><br><span class="line">        <span class="keyword">assert</span> torch.distributed.is_initialized(), <span class="string">f&quot;default torch process group must be initialized&quot;</span></span><br><span class="line">        <span class="keyword">assert</span> group_name != <span class="string">&quot;&quot;</span>, <span class="string">f&quot;group name must not be empty&quot;</span></span><br><span class="line">        <span class="comment"># =====================================================================</span></span><br><span class="line">        <span class="comment"># torch.distributed.get_rank(): 在当前vllm_engine内部的rank，</span></span><br><span class="line">        <span class="comment">#                               例如在tp_size = 2时，这个值要么是0，要么是1</span></span><br><span class="line">        <span class="comment"># rank_offset：当前vllm_engine中的第一个rank在“ds_rank0 + all_vllm_ranks&quot;中的global_rank</span></span><br><span class="line">        <span class="comment"># 两者相加：最终得到当前rank在“ds_rank0 + all_vllm_ranks&quot;中的global_rank</span></span><br><span class="line">        <span class="comment"># =====================================================================</span></span><br><span class="line">        rank = torch.distributed.get_rank() + rank_offset</span><br><span class="line">        <span class="variable language_">self</span>._model_update_group = init_process_group(</span><br><span class="line">            backend=backend,</span><br><span class="line">            init_method=<span class="string">f&quot;tcp://<span class="subst">&#123;master_address&#125;</span>:<span class="subst">&#123;master_port&#125;</span>&quot;</span>,</span><br><span class="line">            world_size=world_size,</span><br><span class="line">            rank=rank,</span><br><span class="line">            group_name=group_name,</span><br><span class="line">        )</span><br><span class="line">        ...</span><br></pre></td></tr></table></figure></li></ol><h4 id="广播ppo-actor权重到all_vllm_ranks">广播PPO-Actor权重到all_vllm_ranks</h4><p>分成以下两步：</p><ol type="1"><li><p><strong>ds_rank0对应的worker进程中</strong>：<strong>PPO-Actords_rank0发送权重</strong> <a href="https://github.com/OpenRLHF/OpenRLHF/blob/bb46342711a203c457df2fbca5967fd0549557e0/openrlhf/trainer/ray/ppo_actor.py#L146">code</a></p><p>准备工作：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_broadcast_to_vllm</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="comment"># 1. 前缀缓存清理：清空 vLLM 的 KV Cache，避免旧参数生成的缓存影响新结果</span></span><br><span class="line">  use_prefix_cache = <span class="built_in">getattr</span>(<span class="variable language_">self</span>.strategy.args, <span class="string">&quot;enable_prefix_caching&quot;</span>, <span class="literal">False</span>)</span><br><span class="line">    cache_reset_refs = []</span><br><span class="line">    <span class="keyword">if</span> use_prefix_cache <span class="keyword">and</span> torch.distributed.get_rank() == <span class="number">0</span>:</span><br><span class="line">        <span class="comment"># clear prefix cache</span></span><br><span class="line">        <span class="keyword">for</span> engine <span class="keyword">in</span> <span class="variable language_">self</span>.vllm_engines:</span><br><span class="line">            cache_reset_refs.append(engine.reset_prefix_cache.remote())</span><br><span class="line">    <span class="comment"># 2. 清理GPU缓存，避免OOM</span></span><br><span class="line">    torch.cuda.empty_cache()</span><br><span class="line">    <span class="comment"># 3. 遍历模型参数，记录当前参数序号（count）和总参数数（num_params）</span></span><br><span class="line">    model = <span class="variable language_">self</span>.actor.model.module<span class="comment"># 获取底层模型（去掉 DP/DDP 包装）</span></span><br><span class="line">    count, num_params = <span class="number">0</span>, <span class="built_in">len</span>(<span class="built_in">list</span>(model.named_parameters()))</span><br><span class="line">    <span class="keyword">for</span> name, param <span class="keyword">in</span> model.named_parameters():</span><br><span class="line">        count += <span class="number">1</span>  </span><br></pre></td></tr></table></figure><p>广播模式分为两种，通过<code>self.use_cuda_ipc</code>切换：之后详细阐述</p></li><li><p><strong>每个vllm_engine（即每个包装后的vllm实例）下的worker进程</strong>：<strong>各个vllm_ranks接收权重</strong><a href="https://github.com/OpenRLHF/OpenRLHF/blob/bb46342711a203c457df2fbca5967fd0549557e0/openrlhf/trainer/ray/vllm_worker_wrap.py#L29">code</a></p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">update_weight</span>(<span class="params">self, name, dtype, shape, empty_cache=<span class="literal">False</span></span>):</span><br><span class="line">    <span class="keyword">if</span> torch.distributed.get_rank() == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;update weight: <span class="subst">&#123;name&#125;</span>, dtype: <span class="subst">&#123;dtype&#125;</span>, shape: <span class="subst">&#123;shape&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">assert</span> dtype == <span class="variable language_">self</span>.model_config.dtype, <span class="string">f&quot;mismatch dtype: src <span class="subst">&#123;dtype&#125;</span>, dst <span class="subst">&#123;self.model_config.dtype&#125;</span>&quot;</span></span><br><span class="line">    <span class="comment"># 创建同尺寸空张量用于接收ds_rank0广播来的权重</span></span><br><span class="line">    weight = torch.empty(shape, dtype=dtype, device=<span class="string">&quot;cuda&quot;</span>)</span><br><span class="line">    <span class="comment"># 接收权重</span></span><br><span class="line">    torch.distributed.broadcast(weight, <span class="number">0</span>, group=<span class="variable language_">self</span>._model_update_group)</span><br><span class="line"><span class="comment"># 使用接收到的权重进行更新</span></span><br><span class="line">    <span class="variable language_">self</span>.model_runner.model.load_weights(weights=[(name, weight)])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">del</span> weight</span><br></pre></td></tr></table></figure></li></ol><h5 id="默认常规广播ray-collective-或-pytorch-ddp">默认：常规广播（RayCollective 或 PyTorch DDP）</h5><p>条件：<code>self.use_cuda_ipc = False</code>（初始化）</p><ul><li><code>use_ray=True</code>：使用 <code>ray.util.collective</code>进行跨节点广播</li><li><code>use_ray=False</code>：使用 PyTorch 原生<code>torch.distributed.broadcast</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> <span class="variable language_">self</span>.use_cuda_ipc:</span><br><span class="line">    use_ray = <span class="built_in">getattr</span>(<span class="variable language_">self</span>.strategy.args, <span class="string">&quot;vllm_sync_with_ray&quot;</span>, <span class="literal">False</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Rank 0 准备vLLM更新请求</span></span><br><span class="line">    <span class="keyword">if</span> torch.distributed.get_rank() == <span class="number">0</span>:</span><br><span class="line">        shape = param.shape <span class="keyword">if</span> <span class="variable language_">self</span>.strategy.args.zero_stage != <span class="number">3</span> <span class="keyword">else</span> param.ds_shape</span><br><span class="line">        refs = [engine.update_weight.remote(name, dtype, shape, count==num_params) </span><br><span class="line">               <span class="keyword">for</span> engine <span class="keyword">in</span> <span class="variable language_">self</span>.vllm_engines]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ZeRO-3 参数全收集 + 广播</span></span><br><span class="line">    <span class="keyword">with</span> deepspeed.zero.GatheredParameters([param], enabled=<span class="variable language_">self</span>.strategy.args.zero_stage == <span class="number">3</span>):</span><br><span class="line">        <span class="keyword">if</span> torch.distributed.get_rank() == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">if</span> use_ray:</span><br><span class="line">                collective.broadcast(param.data, <span class="number">0</span>, group_name=<span class="variable language_">self</span>._model_update_group)  <span class="comment"># Ray Collective</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                torch.distributed.broadcast(param.data, <span class="number">0</span>, group=<span class="variable language_">self</span>._model_update_group)  <span class="comment"># PyTorch DDP</span></span><br><span class="line">            ray.get(refs)  <span class="comment"># 等待vLLM更新完成</span></span><br></pre></td></tr></table></figure><h5 id="cuda-ipc-高速通信">CUDA IPC 高速通信</h5><p>条件：<strong>Actor和Rolloutcolocate</strong>，即采用<code>colocate_all_models</code>策略</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> backend == <span class="string">&quot;nccl&quot;</span> <span class="keyword">and</span> <span class="variable language_">self</span>.strategy.args.colocate_all_models:</span><br><span class="line">        <span class="variable language_">self</span>.use_cuda_ipc = <span class="literal">True</span></span><br></pre></td></tr></table></figure><p>当两个模块时 colocate 到一张卡上时，NCCL无法做同一张卡上两个进程的通信，所以需要<a href="https://link.zhihu.com/?target=https%3A//github.com/OpenRLHF/OpenRLHF/blob/17bbb313551a3af3cdd213d8b9e7522fe9c6271b/openrlhf/trainer/ray/ppo_actor.py%23L223-L232">用CUDA IPC 做进程间通信</a>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">with</span> deepspeed.zero.GatheredParameters([param], enabled=<span class="variable language_">self</span>.strategy.args.zero_stage == <span class="number">3</span>):</span><br><span class="line">        weight = param.data.clone()</span><br><span class="line">        ipc_handle = reduce_tensor(weight)  <span class="comment"># 生成IPC内存句柄</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 全收集所有Rank的IPC句柄</span></span><br><span class="line">        ipc_handle = &#123;get_physical_gpu_id(): ipc_handle&#125;</span><br><span class="line">        ipc_handle_list = [<span class="literal">None</span>] * torch.distributed.get_world_size()</span><br><span class="line">        torch.distributed.all_gather_object(ipc_handle_list, ipc_handle)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Rank 0 通过IPC更新vLLM</span></span><br><span class="line">        <span class="keyword">if</span> torch.distributed.get_rank() == <span class="number">0</span>:</span><br><span class="line">            ipc_handles = &#123;&#125;</span><br><span class="line">            <span class="keyword">for</span> d <span class="keyword">in</span> ipc_handle_list: ipc_handles.update(d)  <span class="comment"># 合并所有GPU的句柄</span></span><br><span class="line">            </span><br><span class="line">            refs = [engine.update_weight_cuda_ipc.remote(name, dtype, shape, ipc_handles, count==num_params)</span><br><span class="line">                   <span class="keyword">for</span> engine <span class="keyword">in</span> <span class="variable language_">self</span>.vllm_engines]</span><br><span class="line">            ray.get(refs)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 同步点</span></span><br><span class="line">        torch.distributed.barrier()</span><br><span class="line">        torch.cuda.synchronize()</span><br></pre></td></tr></table></figure><blockquote><p>ZeRO-3并行：</p><ol type="1"><li>先在 Actor workers 内部 all_gather 权重；</li><li>再由 rank0 代表 Actor 向所有 Rollout 实例 broadcast 权重。</li></ol></blockquote><h2 id="参考">参考</h2><p><a href="https://arxiv.org/html/2405.11143v4">OpenRLHF: AnEasy-to-use, Scalable and High-performance RLHF Framework</a></p><p><a href="https://arxiv.org/abs/2409.19256">HybridFlow: A Flexible andEfficient RLHF Framework</a></p><p><a href="https://en.wikipedia.org/wiki/Single_program,_multiple_data">Singleprogram, multiple data</a></p><p><a href="https://zhuanlan.zhihu.com/p/29046833667">品鉴一下OpenRLHF和verl的系统设计</a></p><p><a href="https://zhuanlan.zhihu.com/p/26833089345">基于 Ray的分离式架构：veRL、OpenRLHF 工程设计</a></p><p><a href="https://github.com/zhaochenyang20/Awesome-ML-SYS-Tutorial/blob/main/rlhf/verl/readme.md">HybridFlowveRL 原文浅析</a></p><p><a href="https://github.com/zhaochenyang20/Awesome-ML-SYS-Tutorial/blob/main/rlhf/OpenRLHF/readme.md#更新流程">浅析以OpenRLHF 为代表的 post-training 系统的计算流程</a></p><p><a href="https://zhuanlan.zhihu.com/p/12871616401">图解OpenRLHF中基于Ray的分布式训练流程</a></p><p><a href="https://zhuanlan.zhihu.com/p/1902472584827732882">分布式RLHF武庙十哲下- 手抓饼熊的文章 - 知乎</a></p>]]></content>
      
      
      <categories>
          
          <category> Parallelism </category>
          
          <category> verl </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>verl框架：1. Ray集群介绍+verl中基于Ray的执行流程解析</title>
      <link href="/posts/5d9f220e.html"/>
      <url>/posts/5d9f220e.html</url>
      
        <content type="html"><![CDATA[<h2 id="现代计算机体系结构">现代计算机体系结构</h2><p>现代计算机体系结构如下：</p><ul><li><strong>多核</strong>：一台计算机上有多颗CPU，每个 CPU有多个计算核心。CPU内部有缓存结构，外部有主存。</li><li><strong>集群</strong>：多台计算机通过高速网络互联，每台计算机上配有至少一块高速网卡。使得不同节点之间互相访问数据就像在单个节点一样。</li><li><strong>异构计算</strong>：CPU和主存通常被称为主机（Host），各类专用的加速器被称为设备（Device）。当前基于GPU 的异构计算是主流，GPU 有区别于 CPU 的芯片微架构和编译软件栈。<ul><li>软件层面：GPU 提供了 CUDA编程接口；</li><li>硬件层面：GPU 有很多个专用计算核心，和 GPU 上的存储。</li></ul></li></ul><p><img src="/posts/5d9f220e/computer-arch.svg"></p><h2 id="并行程序设计方法pcam">并行程序设计方法：PCAM</h2><p>如何设计软件和算法，使得程序可以并行运行在多核或者集群上？PCAM共包括4个步骤：</p><ul><li><strong>切分</strong>：将整个问题切分为多个子问题或子任务，既包括计算部分也包括数据部分；</li><li><strong>通信</strong>：不同子任务之间通信方式，需要包括通信的数据结构、通信算法；</li><li><strong>聚集</strong>：考虑到当前所拥有的硬件性能和编程难度，将上面两步进一步整合，将细粒度的任务整合成更高效的任务；</li><li><strong>分发</strong>：将整合好的任务分发给多个处理器。</li></ul><blockquote><p>举个栗子：有一个超大矩阵，矩阵大小为M×M，这个矩阵大到无法放在单个计算节点上计算，现在想获取这个矩阵的最大值。设计并行算法时，可以考虑如下思路：</p><ul><li>将矩阵切分成子矩阵，每个子矩阵 m×m大小，在<strong>每台计算节点上执行 <code>max()</code>函数</strong>求得子矩阵的最大值；</li><li>将<strong>每个子矩阵的最大值汇集到一个计算节点</strong>，在该节点再次执行一下<code>max()</code> 求得整个矩阵的最大值；</li></ul></blockquote><p><img src="/posts/5d9f220e/pcam.svg"></p><h3 id="案例mapreduce">案例：MapReduce</h3><p>Google在2004年提出的MapReduce是一种经典的大数据并行计算范式。其中主要涉及四个阶段：</p><ul><li>切分（Split）：将大数据切分成很多份小数据，<strong>每份小数据可以在单个Worker 上计算</strong>。</li><li>映射（Map）：<strong>对每个小数据执行 Map 操作</strong>，Map是一个函数映射，程序员需要<strong>自定义 Map 函数，Map函数输出一个键值对（Key-Value）</strong>。在词频统计的例子中，每出现一个词，计1 次，Key 是词，Value 是 1，表示出现 1 次。</li><li>交换（Shuffle）：<strong>将相同的 Key 归结到相同的 Worker上</strong>。这一步涉及数据交换。词频统计的例子中，将相同的词发送到同一个Worker 上。</li><li>聚合（Reduce）：<strong>所有相同的 Key进行聚合操作</strong>，程序员需要<strong>自定义 Reduce函数</strong>。词频统计的例子中，之前 Shuffle 阶段将已经将相同的 Key归结到了一起，现在只需要将所有词频求和。</li></ul><p><img src="/posts/5d9f220e/map-reduce.svg"></p><h3 id="性能指标">性能指标</h3><h4 id="flops">FLOPs</h4><p>FLOPS 指<strong>每秒钟能够完成多少次浮点计算</strong>。如果进行一个 n维向量加法：a+b，所需的浮点计算次数为 n。将浮点计算次数除以时间，就是FLOPS。</p><h4 id="加速比">加速比</h4><p>衡量并行相对于串行执行时间的缩短程度：加速比=<span class="math inline">\(\frac{t_s}{t_p}\)</span>，其中 <span class="math inline">\(t_s\)</span> 为串行程序执行时间，<span class="math inline">\(t_p\)</span> 为并行程序执行时间。</p><ul><li><strong>效率</strong>：效率=<span class="math inline">\(\frac{加速比}{N}\)</span>。其中 N为并行程序所使用的计算核心的数目。</li></ul><p>当加速比为 N时，串行程序可以被线性拓展到多个计算核心上，可以说并行程序获得了<strong>线性加速比</strong>，即理想情况。现实中，并行程序需要有调度器将不同的任务分发到多个Worker 上，多个 Worker 之间需要通信，以及数据需要在多个 Worker之间需要同步，这些步骤都会浪费时间。</p><h2 id="ray">Ray</h2><h3 id="ray结构">Ray结构</h3><p>Ray最初为强化学习设计。</p><p>当前 Ray 主要由底层的 Ray Core 和上层的各类 Ray AI (ArtificialIntelligence) 生态组成：</p><ul><li>Ray Core 是一系列底层 API, 可以将 Python 函数或者 Python类等计算任务<strong>横向扩展到多个计算节点上</strong>；</li><li>在 Ray Core 之上，Ray 封装了一些面向数据科学和人工智能的库（Ray AILibraries），可以进行数据的处理（Ray Data）、模型训练（RayTrain）、模型的超参数调优（Ray Tune），模型推理服务（RayServe），强化学习（RLib）等。</li></ul><h5 id="ray-core-api">Ray Core API</h5><p>Ray Core的核心API如下：</p><ul><li><strong>Task</strong>：面向<strong>函数</strong>的接口，该函数可在集群中分布式执行；</li><li><strong>Actor</strong>：面向<strong>类</strong>的接口，该类可在集群中分布式执行；</li><li><strong>Object</strong>：分布式对象（不可变），用于在<strong>Task和Actor之间传递数据</strong>。</li></ul><p><img src="/posts/5d9f220e/ray-apis.svg"></p><h4 id="分布式函数remote-functionray.remote-装饰器">分布式函数（RemoteFunction）：<code>@ray.remote</code> 装饰器</h4><p>通过RayAPI定义的Task即远程函数，可以运行在远程的Ray集群上。远程函数是<strong>无状态</strong>的：只依赖于函数的输入和输出，不依赖函数作用域之外的中间变量。那么如何将Python 函数横向扩展到 Ray 集群上？</p><ul><li><p><strong>启动Ray集群</strong>：可使用<a href="https://docs.ray.io/en/latest/ray-core/api/doc/ray.init.html">ray.init()函数</a>，启动一个<strong>单节点的Ray集群</strong>，运行在执行这个Python 任务的计算机上。例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> ray.is_initialized:</span><br><span class="line">    ray.shutdown()</span><br><span class="line">ray.init(logging_level=logging.ERROR)</span><br></pre></td></tr></table></figure></li></ul><p>通过几个栗子演示。假设使用原生的Python定义一个fibonacci函数，想让这个Python 函数被 Ray 分布式执行，只需要<strong>在函数上增加一个<code>@ray.remote</code> 装饰器</strong>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># fibonacci函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate_fibonacci</span>(<span class="params">sequence_size</span>):</span><br><span class="line">    fibonacci = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, sequence_size):</span><br><span class="line">        <span class="keyword">if</span> i &lt; <span class="number">2</span>:</span><br><span class="line">            fibonacci.append(i)</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        fibonacci.append(fibonacci[i-<span class="number">1</span>] + fibonacci[i-<span class="number">2</span>])</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">len</span>(fibonacci)</span><br><span class="line"><span class="comment"># 在函数上增加一个 @ray.remote 装饰器</span></span><br><span class="line"><span class="meta">@ray.remote</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate_fibonacci_distributed</span>(<span class="params">sequence_size</span>):</span><br><span class="line">    <span class="keyword">return</span> generate_fibonacci(sequence_size)</span><br></pre></td></tr></table></figure><p><strong>作为 Ray 的使用者，无需关心 Task 在 Ray集群中是如何被分布式执行的，也不需要了解这个 Task被调度到哪些计算节点</strong>。所有这些分布式执行的细节都被 Ray所隐藏，或者说 Ray 帮我们做了底层的分布式与调度这些工作。</p><p>使用 Ray 进行分布式扩展，函数可并行地在多个 CPU 核心上执行：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用 Ray 进行分布式扩展</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run_remote</span>(<span class="params">sequence_size</span>):</span><br><span class="line">    results = ray.get([generate_fibonacci_distributed.remote(sequence_size) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(os.cpu_count())])</span><br><span class="line">    <span class="keyword">return</span> results</span><br></pre></td></tr></table></figure><blockquote><p>原生Python函数和Ray的区别：</p><ul><li><strong>调用方式</strong>：<ul><li>原生Python函数：使用 <code>func_name()</code> 调用；</li><li>使用 Ray 时：函数定义增加 <code>@ray.remote</code>装饰器，调用时使用 <a href="https://docs.ray.io/en/latest/ray-core/api/doc/ray.remote.html"><code>func_name.remote()</code></a>的形式。</li></ul></li><li><strong>返回值</strong>：<ul><li>使用 Ray 时：<code>func_name.remote()</code> 返回值是<code>ray.ObjectRef</code><strong>类型的对象</strong>，<code>ray.ObjectRef</code>并不是一个具体的值，而是一个Future（尚未完成但未来会完成的计算），需要<strong>使用 <a href="https://docs.ray.io/en/latest/ray-core/api/doc/ray.get.html"><code>ray.get()</code></a>函数获取该调用的实际返回值</strong>。</li></ul></li><li><strong>执行方式</strong>：<ul><li>原生Python函数：调用形成阻塞，等待结果返回才进行后续计算（<strong>同步执行</strong>）；<ul><li>使用 Ray时：<strong>异步执行</strong>（<code>func_name.remote</code>非阻塞；<code>ray.get(ObjectRef)</code>阻塞）</li><li>立即返回一个<code>ray.ObjectRef</code>，调用者不需要等待这个函数的计算真正执行完，函数的计算是在后台某个计算节点上执行的；</li><li><code>ray.get(ObjectRef)</code>会等待后台计算结果执行完，将结果返回给调用者。</li></ul></li></ul></li></ul></blockquote><h4 id="分布式对象remote-object存储ray.put-与-ray.get">分布式对象（RemoteObject）存储：<code>ray.put()</code> 与 <code>ray.get()</code></h4><p>Ray分布式计算中涉及共享数据可被放在分布式对象存储中，这些数据被称为<strong>远程对象</strong>。我们可以使用<a href="https://docs.ray.io/en/latest/ray-core/api/doc/ray.get.html"><code>ray.get()</code></a>和 <a href="https://docs.ray.io/en/latest/ray-core/api/doc/ray.put.html"><code>ray.put()</code></a>读写这些远程对象。与内存中的 Python 对象实例不同，Remote Object是不可原地直接更改的。</p><p>操作 Remote Object 主要有 <code>ray.put()</code> 和<code>ray.get()</code> 两个 API：</p><ul><li><code>ray.put()</code>：把<strong>某个计算节点中的对象数据进行序列化</strong>，并将其<strong>写入到Ray 集群的分布式对象存储中</strong>，返回一个<code>RefObjectID</code>（<code>RefObjectID</code> 是<strong>指向这个Remote Object 的指针</strong>）。我们可以通过引用这个<code>RefObjectID</code>，在 Remote Function 或 Remote Class中分布式地使用这个数据对象。</li><li><code>ray.get()</code> ：使用 <code>RefObjectID</code>把数据从分布式对象存储中拉取回来，并进行<strong>反序列化</strong>。</li><li><img src="/posts/5d9f220e/put-get-object-store.svg"></li></ul><p>举个栗子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">create_rand_tensor</span>(<span class="params">size: <span class="type">Tuple</span>[<span class="built_in">int</span>, <span class="built_in">int</span>, <span class="built_in">int</span>]</span>) -&gt; torch.tensor:</span><br><span class="line">    <span class="keyword">return</span> torch.randn(size=(size), dtype=torch.<span class="built_in">float</span>)</span><br><span class="line"></span><br><span class="line">torch.manual_seed(<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 写入数据：put(创建 16 个张量，每个张量大小为 (X, 8, 8))</span></span><br><span class="line">tensor_obj_ref_list = [ray.put(create_rand_tensor((i, <span class="number">8</span>, <span class="number">8</span>))) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">16</span>)]</span><br><span class="line"><span class="comment"># 读取数据：get</span></span><br><span class="line">val = ray.get(tensor_obj_ref_list[<span class="number">0</span>])</span><br></pre></td></tr></table></figure><h5 id="修改数据">修改数据</h5><p>Remote Ojbect中的数据是不可修改的（Immutable），即无法对变量原地更改。在单机上，我们可以对变量进行赋值；但<strong>在Ray 中，我们无法原地更改 Remote Object 的值</strong>。</p><p>如果想使用新数据，应该使用 Remote Function 或者 Remote Class 对Remote Object 进行转换操作，<strong>生成新的 RemoteObject</strong>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@ray.remote</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">transform_tensor</span>(<span class="params">tensor: torch.tensor</span>) -&gt; torch.tensor:</span><br><span class="line">    <span class="keyword">return</span> torch.transpose(tensor, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line"><span class="comment"># 使用Remote Function更改数据</span></span><br><span class="line">transformed_object_list = [transform_tensor.remote(t_obj_ref) <span class="keyword">for</span> t_obj_ref <span class="keyword">in</span> tensor_obj_ref_list]</span><br></pre></td></tr></table></figure><h5 id="传递参数通过refobjectid">传递参数：通过<code>RefObjectID</code></h5><ol type="1"><li><p><strong>直接传递</strong>：在 Task 或者 Actor 的函数调用时，将<code>RefObjectID</code> 作为参数传递进去。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@ray.remote</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">echo</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;current value of argument x: <span class="subst">&#123;x&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">x = <span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">5</span>))</span><br><span class="line"><span class="comment"># `x_obj_ref` 是一个 `RefObjectID`</span></span><br><span class="line">x_obj_ref = ray.put(x)</span><br><span class="line"><span class="comment"># 直接将RefObjectID作为参数传递，echo()这个 Remote Function 将自动从 `x_obj_ref` 获取 `x` 的值，该过程称为：自动反引用</span></span><br><span class="line">ray.get(echo.remote(x_obj_ref))</span><br></pre></td></tr></table></figure></li></ol><p>​输出：<code>(echo pid=22623) current value of argument x: [0, 1, 2, 3, 4]</code></p><ol start="2" type="1"><li><p><strong>复杂数据结构</strong>：如果 <code>RefObjectID</code>被包裹在一个复杂的数据结构中，Ray 并不会自动获取<code>RefObjectID</code> 对应的值，即反引用并不是自动的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ray.get(echo.remote(&#123;<span class="string">&quot;obj&quot;</span>: x_obj_ref&#125;))<span class="comment"># 包裹在一个 dict 中</span></span><br><span class="line">ray.get(echo.remote([x_obj_ref]))<span class="comment"># 包裹在一个 list 中</span></span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(echo pid=<span class="number">70963</span>) current value of argument x: &#123;<span class="string">&#x27;obj&#x27;</span>: ObjectRef(00ffffffffffffffffffffffffffffffffffffff0100000010000000)&#125;</span><br><span class="line">(echo pid=<span class="number">70963</span>) current value of argument x: [ObjectRef(00ffffffffffffffffffffffffffffffffffffff0100000010000000)]</span><br></pre></td></tr></table></figure></li></ol><h5 id="底层实现">底层实现</h5><ol type="1"><li><p>Ray集群的<strong>每个计算节点，都有一个基于共享内存的对象存储</strong>。</p></li><li><p>当某个 Remote Object 的数据量较小时（&lt;= 100KB），它会被存储在<strong>计算节点进程内存</strong>中；当数据量较大时，它会被存储在<strong>分布式的共享内存</strong>中；当集群的共享内存的空间不够时，数据会被<strong>外溢（Spill）到持久化的存储上</strong>，比如硬盘或者S3。</p></li></ol><h4 id="分布式类actor">分布式类（Actor）</h4><p>举个栗子：</p><ol type="1"><li><p>Ray 的 Remote Class 也使用 <a href="https://docs.ray.io/en/latest/ray-core/api/doc/ray.remote.html"><code>ray.remote()</code></a>来装饰；</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@ray.remote</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Counter</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.value = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">increment</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.value += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.value</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_counter</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.value</span><br></pre></td></tr></table></figure></li><li><p>初始化一个实例：在类名 <code>Counter</code> 后面加上<code>remote()</code>，即创建一个分布式的 Actor;</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">counter = Counter.remote()</span><br></pre></td></tr></table></figure></li><li><p>调用实例的函数：加上<code>remote()</code>，即<code>对象实例.函数名.remote()</code>；</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">obj_ref = counter.increment.remote()</span><br><span class="line"><span class="built_in">print</span>(ray.get(obj_ref))</span><br></pre></td></tr></table></figure></li></ol><p>可以用同一个类创建不同的 Actor 实例：<strong>不同 Actor实例的成员函数调用可以并行化执行；同一个 Actor的成员函数调用顺序执行。</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建 10 个 Actor 实例</span></span><br><span class="line">counters = [Counter.remote() <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对每个 Actor 进行 increment 操作</span></span><br><span class="line"><span class="comment"># 这些操作可以分布式执行</span></span><br><span class="line">results = ray.get([c.increment.remote() <span class="keyword">for</span> c <span class="keyword">in</span> counters])</span><br><span class="line"><span class="built_in">print</span>(results)</span><br></pre></td></tr></table></figure><blockquote><p>Actor编程模型：分布式编程的范式，基本要素是 <strong>Actor实例</strong>，即每个 Actor 对象都是唯一的。可以把单个 Actor实例理解成单个带地址信息的进程。</p><ul><li>Actor 存储的状态数据只能由 Actor 自己来管理，不能被其他 Actor修改；</li><li><strong>消息驱动</strong>：给某个 Actor发送消息，它就会对该消息进行响应，修改自身的状态或者继续给其他 Actor发送消息。</li><li>对同一个 Actor 多次发送同样请求，多次请求是顺序执行的。</li></ul></blockquote><h5 id="栗子actor-pool">栗子：Actor Pool</h5><p>实践上，经常创建一个 Actor 资源池（Actor Pool），<a href="https://docs.ray.io/en/latest/ray-core/api/doc/ray.util.ActorPool.html"><code>ActorPool</code></a>有点像 <code>multiprocessing.Pool</code>，包含多个 Actor，每个 Actor功能一样，而且可以分布式地在多个计算节点上运行。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> ray.util <span class="keyword">import</span> ActorPool</span><br><span class="line"><span class="comment"># 定义一个Actor</span></span><br><span class="line"><span class="meta">@ray.remote</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PoolActor</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">add</span>(<span class="params">self, operands</span>):</span><br><span class="line">        (a, b) = operands</span><br><span class="line">        <span class="keyword">return</span> a + b</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">double</span>(<span class="params">self, operand</span>):</span><br><span class="line">        <span class="keyword">return</span> operand * <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建3个Actor实例</span></span><br><span class="line">a1, a2, a3 = PoolActor.remote(), PoolActor.remote(), PoolActor.remote()</span><br><span class="line"><span class="comment"># 将创建的 Actor 添加至 ActorPool 中</span></span><br><span class="line">pool = ActorPool([a1, a2, a3])</span><br></pre></td></tr></table></figure><p>如果我们想调用 <code>ActorPool</code> 中的 Actor，可以使用 <a href="https://docs.ray.io/en/latest/ray-core/api/doc/ray.util.ActorPool.map.html"><code>map(fn, values)</code></a>和 <a href="https://docs.ray.io/en/latest/ray-core/api/doc/ray.util.ActorPool.submit.html"><code>submit(fn, value)</code></a>方法。</p><ul><li><code>map()</code> ：<code>values</code>是一个列表，让函数<strong>并行地分发给多个 Actor 处理</strong>；</li><li><code>submit()</code>： <code>value</code> 是单个值，<strong>每次从<code>ActorPool</code> 中选择一个 Actor 执行</strong>。<ul><li><code>submit()</code> 的 <code>value</code>参数只能是单个对象，不能是参数列表，如果想传入多个参数，可以把参数包裹成元组。</li></ul></li></ul><p><code>fn</code> 是一个 Lambda 表达式，或者说是一个匿名函数。这个Lambda 表达式有两个参数：<code>actor</code> 和<code>value</code>，<code>actor</code> 是<code>ActorPool</code> 中的Actor，第二个参数是函数的参数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pool.<span class="built_in">map</span>(<span class="keyword">lambda</span> a, v: a.double.remote(v), [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">4</span>])</span><br><span class="line"></span><br><span class="line">pool.submit(<span class="keyword">lambda</span> a, v: a.double.remote(v), <span class="number">3</span>)</span><br><span class="line">pool.submit(<span class="keyword">lambda</span> a, v: a.double.remote(v), <span class="number">4</span>)</span><br></pre></td></tr></table></figure><p><code>map()</code> 和 <code>submit()</code> 将计算任务提交到了<code>ActorPool</code> 中，<code>ActorPool</code>并不是直接返回结果，而是异步地分发给后台不同的 Actor 去执行。需要使用 <a href="https://docs.ray.io/en/latest/ray-core/api/doc/ray.util.ActorPool.get_next.html"><code>get_next()</code></a>阻塞地返回结果。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="built_in">print</span>(pool.get_next())</span><br><span class="line">    <span class="built_in">print</span>(pool.get_next())</span><br><span class="line">    <span class="built_in">print</span>(pool.get_next())</span><br><span class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(e)</span><br></pre></td></tr></table></figure><p>结果为：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">6</span><br><span class="line">8</span><br><span class="line">10</span><br></pre></td></tr></table></figure><h3 id="ray集群">Ray集群</h3><p>Ray集群由一系列计算节点组成，包括两类关键的节点：<strong>头节点</strong>（Head）和<strong>工作节点</strong>（Worker）。这些节点可以部署在虚拟机、容器或者是裸金属服务器上。</p><p>头节点额外包括：GCS，即Ray集群的全局元数据管理服务；负责存储和管理诸如哪个 Actor被分配到哪个计算节点等元数据信息。这些<strong>元数据被所有 Worker共享</strong>。</p><p>每个节点包括一个<strong>Driver：执行程序的入口点，指的是Python 的<code>__main__</code> 函数</strong>。通常，<code>__main__</code>在运行时不应该执行大规模计算，而是负责将 Task 和 Actor调度到具备足够资源的 Worker 上。</p><p><img src="/posts/5d9f220e/ray-cluster.svg"></p><p>在 Ray 分布式计算环境中，所有节点上都运行着一些关键进程。</p><ul><li><p><strong>Raylet</strong>：<strong>每个计算节点上运行着一个Raylet</strong>， Raylet 被多个 Worker 进程所共享。Raylet主要包含两个组件：一个是<strong>调度器</strong>，它负责资源管理和任务分配；另一个是<strong>基于共享内存的对象存储</strong>，它负责本地数据存储，各个计算节点上的对象存储共同构成了Ray 集群的分布式对象存储。</p></li><li><p><strong>Worker</strong>：<strong>每个计算节点上运行着一个或多个Worker 进程</strong>，这些进程负责执行计算任务。Worker进程可以是无状态的，意味着它们可以反复执行 Task对应的任务；它们也可以是有状态的Actor，即执行远程类的方法。<strong>默认情况下，Worker的数量等于其所在计算节点的 CPU 核心数</strong>。</p></li></ul><p>启动Ray集群：如果Python 代码中使用 <code>ray.init()</code>方式，仅在本地启动了一个单机的 Ray 集群。实际上，Ray集群包括头节点和工作节点，应该分别启动。先在头节点启动：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ray start --<span class="built_in">head</span> --port=6379</span><br></pre></td></tr></table></figure><p>启动工作节点：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ray start --address=&lt;head-node-address&gt;:&lt;port&gt;</span><br></pre></td></tr></table></figure><p>通过<code>ray up example.yaml</code>启动：接收 yaml 文件作为参数，在yaml 文件里定义好头节点地址、工作节点地址。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">cluster_name:</span> <span class="string">default</span></span><br><span class="line"></span><br><span class="line"><span class="attr">provider:</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">local</span></span><br><span class="line">    <span class="attr">head_ip:</span> <span class="string">YOUR_HEAD_NODE_HOSTNAME</span></span><br><span class="line">    <span class="attr">worker_ips:</span> [<span class="string">WORKER_NODE_1_HOSTNAME</span>, <span class="string">WORKER_NODE_2_HOSTNAME</span>, <span class="string">...</span> ]</span><br></pre></td></tr></table></figure><blockquote><p>Ray 的头节点暴露三个端口号，默认分别是 6379, 8265, 10001。</p><ol type="1"><li>启动 Ray 时，设置了 Ray 头节点的端口号，默认为<strong>6379</strong>，是<strong>头节点和工作节点之间通信的端口</strong>；</li><li>Ray 头节点启动后，提供了一个 Ray 仪表盘端口号，默认为8265，可用来接收 Ray 命令行提交的作业；</li><li>此外，还有一个端口 10001，默认为 <code>ray.init()</code>连接时使用。</li></ol></blockquote><h4 id="计算资源与资源组">计算资源与资源组</h4><p>Ray 可以管理计算资源，包括 CPU、内存和 GPU等各类加速器。这里的计算资源是逻辑上的，逻辑资源与物理上的计算资源相对应。<strong>Ray集群的各个节点启动时会探测物理计算资源，并根据一定规则映射为逻辑上的计算资源。</strong>默认规则如下：</p><ul><li><p>CPU：每个节点中的物理 CPU 个数（<code>num_cpus</code>）</p></li><li><p>GPU：每个节点中的物理 GPU 个数（<code>num_gpus</code>）</p></li><li><p>内存：每个节点可用内存的 70%（<code>memory</code>）</p><p>可自行指定：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ray start --num-cpus=32 --num-gpus=4</span><br></pre></td></tr></table></figure></li></ul><p>Ray集群支持<strong>自动缩放</strong>，指的是满足 Task 或 Actor代码中定义的计算资源请求（比如，<code>task.options()</code>请求的计算资源），而不是根据计算节点的资源实际利用情况自动缩放。主要面向以下场景：</p><ul><li>当 Ray 集群的资源不够时，创建新的工作节点。</li><li>当某个工作节点闲置或者无法启动，将该工作节点关闭。</li></ul><h5 id="资源需求">资源需求</h5><p>默认情况下：</p><ul><li><p>RayTask使用1个逻辑CPU，既用于任务调度，也用于执行计算任务；</p></li><li><p>Ray Actor使用1个逻辑CPU进行任务调度，0 个 CPU 运行计算任务。</p><ul><li><p>如果不做设置，可能造成 Ray Actor 不需要计算资源的假象，导致大量Actor 被调度到同一个计算节点上。可进行指定：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@ray.remote(<span class="params">num_cpus=<span class="number">4</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">func</span>():</span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line"><span class="meta">@ray.remote(<span class="params">num_cpus=<span class="number">16</span>, num_gpus=<span class="number">1</span></span>)</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Actor</span>:</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 或者：</span></span><br><span class="line">func.options(num_cpus=<span class="number">4</span>).remote()</span><br></pre></td></tr></table></figure></li></ul></li></ul><h5 id="资源组placement-group">资源组（Placement Group）</h5><p>允许用户<strong>原子地</strong>使用集群上多个节点的计算资源：资源要么全部分配给用户，要么完全不分配，不会出现只分配部分资源的情况。主要适用以下场景：</p><ul><li><strong>组调度</strong>：一个作业需要一组资源，这些资源需要协同工作以完成任务。要么分配，要么不分配。如果只分配给这个作业部分资源，将无法完成整个任务。<ul><li>例如在大规模分布式训练中：可能需要多台计算节点和多块GPU，这时可以在Ray集群中申请并分配这些资源。</li></ul></li><li><strong>负载均衡</strong>：作业需要在多个节点上进行负载均衡，每个节点承担一小部分任务。PlacementGroup可以确保作业尽量分散到多个计算节点上。<ul><li>例如在分布式推理场景中：如果一个作业需要8块GPU，每个GPU负责加载模型并独立进行推理，为了实现负载均衡，应该将作业调度到8个计算节点上，每个节点使用1块GPU。这样做的好处是，如果一个节点发生故障，不会导致整个推理服务不可用，因为其他节点仍然可以继续工作。</li></ul></li></ul><p>关键概念：</p><ul><li><strong>资源包（Bundle）</strong>：<strong>一个键值对，定义所需的计算资源</strong>，比如<code>&#123;"CPU": 2&#125;</code>，或<code>&#123;"CPU": 8, "GPU": 4&#125;</code>。<strong>一个 Bundle必须可以调度到单个计算节点</strong>；比如，一个计算节点只有 8 块GPU，<code>&#123;"GPU": 10&#125;</code> 是不合理的。<ul><li>多个 Ray Task 或 Actor 可以运行在同一个 Bundle 上；任何使用同一个Bundle 的 Task 或 Actor 将一直运行在该计算节点上。</li></ul></li><li><strong>资源组（Placement Group）</strong>：Placement Group是<strong>一组 Bundle</strong>。比如，<code>&#123;"CPU": 8&#125; * 4</code> 向 Ray集群申请 4 个 Bundle，每个 Bundle 预留 8 个 CPU。</li></ul><p>举个完整栗子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> ray.util.placement_group <span class="keyword">import</span> (</span><br><span class="line">    placement_group,</span><br><span class="line">    placement_group_table,</span><br><span class="line">    remove_placement_group,</span><br><span class="line">)</span><br><span class="line"><span class="keyword">from</span> ray.util.scheduling_strategies <span class="keyword">import</span> PlacementGroupSchedulingStrategy</span><br><span class="line"><span class="keyword">import</span> ray</span><br><span class="line"><span class="comment"># 启动ray集群</span></span><br><span class="line">ray.init()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;&#x27;&#x27;Available Resources: &#123;&#125;&#x27;&#x27;&#x27;</span>.<span class="built_in">format</span>(ray.available_resources()))</span><br><span class="line"></span><br><span class="line"><span class="meta">@ray.remote(<span class="params">num_gpus=<span class="number">2</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gpu_task</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;GPU ids: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(ray.get_runtime_context().get_accelerator_ids()[<span class="string">&quot;GPU&quot;</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 Placement Group：包括一个Bundle</span></span><br><span class="line">pg = placement_group([&#123;<span class="string">&quot;CPU&quot;</span>: <span class="number">16</span>, <span class="string">&quot;GPU&quot;</span>: <span class="number">2</span>&#125;])</span><br><span class="line"><span class="comment"># 等待 Placement Group 创建成功</span></span><br><span class="line">ray.get(pg.ready(), timeout=<span class="number">10</span>)</span><br><span class="line"><span class="comment"># 也可以使用 ray.wait</span></span><br><span class="line">ready, unready = ray.wait([pg.ready()], timeout=<span class="number">10</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;&#x27;&#x27;Placement Group: &#123;&#125;&#x27;&#x27;&#x27;</span>.<span class="built_in">format</span>(placement_group_table(pg)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将 Ray Task 调度到这个 Placement Group</span></span><br><span class="line">ray.get(gpu_task.options(</span><br><span class="line">    scheduling_strategy=PlacementGroupSchedulingStrategy(placement_group=pg)</span><br><span class="line">).remote())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除这个 Placement Group</span></span><br><span class="line">remove_placement_group(pg)</span><br></pre></td></tr></table></figure><blockquote><p><code>placement_group()</code> 接收 <code>strategy</code> 参数：</p><ul><li><p><code>STRICT_PACK</code>：所有 Bundle都必须调度到单个计算节点。</p></li><li><p><code>PACK</code>（默认策略）：<strong>所有 Bundle优先调度到单个计算节点</strong>，如果无法满足条件，再调度到其他计算节点，</p><p><img src="/posts/5d9f220e/pg-pack.svg"></p></li><li><p><code>STRICT_SPREAD</code>：每个 Bundle必须调度到不同的计算节点。</p></li><li><p><code>SPREAD</code>：每个 Bundle优先调度到不同的计算节点，如果无法满足条件，有些 Bundle可以共用一个计算节点。</p><p><img src="/posts/5d9f220e/pg-spread.svg"></p><p>对比：</p><ul><li><code>STRICT_PACK</code> 和 <code>PACK</code>保证了数据的<strong>局部性</strong>，计算任务可以快速访问本地的数据；</li><li><code>STRICT_SPREAD</code> 和 <code>SPREAD</code>使得计算更好地负载均衡。</li></ul></li></ul></blockquote><h4 id="ray作业">Ray作业</h4><p>Ray 作业指的是用户编写的，基于 Task、Actor 或者 Ray 各类生态（RayTrain、Ray Tune、Ray Serve、RLlib等）的<strong>具体的计算任务</strong>。主要包括三种作业提交方式：</p><ol type="1"><li><p><strong>Ray Jobs 命令行</strong>：<code>RAY_ADDRESS</code>根据头节点的地址设定； <code>--working-dir</code> 为工作目录，Ray会将该目录下的内容打包，分发到 Ray集群各个节点；ENTRYPOINT指的是需要执行的 Python 脚本，本例中，是<code>python script.py</code>.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">RAY_ADDRESS=<span class="string">&#x27;http://127.0.0.1:8265&#x27;</span> ray job submit --working-dir ./ -- python script.py</span><br></pre></td></tr></table></figure><p>依赖管理：启动作业时，设置<code>--runtime-env-json</code>，原理是为每个作业创建一个独立的虚拟环境。</p></li><li><p><strong>Python SDK</strong>：将提交作业的各类参数写在 Python代码中，执行 Python 代码来提交作业。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> ray.job_submission <span class="keyword">import</span> JobSubmissionClient, JobStatus</span><br><span class="line"></span><br><span class="line">client = JobSubmissionClient(<span class="string">&quot;http://127.0.0.1:8265&quot;</span>)</span><br><span class="line"><span class="comment"># submit_job()方法的作业提交是异步的：调用此方法后，Ray 会马上返回作业的 ID</span></span><br><span class="line">job_id = client.submit_job(</span><br><span class="line">    entrypoint=<span class="string">&quot;python script.py&quot;</span>,</span><br><span class="line">    runtime_env=&#123;<span class="string">&quot;working_dir&quot;</span>: <span class="string">&quot;./&quot;</span>&#125;</span><br><span class="line">)</span><br><span class="line"><span class="built_in">print</span>(job_id)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">wait_until_status</span>(<span class="params">job_id, status_to_wait_for, timeout_seconds=<span class="number">5</span></span>):</span><br><span class="line">    start = time.time()</span><br><span class="line">    <span class="keyword">while</span> time.time() - start &lt;= timeout_seconds:</span><br><span class="line">        status = client.get_job_status(job_id)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;status: <span class="subst">&#123;status&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> status <span class="keyword">in</span> status_to_wait_for:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        time.sleep(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># wait_until_status() 函数不断向 Ray 集群请求，检查作业的当前状态</span></span><br><span class="line">wait_until_status(job_id, &#123;JobStatus.SUCCEEDED, JobStatus.STOPPED, JobStatus.FAILED&#125;)</span><br><span class="line">logs = client.get_job_logs(job_id)</span><br><span class="line"><span class="built_in">print</span>(logs)</span><br></pre></td></tr></table></figure></li><li><p><strong>Ray客户端</strong>：在 Python 中使用<code>ray.init()</code>函数，直接指定Ray集群的地址：<code>ray.init("ray://&lt;head-node-host&gt;:&lt;port&gt;")</code>。</p><p>在客户端与Ray集群意外断开连接的情况下，Ray会尝试在30秒后重新建立连接。如果重新连接失败，Ray将销毁所有相关的引用。可以通过设置环境变量<code>RAY_CLIENT_RECONNECT_GRACE_PERIOD</code>来自定义这个重连尝试的时间间隔。</p></li></ol><h3 id="ray-data">Ray Data</h3><p>Ray Data 是一个构建在 Ray Core之上的数据处理框架，对数据提供了一个抽象类：<a href="https://docs.ray.io/en/latest/data/api/doc/ray.data.Dataset.html"><code>ray.data.Dataset</code></a>，它封装了数据并在上面实现了常见的大数据处理原语。包括：</p><ul><li>数据的读取：比如读取 Parquet 文件等。</li><li>对数据的转换（Transformation）操作：比如 <a href="https://docs.ray.io/en/latest/data/api/doc/ray.data.Dataset.map_batches.html"><code>map_batches()</code></a>。</li><li>分组聚合操作：比如 <a href="https://docs.ray.io/en/latest/data/api/doc/ray.data.Dataset.groupby.html"><code>groupby()</code></a></li><li>数据在计算节点间的交换：比如 <a href="https://docs.ray.io/en/latest/data/api/doc/ray.data.Dataset.random_shuffle.html"><code>random_shuffle()</code></a>和 <a href="https://docs.ray.io/en/latest/data/api/doc/ray.data.Dataset.repartition.html"><code>repartition()</code></a>等。</li></ul><h4 id="ray.data.dataset"><code>ray.data.Dataset</code></h4><p><code>Dataset</code> 底层的基本单元是<code>Block</code>；<code>Dataset</code> 实际上是一个分布式的<code>ObjectRef[Block]</code>。</p><p><code>Block</code> 是一个数据结构，它基于ApacheArrow格式构建，这是一种高效率的<strong>列式存储</strong>格式，适用于在内存中处理和操作大量数据。</p><p>以下展示了一个由 3 个 <code>Block</code> 组成的<code>Dataset</code>：可以使用 <code>from_*()</code> API从其他系统或格式导入成 <code>Dataset</code>，比如 <a href="https://docs.ray.io/en/latest/data/api/doc/ray.data.from_pandas.html"><code>from_pandas()</code></a>、<a href="https://docs.ray.io/en/latest/data/api/doc/ray.data.from_spark.html"><code>from_spark()</code></a>。或者使用<code>read_*()</code> API 从持久化的文件系统重读取，比如 <a href="https://docs.ray.io/en/latest/data/api/doc/ray.data.read_parquet.html"><code>read_parquet()</code></a>、<a href="https://docs.ray.io/en/latest/data/api/doc/ray.data.read_json.html"><code>read_json()</code></a>等。</p><p><img src="/posts/5d9f220e/Dataset.svg"></p><h4 id="数据读写">数据读写</h4><p>Ray Data 使用 <strong>Ray Task 并行地读写数据</strong>： <img src="/posts/5d9f220e/dataset-read.svg"></p><ul><li><p>数据加载：</p><table><colgroup><col style="width: 4%"><col style="width: 19%"><col style="width: 15%"><col style="width: 14%"><col style="width: 21%"><col style="width: 25%"></colgroup><thead><tr><th></th><th>Parquet</th><th>Text</th><th>CSV</th><th>TFRecord</th><th>二进制</th></tr></thead><tbody><tr><td>方法</td><td><code>read_parquet()</code></td><td><code>read_text()</code></td><td><code>read_csv()</code></td><td><code>read_tfrecords()</code></td><td><code>read_binary_files()</code></td></tr></tbody></table></li><li><p>行列裁剪：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pyarrow <span class="keyword">as</span> pa</span><br><span class="line"></span><br><span class="line">dataset = ray.data.read_parquet(</span><br><span class="line">    dataset_path,</span><br><span class="line">    columns=[<span class="string">&quot;passenger_count&quot;</span>, <span class="string">&quot;tip_amount&quot;</span>, <span class="string">&quot;payment_type&quot;</span>],</span><br><span class="line">    <span class="built_in">filter</span>=pa.dataset.field(<span class="string">&quot;tip_amount&quot;</span>) &gt; <span class="number">6.0</span></span><br><span class="line">)</span><br><span class="line">dataset.show(limit=<span class="number">2</span>)</span><br></pre></td></tr></table></figure></li><li><p>并行度：各类数据读取方法都可以设置 <code>parallelism</code>参数，来控制底层的并行执行的过程。如果不设置<code>parallelism</code>，Ray Data 通过以下方式试探<code>parallelism</code>：</p><ol type="1"><li>Ray 获取集群中可用的 CPU 核数；</li><li><code>parallelism</code> 被设置为 CPU 核数的 2 倍。如果<code>parallelism</code> 小于 8，则设置为 8；</li><li>估计每个 <code>Block</code> 的大小，如果每个 <code>Block</code>平均大于 512 MiB，Ray 增大 <code>parallelism</code>，<strong>直到每个<code>Block</code> 小于 512 MiB</strong>。</li></ol></li><li><p>查看数据：...</p></li></ul><h4 id="数据转换">数据转换</h4><p>略</p><h2 id="verl-ray-api">verl Ray API</h2><h3 id="基础执行单元worker">基础执行单元：Worker</h3><p><img src="/posts/5d9f220e/class_diagram_simplified.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 简化后代码：原始代码位于verl/single_controller/base/worker.py</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Worker</span>(<span class="title class_ inherited__">WorkerHelper</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__new__</span>(<span class="params">cls, *args, **kwargs</span>):</span><br><span class="line">        instance = <span class="built_in">super</span>().__new__(cls)</span><br><span class="line">        rank = os.environ.get(<span class="string">&quot;RANK&quot;</span>, <span class="literal">None</span>)</span><br><span class="line">        worker_group_prefix = os.environ.get(<span class="string">&quot;WG_PREFIX&quot;</span>, <span class="literal">None</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="literal">None</span> <span class="keyword">not</span> <span class="keyword">in</span> [rank, worker_group_prefix] <span class="keyword">and</span> <span class="string">&#x27;ActorClass(&#x27;</span> <span class="keyword">not</span> <span class="keyword">in</span> cls.__name__:</span><br><span class="line">            instance._configure_before_init(<span class="string">f&quot;<span class="subst">&#123;worker_group_prefix&#125;</span>_register_center&quot;</span>, <span class="built_in">int</span>(rank))</span><br><span class="line">        <span class="keyword">return</span> instance</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_configure_before_init</span>(<span class="params">self, register_center_name: <span class="built_in">str</span>, rank: <span class="built_in">int</span></span>):</span><br><span class="line">        <span class="comment"># rank=0时，配置MASTER_ADDR和MASTER_PORT环境变量，并将该信息存储在self.register_center中</span></span><br><span class="line">        <span class="keyword">if</span> rank == <span class="number">0</span>:</span><br><span class="line">            master_addr, master_port = <span class="variable language_">self</span>.get_availale_master_addr_port()</span><br><span class="line">            rank_zero_info = &#123;</span><br><span class="line">                <span class="string">&quot;MASTER_ADDR&quot;</span>: master_addr,</span><br><span class="line">                <span class="string">&quot;MASTER_PORT&quot;</span>: master_port,</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> os.getenv(<span class="string">&quot;WG_BACKEND&quot;</span>, <span class="literal">None</span>) == <span class="string">&quot;ray&quot;</span>:</span><br><span class="line">                <span class="keyword">from</span> verl.single_controller.base.register_center.ray <span class="keyword">import</span> create_worker_group_register_center</span><br><span class="line">                <span class="variable language_">self</span>.register_center = create_worker_group_register_center(name=register_center_name,info=rank_zero_info)</span><br><span class="line">            os.environ.update(rank_zero_info)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, cuda_visible_devices=<span class="literal">None</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        world_size = <span class="built_in">int</span>(os.environ[<span class="string">&#x27;WORLD_SIZE&#x27;</span>])</span><br><span class="line">        rank = <span class="built_in">int</span>(os.environ[<span class="string">&#x27;RANK&#x27;</span>])</span><br><span class="line">        <span class="variable language_">self</span>._rank = rank</span><br><span class="line">        <span class="variable language_">self</span>._world_size = world_size</span><br><span class="line"></span><br><span class="line">        master_addr = os.environ[<span class="string">&quot;MASTER_ADDR&quot;</span>]</span><br><span class="line">        master_port = os.environ[<span class="string">&quot;MASTER_PORT&quot;</span>]</span><br><span class="line"></span><br><span class="line">        local_world_size = <span class="built_in">int</span>(os.getenv(<span class="string">&quot;LOCAL_WORLD_SIZE&quot;</span>, <span class="string">&quot;1&quot;</span>))</span><br><span class="line">        local_rank = <span class="built_in">int</span>(os.getenv(<span class="string">&quot;LOCAL_RANK&quot;</span>, <span class="string">&quot;0&quot;</span>))</span><br><span class="line"></span><br><span class="line">        store = &#123;</span><br><span class="line">            <span class="string">&#x27;_world_size&#x27;</span>: world_size,</span><br><span class="line">            <span class="string">&#x27;_rank&#x27;</span>: rank,</span><br><span class="line">            <span class="string">&#x27;_local_world_size&#x27;</span>: local_world_size,</span><br><span class="line">            <span class="string">&#x27;_local_rank&#x27;</span>: local_rank,</span><br><span class="line">            <span class="string">&#x27;_master_addr&#x27;</span>: master_addr,</span><br><span class="line">            <span class="string">&#x27;_master_port&#x27;</span>: master_port</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment"># WorkerMeta仅是包store信息存储在实例对象中</span></span><br><span class="line">        meta = WorkerMeta(store=store)</span><br><span class="line">        <span class="comment"># 将meta(store)信息更新到当前实例的__dict__中并配置环境变量</span></span><br><span class="line">        <span class="variable language_">self</span>._configure_with_meta(meta=meta)</span><br></pre></td></tr></table></figure><p>一个栗子：自定义<code>GPUAccumulator</code>：继承<code>Worker</code>类，假设有4个GPU，则每个GPU实例化一个GPUAccumlator，其成员变量value初始化为GPUrank，然后对所有value执行加1操作。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@ray.remote</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GPUAccumulator</span>(<span class="title class_ inherited__">Worker</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="comment"># The initial value of each rank is the same as the rank</span></span><br><span class="line">        <span class="variable language_">self</span>.value = torch.zeros(size=(<span class="number">1</span>,), device=<span class="string">&quot;cuda&quot;</span>) + <span class="variable language_">self</span>.rank</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">add</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="variable language_">self</span>.value += x</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;rank <span class="subst">&#123;self.rank&#125;</span>, value: <span class="subst">&#123;self.value&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.value.cpu()</span><br><span class="line">      </span><br><span class="line">class_with_args = RayClassWithInitArgs(GPUAccumulator)</span><br><span class="line">resource_pool = RayResourcePool([<span class="number">4</span>], use_gpu=<span class="literal">True</span>)</span><br><span class="line">workergroup = RayWorkerGroup(resource_pool, class_with_args)</span><br><span class="line"><span class="built_in">print</span>(workergroup.add(x=<span class="number">1</span>)) <span class="comment"># 输出：[tensor([1.]), tensor([2.]), tensor([3.]), tensor([4.])]</span></span><br></pre></td></tr></table></figure><h4 id="初始化参数rayclasswithinitargs">初始化参数：RayClassWithInitArgs</h4><p><strong><code>RayClassWithInitArgs</code>保存通过<code>@ray.remote</code>定义的Actor类，以及一些用于异步调用该Actor时所需要的参数</strong>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">class_with_args = RayClassWithInitArgs(GPUAccumulator)</span><br></pre></td></tr></table></figure><h4 id="资源池rayresourcepool">资源池：<strong>RayResourcePool</strong></h4><p><strong>RayResourcePool继承自ResourcePool</strong>。</p><ol type="1"><li><strong>ResourcePool负责存储资源相关的信息</strong>：</li></ol><ul><li><p>初始化参数：</p><ul><li><p><strong>process_on_nodes</strong>:节点进程数列表，表示每个节点上要运行的进程数量</p></li><li><p><strong>max_colocate_count</strong>:单个节点上最大并行进程数，默认10</p></li><li><p><strong>n_gpus_per_node</strong>:每个节点的GPU数量，默认8</p></li></ul></li><li><p>关键属性：</p><ul><li><p><code>_store</code>: 存储各节点的进程数配置</p></li><li><p><code>world_size</code>: 属性，计算所有节点的总进程数</p></li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ResourcePool</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, process_on_nodes=<span class="literal">None</span>, max_colocate_count: <span class="built_in">int</span> = <span class="number">10</span>, n_gpus_per_node=<span class="number">8</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">if</span> process_on_nodes <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            process_on_nodes = []</span><br><span class="line">        <span class="variable language_">self</span>._store = process_on_nodes</span><br><span class="line">        <span class="variable language_">self</span>.max_colocate_count = max_colocate_count</span><br><span class="line">        <span class="variable language_">self</span>.n_gpus_per_node = n_gpus_per_node  <span class="comment"># this is left for future huawei GPU that contains 16 GPUs per node</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">add_node</span>(<span class="params">self, process_count</span>):<span class="comment"># 添加新节点到资源池（动态扩展）</span></span><br><span class="line">        <span class="variable language_">self</span>._store.append(process_count)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">world_size</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">sum</span>(<span class="variable language_">self</span>._store)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self</span>) -&gt; <span class="type">Any</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>._store</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">store</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>._store</span><br><span class="line"><span class="comment"># 获取本地信息</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">local_world_size_list</span>(<span class="params">self</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:<span class="comment"># 生成每个进程对应的本地世界大小列表</span></span><br><span class="line">        nested_local_world_size_list = [[local_world_size <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(local_world_size)] <span class="keyword">for</span> local_world_size <span class="keyword">in</span> <span class="variable language_">self</span>._store]</span><br><span class="line">        <span class="keyword">return</span> [item <span class="keyword">for</span> row <span class="keyword">in</span> nested_local_world_size_list <span class="keyword">for</span> item <span class="keyword">in</span> row]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">local_rank_list</span>(<span class="params">self</span>) -&gt; <span class="type">List</span>[<span class="built_in">int</span>]:<span class="comment"># 生成每个进程的本地rank列表</span></span><br><span class="line">        nested_local_rank_list = [[i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(local_world_size)] <span class="keyword">for</span> local_world_size <span class="keyword">in</span> <span class="variable language_">self</span>._store]</span><br><span class="line">        <span class="keyword">return</span> [item <span class="keyword">for</span> row <span class="keyword">in</span> nested_local_rank_list <span class="keyword">for</span> item <span class="keyword">in</span> row]</span><br></pre></td></tr></table></figure><ol start="2" type="1"><li><strong>RayResourcePool通过Ray的PlacementGroup实现资源池的分配</strong>。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">RayResourcePool</span>(<span class="title class_ inherited__">ResourcePool</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">        ......</span></span><br><span class="line"><span class="params">    </span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="built_in">super</span>().__init__(process_on_nodes, max_colocate_count)</span><br><span class="line">        ......</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_placement_groups</span>(<span class="params">self, strategy=<span class="string">&quot;STRICT_PACK&quot;</span>, name=<span class="literal">None</span></span>):</span><br><span class="line">      <span class="comment"># 默认使用STRICT_PACK策略：所有 Bundle 都必须调度到单个计算节点</span></span><br><span class="line">      <span class="comment"># (每个bundle包含max_colocate_count个CPU核心)</span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.pgs <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="variable language_">self</span>.pgs<span class="comment"># 缓存已创建的placement groups</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 生成唯一资源组名称</span></span><br><span class="line">        pg_name_prefix = name <span class="keyword">if</span> name <span class="keyword">else</span> <span class="string">f&quot;<span class="subst">&#123;self.name_prefix&#125;</span>verl_group_<span class="subst">&#123;<span class="string">&#x27;_&#x27;</span>.join([<span class="built_in">str</span>(count) <span class="keyword">for</span> count <span class="keyword">in</span> self._store])&#125;</span>:&quot;</span></span><br><span class="line">        <span class="comment"># 构建资源bundle配置</span></span><br><span class="line">        pg_scheme = [[&#123;<span class="string">&quot;CPU&quot;</span>: <span class="variable language_">self</span>.max_colocate_count, <span class="string">&quot;GPU&quot;</span>: <span class="number">1</span>&#125; <span class="keyword">if</span> <span class="variable language_">self</span>.use_gpu <span class="keyword">else</span> &#123;<span class="string">&quot;CPU&quot;</span>: <span class="variable language_">self</span>.max_colocate_count&#125; <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(process_count)] <span class="keyword">for</span> process_count <span class="keyword">in</span> <span class="variable language_">self</span>._store]</span><br><span class="line"></span><br><span class="line">        lifetime = <span class="string">&quot;detached&quot;</span> <span class="keyword">if</span> <span class="variable language_">self</span>.detached <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line"><span class="comment"># 创建placement groups</span></span><br><span class="line">        pgs = [placement_group(bundles=bundles, strategy=strategy, name=pg_name_prefix + <span class="built_in">str</span>(idx), lifetime=lifetime) <span class="keyword">for</span> idx, bundles <span class="keyword">in</span> <span class="built_in">enumerate</span>(pg_scheme)]</span><br><span class="line"></span><br><span class="line">        ray.get([pg.ready() <span class="keyword">for</span> pg <span class="keyword">in</span> pgs]) <span class="comment"># 等待所有资源组就绪</span></span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.pgs = pgs<span class="comment"># 缓存结果</span></span><br><span class="line">        <span class="keyword">return</span> pgs</span><br></pre></td></tr></table></figure><p>一个栗子：</p><p>创建集群：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> ray</span><br><span class="line"><span class="keyword">from</span> ray.util.placement_group</span><br><span class="line"><span class="comment"># 创建包含8GPU、16CPU的Ray集群</span></span><br><span class="line">ray.init(num_cpus=<span class="number">16</span>, num_gpus=<span class="number">8</span>)</span><br></pre></td></tr></table></figure><p>创建两个Placement Group，每个Placement Group包含4个GPU和8个CPU。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">resource_pool = RayResourcePool(process_on_nodes=[<span class="number">4</span>,<span class="number">4</span>], max_colocate_count=<span class="number">2</span>, use_gpu=<span class="literal">True</span>) <span class="comment"># 创建资源池</span></span><br><span class="line">pgs = resource_pool.get_placement_groups() <span class="comment"># 创建placement group的列表</span></span><br></pre></td></tr></table></figure><p>单个Placement Group创建为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pg = placement_group(bundles=[&#123;<span class="string">&quot;CPU&quot;</span>: <span class="number">2</span>, <span class="string">&quot;GPU&quot;</span>: <span class="number">1</span>&#125;,</span><br><span class="line">                             &#123;<span class="string">&quot;CPU&quot;</span>: <span class="number">2</span>, <span class="string">&quot;GPU&quot;</span>: <span class="number">1</span>&#125;,</span><br><span class="line">                             &#123;<span class="string">&quot;CPU&quot;</span>: <span class="number">2</span>, <span class="string">&quot;GPU&quot;</span>: <span class="number">1</span>&#125;,</span><br><span class="line">                             &#123;<span class="string">&quot;CPU&quot;</span>: <span class="number">2</span>, <span class="string">&quot;GPU&quot;</span>: <span class="number">1</span>&#125;])</span><br></pre></td></tr></table></figure><p>即<code>process_on_nodes</code>指定要创建几个PlacementGroup，以及每个包含多少GPU；<code>max_colocate_count</code>是则bundle中单个GPU最多对应多少个CPU，因为colocate的actor至少要有1个CPU。</p><h4 id="资源调度器rayworkergroup">资源调度器：RayWorkerGroup</h4><h5 id="初始化函数__init__">初始化函数：<code>__init__</code></h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        resource_pool: RayResourcePool = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">        ray_cls_with_init: RayClassWithInitArgs = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">        bin_pack: <span class="built_in">bool</span> = <span class="literal">True</span>,</span></span><br><span class="line"><span class="params">        name_prefix: <span class="built_in">str</span> = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">        detached=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">        worker_names=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">        ray_wait_register_center_timeout: <span class="built_in">int</span> = <span class="number">300</span>,</span></span><br><span class="line"><span class="params">        **kwargs,</span></span><br><span class="line"><span class="params">    </span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="built_in">super</span>().__init__(resource_pool=resource_pool, **kwargs)</span><br><span class="line">        <span class="variable language_">self</span>.ray_cls_with_init = ray_cls_with_init</span><br><span class="line">        ......</span><br><span class="line"><span class="comment"># 分离模式：连接已存在的持久化工作者</span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>._is_init_with_detached_workers:</span><br><span class="line">            <span class="variable language_">self</span>._init_with_detached_workers(worker_names=worker_names)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 附着模式：基于资源池创建新工作者（基于resource_pool的信息，启动worker）</span></span><br><span class="line">            <span class="variable language_">self</span>._init_with_resource_pool(resource_pool=resource_pool, ray_cls_with_init=ray_cls_with_init, bin_pack=bin_pack, detached=detached)</span><br><span class="line"><span class="comment"># ray_cls_with_init.clsz中的某些方法绑定到RayWorkerGroup上</span></span><br><span class="line">        <span class="keyword">if</span> ray_cls_with_init <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="variable language_">self</span>.(<span class="variable language_">self</span>.ray_cls_with_init.cls, func_generator)</span><br></pre></td></tr></table></figure><h5 id="启动workers_init_with_resource_pool">启动Workers：<code>_init_with_resource_pool</code></h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_init_with_resource_pool</span>(<span class="params">self, resource_pool, ray_cls_with_init, bin_pack, detached</span>):</span><br><span class="line">......</span><br><span class="line">      <span class="comment"># max_collocate_count意味着单个GPU上至多有对应几个CPU</span></span><br><span class="line">        num_gpus = <span class="number">1</span> / resource_pool.max_colocate_count</span><br><span class="line"></span><br><span class="line">        rank = -<span class="number">1</span></span><br><span class="line">        local_world_size = resource_pool.store[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">for</span> pg_idx, pg <span class="keyword">in</span> <span class="built_in">enumerate</span>(sort_placement_group_by_node_ip(pgs)):</span><br><span class="line">            <span class="keyword">assert</span> local_world_size &lt;= pg.bundle_count, <span class="string">f&quot;when generating for <span class="subst">&#123;self.name_prefix&#125;</span>, for the &quot;</span></span><br><span class="line">            <span class="keyword">for</span> local_rank <span class="keyword">in</span> <span class="built_in">range</span>(local_world_size):</span><br><span class="line">                rank += <span class="number">1</span></span><br><span class="line">                <span class="comment"># 1. 构造worker需要的配置信息，包括环境变量等；</span></span><br><span class="line">                <span class="comment"># 2. 通过ray_cls_with_init.update_options更新这些配置信息</span></span><br><span class="line">                <span class="comment"># 3. 创建一个worker：</span></span><br><span class="line">                worker = ray_cls_with_init(placement_group=pg, placement_group_bundle_idx=local_rank, use_gpu=use_gpu, num_gpus=num_gpus)</span><br><span class="line">                <span class="variable language_">self</span>._workers.append(worker)</span><br><span class="line">                <span class="variable language_">self</span>._worker_names.append(name)</span><br><span class="line">......</span><br></pre></td></tr></table></figure><h5 id="异步执行execute_all_async">异步执行：<code>execute_all_async</code></h5><p>在<code>_init_with_resource_pool</code>后，<code>self._workers</code>中保存着所有的<code>worker</code>。</p><p>同步执行：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">execute_all_sync</span>(<span class="params">self, method_name: <span class="built_in">str</span>, *args, **kwargs</span>):</span><br><span class="line">        <span class="keyword">return</span> ray.get(<span class="variable language_">self</span>.execute_all_async(method_name, *args, **kwargs))</span><br></pre></td></tr></table></figure><p>调用异步执行：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">execute_all_async</span>(<span class="params">self, method_name: <span class="built_in">str</span>, *args, **kwargs</span>):</span><br><span class="line">        length = <span class="built_in">len</span>(<span class="variable language_">self</span>._workers)</span><br><span class="line">    <span class="comment"># 检查参数是否为列表且长度匹配:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">all</span>(<span class="built_in">isinstance</span>(arg, <span class="built_in">list</span>) <span class="keyword">for</span> arg <span class="keyword">in</span> args) <span class="keyword">and</span> <span class="built_in">all</span>(<span class="built_in">isinstance</span>(kwarg, <span class="built_in">list</span>) <span class="keyword">for</span> kwarg <span class="keyword">in</span> kwargs.values()):</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">all</span>(<span class="built_in">len</span>(arg) == length <span class="keyword">for</span> arg <span class="keyword">in</span> args) <span class="keyword">and</span> <span class="built_in">all</span>(<span class="built_in">len</span>(kwarg) == length <span class="keyword">for</span> kwarg <span class="keyword">in</span> kwargs.values()):</span><br><span class="line">                <span class="comment"># 1. 参数分片并执行:遍历每个 worker 的索引i</span></span><br><span class="line">                result = []</span><br><span class="line">                <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(length):</span><br><span class="line">                  <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">                  sliced_args: 从每个位置参数 args 中取出第 i 个元素，组成新的位置参数。</span></span><br><span class="line"><span class="string">sliced_kwargs: 从每个关键字参数 kwargs 的值中取出第 i 个元素，组成新的关键字参数。</span></span><br><span class="line"><span class="string">                  &#x27;&#x27;&#x27;</span></span><br><span class="line">                    sliced_args = <span class="built_in">tuple</span>(arg[i] <span class="keyword">for</span> arg <span class="keyword">in</span> args)</span><br><span class="line">                    sliced_kwargs = &#123;k: v[i] <span class="keyword">for</span> k, v <span class="keyword">in</span> kwargs.items()&#125;</span><br><span class="line">                    result.append(<span class="variable language_">self</span>._execute_remote_single_worker(<span class="variable language_">self</span>._workers[i], method_name, *sliced_args, **sliced_kwargs))</span><br><span class="line">                <span class="keyword">return</span> result</span><br><span class="line"><span class="comment"># 2. 如果参数不是分片的: 对每个 worker 使用相同的 args 和 kwargs 调用方法</span></span><br><span class="line">        <span class="keyword">return</span> [<span class="variable language_">self</span>._execute_remote_single_worker(worker, method_name, *args, **kwargs) <span class="keyword">for</span> worker <span class="keyword">in</span> <span class="variable language_">self</span>._workers]</span><br></pre></td></tr></table></figure><p>但是，利用<code>execute_all_async</code>来调用worker的不太方便。所以，利用装饰器<code>register</code>和<code>_bind_worker_method</code>来令调用更加自然。</p><h5 id="worker方法绑定至workergroup_bind_worker_method">worker方法绑定至workergroup：<code>_bind_worker_method</code></h5><p><code>_bind_worker_method</code>来自基类<code>WorkerGroup</code>，参数包含<code>user_defined_cls</code>和<code>func_generator</code>。其中<code>user_defined_cls</code>就是用户自定义的worker类。</p><p><strong>函数生成器</strong><code>func_generator</code>：<strong>动态生成一个可执行函数</strong>，用于在分布式Worker组（<code>WorkerGroup</code>）上执行任务。这个生成的函数会按照指定的<strong>分发（dispatch）、执行（execute）、收集（collect）</strong>逻辑运行，并支持阻塞和非阻塞模式。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">func_generator</span>(<span class="params">self, method_name, dispatch_fn, collect_fn, execute_fn, blocking</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;method_name: 要在 Worker 上调用的方法名（如 &quot;foo&quot;）。</span></span><br><span class="line"><span class="string">dispatch_fn: 分发函数，负责将输入参数分发给各个 Worker。</span></span><br><span class="line"><span class="string">collect_fn: 收集函数，负责聚合 Worker 返回的结果。</span></span><br><span class="line"><span class="string">execute_fn: 执行函数，负责在 Worker 上真正运行方法。</span></span><br><span class="line"><span class="string">blocking: 是否阻塞等待结果（True 表示同步，False 表示异步）。&#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">func</span>(<span class="params">*args, **kwargs</span>):</span><br><span class="line">        args, kwargs = dispatch_fn(<span class="variable language_">self</span>, *args, **kwargs)<span class="comment"># 1. 分发参数</span></span><br><span class="line">        padding_count = kwargs.pop(_padding_size_key, <span class="number">0</span>)<span class="comment"># 2. 处理可能的填充</span></span><br><span class="line">        output = execute_fn(method_name, *args, **kwargs)<span class="comment"># 3. 执行任务</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;判断是否阻塞等待结果：</span></span><br><span class="line"><span class="string">        1. 如果 blocking=True，调用 ray.get(output) 等待所有 Worker 完成计算；</span></span><br><span class="line"><span class="string">        2. 如果 blocking=False，直接返回异步引用。</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">if</span> blocking:</span><br><span class="line">            output = ray.get(output)</span><br><span class="line">        <span class="comment"># 4. 收集结果</span></span><br><span class="line">        output = collect_fn(<span class="variable language_">self</span>, output)</span><br><span class="line">        <span class="comment"># 5. 移除填充（如果有）</span></span><br><span class="line">        <span class="keyword">if</span> padding_count &gt; <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(output, DataProto):</span><br><span class="line">                indices = [i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(output))][:-padding_count]</span><br><span class="line">                output = output.select_idxs(indices)</span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">isinstance</span>(output, <span class="built_in">list</span>):</span><br><span class="line">                output = output[:-padding_count]</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> func</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_bind_worker_method</span>(<span class="params">self, user_defined_cls, func_generator</span>):</span><br><span class="line">        method_names = []</span><br><span class="line">        <span class="keyword">for</span> method_name <span class="keyword">in</span> <span class="built_in">dir</span>(user_defined_cls):<span class="comment"># 遍历类的所有方法</span></span><br><span class="line">        <span class="comment"># 尝试获取方法并检查是否可调用（callable），跳过不可调用的属性（如 property）</span></span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                method = <span class="built_in">getattr</span>(user_defined_cls, method_name)</span><br><span class="line">                <span class="keyword">assert</span> <span class="built_in">callable</span>(method), <span class="string">f&quot;<span class="subst">&#123;method_name&#125;</span> in <span class="subst">&#123;user_defined_cls&#125;</span> is not callable&quot;</span></span><br><span class="line">            <span class="keyword">except</span> Exception:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line"><span class="comment"># 检查方法是否带有特定装饰器标记MAGIC_ATTR</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">hasattr</span>(method, MAGIC_ATTR):</span><br><span class="line">              <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">              获取装饰器设置的属性（attribute），并检查它是否是字典。</span></span><br><span class="line"><span class="string">确保属性中包含 dispatch_mode（分发模式）、execute_mode（执行模式）和 blocking（是否阻塞）字段。</span></span><br><span class="line"><span class="string">              &#x27;&#x27;&#x27;</span></span><br><span class="line">                attribute = <span class="built_in">getattr</span>(method, MAGIC_ATTR)</span><br><span class="line">                <span class="keyword">assert</span> <span class="built_in">isinstance</span>(attribute, <span class="type">Dict</span>), <span class="string">f&quot;attribute must be a dictionary. Got <span class="subst">&#123;<span class="built_in">type</span>(attribute)&#125;</span>&quot;</span></span><br><span class="line">                <span class="keyword">assert</span> <span class="string">&quot;dispatch_mode&quot;</span> <span class="keyword">in</span> attribute, <span class="string">&quot;attribute must contain dispatch_mode in its key&quot;</span></span><br><span class="line">                dispatch_mode = attribute[<span class="string">&quot;dispatch_mode&quot;</span>]</span><br><span class="line">                execute_mode = attribute[<span class="string">&quot;execute_mode&quot;</span>]</span><br><span class="line">                blocking = attribute[<span class="string">&quot;blocking&quot;</span>]</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 获取分发函数（dispatch_fn 和 collect_fn）</span></span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">isinstance</span>(dispatch_mode, Dispatch):</span><br><span class="line">                    fn = get_predefined_dispatch_fn(dispatch_mode=dispatch_mode)</span><br><span class="line">                    dispatch_fn = fn[<span class="string">&quot;dispatch_fn&quot;</span>]</span><br><span class="line">                    collect_fn = fn[<span class="string">&quot;collect_fn&quot;</span>]</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">assert</span> <span class="built_in">isinstance</span>(dispatch_mode, <span class="built_in">dict</span>)</span><br><span class="line">                    <span class="keyword">assert</span> <span class="string">&quot;dispatch_fn&quot;</span> <span class="keyword">in</span> dispatch_mode</span><br><span class="line">                    <span class="keyword">assert</span> <span class="string">&quot;collect_fn&quot;</span> <span class="keyword">in</span> dispatch_mode</span><br><span class="line">                    dispatch_fn = dispatch_mode[<span class="string">&quot;dispatch_fn&quot;</span>]</span><br><span class="line">                    collect_fn = dispatch_mode[<span class="string">&quot;collect_fn&quot;</span>]</span><br><span class="line"></span><br><span class="line">                <span class="comment">#  获取执行函数（execute_fn）</span></span><br><span class="line">                execute_mode = get_predefined_execute_fn(execute_mode=execute_mode)</span><br><span class="line">                wg_execute_fn_name = execute_mode[<span class="string">&quot;execute_fn_name&quot;</span>]</span><br><span class="line">                <span class="keyword">try</span>:</span><br><span class="line">                    execute_fn = <span class="built_in">getattr</span>(<span class="variable language_">self</span>, wg_execute_fn_name)</span><br><span class="line">                    <span class="keyword">assert</span> <span class="built_in">callable</span>(execute_fn), <span class="string">&quot;execute_fn must be callable&quot;</span></span><br><span class="line">                <span class="keyword">except</span> Exception:</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">f&quot;execute_fn <span class="subst">&#123;wg_execute_fn_name&#125;</span> is invalid&quot;</span>)</span><br><span class="line">                    <span class="keyword">raise</span></span><br><span class="line"></span><br><span class="line">                <span class="comment"># 生成并绑定新方法：</span></span><br><span class="line">                <span class="comment"># 利用func_generator将dispatch_fn、collect_fn组装到method_name上</span></span><br><span class="line">                func = func_generator(</span><br><span class="line">                    <span class="variable language_">self</span>,</span><br><span class="line">                    method_name,</span><br><span class="line">                    dispatch_fn=dispatch_fn,</span><br><span class="line">                    collect_fn=collect_fn,</span><br><span class="line">                    execute_fn=execute_fn,</span><br><span class="line">                    blocking=blocking,</span><br><span class="line">                )</span><br><span class="line">                <span class="keyword">try</span>:</span><br><span class="line">                    <span class="built_in">setattr</span>(<span class="variable language_">self</span>, method_name, func)</span><br><span class="line">                    method_names.append(method_name)</span><br><span class="line">                <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                    <span class="keyword">raise</span> ValueError(<span class="string">f&quot;Fail to set method_name <span class="subst">&#123;method_name&#125;</span>&quot;</span>) <span class="keyword">from</span> e</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> method_names</span><br></pre></td></tr></table></figure><p>一个栗子：</p><ol type="1"><li><p>自定义分发函数： <strong>将 2 个输入参数扩展到所有Worker</strong>（<code>world_size</code> 个 Worker）</p><ul><li>例如，如果 <code>world_size=4</code>，输入 <code>x=[1, 2]</code>会被扩展为 <code>x=[1, 2, 1, 2]</code>，使得每个 Worker都能接收一个参数。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">two_to_all_dispatch_fn</span>(<span class="params">worker_group, *args, **kwargs</span>):</span><br><span class="line">    <span class="keyword">for</span> arg <span class="keyword">in</span> args:</span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">len</span>(arg) == <span class="number">2</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(worker_group.world_size - <span class="number">2</span>):</span><br><span class="line">            arg.append(arg[i % <span class="number">2</span>])</span><br><span class="line">    <span class="keyword">for</span> k, v <span class="keyword">in</span> kwargs.items():</span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">len</span>(v) == <span class="number">2</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(worker_group.world_size - <span class="number">2</span>):</span><br><span class="line">            v.append(v[i % <span class="number">2</span>])</span><br><span class="line">    <span class="keyword">return</span> args, kwargs</span><br></pre></td></tr></table></figure></li><li><p><code>TestActor</code>（Worker 类）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@ray.remote</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TestActor</span>(<span class="title class_ inherited__">Worker</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, x</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>._x = x</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">foo</span>(<span class="params">self, y</span>):<span class="comment"># 普通方法：直接计算 self._x + y</span></span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>._x + y</span><br><span class="line"></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;使用 @register 装饰器，指定分发模式 ALL_TO_ALL 和执行模式 RANK_ZERO：</span></span><br><span class="line"><span class="string">    只会在 rank=0 的 Worker 上执行&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="meta">    @register(<span class="params">dispatch_mode=Dispatch.ALL_TO_ALL, execute_mode=Execute.RANK_ZERO</span>)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">foo_rank_zero</span>(<span class="params">self, x, y</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>._x + y + x</span><br><span class="line"></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;使用自定义分发函数 two_to_all_dispatch_fn和收集函数 collect_all_to_all</span></span><br><span class="line"><span class="string">    输入 x 和 y 会被 two_to_all_dispatch_fn 扩展后分发给所有 Worker&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="meta">    @register(<span class="params">dispatch_mode=&#123;<span class="string">&quot;dispatch_fn&quot;</span>: two_to_all_dispatch_fn, <span class="string">&quot;collect_fn&quot;</span>: collect_all_to_all&#125;</span>)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">foo_custom</span>(<span class="params">self, x, y</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>._x + y + x</span><br><span class="line">class_with_args = RayClassWithInitArgs(cls=TestActor, x=<span class="number">2</span>)</span><br><span class="line">worker_group = RayWorkerGroup(resource_pool, class_with_args)</span><br><span class="line">output_ref = worker_group.foo_custom(x=[<span class="number">1</span>, <span class="number">2</span>], y=[<span class="number">5</span>, <span class="number">6</span>])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;每个 Worker 计算 self._x + y + x：</span></span><br><span class="line"><span class="string">Worker 0: 2 + 5 + 1 = 8</span></span><br><span class="line"><span class="string">Worker 1: 2 + 6 + 2 = 10</span></span><br><span class="line"><span class="string">Worker 2: 2 + 5 + 1 = 8</span></span><br><span class="line"><span class="string">Worker 3: 2 + 6 + 2 = 10&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">assert</span> output_ref == [<span class="number">8</span>, <span class="number">10</span>, <span class="number">8</span>, <span class="number">10</span>]</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;只有 rank=0 的 Worker 执行计算：2 + 2 + 1 = 5&#x27;&#x27;&#x27;</span></span><br><span class="line">output_ref = worker_group.foo_rank_zero(x=<span class="number">1</span>, y=<span class="number">2</span>)</span><br><span class="line"><span class="keyword">assert</span> output_ref == <span class="number">5</span></span><br></pre></td></tr></table></figure></li></ol><h2 id="参考">参考</h2><p><a href="https://scale-py.godaai.org/index.html">Python数据科学加速</a></p><p><a href="https://scale-py.godaai.org/index.html">Ray Tutorial</a></p><p><a href="https://zhuanlan.zhihu.com/p/29997527557">【AIInfra】【RLHF框架】一、VeRL中基于Ray的执行流程源码解析</a></p><p><a href="https://github.com/volcengine">volcengine</a>/<a href="https://github.com/volcengine/verl">verl</a></p><p><a href="https://github.com/volcengine/verl/blob/main/examples/ray/tutorial.ipynb">tutorial.ipynb</a></p>]]></content>
      
      
      <categories>
          
          <category> Parallelism </category>
          
          <category> verl </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>FSDP设计解读</title>
      <link href="/posts/48646366.html"/>
      <url>/posts/48646366.html</url>
      
        <content type="html"><![CDATA[<p><a href="https://engineering.fb.com/2021/07/15/open-source/fsdp/">Meta官方文档</a></p><p>FSDP(Fully Sharded DataParallelism)将AI模型的参数分片至多个数据并行的workers上，可选择性地将训练中的计算移至CPU上。每个worker上microbatch的数据是不同的。</p><p>分片（Shard）：<a href="https://engineering.fb.com/2020/08/24/production-engineering/scaling-services-with-shard-manager/">官方文档：Scalingservices with Shard Manager</a></p><p>通常数据并行训练要求在每个GPU上，保存模型副本（引入冗余）；模型并行训练在workers（GPUs）之间增添了额外的通信负担，用于同步激活值。</p><blockquote><p>激活值（activations）：</p><p>神经网络中每一层的输入输出都是一个线性求和的过程，下一层的输出只是承接了上一层输入函数的线性变换，所以如果没有激活函数，那么无论构造的神经网络多么复杂，有多少层，最后的输出都是输入的线性组合，纯粹的线性组合并不能够解决更为复杂的问题。常见的激活函数都是非线性的，因此向神经元引入非线性元素，使得神经网络可以逼近其他的任何非线性函数，这样可以<strong>使得神经网络应用到更多非线性模型中。</strong></p><p><img src="/posts/48646366/image-17.png"></p><p><strong>常见激活函数</strong>：参见<a href="https://medium.com/analytics-vidhya/activation-functions-all-you-need-to-know-355a850d025e">ActivationFunctions — All You Need To Know!</a> 1.<strong>Sigmoid函数</strong>：取值范围为(0,1)，它可以将一个实数映射到(0,1)的区间，可以用来做二分类。<span class="math inline">\(f(x)=\frac{1}{1+e^{-x}}\)</span>。不足如下： *<strong>梯度消失</strong>：<strong>Sigmoid 函数趋近 0 和 1的时候，Sigmoid 的梯度趋近于 0。</strong> 神经网络使用 Sigmoid激活函数进行反向传播时，输出接近 0 或 1 的神经元其梯度趋近于0。这些神经元叫作饱和神经元。因此，这些神经元的权重不会更新； *<strong>不以0为中心</strong>：输出恒大于0，非零中心化的输出会使得其后一层的神经元的输入发生偏置偏移（BiasShift），并进一步使得梯度下降的收敛速度变慢； *<strong>计算成本高昂</strong>：exp()函数与其他非线性激活函数相比，计算成本高昂。</p><ol start="2" type="1"><li><strong>Tanh/双曲正切函数</strong>：<span class="math inline">\(f(x)=tanh(x)=\frac{e^{x}-e^{-x}}{e^{x}+e^{-x}}\)</span>，值域为(-1,1).</li></ol><ul><li>Tanh函数有梯度消失问题，但解决了不以0为中心的问题，比sigmoid函数更好。</li></ul><p>一般的二元分类问题中，tanh用于隐藏层，sigmoid用于输出层。（并非固定，根据特定问题调整）</p><ol start="3" type="1"><li><strong>ReLU函数</strong>：x&gt;=0时，f(x)=x；x&lt;0时，f(x)=0.即：f(x)=max(0,x).ReLU优点如下：</li></ol><ul><li>x&gt;0时，导数为1；一定程度改善梯度消失，加速梯度下降的收敛速度；</li><li>计算速度加快：只存在线性关系。</li></ul><p>不足如下： * <strong>DeadReLU</strong>：x&lt;0时，ReLU完全失效。在反向传播中，导致梯度为0。在训练时，如果参数在一次不恰当的更新之后，第一个隐藏层中的某个ReLU神经元在所有的训练数据上都不能被激活，那么这个神经元自身参数的梯度永远都会是0，在以后的训练过程中永远不能被激活。<strong>不以0为中心</strong></p><ol start="4" type="1"><li><strong>Leaky ReLU</strong>：<img src="/posts/48646366/image-18.png">相较于ReLU的优点如下：</li></ol><ul><li>Leaky ReLU 通过把 x的非常小的线性分量给予负输入（0.01x）来调整负值的零梯度（zerogradients）问题，当 x &lt; 0 时，它得到 0.1的正梯度。该函数一定程度上<strong>缓解了 dead ReLU 问题</strong>； leak有助于扩大 ReLU 函数的范围，通常 a 的值为 0.01 左右； Leaky ReLU的函数范围是（负无穷到正无穷）</li></ul><ol start="5" type="1"><li><strong>ELU</strong>：<img src="/posts/48646366/image-19.png"> 与ReLU 相比，ELU有负值，这会使激活的平均值接近零。均值激活接近于零可以使学习更快，因为它们使梯度更接近自然梯度；</li><li><strong>Softmax函数</strong>：用于<strong>多类分类问题</strong>。对于长度为K 的任意实向量，Softmax 可以将其压缩为<strong>长度为K，值在（0，1）范围内，并且向量中元素的总和为 1的实向量</strong>。优点：</li></ol><ul><li>Softmax 与正常的 max 函数不同：max 函数仅输出最大值，但 Softmax确保较小的值具有较小的概率，并且不会直接丢弃。我们可以认为它是 argmax函数的概率版本或「soft」版本。</li><li>Softmax 函数的分母结合了原始输出值的所有因子，这意味着 Softmax函数获得的各种概率彼此相关。</li></ul><p>不足： * 在0点不可微； *<strong>负输入的梯度为零</strong>，这意味着对于该区域的激活，权重不会在反向传播期间更新，因此会产生永不激活的死亡神经元。</p><ol start="7" type="1"><li><strong>Maxout函数</strong>：任意凸函数的分段线性近似，在有限的点上是不可微的。</li></ol></blockquote><p>FSDP平衡了上述问题。它通过在GPUs上对模型参数、梯度、优化器状态分片，提升了内存效率；通过分解通信并将其与计算重合（前向/反向传播中均实现），提高计算效率。</p><h2 id="how-fsdp-works">How FSDP works</h2><p>在标准的DDP（Distributed DataParallelism）训练中，每个worker处理一个单独的batch，通过all-reduce实现梯度同步；然而，DDP中模型权重和优化器状态，在各个DDPworkers中重复，带来冗余。</p><blockquote><p><img src="/posts/48646366/image-20.png"> *<strong>Reduce-Scatter</strong>：合并梯度在不同rank上的相同blocks； *<strong>All-Gather</strong>：每个 GPU 上聚合的梯度碎片，被共享给所有GPU。</p></blockquote><p>标准的DP训练 &amp; 完全分片的DP训练：</p><ul><li><p><strong>完整的模型副本在每个GPU上保存</strong>；前向/反向传播只在一个数据分片上执行。</p></li><li><p>每个GPU完成本地计算后：<strong>每个本地进程的梯度和优化器状态，在所有GPUs上共享</strong>，以计算全局权重的更新。<img src="/posts/48646366/image-21.png"></p></li><li><p><strong>每个GPU上只保存一个模型分片</strong>：</p><ul><li><strong>在前向/反向传播开始前：通过一个all-gather操作，从其他GPUs上收集权重；</strong></li><li><strong>反向传播之后</strong>：平均本地梯度，通过一个reduce-scatter操作，共享至所有GPUs，允许每个GPU更新自己的本地权重分片。</li></ul></li></ul><h3 id="前向传播">前向传播</h3><ol type="1"><li>对每个FSDPunit，运行all-gather收集所有rank上的模型参数切片，则<strong>每个rank上拥有当前unit的所有参数</strong>（虽然切分了模型参数，但计算时用的原始全部参数，因此FSDP依然属于数据并行）；</li><li>执行前向传播计算；</li><li>每个rank上，丢掉不属于当前rank的模型参数，释放内存；</li></ol><h3 id="反向传播">反向传播</h3><ol type="1"><li>对每个FSDP unit，运行all-gather收集所有rank上的模型参数切片；</li><li>执行反向传播计算；</li><li>每个rank上，丢掉不属于当前rank的模型参数，释放内存；</li><li><strong>执行reduce-scatter，在不同rank之间同步梯度。</strong></li></ol><h3 id="优化器更新">优化器更新</h3><p>每个rank更新自己的局部梯度分片</p><p>一个更详细的图： <img src="/posts/48646366/image-23.png"></p><h2 id="fsdp-design">FSDP Design</h2><p><a href="https://arxiv.org/abs/2304.11277">PyTorch FSDP: Experienceson Scaling Fully Sharded Data Parallel</a></p><p><a href="https://github.com/pytorch/pytorch/blob/main/torch/distributed/fsdp/fully_sharded_data_parallel.py#L401">pytorch/torch/distributed/fsdp/fully_sharded_data_parallel.py</a></p><p>引入Sharding factor（F），取值在1~W之间（W为设备数）。令F=W，此时采取fully sharded策略。</p><p>调用例子： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># xdoctest: +SKIP(&quot;undefined variables&quot;)</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.distributed.fsdp <span class="keyword">import</span> FullyShardedDataParallel <span class="keyword">as</span> FSDP</span><br><span class="line">torch.cuda.set_device(device_id)</span><br><span class="line">sharded_module = FSDP(my_module)</span><br><span class="line">optim = torch.optim.Adam(sharded_module.parameters(), lr=<span class="number">0.0001</span>)</span><br><span class="line">x = sharded_module(x, y=<span class="number">3</span>, z=torch.Tensor([<span class="number">1</span>]))</span><br><span class="line">loss = x.<span class="built_in">sum</span>()</span><br><span class="line">loss.backward()</span><br><span class="line">optim.step()</span><br></pre></td></tr></table></figure></p><h3 id="初始化">初始化</h3><p>FSDP的工作过程中，前向/反向传播都以FSDPunit为规模执行，<strong>该unit即FSDP计算和通信的执行单元</strong>。这个unit是什么呢？</p><p>在源码中，FSDP采用<code>FlatParameter</code>类的实例，来表示一个unit，即计算和通信的基本单元。在当前设计中，<code>FlatParameter</code>逻辑上表示一个1D的tensor，通过n个模型参数tensor展开拼接而成（可以是sharded或unsharded）。假设unit是<code>LlamaDecoderLayer</code>，那么其中的所有weight，包括q_proj,k_proj, v_proj等，layernorm的所有weight全部展平拼接为一个大的1Dtensor，再将这个1Dtensor平均分配到每个rank。如果不能整除，先padding再切分，这样每个rank上维护一份localshard tensor。</p><p><img src="/posts/48646366/image-17.png"></p><p><strong>为什么要使用1Dtensor呢</strong>？主要考量通信性能的约束。包括两方面原因：</p><ol type="1"><li>对于NCCLbackend来说，FSDP需要调用allgather和reduce_scatter两个collective op，<a href="https://github.com/pytorch/pytorch/blob/ce00ec7ecf08af3aede9f5f0a428848f07a5234c/torch/distributed/distributed_c10d.py#L3850">all_gather_into_tensor</a>和<a href="https://github.com/pytorch/pytorch/blob/ce00ec7ecf08af3aede9f5f0a428848f07a5234c/torch/distributed/distributed_c10d.py#L4320">reduce_scatter_tensor</a>比<a href="https://github.com/pytorch/pytorch/blob/ce00ec7ecf08af3aede9f5f0a428848f07a5234c/torch/distributed/distributed_c10d.py#L3750">all_gather</a>和<a href="https://github.com/pytorch/pytorch/blob/ce00ec7ecf08af3aede9f5f0a428848f07a5234c/torch/distributed/distributed_c10d.py#L4277">reduce_scatter</a>的性能更好，而这两个op要求输入的tensorsize是均等的；</li><li>合并和展平tensor，减少了issue collective call的次数。</li></ol><p><strong>如何构建1D tensor呢</strong>？提供wrap策略。</p><h4 id="初始化fsdp-module">初始化FSDP module</h4><p><code>FullyShardedDataParallel</code>的初始化函数中调用路径如下： 1.调用<code>_init_param_handle_from_module</code>初始化FSDP module的参数；2.在<code>_init_param_handle_from_params</code>中初始化<code>FlatParamHandle</code>实例；调用<code>shard</code>进行分片</p><h5 id="分片shard函数">分片：<code>shard</code>函数</h5><ul><li>将<code>FlatParameter</code>分片：为切片后的flatparameter分配新内存；清空未分片的flat parameter的内存。</li></ul><p>调用链：<code>shard()</code>-&gt;<code>_get_shard</code>-&gt;<code>_get_unpadded_shard</code>，核心的分片操作通过<code>_get_shard()</code>完成，而<code>_get_shard()</code>则依赖于<code>_get_unpadded_shard()</code>来获取原始的、未填充的分片。整个调用链的流程如下：1. <code>shard()</code>方法被调用； 2.<code>shard()</code>根据是否使用分片策略来选择执行路径：如果使用分片策略，它会调用<code>FlatParamHandle._get_shard()</code>；3.<code>FlatParamHandle._get_shard()</code>调用<code>_get_unpadded_shard()</code>来获取当前进程（rank）和总进程数（world_size）下的未填充分片，并计算需要填充的元素数量；4.<code>FlatParamHandle._get_shard()</code>根据需要填充的元素数量<strong>对分片进行填充</strong>，并返回填充后的分片和填充的元素数量；5.<code>shard()</code>方法将填充后的分片设置到<code>flat_param</code>中，并初始化相关的分片元数据。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@torch.no_grad()    </span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">shard</span>(<span class="params">self</span>):</span><br><span class="line">        flat_param = <span class="variable language_">self</span>.flat_param</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="variable language_">self</span>.uses_sharded_strategy:</span><br><span class="line">            <span class="variable language_">self</span>._init_shard_metadata(<span class="number">0</span>, <span class="number">0</span>, flat_param.numel() - <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            _p_assert(</span><br><span class="line">                flat_param.storage_offset() == <span class="number">0</span>,</span><br><span class="line">                <span class="string">&quot;The `FlatParameter` is not the sole occupant of its storage&quot;</span>,</span><br><span class="line">            )</span><br><span class="line">            sharded_flat_param, numel_padded = FlatParamHandle._get_shard(</span><br><span class="line">                flat_param, <span class="variable language_">self</span>.rank, <span class="variable language_">self</span>.world_size</span><br><span class="line">            )</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> torch.distributed._functional_collectives.is_torchdynamo_compiling():</span><br><span class="line">                allocated = flat_param._typed_storage()._size() &gt; <span class="number">0</span></span><br><span class="line">                <span class="keyword">if</span> allocated:</span><br><span class="line">                    flat_param._typed_storage()._resize_(<span class="number">0</span>)</span><br><span class="line">            flat_param.set_(sharded_flat_param)  <span class="comment"># type: ignore[call-overload]</span></span><br><span class="line">            start_idx = sharded_flat_param.numel() * <span class="variable language_">self</span>.rank</span><br><span class="line">            end_idx = sharded_flat_param.numel() * (<span class="variable language_">self</span>.rank + <span class="number">1</span>) - <span class="number">1</span>  <span class="comment"># inclusive</span></span><br><span class="line">            <span class="variable language_">self</span>._init_shard_metadata(numel_padded, start_idx, end_idx)</span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>._use_orig_params:</span><br><span class="line">            <span class="variable language_">self</span>._use_sharded_views()</span><br></pre></td></tr></table></figure><p>综上所述，在<code>FlatParamHandle._get_shard</code>函数中，将张量分割为<code>world_size</code>（总进程数）个分片，并padding到相同的大小，调用<code>_init_shard_metadata</code>初始化当前进程分片的元数据。</p>]]></content>
      
      
      <categories>
          
          <category> Parallelism </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>基于图像处理的智能纤维截面分析系统：系统展示</title>
      <link href="/posts/27b7154a.html"/>
      <url>/posts/27b7154a.html</url>
      
        <content type="html"><![CDATA[<h2 id="系统演示">系统演示</h2><div id="dplayer4" class="dplayer hexo-tag-dplayer-mark" style="margin-bottom: 20px;"></div><script>(function(){var player = new DPlayer({"container":document.getElementById("dplayer4"),"theme":"#FADFA3","loop":true,"video":{"url":"/posts/27b7154a/1.mp4","pic":"1.png"}});window.dplayers||(window.dplayers=[]);window.dplayers.push(player);})()</script>]]></content>
      
      
      
        <tags>
            
            <tag> Web Platforms Display </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>大模型推理框架vLLM：paper + code 解析</title>
      <link href="/posts/f79d4b0.html"/>
      <url>/posts/f79d4b0.html</url>
      
        <content type="html"><![CDATA[<h2 id="论文解读efficient-memory-management-for-large-language-model-serving-with-pagedattention">论文解读：EfficientMemory Management for Large Language Model Serving withPagedAttention</h2><p><a href="https://arxiv.org/abs/2309.06180">论文原文</a></p><h3 id="abstract">Abstract</h3><p>为了提供LLM的高吞吐量服务，每次需要批量处理足够多的请求。然而现有系统面临<strong>KV缓存内存不足</strong>的挑战：每个请求的KV缓存内存占用巨大，且动态增减。当内存管理效率低下时，碎片化和冗余复制会造成显著的内存浪费，从而限制批处理规模。为解决这一问题，我们提出PagedAttention，这是一种受经典操作系统虚拟内存与分页技术启发的注意力算法。基于此，我们构建了vLLM这一LLM服务系统，其实现了：(1)KV缓存内存接近零浪费；(2)支持请求内及跨请求的KV缓存灵活共享，进一步降低内存占用。评估表明，在相同延迟水平下，vLLM将主流LLM的吞吐量较FasterTransformer、Orca等最先进系统提升了2-4倍。当处理更长序列、更大模型及更复杂解码算法时，性能提升尤为显著。</p><h3 id="introduction">Introduction</h3><p>当前LLM servingsystem主要面临：KV缓存的管理问题。通常做法是将一条request的KVcache存储在连续的内存空间内（大部分deeplearning框架要求tensors在连续内存空间中存储）。KVcache和tensors的区别在于： 1. <strong>KVCache随模型生成新token，而动态增减</strong>； 2.其生命周期和长度无法提前预测。</p><p>因此，在两个方向上导致了内存使用的低效：</p><ol type="1"><li><p><strong>内存的内外碎片</strong>：为满足连续空间存储的要求，需要<strong>预先分配一段连续的最大内存空间</strong>（例如：2048tokens），这会导致内部碎片（request的实际长度小于最大长度）；</p><blockquote><p>即使长度预知，预先分配也是低效的：在request的生命周期内，内存块为其保留；导致其他更短的request也无法使用当前空闲的内存块。</p></blockquote><p>另外，对于每个request，预分配不同长度的空间，会导致外部碎片。</p></li><li><p><strong>未实现内存共享的最大优化</strong>：LLM通常采用advanceddecoding算法（并行采样或束搜索），这些算法为每个request生成多个输出序列，可以部分共享KVCache，但已有系统未考虑这一点。</p></li></ol><p>PagedAttention的想法是什么呢？提出了页式虚拟内存机制。</p><p>将request的KVcache拆分为多个blocks：每个block包括固定数量tokens的attentionkeys和values。因此，KV Cache无需存储在连续内存空间。 &gt;联动OS的理念：将blocks当作页面；tokens当作字节；requests当作进程。 &gt;&gt;这个设计通过使用更小尺寸的的blocks和按需分配，消除内部碎片；通过固定大小的blocks消除外部碎片。</p><h3 id="backgrounds">BackGrounds</h3><h4 id="基于transformer的llm">基于Transformer的LLM</h4><p>LLM的任务是：对token序列<span class="math inline">\((x_1, x_2, ...,x_n)\)</span>的概率模型建模。采用<strong>自回归分解</strong>：将整个序列的联合概率，分解为条件概率的乘积：<span class="math display">\[P(x)=P(x_1)\cdot P(x_2|x_1)\cdot\cdot\cdot P(x_n|x_1,...,x_{n-1}).\]</span></p><p>Transformer模型是大规模概率建模的事实标准架构，其核心组件是<strong>自注意力层（self-attentionlayer）</strong>。处理输入隐藏状态序列<span class="math inline">\((x_1,..., x_n)\in\mathbb{R}^{n\times d}\)</span>时，首先对每个位置<span class="math inline">\(i\)</span>进行线性变换生成查询（query）、键（key）和值（value）向量：<span class="math display">\[q_i=W_q x_i, k_i=W_k x_i, v_i=W_v x_i.\]</span>随后，该层通过计算当前位置query向量与所有历史位置的key向量的点积，得到注意力分数<span class="math inline">\(a_{ij}\)</span>： <span class="math display">\[a_{ij}=\frac{\exp(\frac{q_i^{T}k_j}{\sqrt{d}})}{\sum_{t=1}^{i}\exp(\frac{q_i^{T}k_t}{\sqrt{d}})},o_i=\sum_{j=1}^{i}a_{ij}v_j.\]</span></p><h4 id="llm服务自回归生成">LLM服务&amp;自回归生成</h4><p>经过训练后，大型语言模型（LLM）通常被部署为条件生成服务（例如自动补全API或聊天机器人）。向LLM服务发出的请求会提供一组inputprompt tokens<span class="math inline">\((x_1,x_2,...,x_n)\)</span>，LLM服务则根据自回归分解公式，生成outputtokens<span class="math inline">\((x_{n+1},x_{n+2},...,x_{n+T})\)</span>。将inputprompt tokens与output tokens的组合称为序列（sequence）。</p><p>由于自回归分解公式的分解特性，LLM只能<strong>逐个采样生成新token</strong>，且每个新token的生成过程都依赖于该序列中所有先前的tokens——特别是它们的键（key）和值（value）向量。在这一顺序生成过程中，现有token的键值向量，通常会被缓存以供后续token生成使用，即KV缓存（KVcache）。需要注意的是，<strong>某个token的KV缓存取决于其之前的所有token</strong>，这意味着同一token出现在序列不同位置时，其KV缓存也会不同。</p><p>对于给定的一个request prompt，生成过程分为两个阶段：</p><ol type="1"><li><p>prompt phase：以完整用户prompt<span class="math inline">\((x_1,x_2,...,x_n)\)</span>为输入，<strong>计算首个新token的概率<span class="math inline">\(P(x_{n+1}|x_1,...,x_n)\)</span></strong>。在此过程中，同时生成键向量<span class="math inline">\(k_1,...,k_n\)</span>和值向量<span class="math inline">\(v_1,...,v_n\)</span>。由于token<span class="math inline">\(x_1,...,x_n\)</span>均为已知，该阶段可通过矩阵-矩阵乘法实现并行计算，因此能充分利用GPU的并行计算优势。</p></li><li><p>autoregressive generationphase：按顺序生成剩余新tokens。在第<span class="math inline">\(t\)</span>次迭代时，模型接收单个token<span class="math inline">\(x_{n+t}\)</span>作为输入，基于缓存的键向量<span class="math inline">\(k_1,...,k_{n+t-1}\)</span>和值向量<span class="math inline">\(v_1,...,v_{n+t-1}\)</span>，计算概率<span class="math inline">\(P(x_{n+t+1}|x_1,...,x_{n+t})\)</span>，并生成新的键值向量<span class="math inline">\(k_{n+t}\)</span>和<span class="math inline">\(v_{n+t}\)</span>。该阶段在序列达到最大长度（用户指定或模型限制）或生成结束符<eos>时终止。<strong>由于数据依赖性，不同迭代的计算无法并行化，且多采用效率较低的矩阵-向量乘法运算</strong>，导致GPU计算资源利用率严重不足，形成内存瓶颈——这构成了单个请求延迟的主要来源。</eos></p></li></ol><h4 id="llm批处理">LLM批处理</h4><p>由于同一批次内的请求共享模型权重，权重加载的开销可被批量请求均摊——当批次规模足够大时，计算开销将完全覆盖权重传输成本。然而LLM批处理面临两大挑战：</p><ol type="1"><li><strong>请求的异步到达</strong>特性。若采用简单批处理策略，要么让先到请求等待后续请求（导致排队延迟），要么推迟新请求直至当前批次完成（造成吞吐量下降）。</li><li><strong>请求的输入输出长度差异巨大</strong>。若强行通过填充（padding）对齐序列长度，将导致GPU计算资源和内存的严重浪费。</li></ol><blockquote><p>为解决这些问题，学界提出了<strong>细粒度批处理机制</strong>（如蜂窝批处理和迭代级调度）。与传统请求级批处理不同，这些技术基于迭代维度运作：每完成一次迭代，系统便移除已处理完成的请求，并动态加入新请求。这使得<strong>新请求仅需等待单个迭代周期即可被处理</strong>，无需阻塞至整批请求完成。此外，借助专用GPU内核，这些技术彻底消除了序列填充需求。通过降低排队延迟与填充损耗，细粒度批处理机制能显著提升LLM服务的吞吐效率。</p></blockquote><h3 id="methods">Methods</h3><p><img src="/posts/f79d4b0/image.png"></p><h4 id="pagedattention">PagedAttention</h4><p>将每个序列的KV Cache分为若干个KVblocks，每个block包含：固定数量的键向量和值向量。将keyblock表示为：<span class="math inline">\(K_j=(k_{(j-1)B+1},...,v_{jB})\)</span>；valueblock表示为：<span class="math inline">\(V_j=(v_{(j-1)B+1},...,v_{jB})\)</span>.注意力计算公式变为：<span class="math display">\[A_{ij}=\frac{\exp(\frac{q_{i}^{T}K_j}{\sqrt{d}})}{\sum_{t=1}^{\lceil\frac{i}{B}\rceil}\exp(\frac{q_{i}^{T}K_t}{\sqrt{d}})},o_i=\sum_{j=1}^{\lceil \frac{i}{B}\rceil}V_jA_{ij}^T\]</span> 其中，<span class="math inline">\(A_{ij}=(a_{i,(j-1)B+1},...,a_{i,jB})\)</span>是第<span class="math inline">\(j\)</span>个KV block的注意力分数。</p><p>在注意力计算过程中，PagedAttention内核会动态识别、并分别获取不同的KV块。如图所示，键值向量分散存储在三个非连续物理内存块中（例如块0存储"Fourscore and seven"的键值向量）。 <img src="/posts/f79d4b0/image-1.png">内核执行分阶段计算：</p><ol type="1"><li><strong>query-key交互</strong>：每一次计算中，内核将querytoken（"forth"）的query向量<span class="math inline">\(q_i\)</span>，与一个block内的key向量<span class="math inline">\(K_j\)</span>相乘，以计算注意力分数<span class="math inline">\(A_{ij}\)</span>。</li><li><strong>value聚合</strong>：将<span class="math inline">\(A_{ij}\)</span>与当前块的<span class="math inline">\(V_j\)</span>相乘，生成局部注意力输出<span class="math inline">\(o_i\)</span>。</li></ol><p>总结来说，PagedAttention算法允许KVblocks存储在非连续的物理内存空间，使得vLLM中能够采用更灵活的页内存管理。</p><h4 id="kv-cache-manager">KV Cache Manager</h4><p>vLLM内存管理器的核心设计思想源于：操作系统的<strong>虚拟内存</strong>机制。操作系统将内存划分为固定大小的页（page），并将用户程序的逻辑页映射到物理页上——<strong>连续的逻辑页可对应非连续的物理内存页，使得用户程序能以连续视角访问内存</strong>。更重要的是，物理内存空间无需预先全量分配，操作系统可<strong>按需动态分配物理页</strong>。</p><p>vLLM将虚拟内存的思想应用于LLM服务的KV缓存管理：</p><ol type="1"><li>存储结构：<ul><li>通过PagedAttention将KV缓存组织为固定大小的<strong>KV块</strong>（类比虚拟内存中的页）；</li><li>每个请求的KV缓存表示为从左到右填充的<strong>逻辑KV块序列</strong>，末块预留空位供未来生成使用。</li></ul></li><li>硬件资源管理：<ul><li>GPU工作节点：块引擎（blockengine）分配连续GPU显存，并划分为物理KV块；</li><li>CPU内存：同样分块以支持交换机制</li></ul></li><li>映射系统：<ul><li>块表（block table）：维护逻辑KV块与物理KV块的映射关系</li><li>每个块表条目记录：<ul><li>逻辑块对应的物理块地址</li><li>已填充位置数量</li></ul></li></ul></li></ol><h4 id="使用pagedattention和vllm解码">使用PagedAttention和vLLM解码</h4><p>通过以下示例，说明vLLM如何在单输入序列的解码过程中执行PagedAttention并管理内存：<img src="/posts/f79d4b0/image-2.png"></p><ol type="1"><li>prefill：与操作系统虚拟内存类似，vLLM无需预先为最大可能序列长度保留内存，而是仅分配prompt计算所需的KV块。<ul><li>7个prompt tokens被分配到2个逻辑KV块（块0和块1）；</li><li>逻辑块映射到物理块7和1；</li><li>使用常规自注意力算法，生成prompt的KV Cache和首个输出token；</li><li>前4个tokens存入逻辑块0，后3个tokens存入逻辑块1（末位预留空位）。</li></ul></li><li>首次自回归解码<ul><li>基于物理块7和1执行PagedAttention生成新token；</li><li>新生成的KV缓存存入逻辑块1预留槽；</li><li>块表中#filled字段更新。</li></ul></li><li>二次解码<ul><li>当逻辑块1写满时，分配新逻辑块；</li><li>从空闲池获取物理块3并建立映射；</li><li>更新块表记录新增的逻辑-物理块对应关系。</li></ul></li></ol><p>全局来看，vLLM在每次解码迭代时执行以下关键操作：</p><ol type="1"><li>动态批处理构建：选择候选序列集合进行批处理；为新需求的逻辑KV块分配物理块。</li><li>输入序列整合：将当前迭代内，所有输入tokens拼接为单一序列：提示阶段请求的所有tokens+生成阶段请求的最新token</li><li>分页注意力执行：通过PagedAttention内核：访问以逻辑KV块形式存储的历史KV缓存；将新生成的KV缓存写入分配的物理KV块。</li></ol><p>vLLM采用<strong>动态物理块分配</strong>机制：随着新token及其KV缓存的生成，系统持续为逻辑块分配新的物理块。其内存高效性体现在两个关键设计：</p><ol type="1"><li>紧凑的内存布局：<ul><li>严格遵循从左到右的填充顺序；</li><li>仅当所有现存块写满时，才分配新物理块；</li><li>将内存浪费严格限制在单个块容量内。</li></ul></li><li>弹性资源共享：<ul><li>请求完成生成后，立即释放其KV块，供其他请求复用；</li></ul><blockquote><p><img src="/posts/f79d4b0/image-3.png">如图所示：两个序列的逻辑块，可映射到不同的物理块，实现GPU节点的内存共享。</p></blockquote></li></ol><h4 id="vllm在其他解码场景的应用">vLLM在其他解码场景的应用</h4><h5 id="并行采样parallel-sampling">并行采样（Parallel Sampling）</h5><p>对于一个输入prompt，LLM生成多个输出采样。用户可从多个候选者中，选出最喜欢的输出。</p><p>并行采样场景中，<strong>单个请求包含：共享相同输入prompt的多个输出样本</strong>，这使得prompt的KV缓存也可被共享。借助PagedAttention和分页内存管理机制，vLLM能够轻松实现这种内存共享优化。共享机制的实现如下图：<img src="/posts/f79d4b0/image-4.png"></p><ol type="1"><li>prompt阶段：双输出样本共享相同的prompt，因此只保留一份prompt状态的拷贝；<strong>两个序列的prompts对应逻辑块，映射至相同的物理块</strong>。<ul><li>逻辑块映射：序列A1/A2的逻辑块0 → 物理块7；序列A1/A2的逻辑块1 →物理块1</li><li>物理块引用计数：物理块7和1的引用计数均为2</li></ul></li><li>generation阶段：<strong>写时复制机制（copy-on-write）</strong><ul><li>当样本A1需修改逻辑块1时：检测物理块1引用计数&gt;1；分配新物理块3并复制原数据；物理块1引用计数降为1</li><li>样本A2写入物理块1时：引用计数已为1，直接写入</li></ul></li></ol><p>vLLM的技术优势：</p><ul><li>内存节省：多个输出共享prompt的KV缓存，显著减少长提示词场景的内存占用；</li><li>安全隔离：块级写时复制，确保多样本修改隔离性；</li><li>零冗余设计：仅末位逻辑块需写时复制，其余物理块完全共享。</li></ul><h5 id="束搜索beam-search">束搜索（Beam Search）</h5><p>在机器翻译等LLM任务中，束搜索用于获取<strong>最优k个输出</strong>。通过束宽参数<span class="math inline">\(k\)</span>，控制每一步保留的候选序列数，有效避免全量遍历样本空间的计算复杂度。其工作流程分为三步：</p><ol type="1"><li>候选扩展：对束内的每个候选序列，枚举词汇表<span class="math inline">\(V\)</span>的所有可能续接tokens；</li><li>概率评估：调用LLM计算<span class="math inline">\(k\times|V|\)</span>个候选序列各自的生成概率（<span class="math inline">\(|V|\)</span>为词汇表大小）</li><li>择优保留：筛选概率最高的<span class="math inline">\(k\)</span>个序列，进入下一轮迭代。</li></ol><p>与并行解码不同，束搜索实现了更深层次的KV块共享机制：不止共享prompt对应block，<strong>不同候选序列也共享对应blocks，共享机制随着解码过程动态迭代</strong>。</p><ol type="1"><li>动态共享拓扑：<ul><li>所有候选序列，强制共享首个block（prompt block 0）</li><li>候选序列3从第2块开始分叉；候选序列0-2共享前3块，在第四块分叉</li><li>淘汰候选序列（0和3）时自动释放其逻辑块</li></ul></li><li>智能内存管理：<ul><li>引用计数归零的物理块即时释放；</li><li>为新候选序列动态分配物理块（块9-12）</li></ul></li></ol><p><img src="/posts/f79d4b0/image-5.png"></p><h5 id="共享前缀">共享前缀</h5><p>在LLM应用中，用户通常需要提供<strong>包含instructions和exampleinputs/outputs</strong>的<strong>系统提示词（systemprompt）</strong>，这些内容会与实际任务input拼接，形成完整prompt。此类共享prefix可通过提示词工程进一步微调，以提升下游任务的准确率。vLLM的实现方式如下：</p><ol type="1"><li><strong>预缓存机制</strong>：预先将共享prefix的KV缓存，存入专用物理块（类比OS对共享库的内存管理）；</li><li>动态映射：含有共享prefix的用户请求，可直接将逻辑块映射到已缓存的物理块（末位块标记为copy-on-write）；</li><li>计算优化：promptphase仅需执行用户独有输入的计算（消除对共享prefix的冗余计算）</li></ol><h4 id="调度与抢占机制">调度与抢占机制</h4><p>当请求流量超过系统容量时，vLLM优先处理部分请求。vLLM采用<strong>先来先服务（FCFS）</strong>算法，以确保公平性并避免请求饥饿。</p><p>LLM服务面临的挑战有：输入prompts的长度差异显著；输出长度无法预知（由输入和模型行为决定）。随着请求数量和输出数量增加，VLLM可能会耗尽GPU的物理块，以致无法存储新生成的KVCache。对此有两个亟需解决的问题：</p><ol type="1"><li><p><strong>块驱逐</strong>策略：通常使用启发式算法，预测最晚访问的物理块</p><ul><li><strong>全有或全无（All-or-Nothing）原则</strong>：同一序列的所有blocks，必须同时被驱逐或保留（由于一个序列的所有blocks同时被访问）；</li><li><strong>组调度（Gang-Scheduling）</strong>：同一请求内的多序列（如束搜索中的候选序列）作为<strong>序列组</strong>统一调度（需要避免破坏序列间潜在的内存共享关系）</li></ul></li><li><p><strong>驱逐块恢复</strong>：</p><ul><li><p><strong>内存交换（Swapping）</strong>：将被驱逐的KV块，暂存至CPURAM。工作流程如下：</p><ul><li>一旦GPU中没有空闲的物理块以分配给新token，选择待驱逐的序列组；</li><li>将该序列组的所有KV块，整体迁移至CPURAM（在此期间，vLLM暂停接收新需求，直至所有被抢占的序列迁移完成）；</li><li>一旦请求完成，从GPU内存释放其所有blocks，被抢占的序列从CPU中迁移回GPU，继续计算。</li></ul><blockquote><p>注意：CPU RAM永不超过GPU RAM中的物理块总数，因此：CPURAM中交换空间大小严格受限于GPU显存容量。</p></blockquote></li><li><p><strong>重计算（Recomputation）</strong>：当被抢占的序列被重新调度时，重新计算其KVCache。</p><ul><li>加速机制：将被抢占序列的已解码tokens，与原始用户prmpt，拼接形成新prompt；通过单次prompt阶段（prefillphase）并行，重构完整KV缓存。</li></ul></li></ul></li></ol><h4 id="分布式执行">分布式执行</h4><p>许多LLMs的参数量超过了单个GPU的容量。因此，需要将参数分区并分布到多个GPU上，并采用模型并行策略处理。vLLM通过以下机制实现分布式部署：</p><ol type="1"><li><p><strong>模型并行架构</strong>：<strong>Megatron-LM</strong>风格的<strong>张量并行</strong>策略</p><p>基于<strong>SPMD</strong>的执行模式：</p><ul><li><strong>线性层</strong>：块状矩阵乘法分区计算</li><li><strong>注意力层</strong>：按注意力头维度切分（每个SPMD进程处理一部分注意力头）</li><li><strong>同步机制</strong>：通过all-reduce操作同步中间结果</li></ul></li><li><p><strong>全局KV缓存管理</strong>：（每个GPU处理相同的输入tokens）</p><ul><li>采用<strong>集中式调度器</strong>统一管理：维护逻辑块到物理块的全局映射（所有GPU共享）；为每个请求，分配物理块ID</li><li>分布式存储：相同物理块ID在不同GPU存储不同内容（对应各自分片的注意力头KVCache）；各GPU仅保留自身注意力头对应的KV Cache分片</li></ul></li></ol><h5 id="工作流程">工作流程</h5><ol type="1"><li><strong>调度器预处理阶段</strong>：<ul><li>对于batch中的每个请求，生成<strong>包含输入tokens的ID的集合</strong>，和<strong>逻辑-物理块映射表（BlockTable）</strong>；</li><li>将控制信息（token IDs+Block Table）<strong>广播至所有GPUworkers</strong>；</li></ul></li><li><strong>GPU workers并行计算阶段</strong>：<ul><li>注意力层：根据控制信息中的块表，读取对应的KVCache；各worker独立处理分配的注意力头子集；</li><li>全局同步：通过all-reduce原语自动同步中间结果（无需调度器介入）</li></ul></li><li><strong>回收迭代结果</strong>：GPUworkers将采样生成的tokens回传至调度器。</li></ol><p>vLLM仅需在每个解码迭代开始时，一次性同步由调度器下发的控制信息包含的内存状态；执行期间无需额外同步内存状态。</p><h3 id="implementation">Implementation</h3><p>vLLM作为端到端的LLM服务系统，采用分层架构设计：</p><ol type="1"><li><strong>前端接口层</strong>：基于FastAPI构建RESTful服务，完整支持OpenAIAPI协议；其可定制的参数包括：最大序列长度，束搜索宽度<span class="math inline">\(k\)</span>，温度系数等采样参数；</li><li><strong>核心引擎层</strong>：<strong>控制平台</strong>（8.5KPython代码）包括分布式调度器和块管理器；<strong>数据平台</strong>（2KC++/CUDA代码）包括PagedAttention定制内核和高并发内存操作原语。集成PyTorch与HuggingFaceTransformers等，原生适配：GPT系列，OPT和LLaMA等主流架构。</li><li><strong>分布式通信层</strong>：基于NCCL实现跨GPU张量高效同步，和全兼容Megatron-LM的并行模式。</li></ol><h4 id="内核级优化">内核级优化</h4><p>针对PagedAttention的特有内存访问模式，vLLM开发了三大定制化GPU内核：</p><ol type="1"><li><strong>融合式KV缓存写入</strong>：在每个Transformer层，KVCache被划分为若干个blocks，重构为一个为读取blocks而优化的内存布局，再按块表写入。<ul><li>传统方案需多次内核启动完成；而当前将三级操作融合为单一内核。</li></ul></li><li><strong>块感知注意力计算</strong>：基于FasterTransformer内核改造，使得每个GPUwarp专门负责读取单个KV块，支持动态批处理（变长序列混合计算）。<ul><li>该方法强制合并内存访问，实现块内计算零拷贝。</li></ul></li><li><strong>批量块拷贝</strong>：传统的<code>cudaMemcpyAsync</code>导致碎片化小拷贝；因此该方法实现非连续块拷贝操作批量提交，采用写时复制。</li></ol><h4 id="解码算法支持框架">解码算法支持框架</h4><p>vLLM通过三大原子操作实现多样化解码算法：</p><table><thead><tr><th>操作</th><th>功能描述</th><th>典型应用场景</th></tr></thead><tbody><tr><td>fork</td><td>从现有序列克隆新序列</td><td>并行采样/束搜索候选分支</td></tr><tr><td>append</td><td>追加新tokens到指定序列</td><td>自回归生成迭代step</td></tr><tr><td>free</td><td>释放序列及其KV Cache</td><td>终止条件触发/低概率路径修剪</td></tr></tbody></table><h2 id="源码">源码</h2><p>vLLM整体架构如下，支持<strong>离线批处理（同步）</strong>和<strong>在线API服务（异步）</strong>。<img src="/posts/f79d4b0/image-6.png"></p><h3 id="调用方式">调用方式</h3><h4 id="离线批推理offline-batched-inference">离线批推理（Offline BatchedInference）</h4><p>从一个最基础的离线推理脚本开始： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Sample prompts.</span></span><br><span class="line">prompts = [</span><br><span class="line">    <span class="string">&quot;Hello, my name is&quot;</span>,</span><br><span class="line">    <span class="string">&quot;The president of the United States is&quot;</span>,</span><br><span class="line">    <span class="string">&quot;The capital of France is&quot;</span>,</span><br><span class="line">    <span class="string">&quot;The future of AI is&quot;</span>,</span><br><span class="line">]</span><br><span class="line"><span class="comment"># Create a sampling params object.</span></span><br><span class="line">sampling_params = SamplingParams(temperature=<span class="number">0.8</span>, top_p=<span class="number">0.95</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create an LLM.</span></span><br><span class="line">llm = LLM(model=<span class="string">&quot;facebook/opt-125m&quot;</span>)</span><br><span class="line"><span class="comment"># Generate texts from the prompts. The output is a list of RequestOutput objects that contain the prompt, generated text, and other information.</span></span><br><span class="line">outputs = llm.generate(prompts, sampling_params)</span><br><span class="line"><span class="comment"># Print the outputs.</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\nGenerated Outputs:\n&quot;</span> + <span class="string">&quot;-&quot;</span> * <span class="number">60</span>)</span><br><span class="line"><span class="keyword">for</span> output <span class="keyword">in</span> outputs:</span><br><span class="line">    prompt = output.prompt</span><br><span class="line">    generated_text = output.outputs[<span class="number">0</span>].text</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Prompt:    <span class="subst">&#123;prompt!r&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Output:    <span class="subst">&#123;generated_text!r&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;-&quot;</span> * <span class="number">60</span>)</span><br></pre></td></tr></table></figure><code>llm = LLM(model="facebook/opt-125m")</code>实例化一个<code>LLM</code>对象，其本质是实例化一个<code>LLMEngine</code>对象，通过<code>EngineArgs</code>加载配置。</p><p>在离线批推理中，每次给模型发送推理请求时，需要<strong>整个batch的数据一起发送、推理、返回推理结果</strong>，称为（batch内部）<strong>同步</strong>。</p><h4 id="在线api服务api-server-for-online-serving">在线API服务（APIServer For Online Serving）</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">curl http://localhost:<span class="number">8000</span>/v1/completions \</span><br><span class="line">    -H <span class="string">&quot;Content-Type: application/json&quot;</span> \</span><br><span class="line">    -d <span class="string">&#x27;&#123;</span></span><br><span class="line"><span class="string">        &quot;model&quot;: &quot;Qwen/Qwen2.5-1.5B-Instruct&quot;,</span></span><br><span class="line"><span class="string">        &quot;prompt&quot;: &quot;San Francisco is a&quot;,</span></span><br><span class="line"><span class="string">        &quot;max_tokens&quot;: 7,</span></span><br><span class="line"><span class="string">        &quot;temperature&quot;: 0</span></span><br><span class="line"><span class="string">    &#125;&#x27;</span></span><br></pre></td></tr></table></figure><p><strong>异步</strong>请求推理：核心处理逻辑封装在<code>AsyncLLMEngine</code>类中（继承自<code>LLMEngine</code>）。</p><h3 id="从llm开始">从<code>LLM</code>开始</h3><ol type="1"><li>通过<code>EngineArgs</code>加载配置： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">engine_args = EngineArgs(...)</span><br></pre></td></tr></table></figure></li><li>创建<code>LLMEngine</code>引擎： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 使用配置好的engine参数，初始化LLMEngine实例</span></span><br><span class="line"><span class="variable language_">self</span>.llm_engine = LLMEngine.from_engine_args(</span><br><span class="line">engine_args=engine_args, usage_context=UsageContext.LLM_CLASS)</span><br><span class="line"><span class="variable language_">self</span>.engine_class = <span class="built_in">type</span>(<span class="variable language_">self</span>.llm_engine)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;2. 用于全局唯一的request_id：</span></span><br><span class="line"><span class="string">在vLLM中内核引擎的处理中，1个prompt视为1个request，分配全局唯一的request_id&#x27;&#x27;&#x27;</span> </span><br><span class="line"><span class="variable language_">self</span>.request_counter = Counter()</span><br><span class="line"><span class="variable language_">self</span>.default_sampling_params: <span class="type">Union</span>[<span class="built_in">dict</span>[<span class="built_in">str</span>, <span class="type">Any</span>], <span class="literal">None</span>] = <span class="literal">None</span></span><br></pre></td></tr></table></figure></li></ol><blockquote><p>进入<code>from_engine_args</code>函数，看看引擎的创建过程：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@classmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">from_engine_args</span>(<span class="params"></span></span><br><span class="line"><span class="params">       cls,</span></span><br><span class="line"><span class="params">       engine_args: EngineArgs,</span></span><br><span class="line"><span class="params">       usage_context: UsageContext = UsageContext.ENGINE_CONTEXT,</span></span><br><span class="line"><span class="params">       stat_loggers: <span class="type">Optional</span>[<span class="type">Dict</span>[<span class="built_in">str</span>, StatLoggerBase]] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">   </span>) -&gt; <span class="string">&quot;LLMEngine&quot;</span>:</span><br><span class="line">       <span class="comment"># 1. 生成引擎配置对象`vllm_config`</span></span><br><span class="line">       vllm_config = engine_args.create_engine_config(usage_context)</span><br><span class="line"></span><br><span class="line">       engine_cls = cls</span><br><span class="line">       <span class="keyword">if</span> envs.VLLM_USE_V1:</span><br><span class="line">           <span class="keyword">from</span> vllm.v1.engine.llm_engine <span class="keyword">import</span> LLMEngine <span class="keyword">as</span> V1LLMEngine</span><br><span class="line">           engine_cls = V1LLMEngine</span><br><span class="line">       <span class="comment"># 2. 创建引擎实例</span></span><br><span class="line">       <span class="keyword">return</span> engine_cls.from_vllm_config(</span><br><span class="line">           vllm_config=vllm_config,</span><br><span class="line">           usage_context=usage_context,</span><br><span class="line">           stat_loggers=stat_loggers,</span><br><span class="line">           disable_log_stats=engine_args.disable_log_stats,</span><br><span class="line">       )</span><br></pre></td></tr></table></figure></p><ol type="1"><li>引擎配置实例的生成函数：<a href="https://github.com/vllm-project/vllm/blob/f7030df3be651bbce42932be736129d37caa856b/vllm/engine/arg_utils.py#L1155">create_engine_config</a>：将EngineArgs分解成ModelConfig，CacheConfig，ParallelConfig和SchedulerConfig，返回一个<code>VllmConfig</code>实例；</li><li>引擎实例的创建函数：<a href="https://github.com/vllm-project/vllm/blob/aa3b3d76e0db63a4214b45805dc9bc3e5609c30e/vllm/engine/llm_engine.py#L491">from_vllm_config</a>：（工厂方法）使用传入的<code>VllmConfig</code> 配置对象，创建并返回一个新的<code>LLMEngine</code> 实例。</li></ol></blockquote><p>采用推理引擎<code>LLMEngine</code>，整体架构如下： <img src="/posts/f79d4b0/image-7.png"></p><p>每个推理包含两个阶段：</p><ul><li>调度预处理阶段：<code>Scheduler</code>决定可参与推理的请求，为每个请求创建：<strong>包含输入tokens的ID的集合</strong>，和<strong>逻辑-物理块映射表</strong>；</li><li><strong>Worker并行计算阶段</strong>：将请求的控制信息，分发到各个worker上推理。<code>Worker</code>中的<code>CacheEngine</code>管理KVCache；<code>Worker</code>中的model加载模型并开展推理。</li></ul><h3 id="模型执行器executor">模型执行器<code>Executor</code></h3><ul><li><p>首先，<strong>模型执行器的类型是如何指定的呢</strong>？：<strong><code>_get_executor_cls</code>函数</strong></p><p>在创建引擎实例的函数<code>from_vllm_config</code>中，有：<code>executor_class=cls._get_executor_cls(vllm_config),</code></p><p>来到<a href="https://github.com/vllm-project/vllm/blob/aa3b3d76e0db63a4214b45805dc9bc3e5609c30e/vllm/engine/llm_engine.py#L453"><code>_get_executor_cls</code></a>函数：根据<code>VllmConfig</code> 配置中的<code>distributed_executor_backend</code>配置，动态选择并返回合适的<strong>执行器类：均为<code>ExecutorBase</code>的子类</strong>。</p></li><li><p><strong>有哪些执行器类型可供选择呢？</strong></p><p><code>ExecutorBase</code>为执行器基类；<code>DistributedExecutorBase</code>继承<code>ExecutorBase</code>，为分布式执行器的基类。</p><ol type="1"><li><p><code>UniProcExecutor</code>（继承<code>ExecutorBase</code>）：在<strong>单个节点</strong>上启动<strong>单个进程</strong>（支持单个节点上的<strong>多个GPU</strong>）；</p><ul><li><p><code>ExecutorWithExternalLauncher</code>（继承<code>UniProcExecutor</code>）：专门与<code>torchrun-compatible</code> 的启动器配合使用：</p><p>通过<code>torchrun</code><strong>启动多个引擎，每个引擎对应一个工作进程（worker），每个进程负责一个或多个设备（GPU）</strong>；</p><p>所有进程在处理相同的输入时会生成相同的输出，无需进行状态同步；</p><p>不支持流水线并行，执行张量并行。</p></li></ul></li><li><p><code>RayDistributedExecutor</code>（继承<code>DistributedExecutorBase</code>）：使用Ray集群进行分布式训练</p><ul><li><strong>进程数：启动多个 Ray worker，每个 worker是一个独立的进程</strong>，负责执行推理任务；（进程的数量由<code>world_size</code> 决定）</li><li><strong>设备数：每个 worker 指定使用的 GPU 数量（通过<code>num_gpus</code> 配置）</strong></li><li><strong>节点数：执行器支持在多个节点上运行多个worker；节点的分配通过 Ray placement group 管理</strong></li></ul></li><li><p><code>MultiprocessingDistributedExecutor</code>（继承<code>DistributedExecutorBase</code>）：基于Python 多进程：</p><ul><li>支持在<strong>单节点</strong>（即只有一个物理机器）上运行；通过<code>world_size</code>指定创建的工作进程数；每个进程的任务由<code>tensor_parallel_size</code>分配。通过回环地址进行进程间通信。</li></ul></li></ol></li><li><p><strong>执行器是何时创建的呢？</strong></p><p>由<code>LLMEngine</code>的初始化函数中以下语句创建：<code>self.model_executor = executor_class(vllm_config=vllm_config, )；</code></p></li><li><p><strong>执行器的初始化流程是怎样的呢？</strong>：<code>self._init_executor()</code></p></li></ul><h4 id="执行器初始化_init_executor函数">执行器初始化：<code>_init_executor</code>函数</h4><h5 id="uniprocexecutor的初始化"><code>UniProcExecutor</code>的初始化</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_init_executor</span>(<span class="params">self</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">   <span class="comment"># 1. 初始化驱动进程：driver_worker</span></span><br><span class="line">   <span class="variable language_">self</span>.driver_worker = WorkerWrapperBase(vllm_config=<span class="variable language_">self</span>.vllm_config,</span><br><span class="line">                                          rpc_rank=<span class="number">0</span>) <span class="comment"># 设置了进程的 rank 为 0</span></span><br><span class="line"></span><br><span class="line">   <span class="comment"># 2. 分布式初始化方法：获取当前机器的 IP 地址（get_ip()）和一个可用的端口号（get_open_port()）</span></span><br><span class="line">   distributed_init_method = get_distributed_init_method(</span><br><span class="line">      get_ip(), get_open_port())</span><br><span class="line">   </span><br><span class="line">   <span class="comment"># 3. 设置本地设备索引（GPU编号）：local_rank</span></span><br><span class="line">   local_rank = <span class="number">0</span></span><br><span class="line">   device_info = <span class="variable language_">self</span>.vllm_config.device_config.device.__str__().split(<span class="string">&quot;:&quot;</span>)</span><br><span class="line">   <span class="keyword">if</span> <span class="built_in">len</span>(device_info) &gt; <span class="number">1</span>:</span><br><span class="line">      local_rank = <span class="built_in">int</span>(device_info[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">   <span class="comment"># 4. 设置工作进程的 rank 和 is_driver_worker</span></span><br><span class="line">   rank = <span class="number">0</span></span><br><span class="line">   kwargs = <span class="built_in">dict</span>(</span><br><span class="line">      vllm_config=<span class="variable language_">self</span>.vllm_config,</span><br><span class="line">      local_rank=local_rank,</span><br><span class="line">      rank=rank,</span><br><span class="line">      distributed_init_method=distributed_init_method,</span><br><span class="line">      <span class="comment"># 若未启用并行配置：当前进程即为驱动进程</span></span><br><span class="line">      is_driver_worker=(<span class="keyword">not</span> <span class="variable language_">self</span>.parallel_config)</span><br><span class="line">      <span class="keyword">or</span> (rank % <span class="variable language_">self</span>.parallel_config.tensor_parallel_size == <span class="number">0</span>),</span><br><span class="line">   )</span><br><span class="line">   <span class="comment"># 5. 集体 RPC 调用</span></span><br><span class="line">   <span class="variable language_">self</span>.collective_rpc(<span class="string">&quot;init_worker&quot;</span>, args=([kwargs], ))</span><br><span class="line">   <span class="variable language_">self</span>.collective_rpc(<span class="string">&quot;init_device&quot;</span>)</span><br><span class="line">   <span class="variable language_">self</span>.collective_rpc(<span class="string">&quot;load_model&quot;</span>)</span><br></pre></td></tr></table></figure><blockquote><p>工作进程包装器（<code>WorkerWrapperBase</code>）：代表一个执行器中的一个进程，延迟初始化worker实例（真正的worker实例在<code>init_worker</code>中创建），控制worker的生命周期。</p></blockquote><h5 id="executorwithexternallauncher的初始化"><code>ExecutorWithExternalLauncher</code>的初始化</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_init_executor</span>(<span class="params">self</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">   <span class="comment"># 1. 验证配置：</span></span><br><span class="line">   <span class="comment"># 确认执行器不支持管道并行，只使用张量并行</span></span><br><span class="line">   <span class="keyword">assert</span> <span class="variable language_">self</span>.vllm_config.parallel_config.pipeline_parallel_size == <span class="number">1</span>, \</span><br><span class="line">      (<span class="string">&quot;ExecutorWithExternalLauncher does not support pipeline parallelism.&quot;</span>)</span><br><span class="line">   <span class="comment"># 确保调度器的延迟因子为 0.0，保证执行是确定性的，即每个引擎产生相同输出，无需同步状态</span></span><br><span class="line">   <span class="keyword">assert</span> <span class="variable language_">self</span>.vllm_config.scheduler_config.delay_factor == <span class="number">0.0</span>, \</span><br><span class="line">      (<span class="string">&quot;ExecutorWithExternalLauncher needs deterministic &quot;</span></span><br><span class="line">      <span class="string">&quot;execution, so it does not support delay_factor in scheduling&quot;</span>)</span><br><span class="line">   <span class="keyword">if</span> envs.VLLM_USE_V1:</span><br><span class="line">      <span class="keyword">assert</span> <span class="keyword">not</span> envs.VLLM_ENABLE_V1_MULTIPROCESSING, \</span><br><span class="line">      (<span class="string">&quot;To get deterministic execution in V1, &quot;</span></span><br><span class="line">      <span class="string">&quot;please set VLLM_ENABLE_V1_MULTIPROCESSING=0&quot;</span>)</span><br><span class="line">   </span><br><span class="line">   <span class="comment"># 2. 初始化驱动进程（rpc_rank=0）</span></span><br><span class="line">   <span class="variable language_">self</span>.driver_worker = WorkerWrapperBase(vllm_config=<span class="variable language_">self</span>.vllm_config,</span><br><span class="line">                                          rpc_rank=<span class="number">0</span>)</span><br><span class="line">   <span class="comment"># 3. 设置分布式初始化方法：&quot;env://&quot;</span></span><br><span class="line">   distributed_init_method = <span class="string">&quot;env://&quot;</span></span><br><span class="line">   rank = <span class="built_in">int</span>(os.environ[<span class="string">&quot;RANK&quot;</span>])      <span class="comment"># 当前进程的全局rank</span></span><br><span class="line">   local_rank = <span class="built_in">int</span>(os.environ[<span class="string">&quot;LOCAL_RANK&quot;</span>]) <span class="comment"># 当前进程在本地节点上的 rank，通常对应 GPU 的编号</span></span><br><span class="line">   is_driver_worker = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">   <span class="comment"># 4. 调用 collective_rpc</span></span><br><span class="line">   kwargs = <span class="built_in">dict</span>(</span><br><span class="line">      vllm_config=<span class="variable language_">self</span>.vllm_config,</span><br><span class="line">      local_rank=local_rank,</span><br><span class="line">      rank=rank,</span><br><span class="line">      distributed_init_method=distributed_init_method,</span><br><span class="line">      is_driver_worker=is_driver_worker,</span><br><span class="line">   )</span><br><span class="line">   <span class="variable language_">self</span>.collective_rpc(<span class="string">&quot;init_worker&quot;</span>, args=([kwargs], ))</span><br><span class="line">   <span class="variable language_">self</span>.collective_rpc(<span class="string">&quot;init_device&quot;</span>)</span><br><span class="line">   <span class="variable language_">self</span>.collective_rpc(<span class="string">&quot;load_model&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h5 id="raydistributedexecutor初始化"><code>RayDistributedExecutor</code>初始化</h5><ul><li>提供两种优化路径：编译DAG+SPMD / 传统RPC</li><li>硬件适配：自动检测TPU（切换通信方式：NCCL转为shm共享内存）</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_init_executor</span>(<span class="params">self</span>)-&gt;<span class="literal">None</span>:</span><br><span class="line">  <span class="string">&#x27;&#x27;&#x27;初始化和配置&#x27;&#x27;&#x27;</span></span><br><span class="line">  <span class="comment"># 1. Ray集群初始化</span></span><br><span class="line">  initialize_ray_cluster(<span class="variable language_">self</span>.parallel_config)</span><br><span class="line">  placement_group = <span class="variable language_">self</span>.parallel_config.placement_group</span><br><span class="line">  </span><br><span class="line">  <span class="comment"># 2. 创建并行的GPU Workers</span></span><br><span class="line">  <span class="variable language_">self</span>._init_workers_ray(placement_group)</span><br><span class="line">  </span><br><span class="line">  <span class="comment"># 3. 消息编解码器</span></span><br><span class="line">  <span class="variable language_">self</span>.input_encoder = msgspec.msgpack.Encoder(enc_hook=encode_hook)</span><br><span class="line">  <span class="variable language_">self</span>.output_decoder = msgspec.msgpack.Decoder(</span><br><span class="line">        <span class="type">Optional</span>[<span class="type">List</span>[SamplerOutput]])</span><br></pre></td></tr></table></figure><blockquote><p>初始化Ray集群（<code>initialize_ray_cluster</code>）：负责连接或创建Ray集群，并设置资源分配策略；</p><p>初始化工作进程(workers)（<code>_init_workers_ray</code>）：创建、配置和管理分布式LLM推理所需的所有工作节点。</p><ol type="1"><li>在Ray集群中，创建并配置多个工作进程：使用Ray的PlacementGroup确保GPU资源正确分配；每个worker绑定到特定的资源bundle</li><li>分布式通信：单节点使用127.0.0.1优化通信；多节点使用实际IP地址</li><li>支持并行模式：流水线并行和张量并行</li></ol></blockquote><h3 id="工作进程worker">工作进程<code>Worker</code></h3><h3 id="推理引擎llmengine">推理引擎<code>LLMEngine</code></h3><p><code>LLMEngine</code>是主要的执行引擎，用于处理从客户端接收的请求，执行文本生成任务，并返回生成的结果。该类包括一个tokenizer、一个Languagemodel（可能分布在多个 GPU 上），以及分配给中间状态（即 KV Cache）的 GPU内存空间。</p><h4 id="llmengine初始化"><code>LLMEngine</code>初始化</h4><p><img src="/posts/f79d4b0/image-8.png"></p><ol type="1"><li><p>初始化 <code>tokenizer</code>（可选）：根据配置中的<code>skip_tokenizer_init</code> 参数决定是否初始化<code>tokenizer</code>（分词器）；</p></li><li><p><strong>序列计数器</strong>：<code>self.seq_counter = Counter()</code>，追踪生成的序列数量；</p></li><li><p><strong>输入预处理器</strong>：<code>self.input_preprocessor = InputPreprocessor(self.model_config,self.tokenizer,mm_registry)</code>，将处理输入数据并将其转换为模型能够理解的格式；</p></li><li><p><strong>模型执行器</strong>：<code>self.model_executor = executor_class(vllm_config=vllm_config, )</code>；</p><p>创建继承<code>ExecutorBase</code>基类的实例：初始化函数中包括<code>self._init_executor()</code></p></li><li><p><strong>KVCache初始化</strong>：<code>self._initialize_kv_caches();</code>（如果模型的运行类型不是<code>pooling</code>），用于存储推理过程中间结果，减少重复计算；</p></li><li><p><strong>使用统计信息</strong></p></li><li><p><strong>创建调度器</strong>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable language_">self</span>.scheduler = [</span><br><span class="line">   Scheduler(</span><br><span class="line">     <span class="variable language_">self</span>.scheduler_config, <span class="variable language_">self</span>.cache_config, <span class="variable language_">self</span>.lora_config,</span><br><span class="line">     <span class="variable language_">self</span>.parallel_config.pipeline_parallel_size,</span><br><span class="line">     <span class="variable language_">self</span>.async_callbacks[v_id]</span><br><span class="line">     <span class="keyword">if</span> <span class="variable language_">self</span>.model_config.use_async_output_proc <span class="keyword">else</span> <span class="literal">None</span>)</span><br><span class="line"> <span class="keyword">for</span> v_id <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.parallel_config.pipeline_parallel_size)</span><br><span class="line">]</span><br></pre></td></tr></table></figure></li><li><p><strong>统计日志记录器</strong>：支持输出到 Prometheus或本地日志；</p></li><li><p><strong>初始化输出处理器</strong>：创建输出处理器，用于处理生成的序列，支持序列生成技术（如Beam Search 或推测解码）；</p></li><li><p>其他初始化：初始化<code>self.seq_id_to_seq_group: Dict[str, SequenceGroupBase] = &#123;&#125;</code>字典，跟踪序列的组信息。</p></li></ol><h5 id="初始化kv-cache_initialize_kv_caches">初始化KVCache：<code>_initialize_kv_caches</code></h5><ul><li>决定在GPU Cache和CPU Cache中的block数量。 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_initialize_kv_caches</span>(<span class="params">self</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        start = time.time()</span><br><span class="line">        <span class="comment"># 1. 调用模型执行器：确定可用的 GPU 和 CPU 缓存块数</span></span><br><span class="line">        num_gpu_blocks, num_cpu_blocks = (</span><br><span class="line">            <span class="variable language_">self</span>.model_executor.determine_num_available_blocks())</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 2. 若存在缓存块数的覆盖配置，则使用该覆盖值</span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.cache_config.num_gpu_blocks_override <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            num_gpu_blocks_override = <span class="variable language_">self</span>.cache_config.num_gpu_blocks_override</span><br><span class="line">            logger.info(</span><br><span class="line">                <span class="string">&quot;Overriding num_gpu_blocks=%d with &quot;</span></span><br><span class="line">                <span class="string">&quot;num_gpu_blocks_override=%d&quot;</span>, num_gpu_blocks,</span><br><span class="line">                num_gpu_blocks_override)</span><br><span class="line">            num_gpu_blocks = num_gpu_blocks_override</span><br><span class="line">        <span class="comment"># 3. 更新缓存配置：将GPU 和 CPU 块数，保存到cache_config配置对象中</span></span><br><span class="line">        <span class="variable language_">self</span>.cache_config.num_gpu_blocks = num_gpu_blocks</span><br><span class="line">        <span class="variable language_">self</span>.cache_config.num_cpu_blocks = num_cpu_blocks</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 4. 初始化模型的缓存</span></span><br><span class="line">        <span class="variable language_">self</span>.model_executor.initialize_cache(num_gpu_blocks, num_cpu_blocks)</span><br><span class="line">        elapsed = time.time() - start</span><br><span class="line">        logger.info((<span class="string">&quot;init engine (profile, create kv cache, &quot;</span></span><br><span class="line">                     <span class="string">&quot;warmup model) took %.2f seconds&quot;</span>), elapsed)</span><br></pre></td></tr></table></figure> 总流程如下：<img src="/posts/f79d4b0/image-9.png"></li></ul><blockquote><p>调用两个模型执行器的函数：<code>ExecutorBase</code>类的方法（所有executor的基类）</p><ul><li><p><code>determine_num_available_blocks</code>：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 远程调用（RPC）机制：向集群中的所有 worker 节点发出请求，收集每个节点上可用的缓存块数</span></span><br><span class="line">results = <span class="variable language_">self</span>.collective_rpc(<span class="string">&quot;determine_num_available_blocks&quot;</span>)</span><br><span class="line">a = <span class="built_in">min</span>([r[<span class="number">0</span>] <span class="keyword">for</span> r <span class="keyword">in</span> results])</span><br><span class="line">b = <span class="built_in">min</span>([r[<span class="number">1</span>] <span class="keyword">for</span> r <span class="keyword">in</span> results])</span><br></pre></td></tr></table></figure></p></li><li><p><code>initialize_cache</code>：通过底层的 worker初始化 KV缓存</p><ul><li>计算<strong>最大并发量</strong>：推理过程中同时处理请求的最大数量。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># block_size 是每个缓存块的大小；max_model_len 是模型处理的最大序列长度</span></span><br><span class="line">max_concurrency = (num_gpu_blocks * <span class="variable language_">self</span>.cache_config.block_size /</span><br><span class="line">                      <span class="variable language_">self</span>.model_config.max_model_len)</span><br></pre></td></tr></table></figure></li><li>调用<code>collective_rpc("initialize_cache", args=(num_gpu_blocks, num_cpu_blocks))</code>来通知各个 worker 初始化缓存</li></ul></li></ul></blockquote><h6 id="worker前向推理determine_num_available_blocks"><code>Worker</code>前向推理：<code>determine_num_available_blocks</code></h6><p><img src="/posts/f79d4b0/image-10.png" alt="alt text"><strong>在模型部署的初始化阶段（推理正式开始前），vLLM通过模拟实验的方式，来决定gpu/cpu上到底有多少个KVcache物理块可分配给后续的请求做推理</strong>。这是如何完成的呢？</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@torch.inference_mode()</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">determine_num_available_blocks</span>(<span class="params">self</span>) -&gt; <span class="type">Tuple</span>[<span class="built_in">int</span>, <span class="built_in">int</span>]:</span><br></pre></td></tr></table></figure><ol type="1"><li><p><strong>内存分析准备</strong>： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">torch.cuda.empty_cache()               <span class="comment"># 释放当前 CUDA 上的未使用内存</span></span><br><span class="line">torch.cuda.reset_peak_memory_stats()   <span class="comment"># 重置 GPU 内存的峰值统计信息</span></span><br><span class="line"><span class="comment"># 返回：当前GPU空闲内存 和 总GPU内存</span></span><br><span class="line">free_memory_pre_profile, total_gpu_memory = torch.cuda.mem_get_info()   </span><br></pre></td></tr></table></figure></p></li><li><p><strong>执行内存分析</strong>：调用<code>model_runner</code>的<code>profile_run</code>方法，调用<code>_dummy_run</code>模拟一次前向推理<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> memory_profiling(</span><br><span class="line">        <span class="variable language_">self</span>.baseline_snapshot,</span><br><span class="line">        weights_memory=<span class="variable language_">self</span>.model_runner.model_memory_usage) <span class="keyword">as</span> result:</span><br><span class="line">    <span class="variable language_">self</span>.model_runner.profile_run()</span><br></pre></td></tr></table></figure></p><ul><li><code>profile_run</code>方法：调用<code>_dummy_run</code><ul><li><code>max_num_seqs</code>为在1个推理阶段中，LLMEngine<strong>最多能处理的seq数量</strong>；</li><li><code>max_num_batched_tokens</code>为1个推理阶段中，LLMEngine<strong>最多能处理的token数量</strong>。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@torch.inference_mode()</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">profile_run</span>(<span class="params">self</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">  max_num_batched_tokens = \</span><br><span class="line">      <span class="variable language_">self</span>.scheduler_config.max_num_batched_tokens</span><br><span class="line">  max_num_seqs = <span class="variable language_">self</span>.scheduler_config.max_num_seqs</span><br><span class="line">  <span class="variable language_">self</span>._dummy_run(max_num_batched_tokens, max_num_seqs)</span><br></pre></td></tr></table></figure></li></ul></li></ul></li><li><p><strong>模拟一次前向推理</strong>：调用<code>model_runner</code>的<code>_dummy_run</code>，通过生成虚拟数据和配置来模拟一次模型的推理过程，帮助评估内存使用情况；并不涉及实际的训练过程。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_dummy_run</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                   max_num_batched_tokens: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                   max_num_seqs: <span class="built_in">int</span> = <span class="number">1</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">with</span> <span class="variable language_">self</span>.set_in_profile_run():</span><br><span class="line">            <span class="comment"># 1. 设置配置和采样参数: top-k采样</span></span><br><span class="line">            sampling_params = \</span><br><span class="line">                SamplingParams(top_p=<span class="number">0.99</span>, top_k=<span class="variable language_">self</span>.vocab_size - <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 2. 构造LoRA请求：</span></span><br><span class="line">            dummy_lora_requests: <span class="type">List</span>[LoRARequest] = []</span><br><span class="line">            dummy_lora_requests_per_seq: <span class="type">List</span>[LoRARequest] = []</span><br><span class="line">            <span class="keyword">if</span> <span class="variable language_">self</span>.lora_config:</span><br><span class="line">               <span class="comment"># 调用 self._add_dummy_loras() 方法生成一组虚拟的 LoRA 请求（请求数为max_loras）</span></span><br><span class="line">                dummy_lora_requests = <span class="variable language_">self</span>._add_dummy_loras(  </span><br><span class="line">                    <span class="variable language_">self</span>.lora_config.max_loras)</span><br><span class="line">                <span class="keyword">assert</span> <span class="built_in">len</span>(dummy_lora_requests) == <span class="variable language_">self</span>.lora_config.max_loras</span><br><span class="line">               <span class="comment"># 每个序列都得到一个相应的 LoRA 请求</span></span><br><span class="line">                dummy_lora_requests_per_seq = [</span><br><span class="line">                    dummy_lora_requests[idx % <span class="built_in">len</span>(dummy_lora_requests)]</span><br><span class="line">                    <span class="keyword">for</span> idx <span class="keyword">in</span> <span class="built_in">range</span>(max_num_seqs)</span><br><span class="line">                ]</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 3. 处理多模态数据（可能消耗更多GPU内存）：将batch_size设置为图片的最大数量</span></span><br><span class="line">            max_mm_tokens = <span class="variable language_">self</span>.mm_registry.get_max_multimodal_tokens(</span><br><span class="line">                <span class="variable language_">self</span>.model_config)     <span class="comment"># max_mm_tokens ：多模态数据中可用的最大 token 数量</span></span><br><span class="line">            <span class="keyword">if</span> max_mm_tokens &gt; <span class="number">0</span>:      <span class="comment"># 调整最大序列数max_num_seqs</span></span><br><span class="line">                max_num_seqs_orig = max_num_seqs</span><br><span class="line">                max_num_seqs = <span class="built_in">min</span>(max_num_seqs,</span><br><span class="line">                                   max_num_batched_tokens // max_mm_tokens)</span><br><span class="line">                <span class="keyword">if</span> max_num_seqs &lt; <span class="number">1</span>:</span><br><span class="line">                    expr = (<span class="string">f&quot;min(<span class="subst">&#123;max_num_seqs_orig&#125;</span>, &quot;</span></span><br><span class="line">                            <span class="string">f&quot;<span class="subst">&#123;max_num_batched_tokens&#125;</span> // <span class="subst">&#123;max_mm_tokens&#125;</span>)&quot;</span>)</span><br><span class="line">                    logger.warning(</span><br><span class="line">                        <span class="string">&quot;Computed max_num_seqs (%s) to be less than 1. &quot;</span></span><br><span class="line">                        <span class="string">&quot;Setting it to the minimum value of 1.&quot;</span>, expr)</span><br><span class="line">                    max_num_seqs = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 4. 循环为每个序列，生成虚拟输入数据：</span></span><br><span class="line">            seqs: <span class="type">List</span>[SequenceGroupMetadata] = []</span><br><span class="line">            batch_size = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> group_id <span class="keyword">in</span> <span class="built_in">range</span>(max_num_seqs):</span><br><span class="line">               <span class="comment"># seq_len 计算当前序列的长度，确保每个序列的长度总和等于 max_num_batched_tokens</span></span><br><span class="line">                seq_len = (max_num_batched_tokens // max_num_seqs +</span><br><span class="line">                           (group_id &lt; max_num_batched_tokens % max_num_seqs))</span><br><span class="line">                batch_size += seq_len</span><br><span class="line"></span><br><span class="line">               <span class="comment"># 调用dummy_data_for_profiling：生成用于分析的虚拟数据</span></span><br><span class="line">                dummy_data = <span class="variable language_">self</span>.input_registry \</span><br><span class="line">                    .dummy_data_for_profiling(<span class="variable language_">self</span>.model_config,</span><br><span class="line">                                            seq_len,</span><br><span class="line">                                            <span class="variable language_">self</span>.mm_registry)</span><br><span class="line"></span><br><span class="line">               <span class="comment"># 为每个序列创建一个 SequenceGroupMetadata 对象</span></span><br><span class="line">                seq = SequenceGroupMetadata(</span><br><span class="line">                    request_id=<span class="built_in">str</span>(group_id),</span><br><span class="line">                    is_prompt=<span class="literal">True</span>,</span><br><span class="line">                    seq_data=&#123;group_id: dummy_data.seq_data&#125;,</span><br><span class="line">                    sampling_params=sampling_params,</span><br><span class="line">                    block_tables=<span class="literal">None</span>,</span><br><span class="line">                    lora_request=dummy_lora_requests_per_seq[group_id]</span><br><span class="line">                    <span class="keyword">if</span> dummy_lora_requests_per_seq <span class="keyword">else</span> <span class="literal">None</span>,</span><br><span class="line">                    multi_modal_data=dummy_data.multi_modal_data,</span><br><span class="line">                    multi_modal_placeholders=dummy_data.</span><br><span class="line">                    multi_modal_placeholders,</span><br><span class="line">                )</span><br><span class="line">                seqs.append(seq)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 5. 创建并执行模型推理</span></span><br><span class="line">            <span class="comment"># Run the model with the dummy inputs.</span></span><br><span class="line">            num_layers = <span class="variable language_">self</span>.model_config.get_num_layers(<span class="variable language_">self</span>.parallel_config)</span><br><span class="line">            kv_caches = [           <span class="comment"># 为每个层创建一个空的张量缓存（float32）</span></span><br><span class="line">            <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">            1. 使用空tensor而非None：确保框架（如 PyTorch 的 Dynamo）在处理这些参数时，将它们作为引用传递，而不是根据参数的值（如 None）进行特殊化；</span></span><br><span class="line"><span class="string">            2. 在循环中每次创建新的张量，而不是通过列表复制，避免张量别名问题。</span></span><br><span class="line"><span class="string">            &#x27;&#x27;&#x27;</span></span><br><span class="line">                torch.tensor([], dtype=torch.float32, device=<span class="variable language_">self</span>.device)</span><br><span class="line">                <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_layers)</span><br><span class="line">            ]</span><br><span class="line">            finished_requests_ids = [seq.request_id <span class="keyword">for</span> seq <span class="keyword">in</span> seqs]</span><br><span class="line">            model_input = <span class="variable language_">self</span>.prepare_model_input(         <span class="comment"># 准备模型的输入数据</span></span><br><span class="line">                seqs, finished_requests_ids=finished_requests_ids)</span><br><span class="line">            intermediate_tensors = <span class="literal">None</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> get_pp_group().is_first_rank:</span><br><span class="line">                intermediate_tensors = \</span><br><span class="line">                    <span class="variable language_">self</span>.model.make_empty_intermediate_tensors(</span><br><span class="line">                    batch_size=batch_size,</span><br><span class="line">                    dtype=<span class="variable language_">self</span>.model_config.dtype,</span><br><span class="line">                    device=<span class="variable language_">self</span>.device)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 虚拟模型推理中，禁用键值比例计算</span></span><br><span class="line">            <span class="keyword">if</span> model_input.attn_metadata <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                model_input.attn_metadata.enable_kv_scales_calculation = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 执行模型推理 </span></span><br><span class="line">            <span class="variable language_">self</span>.execute_model(model_input, kv_caches, intermediate_tensors)</span><br><span class="line">            torch.cuda.synchronize()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 6. 清理之前添加的虚拟 LoRA 请求</span></span><br><span class="line">            <span class="keyword">if</span> <span class="variable language_">self</span>.lora_config:</span><br><span class="line">                <span class="variable language_">self</span>._remove_dummy_loras()</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span></span><br></pre></td></tr></table></figure></p></li><li><p>(回到<code>Worker</code>)可分配的KV cache物理块总数：</p></li></ol><ul><li><p><strong>分配给KV cache显存 = gpu总显存 -（不使用KVcache情况下）做1次FWD时的显存占用</strong></p><blockquote><p>对于“不使用KVcache做1次FWD时的显存占用”，使用上一步中模拟的一次FWD计算得出。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">memory_for_current_instance = total_gpu_memory * <span class="variable language_">self</span>.cache_config.gpu_memory_utilization</span><br><span class="line">available_kv_cache_memory = (memory_for_current_instance - result.non_kv_cache_memory)</span><br></pre></td></tr></table></figure></p></blockquote></li><li><p><strong>总物理块数量 = 分配给KV Cache的显存大小/物理块大小，其中“大小”的单位是bytes</strong>。 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">cache_block_size = <span class="variable language_">self</span>.get_cache_block_size_bytes()</span><br><span class="line"><span class="keyword">if</span> cache_block_size == <span class="number">0</span>:</span><br><span class="line">    num_gpu_blocks = <span class="number">0</span></span><br><span class="line">    num_cpu_blocks = <span class="number">0</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    num_gpu_blocks = <span class="built_in">int</span>(available_kv_cache_memory // cache_block_size)</span><br><span class="line">    num_cpu_blocks = <span class="built_in">int</span>(<span class="variable language_">self</span>.cache_config.swap_space_bytes // cache_block_size)</span><br><span class="line">num_gpu_blocks = <span class="built_in">max</span>(num_gpu_blocks, <span class="number">0</span>)</span><br><span class="line">num_cpu_blocks = <span class="built_in">max</span>(num_cpu_blocks, <span class="number">0</span>)</span><br></pre></td></tr></table></figure></p></li></ul><blockquote><p>这里抛出一个问题：GPU上物理块大小<code>cache_block_size</code>如何计算呢？</p><p>调用<code>CacheEngine</code>的<code>get_cache_block_size_bytes</code>方法：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line">   <span class="keyword">def</span> <span class="title function_">get_cache_block_size</span>(<span class="params"></span></span><br><span class="line"><span class="params">       cache_config: CacheConfig,</span></span><br><span class="line"><span class="params">       model_config: ModelConfig,</span></span><br><span class="line"><span class="params">       parallel_config: ParallelConfig,</span></span><br><span class="line"><span class="params">   </span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">       <span class="comment"># head_size：每个 Attention 头部 的大小（即每个头部的维度）</span></span><br><span class="line">       head_size = model_config.get_head_size()     </span><br><span class="line">       <span class="comment"># num_heads：KV Cache中使用的 Attention 头的数量</span></span><br><span class="line">       num_heads = model_config.get_num_kv_heads(parallel_config)</span><br><span class="line">       <span class="comment"># num_attention_layers：Attention 层 的数量</span></span><br><span class="line">       num_attention_layers = model_config.get_num_layers_by_block_type(</span><br><span class="line">           parallel_config, LayerBlockType.attention)</span><br><span class="line">       <span class="comment"># dtype：数据类型</span></span><br><span class="line">       <span class="keyword">if</span> cache_config.cache_dtype == <span class="string">&quot;auto&quot;</span>:</span><br><span class="line">           dtype = model_config.dtype</span><br><span class="line">       <span class="keyword">else</span>:</span><br><span class="line">           dtype = STR_DTYPE_TO_TORCH_DTYPE[cache_config.cache_dtype]</span><br><span class="line">       <span class="comment"># 每个Key Cache条目的大小：num_heads（头数）* head_size（每个头的大小）</span></span><br><span class="line">       key_cache_entry = num_heads * head_size</span><br><span class="line"></span><br><span class="line">       <span class="comment"># 每个Value Cache条目的大小：如果 模型使用 MLA，则没有Value Cache；如果 模型没有使用 MLA，则 value_cache_entry 等于 key_cache_entry</span></span><br><span class="line">       value_cache_entry = key_cache_entry <span class="keyword">if</span> <span class="keyword">not</span> model_config.use_mla <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">       <span class="comment"># 每个 KV Cache所需的总内存大小：</span></span><br><span class="line">       total = num_attention_layers * cache_config.block_size * \</span><br><span class="line">           (key_cache_entry + value_cache_entry)</span><br><span class="line"></span><br><span class="line">       dtype_size = get_dtype_size(dtype)</span><br><span class="line">       <span class="comment"># 缓存块的总大小</span></span><br><span class="line">       <span class="keyword">return</span> dtype_size * total</span><br></pre></td></tr></table></figure>总结：由大模型中KV值的定义，易知：<code>K_cache_block_size = block_size * num_heads * head_size * num_layers * dtype_size</code>。其中<code>dtype_size</code>表示精度对应的大小，例如<code>fp16</code>是2，<code>fp32</code>是4；</p><p>同理可知：<code>V_cache_block_size = K_cache_block_size</code></p><p>最终一个物理块的大小为：<code>cache_block_size = block_size * num_heads * head_size * num_layers * dtype_size * 2</code></p><p>CPU上物理块总数也是同理，但与GPU不同的是，它无需模拟前向推理。CPU上可用的内存总数由用户通过参数传入（默认4G）。</p></blockquote><h6 id="worker初始化-kv-cacheinitialize_cache"><code>Worker</code>初始化KV Cache：<code>initialize_cache</code></h6><p><strong>在确定KV Cache Block的大小后，创建emptytensor，将其先放置到gpu上，实现显存的预分配</strong>。这是如何完成的呢？核心函数：<strong><code>_allocate_kv_cache</code></strong></p><p><img src="/posts/f79d4b0/image-13.png"></p><p>回到<code>LLMEngine</code>初始化函数中，调用<code>_initialize_kv_caches</code>后，进入：<code>self.model_executor.initialize_cache(num_gpu_blocks, num_cpu_blocks)</code>，来看看模型执行器的<code>initialize_cache</code>函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">initialize_cache</span>(<span class="params">self, num_gpu_blocks: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                         num_cpu_blocks: <span class="built_in">int</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">      <span class="comment"># 1. 验证缓存大小：检查给定的缓存大小（num_gpu_blocks 和 block_size）是否有效；</span></span><br><span class="line">        raise_if_cache_size_invalid(...)</span><br><span class="line">      <span class="comment"># 2. 更新缓存配置：</span></span><br><span class="line">        <span class="variable language_">self</span>.cache_config.num_gpu_blocks = num_gpu_blocks</span><br><span class="line">        <span class="variable language_">self</span>.cache_config.num_cpu_blocks = num_cpu_blocks</span><br><span class="line">      <span class="comment"># 3. 选择内存池和分配方式：（是否启用休眠模式）</span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.vllm_config.model_config.enable_sleep_mode:</span><br><span class="line">            allocator = CuMemAllocator.get_instance()</span><br><span class="line">            context = allocator.use_memory_pool(tag=<span class="string">&quot;kv_cache&quot;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">from</span> contextlib <span class="keyword">import</span> nullcontext</span><br><span class="line">            context = nullcontext()</span><br><span class="line">      <span class="comment"># 4. 内存池上下文管理：</span></span><br><span class="line">      <span class="comment"># 如果启用了休眠模式，则在进入上下文时，调用_init_cache_engine分配内存；否则直接继续。</span></span><br><span class="line">        <span class="keyword">with</span> context:</span><br><span class="line">            <span class="variable language_">self</span>._init_cache_engine()</span><br><span class="line">        <span class="variable language_">self</span>._warm_up_model()</span><br></pre></td></tr></table></figure><p>包括两个关键步骤：</p><ol type="1"><li><p><code>_init_cache_engine()</code>：创建一个<code>CacheEngine</code>对象，并初始化：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># CacheEngine的初始化函数中，包括：</span></span><br><span class="line"><span class="variable language_">self</span>.gpu_cache = <span class="variable language_">self</span>._allocate_kv_cache(</span><br><span class="line">            <span class="variable language_">self</span>.num_gpu_blocks, <span class="variable language_">self</span>.device_config.device_type)</span><br><span class="line"><span class="variable language_">self</span>.cpu_cache = <span class="variable language_">self</span>._allocate_kv_cache(<span class="variable language_">self</span>.num_cpu_blocks, <span class="string">&quot;cpu&quot;</span>)</span><br></pre></td></tr></table></figure></li></ol><p><strong><code>_allocate_kv_cache</code>预分配KVCache内存：为每个注意力层创建全零初始化的张量</strong></p><p>​大小为：<code>(2, num_blocks, block_size, num_kv_heads, head_size)</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_allocate_kv_cache</span>(<span class="params"></span></span><br><span class="line"><span class="params">self,</span></span><br><span class="line"><span class="params">num_blocks: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">device: <span class="built_in">str</span>,</span></span><br><span class="line"><span class="params"></span>) -&gt; <span class="type">List</span>[torch.Tensor]:</span><br><span class="line"><span class="comment"># 1. 从注意力后端获取合适的缓存张量形状，记为：kv_cache_shape</span></span><br><span class="line">kv_cache_shape = <span class="variable language_">self</span>.attn_backend.get_kv_cache_shape(</span><br><span class="line">num_blocks, <span class="variable language_">self</span>.block_size, <span class="variable language_">self</span>.num_kv_heads, <span class="variable language_">self</span>.head_size)</span><br><span class="line">  <span class="comment"># 2. 设置内存锁定选项</span></span><br><span class="line">pin_memory = is_pin_memory_available() <span class="keyword">if</span> device == <span class="string">&quot;cpu&quot;</span> <span class="keyword">else</span> <span class="literal">False</span></span><br><span class="line">  <span class="comment"># 3. 逐层分配缓存：为每个注意力层创建全零初始化的张量</span></span><br><span class="line">kv_cache: <span class="type">List</span>[torch.Tensor] = []</span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.num_attention_layers):</span><br><span class="line">layer_kv_cache = torch.zeros(kv_cache_shape,</span><br><span class="line">                               dtype=<span class="variable language_">self</span>.dtype,</span><br><span class="line">                               pin_memory=pin_memory,</span><br><span class="line">                               device=device)</span><br><span class="line">kv_cache.append(layer_kv_cache)</span><br><span class="line"><span class="keyword">return</span> kv_cache</span><br></pre></td></tr></table></figure><ol start="2" type="1"><li><p><strong>模型预热<code>_warm_up_model</code></strong>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_warm_up_model</span>(<span class="params">self</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">  <span class="comment"># 1. 确定预热尺寸：在非eager模式下，过滤掉已被CUDA图捕获的尺寸，避免重复工作</span></span><br><span class="line">warmup_sizes = <span class="variable language_">self</span>.vllm_config.compilation_config.compile_sizes.copy()</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> <span class="variable language_">self</span>.model_config.enforce_eager:</span><br><span class="line">warmup_sizes = [</span><br><span class="line">x <span class="keyword">for</span> x <span class="keyword">in</span> warmup_sizes <span class="keyword">if</span> x <span class="keyword">not</span> <span class="keyword">in</span></span><br><span class="line"><span class="variable language_">self</span>.vllm_config.compilation_config.cudagraph_capture_sizes</span><br><span class="line">]</span><br><span class="line">  <span class="comment"># 2. 按尺寸降序预热：通过_dummy_run执行虚拟推理，触发内核编译和缓存预热</span></span><br><span class="line"><span class="keyword">for</span> size <span class="keyword">in</span> <span class="built_in">sorted</span>(warmup_sizes, reverse=<span class="literal">True</span>):</span><br><span class="line">logger.info(<span class="string">&quot;Compile and warming up model for size %d&quot;</span>, size)</span><br><span class="line"><span class="variable language_">self</span>.model_runner._dummy_run(size)</span><br><span class="line">  <span class="comment"># 3. CUDA图捕获：capture_model</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> <span class="variable language_">self</span>.model_config.enforce_eager:</span><br><span class="line"><span class="variable language_">self</span>.model_runner.capture_model(<span class="variable language_">self</span>.gpu_cache)</span><br><span class="line">set_random_seed(<span class="variable language_">self</span>.model_config.seed)</span><br></pre></td></tr></table></figure><blockquote><p>调用<code>capture_model</code>方法，通过CUDA图捕获模型的计算图：</p><ol type="1"><li>主要支持小批量decoding场景（&lt;=200tokens)：当批处理的token数量超过200时，CUDA图带来的性能提升不明显；</li><li>需要固定大小的tensor，不支持变长批处理</li><li>使用场景：仅支持decodingrequest的捕获（每个序列单个token）：不支持prefill request和chunkedprefill+decoding</li></ol></blockquote></li></ol><h3 id="推理">推理</h3><h4 id="序列组sequencegroup">序列组<code>SequenceGroup</code></h4><h5 id="原生输入">原生输入</h5><h5 id="sequencegroup的作用"><code>SequenceGroup</code>的作用</h5><p>1个<code>SequenceGroup</code>实例包括："<strong>1个prompt -&gt;多个outputs</strong>"</p><p><strong>一个seq_group中的所有seq共享1个prompt</strong></p><ul><li><p><strong>其中每组"prompt -&gt;output"组成一个序列（seq，属于Sequence实例），每个seq下有若干状态(status)属性（<code>class SequenceStatus(enum.IntEnum)</code>），包括</strong>：</p><ul><li><code>WAITING</code>：正在waiting队列中（waiting队列中的序列都没有做过prefill）；</li><li><code>RUNNING</code>：正在running队列中（即已经开始做推理）；</li><li><code>SWAPPED</code>：正在swapped队列中，表示：此时gpu资源不足，相关的seq_group被抢占，导致其暂停推理，相关的KVblock被置换到cpu上（swapout）；等待gpu资源充足时再置换回来重新计算（swap in）；</li><li><code>FINISHED_STOPPED</code>：正常执行完毕（例如：碰到符号，该seq的推理正常结束）；</li><li><code>FINISHED_LENGTH_CAPPED</code>：因为seq的长度达到最大长度限制，而结束推理；</li><li><code>FINISHED_ABORTED</code>：因不正常状态，而被终止的推理。例如客户端断开连接，则服务器会终止相关seq的推理；</li><li><code>FINISHED_IGNORED</code>：因prompt过长而被终止执行的推理（本质上也是受到长度限制）</li></ul><p><img src="/posts/f79d4b0/image-11.png"></p></li></ul><p>推理过程如下：</p><ul><li><p><strong>推理开始之前</strong>：seq_group下只有1条seq，它就是prompt，状态为waiting；</p></li><li><p><strong>在第1个推理阶段</strong>：调度器选中了这个seq_group，由于它的采样参数中n=4，所以在做完prefill之后，它会生成4个seq，它们的状态都是running；</p></li><li><p><strong>在若干个推理阶段后，gpu上的资源不够了，这个seq_group不幸被调度器抢占</strong>：它相关的KVblock也被swapout到cpu上。此时所有seq的状态变为swapped。注意：当一个seq_group被抢占时，对它的处理有两种方式：</p><ul><li><p><code>Swap</code>：如果该seq_group下的seq数量 &gt;1，此时会采取swap策略，即把<strong>seq_group下所有seq的KVblock从gpu上卸载到cpu上</strong>。（seq数量比较多，直接抛弃已计算的KVblock，不划算）</p></li><li><p><code>Recomputation</code>：如果该seq_group下的seq数量 =1，此时采取recomputation策略，即<strong>释放该seq_group相关的物理块，将其重新放回waiting队列中</strong>。等下次它被选中推理时，从prefill阶段开始重新推理。（seq数量少，重新计算KVblock的成本不高）</p></li></ul></li><li><p><strong>又过了若干个推理阶段，gpu上的资源又充足了，此时执行swapin操作</strong>，将卸载到cpu上的KVblock重新读到gpu上，继续对该seq_group做推理，此时seq的状态又变为running；</p></li><li><p><strong>又过了若干个推理阶段，该seq_group中有1个seq已经推理完成了，其状态被标记为finish</strong>，此后这条已经完成的seq将不参与调度；</p></li><li><p><strong>又过了若干个推理阶段，这个seq_group下所有的seq都已经完成推理了</strong>，此时可作为最终output返回。</p></li></ul><h5 id="sequencegroup结构"><code>SequenceGroup</code>结构</h5><p><img src="/posts/f79d4b0/image-12.png"></p><ul><li><p><code>self.seqs_dict = &#123;seq.seq_id: seq for seq in seqs&#125;</code>：一个seq_group下包含若干seqs，其中每个seq是一个Sequence对象；</p></li><li><p><code>self.metrics</code>：<strong>记录该seq_group相关的指标</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable language_">self</span>.metrics = RequestMetrics(arrival_time=arrival_time,</span><br><span class="line">                              last_token_time=arrival_time,</span><br><span class="line">                              first_scheduled_time=<span class="literal">None</span>,</span><br><span class="line">                              first_token_time=<span class="literal">None</span>,</span><br><span class="line">                              time_in_queue=<span class="literal">None</span>,</span><br><span class="line">                              spec_token_acceptance_counts=[<span class="number">0</span>] * draft_size)</span><br></pre></td></tr></table></figure></li><li><p><code>get_max_num_running_steps</code>：<strong>该seq_group在剩余生命周期内，并行running的最大seq数量。“剩余生命周期”指从此刻一直到seq_group中所有的seq都做完推理</strong>。</p><p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_max_num_running_seqs</span>(<span class="params">self</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">    <span class="keyword">if</span> <span class="variable language_">self</span>.is_single_seq:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span> <span class="keyword">if</span> <span class="variable language_">self</span>.first_seq.is_finished() <span class="keyword">else</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> <span class="variable language_">self</span>.num_seqs() - <span class="variable language_">self</span>.num_finished_seqs()</span><br></pre></td></tr></table></figure> &gt; 1. <code>num_seqs()</code>函数：获取符合指定<code>status</code> 状态的所有序列，并返回其长度； &gt; 2.<code>get_finished_seqs()</code>：返回已经完成的序列的数量（包括：<code>FINISHED_STOPPED</code>,<code>FINISHED_LENGTH_CAPPED</code>,<code>FINISHED_ABORTED</code>,<code>FINISHED_IGNORED</code>共四种状态）</p></li></ul><p>离线批推理中，脚本包括以下两个关键步骤：</p><ol type="1"><li><code>llm = LLM(model="facebook/opt-125m")</code>：实例化一个离线批处理的vLLM对象：LLMEngine执行一次模拟实验（profiling），来判断需要在gpu上预留多少的显存空间给KVCache block；</li><li><code>outputs = llm.generate(prompts, sampling_params)</code>：推理入口</li></ol><h4 id="入口函数generate">入口函数：<code>generate</code></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">generate</span>(<span class="params"></span></span><br><span class="line"><span class="params">self,</span></span><br><span class="line"><span class="params">prompts: <span class="type">Union</span>[<span class="type">Union</span>[PromptType, <span class="type">Sequence</span>[PromptType]],</span></span><br><span class="line"><span class="params">                 <span class="type">Optional</span>[<span class="type">Union</span>[<span class="built_in">str</span>, <span class="built_in">list</span>[<span class="built_in">str</span>]]]] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">  <span class="comment"># sampling_params: 采样超参，例如温度、top_k等；如果为None则使用vLLM默认的参数</span></span></span><br><span class="line"><span class="params">sampling_params: <span class="type">Optional</span>[<span class="type">Union</span>[SamplingParams,</span></span><br><span class="line"><span class="params">                                  <span class="type">Sequence</span>[SamplingParams]]] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">  <span class="comment"># prompt_token_ids: prompt对应的token_id，如果没有提供的话，vllm会调用tokenizer进行</span></span></span><br><span class="line"><span class="params">prompt_token_ids: <span class="type">Optional</span>[<span class="type">Union</span>[<span class="built_in">list</span>[<span class="built_in">int</span>], <span class="built_in">list</span>[<span class="built_in">list</span>[<span class="built_in">int</span>]]]] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params"><span class="comment"># use_tqdm: 是否要展示process bar</span></span></span><br><span class="line"><span class="params">  use_tqdm: <span class="built_in">bool</span> = <span class="literal">True</span>,</span></span><br><span class="line"><span class="params">  <span class="comment"># lora_request：如果想请求特定的lora_adapter，可以将它的path等信息包装在该请求中</span></span></span><br><span class="line"><span class="params">lora_request: <span class="type">Optional</span>[<span class="type">Union</span>[<span class="built_in">list</span>[LoRARequest], LoRARequest]] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params"><span class="comment"># prompt_adapter_request：提示器适配请求</span></span></span><br><span class="line"><span class="params">  prompt_adapter_request: <span class="type">Optional</span>[PromptAdapterRequest] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">  <span class="comment"># guided_options_request：引导器解码选项</span></span></span><br><span class="line"><span class="params">guided_options_request: <span class="type">Optional</span>[<span class="type">Union</span>[LLMGuidedOptions,</span></span><br><span class="line"><span class="params">                                         GuidedDecodingRequest]] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">priority: <span class="type">Optional</span>[<span class="built_in">list</span>[<span class="built_in">int</span>]] = <span class="literal">None</span>,</span>) -&gt; <span class="built_in">list</span>[RequestOutput]:</span><br><span class="line">runner_type = <span class="variable language_">self</span>.llm_engine.model_config.runner_type</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 1. 运行器类型验证：确保模型配置支持生成任务</span></span><br><span class="line">  <span class="keyword">if</span> runner_type <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">&quot;generate&quot;</span>, <span class="string">&quot;transcription&quot;</span>]:</span><br><span class="line">    messages = [<span class="string">&quot;...&quot;</span>,]</span><br><span class="line">supported_runner_types = <span class="variable language_">self</span>.llm_engine.model_config.supported_runner_types</span><br><span class="line"><span class="keyword">if</span> <span class="string">&quot;generate&quot;</span> <span class="keyword">in</span> supported_runner_types:</span><br><span class="line">messages.append(<span class="string">&quot;...&quot;</span>)</span><br><span class="line"><span class="keyword">raise</span> ValueError(<span class="string">&quot; &quot;</span>.join(messages))</span><br><span class="line"><span class="comment"># 2. 输入处理：支持直接传入token IDs或文本提示（兼容新旧两种输入格式）</span></span><br><span class="line"><span class="keyword">if</span> prompt_token_ids <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">parsed_prompts = <span class="variable language_">self</span>._convert_v1_inputs(</span><br><span class="line">prompts=cast(<span class="type">Optional</span>[<span class="type">Union</span>[<span class="built_in">str</span>, <span class="built_in">list</span>[<span class="built_in">str</span>]]], prompts),</span><br><span class="line">prompt_token_ids=prompt_token_ids,)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">parsed_prompts = cast(<span class="type">Union</span>[PromptType, <span class="type">Sequence</span>[PromptType]],prompts)</span><br><span class="line"><span class="comment"># 3. 引导解码处理</span></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">isinstance</span>(guided_options_request, <span class="built_in">dict</span>):</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(guided_options_request) &gt; <span class="number">1</span>:</span><br><span class="line"><span class="keyword">raise</span> ValueError(<span class="string">&quot;...&quot;</span>)</span><br><span class="line">guided_options_request = GuidedDecodingRequest(**guided_options_request)</span><br><span class="line"><span class="comment"># 4. 采样参数处理</span></span><br><span class="line"><span class="keyword">if</span> sampling_params <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">sampling_params = <span class="variable language_">self</span>.get_default_sampling_params()</span><br><span class="line"><span class="comment"># 5. 请求验证和添加</span></span><br><span class="line"><span class="variable language_">self</span>._validate_and_add_requests(<span class="comment"># 验证并添加所有请求到引擎</span></span><br><span class="line">prompts=parsed_prompts,</span><br><span class="line">params=sampling_params,</span><br><span class="line">lora_request=lora_request,</span><br><span class="line">prompt_adapter_request=prompt_adapter_request,</span><br><span class="line">guided_options=guided_options_request,</span><br><span class="line">priority=priority)</span><br><span class="line"><span class="comment"># 6. 执行生成</span></span><br><span class="line">outputs = <span class="variable language_">self</span>._run_engine(use_tqdm=use_tqdm)</span><br><span class="line"><span class="keyword">return</span> <span class="variable language_">self</span>.engine_class.validate_outputs(outputs, RequestOutput)</span><br></pre></td></tr></table></figure><blockquote><p><code>_validate_and_add_requests</code>函数内：</p><p>逐个添加请求到引擎；支持优先级调度（默认优先级为0）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i, prompt <span class="keyword">in</span> <span class="built_in">enumerate</span>(prompts):</span><br><span class="line"><span class="variable language_">self</span>._add_request(</span><br><span class="line">prompt,</span><br><span class="line">params[i] <span class="keyword">if</span> <span class="built_in">isinstance</span>(params, <span class="type">Sequence</span>) <span class="keyword">else</span> params,</span><br><span class="line">lora_request=lora_request[i] <span class="keyword">if</span> <span class="built_in">isinstance</span>(</span><br><span class="line">lora_request, <span class="type">Sequence</span>) <span class="keyword">else</span> lora_request,</span><br><span class="line">prompt_adapter_request=prompt_adapter_request,</span><br><span class="line">priority=priority[i] <span class="keyword">if</span> priority <span class="keyword">else</span> <span class="number">0</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p><code>_add_request</code>函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_add_request</span>(<span class="params"></span></span><br><span class="line"><span class="params">self,</span></span><br><span class="line"><span class="params">prompt: PromptType,</span></span><br><span class="line"><span class="params">params: <span class="type">Union</span>[SamplingParams, PoolingParams],</span></span><br><span class="line"><span class="params">lora_request: <span class="type">Optional</span>[LoRARequest] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">prompt_adapter_request: <span class="type">Optional</span>[PromptAdapterRequest] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">priority: <span class="built_in">int</span> = <span class="number">0</span>,</span></span><br><span class="line"><span class="params"></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">request_id = <span class="built_in">str</span>(<span class="built_in">next</span>(<span class="variable language_">self</span>.request_counter))<span class="comment"># 使用计数器 request_counter 生成唯一ID</span></span><br><span class="line"><span class="variable language_">self</span>.llm_engine.add_request(</span><br><span class="line">request_id, prompt, params, lora_request=lora_request, prompt_adapter_request=prompt_adapter_request, priority=priority,)</span><br></pre></td></tr></table></figure><p>调用案例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 多模态请求示例</span></span><br><span class="line"><span class="variable language_">self</span>._add_request(</span><br><span class="line">    prompt=&#123;<span class="string">&quot;text&quot;</span>: <span class="string">&quot;描述这张图片&quot;</span>, <span class="string">&quot;image&quot;</span>: image_tensor&#125;,</span><br><span class="line">    params=SamplingParams(top_p=<span class="number">0.9</span>),</span><br><span class="line">    prompt_adapter_request=ClipAdapterRequest()</span><br><span class="line">)</span><br><span class="line"><span class="comment"># 高优先级实时对话</span></span><br><span class="line"><span class="variable language_">self</span>._add_request(</span><br><span class="line">    prompt=<span class="string">&quot;生成下周会议摘要&quot;</span>,params=SamplingParams(temperature=<span class="number">0.3</span>),priority=<span class="number">100</span></span><br><span class="line">)</span><br><span class="line"><span class="comment"># 低延迟场景</span></span><br><span class="line"><span class="variable language_">self</span>._add_request(</span><br><span class="line">    prompt=[token1, token2, token3],  <span class="comment"># 预分词</span></span><br><span class="line">    params=PoolingParams(stride=<span class="number">128</span>),  <span class="comment"># 池化模式</span></span><br><span class="line">    priority=<span class="number">0</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></blockquote><p>当一条请求到来时，流程如下： <img src="/posts/f79d4b0/image-14.png"></p><p><code>generate</code>函数实际上做了两件事情：</p><ol type="1"><li><code>_add_request</code>：<strong>将输入数据传给LLMEngine</strong>：<ul><li><strong>把每1个prompt包装成一个SequenceGroup对象</strong>：从客户端角度看，1个请求可能包含多个prompts，例如离线批处理场景下，可以将1个batch理解成1个请求；但是<strong>从LLMEngine的角度看，1个prompt是1个请求</strong>，所以它会对输入数据进行预处理；</li><li><strong>把包装成SequenceGroup对象的数据加入调度器（Scheduler）的waiting队列，等待处理</strong>。</li></ul></li><li><code>_run_engine</code>：<strong>执行推理</strong>。只要调度器的waiting/running/swapped队列非空，就认为此时这批batch还没有做完推理，这时会调用LLMEngine的<code>step()</code>函数，来完成1次调度以决定要送哪些数据去做推理。</li></ol><h4 id="add_request接收用户请求"><code>add_request</code>：接收用户请求</h4><ul><li>功能：将请求添加到引擎的请求池中，并在调度器的<code>engine.step()</code> 被调用时，处理这些请求。</li></ul><p>先做输入有效性检查（<code>prompt</code>和<code>params</code>不为None；<code>lora_request</code>请求出现时，配置中是否启用LoRA；是否支持优先级调度；是否启用引导解码等）；设置请求到达时间（若无，则使用当前时间）；进行分词器验证；使用<code>input_preprocessor</code>对传入的<code>prompt</code>、<code>lora_request</code> 和<code>prompt_adapter_request</code>进行预处理，转为适合模型处理的格式。</p><p>最后，将请求添加到请求池：<code>self._add_processed_request(...)</code></p><h4 id="add_processed_request请求添加至请求池"><code>_add_processed_request</code>：请求添加至请求池</h4><ul><li>功能：处理请求，生成相应的序列；根据当前调度器的负载情况（未完成的序列数量），选择最适合的调度器，<strong>将序列组添加到调度队列</strong>中。</li></ul><ol type="1"><li><p>处理多采样请求：如果采样请求需要多个序列（即<code>params.n &gt; 1</code>），将请求添加到<code>ParallelSampleSequenceGroup</code> 中进行并行处理，方法直接返回<code>None</code>； <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="built_in">isinstance</span>(params, SamplingParams) <span class="keyword">and</span> params.n &gt; <span class="number">1</span>:</span><br><span class="line">    ParallelSampleSequenceGroup.add_request(</span><br><span class="line">        ......</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br></pre></td></tr></table></figure></p></li><li><p><strong>创建序列</strong>： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 加载每个KV cache block的大小（默认为16）；</span></span><br><span class="line">block_size = <span class="variable language_">self</span>.cache_config.block_size</span><br><span class="line">seq_id = <span class="built_in">next</span>(<span class="variable language_">self</span>.seq_counter)     <span class="comment"># 当前seq的id</span></span><br><span class="line">eos_token_id = <span class="variable language_">self</span>.input_preprocessor.get_eos_token_id(lora_request) <span class="comment"># 结束符token ID</span></span><br><span class="line"></span><br><span class="line">// <span class="number">2.</span> <span class="built_in">input</span>拆分为：编码器、解码器输入</span><br><span class="line">encoder_inputs, decoder_inputs = split_enc_dec_inputs(processed_inputs)</span><br><span class="line"></span><br><span class="line">// <span class="number">3.</span> 创建序列：</span><br><span class="line">seq = <span class="type">Sequence</span>(seq_id, decoder_inputs, block_size, eos_token_id,</span><br><span class="line">                       lora_request, prompt_adapter_request)</span><br><span class="line"></span><br><span class="line">encoder_seq = (<span class="literal">None</span> <span class="keyword">if</span> encoder_inputs <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">else</span> <span class="type">Sequence</span>(</span><br><span class="line">            seq_id, encoder_inputs, block_size, eos_token_id, lora_request,</span><br><span class="line">            prompt_adapter_request))</span><br></pre></td></tr></table></figure></p></li><li><p><strong>每个prompt被包装成一个<code>SequenceGroup</code>实例</strong>：</p><p>根据<code>params</code>创建<code>SequenceGroup</code>：是<code>SamplingParams</code>，创建采样序列组；是<code>PoolingParams</code>，创建池化序列组。</p><blockquote><ol type="1"><li><code>SamplingParams</code>：调用<code>_create_sequence_group_with_sampling</code>函数</li></ol><p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_create_sequence_group_with_sampling</span>(<span class="params"></span></span><br><span class="line"><span class="params">self, request_id: <span class="built_in">str</span>, seq: <span class="type">Sequence</span>, sampling_params: SamplingParams, arrival_time: <span class="built_in">float</span>, lora_request: <span class="type">Optional</span>[LoRARequest], trace_headers: <span class="type">Optional</span>[Mapping[<span class="built_in">str</span>, <span class="built_in">str</span>]] = <span class="literal">None</span>, prompt_adapter_request: <span class="type">Optional</span>[PromptAdapterRequest] = <span class="literal">None</span>, encoder_seq: <span class="type">Optional</span>[<span class="type">Sequence</span>] = <span class="literal">None</span>, priority: <span class="built_in">int</span> = <span class="number">0</span>,</span>) -&gt; SequenceGroup:</span><br><span class="line"><span class="comment"># 1. 验证Logprobs参数</span></span><br><span class="line">max_logprobs = <span class="variable language_">self</span>.get_model_config().max_logprobs</span><br><span class="line"><span class="keyword">if</span> (sampling_params.logprobs</span><br><span class="line"><span class="keyword">and</span> sampling_params.logprobs &gt; max_logprobs) <span class="keyword">or</span> (</span><br><span class="line">sampling_params.prompt_logprobs</span><br><span class="line"><span class="keyword">and</span> sampling_params.prompt_logprobs &gt; max_logprobs):</span><br><span class="line"><span class="keyword">raise</span> ValueError(<span class="string">f&quot;Cannot request more than <span class="subst">&#123;max_logprobs&#125;</span> logprobs.&quot;</span>)</span><br><span class="line"><span class="comment"># 2. 构建Logits处理器：用于调整生成过程中的 logits 值</span></span><br><span class="line">sampling_params = <span class="variable language_">self</span>._build_logits_processors(sampling_params, lora_request)</span><br><span class="line"><span class="comment"># 3. 复制采样参数：对 sampling_params 进行防御性复制（clone），确保在后续操作中不会修改原始的采样参数</span></span><br><span class="line">sampling_params = sampling_params.clone()</span><br><span class="line">  <span class="comment"># 4. 更新生成配置</span></span><br><span class="line">sampling_params.update_from_generation_config(</span><br><span class="line"><span class="variable language_">self</span>.generation_config_fields, seq.eos_token_id)</span><br><span class="line"><span class="comment"># 5. 创建序列组：</span></span><br><span class="line">  <span class="comment"># 5.1 确定draft_size：如果配置中启用了推测性解码（speculative_config），则根据推测性解码的配置调整 draft_size</span></span><br><span class="line">draft_size = <span class="number">1</span></span><br><span class="line"><span class="keyword">if</span> <span class="variable language_">self</span>.vllm_config.speculative_config <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">draft_size = \</span><br><span class="line"><span class="variable language_">self</span>.vllm_config.speculative_config.num_speculative_tokens + <span class="number">1</span></span><br><span class="line">  <span class="comment"># 5.2 创建 SequenceGroup 对象</span></span><br><span class="line">seq_group = SequenceGroup(</span><br><span class="line">    request_id=request_id, </span><br><span class="line">     seqs=[seq], </span><br><span class="line">     arrival_time=arrival_time, </span><br><span class="line">     sampling_params=sampling_params, </span><br><span class="line">     lora_request=lora_request, </span><br><span class="line">     trace_headers=trace_headers, </span><br><span class="line">     prompt_adapter_request=prompt_adapter_request,</span><br><span class="line"> encoder_seq=encoder_seq, </span><br><span class="line">     priority=priority, </span><br><span class="line">     draft_size=draft_size)</span><br><span class="line"><span class="keyword">return</span> seq_group</span><br></pre></td></tr></table></figure></p></blockquote></li><li><p><strong>选择最空闲的调度器</strong>，添加序列组：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">costs = [</span><br><span class="line">    scheduler.get_num_unfinished_seq_groups()</span><br><span class="line">    <span class="keyword">for</span> scheduler <span class="keyword">in</span> <span class="variable language_">self</span>.scheduler</span><br><span class="line">]</span><br><span class="line">min_cost_scheduler = <span class="variable language_">self</span>.scheduler[costs.index(<span class="built_in">min</span>(costs))]</span><br><span class="line">min_cost_scheduler.add_seq_group(seq_group)</span><br></pre></td></tr></table></figure></p></li></ol><blockquote><ol type="1"><li>如何定义最空闲的调度器？</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_num_unfinished_seq_groups</span>(<span class="params">self</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">       <span class="keyword">return</span> <span class="built_in">len</span>(<span class="variable language_">self</span>.waiting) + <span class="built_in">len</span>(<span class="variable language_">self</span>.running) + <span class="built_in">len</span>(<span class="variable language_">self</span>.swapped);</span><br></pre></td></tr></table></figure><ol start="2" type="1"><li><code>add_seq_group</code>：将<code>seq_group</code>中所有序列，添加进scheduler的<code>self.waiting</code>队列中<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">add_seq_group</span>(<span class="params">self, seq_group: SequenceGroup</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">  <span class="variable language_">self</span>.swapped.append(seq_group)</span><br></pre></td></tr></table></figure></li></ol></blockquote><p>回到入口函数<code>generate</code>，在<code>_validate_and_add_requests</code>函数之后，所有的<code>seq_group</code>都已经被送入调度器（Scheduler）的<code>waiting</code>队列中。</p><p>接下来通过<code>_run_engine</code>执行推理：在1个推理阶段中，调用一次<code>step</code>。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_run_engine</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self, *, use_tqdm: <span class="built_in">bool</span></span></span><br><span class="line"><span class="params"></span>) -&gt; <span class="built_in">list</span>[<span class="type">Union</span>[RequestOutput, PoolingRequestOutput]]:</span><br><span class="line">    <span class="comment"># 1. 初始化进度条</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;...&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2. 初始化输出列表和统计变量：</span></span><br><span class="line">    <span class="comment"># outputs 存储引擎产生的输出；total_in_toks 和 total_out_toks 分别跟踪输入和输出的总 token 数</span></span><br><span class="line">    outputs: <span class="built_in">list</span>[<span class="type">Union</span>[RequestOutput, PoolingRequestOutput]] = []</span><br><span class="line">    total_in_toks = <span class="number">0</span></span><br><span class="line">    total_out_toks = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3. 处理未完成请求： step()完成1次调度</span></span><br><span class="line">    <span class="keyword">while</span> <span class="variable language_">self</span>.llm_engine.has_unfinished_requests():</span><br><span class="line">        step_outputs = <span class="variable language_">self</span>.llm_engine.step()</span><br><span class="line">        <span class="comment"># 4. 遍历 step_outputs 中的每个output：如果输出已完成，则将其加入到 outputs 列表中</span></span><br><span class="line">        <span class="keyword">for</span> output <span class="keyword">in</span> step_outputs:</span><br><span class="line">            <span class="keyword">if</span> output.finished:</span><br><span class="line">                outputs.append(output)</span><br><span class="line">                <span class="keyword">if</span> use_tqdm:</span><br><span class="line">                    <span class="keyword">if</span> <span class="built_in">isinstance</span>(output, RequestOutput):</span><br><span class="line">                        <span class="string">&#x27;&#x27;&#x27;...&#x27;&#x27;&#x27;</span></span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        pbar.update(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> use_tqdm:</span><br><span class="line">        pbar.close()</span><br><span class="line">    <span class="comment"># 5. 按照请求 ID 对输出进行排序</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">sorted</span>(outputs, key=<span class="keyword">lambda</span> x: <span class="built_in">int</span>(x.request_id))</span><br></pre></td></tr></table></figure></p><p>接下来的问题是：<code>step()</code>中如何决定送哪些<code>seq_group</code>去做推理呢？先来看看调度器的结构。</p><h3 id="调度器scheduler">调度器<code>Scheduler</code></h3><h4 id="调度器结构">调度器结构</h4><p>调度器重要属性如下： <img src="/posts/f79d4b0/image-16.png"></p><ul><li><p><code>self.waiting, self.running, self.swapped</code>（双端队列：均通过<code>Deque[SequenceGroup] = deque()</code>初始化）：</p><ul><li><p><strong>waiting队列</strong>：存放所有<strong>尚未开始推理（未经历prefill阶段）或被抢占的seq_group</strong>；初始化时，waiting队列中的seq_group只有一个seq，即原始的prompt；</p></li><li><p><strong>running队列</strong>：存放<strong>当前正在做推理的seq_group</strong>。更准确地说，它存放的是：<strong>上1个推理阶段被送去推理的所有seq_group</strong>；在开始新一轮推理阶段时，调度器会根据本轮的筛选结果，更新running队列，即决定本轮要送哪些seq_group去做推理；</p></li><li><p><strong>swapped队列</strong>：存放<strong>被抢占的seq_group</strong>。若一个seq_group被抢占，调度器会对它执行swap或recomputation操作，分别对应着将它送去swapped队列或waiting队列。</p></li></ul></li></ul><h4 id="整体调度流程">整体调度流程</h4><p><code>_schedule_default</code>：调度待执行的SequenceGroup，在调度过程中根据当前的资源状况（例如 GPU内存），优先处理prefill请求并按需调度decode请求。最终返回一个包含调度结果的SchedulerOutputs 对象。</p><p>预算由<code>SchedulingBudget</code>定义：<code>max_num_seqs</code>，<code>max_num_batched_tokens</code>分别为1个推理阶段中，LLMEngine<strong>最多能处理的seq数量</strong>和<strong>最多能处理的token数量</strong>。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">budget = SchedulingBudget(</span><br><span class="line">        token_budget=<span class="variable language_">self</span>.scheduler_config.max_num_batched_tokens,</span><br><span class="line">        max_num_seqs=<span class="variable language_">self</span>.scheduler_config.max_num_seqs,</span><br><span class="line">    )</span><br></pre></td></tr></table></figure></p><ul><li><p><strong>如果当前swapped队列为空</strong>：<strong>检查是否能从waiting队列中调度seq_group</strong>（调用<code>_schedule_prefills</code>），直到不满足调度条件为止（gpu空间不足，或waiting队列已为空等）。<strong>此时，1个推理阶段中，所有的seq_group都处在prefill阶段。</strong><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> <span class="variable language_">self</span>.swapped:</span><br><span class="line">    prefills = <span class="variable language_">self</span>._schedule_prefills(budget,</span><br><span class="line">                                        curr_loras,</span><br><span class="line">                                        enable_chunking=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure> ####<code>_schedule_prefills</code>：从waiting队列中调度seq_group（调度的prefill）初始化： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ignored_seq_groups: <span class="type">List</span>[SequenceGroup] = []</span><br><span class="line">seq_groups: <span class="type">List</span>[ScheduledSequenceGroup] = []</span><br><span class="line">waiting_queue = <span class="variable language_">self</span>.waiting</span><br><span class="line">leftover_waiting_sequences: Deque[SequenceGroup] = deque()</span><br></pre></td></tr></table></figure></p></li><li><p><code>ignored_seq_groups</code>：存储被忽略的<code>seq_group</code>，即某个<code>seq_group</code>无法在当前调度中被处理（例如，因为资源不足或超出了容量限制）,包括以下两种情况：</p><ul><li><code>num_new_tokens &gt; prompt_limit</code></li><li><code>can_allocate == AllocStatus.NEVER</code>：block_manager无法分配物理块（容量不够）</li></ul></li><li><p><code>seq_groups</code>：存储已成功调度并开始执行的<code>seq_group</code>，每个<code>seq_group</code>在成功调度后，都会被包装为一个<code>ScheduledSequenceGroup</code>对象，并添加到这个列表中。同时，调度信息（例如新分配的token 数量）也会被更新到<code>budget</code>中；</p></li><li><p><code>leftover_waiting_sequences</code>：存储因某些原因（<code>partial_prefill_metadata</code>非空且不支持调度；没有额外空间分配给新的LoRA请求）暂时无法调度的<code>seq_group</code>。最后，未能调度的<code>seq_group</code>被重新加入<code>waiting_queue</code>中，等待下次调度。</p></li><li><p><code>waiting_queue</code>：当前处于等待状态的<code>seq_group</code>队列。即已经进入调度系统，但还没有被分配资源来执行。在调度过程中，代码会逐个检查<code>waiting_queue</code>中的<code>seq_group</code>（以下while循环）：</p><ul><li>成功调度：从队列中移除，从状态从<code>WAITING</code>转为<code>RUNNING</code>；</li><li>不能调度：留在队列中，直到符合调度条件为止。</li></ul></li></ul><ol type="1"><li><p>waiting队列循环：</p><ul><li>当前时间到达waiting队列的调度间隔阈值，且waiting队列非空：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> <span class="variable language_">self</span>._passed_delay(time.time()) <span class="keyword">and</span> waiting_queue:</span><br><span class="line">    <span class="comment"># 1. 取出最早到达的seq_group</span></span><br><span class="line">    seq_group = waiting_queue[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    waiting_seqs = seq_group.get_seqs(status=SequenceStatus.WAITING)</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;......&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;计算给定seq_group中，缓存/未缓存的tokens数：</span></span><br><span class="line"><span class="string">    遍历seq_group中的每个seq:</span></span><br><span class="line"><span class="string">        1. 解码序列：当前序列每次生成一个新的未缓存的token；</span></span><br><span class="line"><span class="string">        2. 预填充序列：all_num_new_tokens_seq=seq总长度-该seq已计算的tokens数量</span></span><br><span class="line"><span class="string">            2.1 未启用前缀缓存：所有的新token都视为未缓存的token，直接计入；</span></span><br><span class="line"><span class="string">                即：num_uncached_new_tokens += all_num_new_tokens_seq</span></span><br><span class="line"><span class="string">            2.2 启用前缀缓存：获取当前seq缓存的tokens数量，即：</span></span><br><span class="line"><span class="string">                num_cached_tokens_seq = self.block_manager.get_num_cached_tokens(</span></span><br><span class="line"><span class="string">                seq)</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    num_new_tokens_uncached, num_new_tokens_cached = (</span><br><span class="line">        <span class="variable language_">self</span>._get_num_new_uncached_and_cached_tokens(</span><br><span class="line">            seq_group,</span><br><span class="line">            SequenceStatus.WAITING,</span><br><span class="line">            enable_chunking,</span><br><span class="line">            budget,</span><br><span class="line">            partial_prefill_metadata=partial_prefill_metadata,</span><br><span class="line">        ))</span><br><span class="line">    num_new_tokens = num_new_tokens_uncached + num_new_tokens_cached</span><br><span class="line"></span><br><span class="line">   <span class="string">&#x27;&#x27;&#x27;...&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># If the sequence group cannot be allocated, stop.</span></span><br><span class="line">    <span class="comment"># 2. block_manager判断：是否有充足gpu空间，为该seq_group分配物理块，用于prefill</span></span><br><span class="line">    can_allocate = <span class="variable language_">self</span>.block_manager.can_allocate(</span><br><span class="line">        seq_group, num_lookahead_slots=num_lookahead_slots)</span><br><span class="line">    <span class="keyword">if</span> can_allocate == AllocStatus.LATER:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">elif</span> can_allocate == AllocStatus.NEVER:</span><br><span class="line">        logger.warning(</span><br><span class="line">            <span class="string">&quot;Input prompt (%d tokens) + lookahead slots (%d) is &quot;</span></span><br><span class="line">            <span class="string">&quot;too long and exceeds the capacity of block_manager&quot;</span>,</span><br><span class="line">            num_new_tokens,</span><br><span class="line">            num_lookahead_slots,</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">for</span> seq <span class="keyword">in</span> waiting_seqs:</span><br><span class="line">            seq.status = SequenceStatus.FINISHED_IGNORED</span><br><span class="line">        ignored_seq_groups.append(seq_group)</span><br><span class="line">        waiting_queue.popleft()</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">    lora_int_id = <span class="number">0</span></span><br><span class="line">    <span class="keyword">if</span> <span class="variable language_">self</span>.lora_enabled:</span><br><span class="line">        lora_int_id = seq_group.lora_int_id</span><br><span class="line">        <span class="keyword">assert</span> curr_loras <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="variable language_">self</span>.lora_config <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span></span><br><span class="line">        <span class="keyword">if</span> (<span class="variable language_">self</span>.lora_enabled <span class="keyword">and</span> lora_int_id &gt; <span class="number">0</span></span><br><span class="line">                <span class="keyword">and</span> lora_int_id <span class="keyword">not</span> <span class="keyword">in</span> curr_loras</span><br><span class="line">                <span class="keyword">and</span> <span class="built_in">len</span>(curr_loras) &gt;= <span class="variable language_">self</span>.lora_config.max_loras):</span><br><span class="line">            <span class="comment"># We don&#x27;t have a space for another LoRA, so</span></span><br><span class="line">            <span class="comment"># we ignore this request for now.</span></span><br><span class="line">            leftover_waiting_sequences.appendleft(seq_group)</span><br><span class="line">            waiting_queue.popleft()</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3. 本次调度的tokens和seq数是否满足：num_new_tokens_uncached, num_new_seqs最大数量的限制</span></span><br><span class="line">    <span class="keyword">if</span> (budget.num_batched_tokens</span><br><span class="line">            &gt;= <span class="variable language_">self</span>.scheduler_config.max_num_batched_tokens):</span><br><span class="line">        <span class="comment"># We&#x27;ve reached the budget limit - since there might be</span></span><br><span class="line">        <span class="comment"># continuous prefills in the running queue, we should break</span></span><br><span class="line">        <span class="comment"># to avoid scheduling any new prefills.</span></span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    num_new_seqs = seq_group.get_max_num_running_seqs()</span><br><span class="line">    <span class="keyword">if</span> num_new_tokens_uncached == <span class="number">0</span> <span class="keyword">or</span> <span class="keyword">not</span> budget.can_schedule(</span><br><span class="line">            num_new_tokens=num_new_tokens_uncached,</span><br><span class="line">            num_new_seqs=num_new_seqs,</span><br><span class="line">    ):</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 4. 满足3中条件：开始调度</span></span><br><span class="line">    <span class="keyword">if</span> curr_loras <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> lora_int_id &gt; <span class="number">0</span>:</span><br><span class="line">        curr_loras.add(lora_int_id)</span><br><span class="line">    <span class="comment"># 4.1 从waiting_queue中移除队首元素</span></span><br><span class="line">    waiting_queue.popleft()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 4.2 block_manager为该seq_group分配物理块，将每个seq的状态标为RUNNING</span></span><br><span class="line">    <span class="variable language_">self</span>._allocate_and_set_running(seq_group)</span><br><span class="line"></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;省略：</span></span><br><span class="line"><span class="string">    1. 若enable_chunking和调度器配置的is_multi_step为True，执行以下操作：</span></span><br><span class="line"><span class="string">        初始化一个空的 blocks_to_copy 列表。</span></span><br><span class="line"><span class="string">        调用 self._append_slots(seq_group, blocks_to_copy, enable_chunking) 来处理多步骤分配；</span></span><br><span class="line"><span class="string">        assert not blocks_to_copy 断言检查，确保 blocks_to_copy 在执行完后为空（避免副本写操作）。如果发生副本写操作，可能会引发此断言。</span></span><br><span class="line"><span class="string">    2. </span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># 4.3 将seq_group包装为ScheduledSequenceGroup，添加到调度的序列组中</span></span><br><span class="line">    seq_groups.append(</span><br><span class="line">        ScheduledSequenceGroup(seq_group=seq_group,</span><br><span class="line">                                token_chunk_size=num_new_tokens))</span><br><span class="line">    <span class="comment"># 4.4 更新budget中的token使用情况和序列数</span></span><br><span class="line">    budget.add_num_batched_tokens(</span><br><span class="line">        seq_group.request_id,</span><br><span class="line">        num_batched_tokens=num_new_tokens_uncached,</span><br><span class="line">        num_cached_tokens=num_new_tokens_cached,</span><br><span class="line">    )</span><br><span class="line">    budget.add_num_seqs(seq_group.request_id, num_new_seqs)</span><br></pre></td></tr></table></figure></li></ul></li><li><p>将<code>leftover_waiting_sequences</code>重新加入<code>waiting_queue</code>队首，等待下一次调度：</p></li><li><p>返回<code>SchedulerPrefillOutputs</code>：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">return</span> SchedulerPrefillOutputs(</span><br><span class="line">    seq_groups=seq_groups,</span><br><span class="line">    ignored_seq_groups=ignored_seq_groups,</span><br><span class="line">    num_lookahead_slots=<span class="variable language_">self</span>._get_num_lookahead_slots(</span><br><span class="line">        is_prefill=<span class="literal">True</span>, enable_chunking=enable_chunking),</span><br><span class="line">)</span><br></pre></td></tr></table></figure></p></li></ol><h5 id="passed_delay判断调度waiting队列的时间点"><code>_passed_delay</code>：判断调度waiting队列的时间点</h5><p>模型在推理时，waiting队列中源源不断地有新的seq_group加入。<strong>一旦选择调度waiting队列，就会停下对running/swapped中seq_group的decode处理，转而去做waiting中seq_group的prefill</strong>（prefill和decode同一时期只有一个在处理中）；也即vLLM必须在新来的seq_group和已经在做推理的seq_group之前达成平衡。“waiting队列调度间隔阈值”就是来控制这种均衡的：</p><ul><li><p><strong>调度间隔设置得太小</strong>：每次调度都只关心waiting中的新请求，这样发送旧请求的用户迟迟得不到反馈结果；此时waiting队列中积累的新请求数量可能比较少，不利于batching，浪费了并发处理的能力。</p></li><li><p><strong>调度间隔设置得太大</strong>：waiting中的请求持续挤压，对vLLM推理的整体吞吐有影响。</p></li></ul><blockquote><p><code>self.prev_prompt</code>：记录上一次调度中，是否从选择了waiting队列中调度seq；*<code>Scheduler</code>初始化时设置为<code>False</code>；若wating队列中有可调度的<code>seq_group</code>（<code>_schedule_prefills</code>中<code>len(seq_groups) &gt; 0</code>），设置为<code>True</code>。<code>self.prev_time</code>：上一次调度的时间点 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_passed_delay</span>(<span class="params">self, now: <span class="built_in">float</span></span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">    <span class="comment"># 1. 若上一次从waiting队列中调度：计算两次调度的时间间隔</span></span><br><span class="line">    <span class="keyword">if</span> <span class="variable language_">self</span>.prev_prompt:</span><br><span class="line">        <span class="variable language_">self</span>.last_prompt_latency = now - <span class="variable language_">self</span>.prev_time</span><br><span class="line">    <span class="variable language_">self</span>.prev_time, <span class="variable language_">self</span>.prev_prompt = now, <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2. 延迟调度，使得waiting队列尽量填满（delay_factor自定义）</span></span><br><span class="line">    <span class="keyword">if</span> <span class="variable language_">self</span>.scheduler_config.delay_factor &gt; <span class="number">0</span> <span class="keyword">and</span> <span class="variable language_">self</span>.waiting:</span><br><span class="line">        <span class="comment"># 2.1 计算waiting队列中，seq_group的最早到达时间</span></span><br><span class="line">        <span class="comment"># now - earliest_arrival_time: seq_group实际等待的时间</span></span><br><span class="line">        <span class="comment"># self.scheduler_config.delay_factor * self.last_prompt_latency：seq_group应该等待的时间</span></span><br><span class="line">        earliest_arrival_time = <span class="built_in">min</span>(</span><br><span class="line">            [e.metrics.arrival_time <span class="keyword">for</span> e <span class="keyword">in</span> <span class="variable language_">self</span>.waiting])</span><br><span class="line">        passed_delay = ((now - earliest_arrival_time)</span><br><span class="line">                        &gt; (<span class="variable language_">self</span>.scheduler_config.delay_factor *</span><br><span class="line">                            <span class="variable language_">self</span>.last_prompt_latency) <span class="keyword">or</span> <span class="keyword">not</span> <span class="variable language_">self</span>.running)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        passed_delay = <span class="literal">True</span></span><br><span class="line">    <span class="keyword">return</span> passed_delay</span><br></pre></td></tr></table></figure></p></blockquote><h5 id="can_allocateblock_manager判断能否为seq_group分配物理块做prefill"><code>can_allocate</code>：block_manager判断能否为<code>seq_group</code>分配物理块做prefill</h5><p>当前我们已从waiting队列中取出了一个<code>seq_group</code>，将对它进行prefill操作。因此需要判断：gpu上是否有充足的物理块分配给该seq_group做prefill呢？</p><ul><li>这里假设：seq_group中的所有sequences共用同一个prompt（在preemptedsequences中不一定成立） <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">can_allocate</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                    seq_group: SequenceGroup,</span></span><br><span class="line"><span class="params">                    num_lookahead_slots: <span class="built_in">int</span> = <span class="number">0</span></span>) -&gt; AllocStatus:</span><br><span class="line"></span><br><span class="line">    check_no_caching_or_swa_for_blockmgr_encdec(<span class="variable language_">self</span>, seq_group)</span><br><span class="line"></span><br><span class="line">     <span class="comment"># 1. 取出这个seq_group下处于waiting状态的序列</span></span><br><span class="line">    seq = seq_group.get_seqs(status=SequenceStatus.WAITING)[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 2. 计算seq所需的逻辑块数量</span></span><br><span class="line">    num_required_blocks = BlockTable.get_num_required_blocks(</span><br><span class="line">        seq.get_token_ids(),</span><br><span class="line">        block_size=<span class="variable language_">self</span>.block_size,</span><br><span class="line">        num_lookahead_slots=num_lookahead_slots,</span><br><span class="line">    )</span><br><span class="line">    <span class="comment"># 3. 如果是encoder-decoder模型（通常是Transformer架构），计算编码器的逻辑块数量：</span></span><br><span class="line">    <span class="keyword">if</span> seq_group.is_encoder_decoder():</span><br><span class="line">        encoder_seq = seq_group.get_encoder_seq()</span><br><span class="line">        <span class="keyword">assert</span> encoder_seq <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span></span><br><span class="line">        num_required_blocks += BlockTable.get_num_required_blocks(</span><br><span class="line">            encoder_seq.get_token_ids(),</span><br><span class="line">            block_size=<span class="variable language_">self</span>.block_size,</span><br><span class="line">        )</span><br><span class="line">    <span class="comment"># 4. 考虑最大块滑动窗口：确保逻辑块数量不会请求超过最大窗口的块数</span></span><br><span class="line">    <span class="keyword">if</span> <span class="variable language_">self</span>.max_block_sliding_window <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        num_required_blocks = <span class="built_in">min</span>(num_required_blocks,</span><br><span class="line">                                    <span class="variable language_">self</span>.max_block_sliding_window)</span><br><span class="line">    <span class="comment"># 5. 获取当前GPU上可用的空闲块数量</span></span><br><span class="line">    num_free_gpu_blocks = <span class="variable language_">self</span>.block_allocator.get_num_free_blocks(</span><br><span class="line">        device=Device.GPU)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 6. 检查是否有足够的块可以分配：</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="variable language_">self</span>.num_total_gpu_blocks - num_required_blocks</span><br><span class="line">            &lt; <span class="variable language_">self</span>.watermark_blocks):</span><br><span class="line">        <span class="keyword">return</span> AllocStatus.NEVER    <span class="comment"># 不分配</span></span><br><span class="line">    <span class="keyword">if</span> num_free_gpu_blocks - num_required_blocks &gt;= <span class="variable language_">self</span>.watermark_blocks:</span><br><span class="line">        <span class="keyword">return</span> AllocStatus.OK       <span class="comment"># 立即分配</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> AllocStatus.LATER    <span class="comment"># 稍后分配</span></span><br></pre></td></tr></table></figure></li></ul><blockquote><ul><li><code>watermark_blocks</code>：水位线block数量，起到缓冲作用，防止在1次调度中把gpu上预留给KVCache的显存空间基本占满，出现一些意外风险（因为预留的显存空间也是估计值）。</li><li><code>NEVER</code>和<code>LATER</code><ul><li>相同点：都是因为当前显存空间不够，而无法继续调度seq_group；</li><li>不同点：<code>NEVER</code>是因为<strong>seq过长（即prompt太长）</strong>，以至于gpu上所有的block（num_total_gpu_blocks）都无法完成处理，因此后续步骤中直接将该seq标记为完成，不再处理；<code>LATER</code>是因为<strong>之前调度的seq_group占据相当一部分显存空间</strong>，导致gpu上剩余的可用block（num_free_gpu_blocks）不够，因此延迟处理。</li></ul></li></ul></blockquote><h4 id="schedule_running"><code>_schedule_running</code>：</h4><p>running队列包含：decode和chunked prefill请求</p><p>初始化： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">decode_seq_groups: <span class="type">List</span>[ScheduledSequenceGroup] = ret.decode_seq_groups</span><br><span class="line">prefill_seq_groups: <span class="type">List</span>[</span><br><span class="line">    ScheduledSequenceGroup] = ret.prefill_seq_groups</span><br><span class="line">preempted: <span class="type">List</span>[SequenceGroup] = ret.preempted <span class="comment"># 存放被抢占的seq_group（recomputation模式）</span></span><br><span class="line">swapped_out: <span class="type">List</span>[SequenceGroup] = ret.swapped_out <span class="comment"># 存放被抢占的seq_group（swap模式）</span></span><br><span class="line"></span><br><span class="line">running_queue = <span class="variable language_">self</span>.running</span><br></pre></td></tr></table></figure></p><ol type="1"><li>running队列循环： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> running_queue:</span><br><span class="line">    <span class="comment"># 1. 取出当前running队列中，最早到达的seq_group</span></span><br><span class="line">    seq_group = running_queue[<span class="number">0</span>]</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; 可以丢弃缓存tokens的信息：</span></span><br><span class="line"><span class="string">        1. 如果seq采用chunked prefill，cached tokens info在第一次prefill已使用；</span></span><br><span class="line"><span class="string">        2. 如果seq采用non-chunked prefill，有解码序列，与cached tokens info无关。</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    num_uncached_new_tokens, _ = \</span><br><span class="line">        <span class="variable language_">self</span>._get_num_new_uncached_and_cached_tokens(</span><br><span class="line">        seq_group,</span><br><span class="line">        SequenceStatus.RUNNING,</span><br><span class="line">        enable_chunking,</span><br><span class="line">        budget,</span><br><span class="line">        partial_prefill_metadata,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    num_running_tokens = num_uncached_new_tokens</span><br><span class="line">    <span class="keyword">if</span> num_running_tokens == <span class="number">0</span>:</span><br><span class="line">        <span class="comment"># No budget =&gt; Stop</span></span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    running_queue.popleft()</span><br><span class="line"></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;如果启用异步输出处理 (use_async_output_proc)，在序列长度超过最大模型长度时：暂停当前序列并加入 _async_stopped 列表，以避免内存溢出。&#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="variable language_">self</span>.use_async_output_proc <span class="keyword">and</span> seq_group.seqs[<span class="number">0</span>].get_len()</span><br><span class="line">            &gt; <span class="variable language_">self</span>.scheduler_config.max_model_len):</span><br><span class="line">        <span class="variable language_">self</span>._async_stopped.append(seq_group)</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2. block_manager循环判断：是否有足够的KV cache空间分配给该seq_group做decode</span></span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">not</span> <span class="variable language_">self</span>._can_append_slots(seq_group, enable_chunking):</span><br><span class="line">        <span class="comment"># 没有充足空闲物理块：执行抢占</span></span><br><span class="line">        budget.subtract_num_batched_tokens(seq_group.request_id,</span><br><span class="line">                                            num_running_tokens)</span><br><span class="line">        num_running_seqs = seq_group.get_max_num_running_seqs()</span><br><span class="line">        budget.subtract_num_seqs(seq_group.request_id,</span><br><span class="line">                                    num_running_seqs)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (curr_loras <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> seq_group.lora_int_id &gt; <span class="number">0</span></span><br><span class="line">                <span class="keyword">and</span> seq_group.lora_int_id <span class="keyword">in</span> curr_loras):</span><br><span class="line">            curr_loras.remove(seq_group.lora_int_id)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 2.1 决定被抢占的seq_group：抢占running队列最低优先级的seq_group（队首，FCFS）；若running队列为空，抢占当前seq_group（此时跳出循环，因为没有seq_group可供抢占）</span></span><br><span class="line">        cont_loop = <span class="literal">True</span></span><br><span class="line">        <span class="keyword">if</span> running_queue:</span><br><span class="line">            victim_seq_group = running_queue.pop()</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            victim_seq_group = seq_group</span><br><span class="line">            cont_loop = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;3. 省略：抢占前确定没有正在进行的异步后处理任务&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 2.2 执行抢占：两种模式</span></span><br><span class="line">        <span class="comment"># swap模式：被抢占的seq_group进入swap队列</span></span><br><span class="line">        <span class="comment"># recomputation模式：被抢占的seq_group进入waiting队列</span></span><br><span class="line">        <span class="keyword">if</span> do_preempt:</span><br><span class="line">            preempted_mode = <span class="variable language_">self</span>._preempt(victim_seq_group,</span><br><span class="line">                                            blocks_to_swap_out)</span><br><span class="line">            <span class="keyword">if</span> preempted_mode == PreemptionMode.RECOMPUTE:</span><br><span class="line">                preempted.append(victim_seq_group)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                swapped_out.append(victim_seq_group)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> cont_loop:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 有充足空闲物理块：进行分配</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="variable language_">self</span>._append_slots(seq_group, blocks_to_copy, enable_chunking)</span><br><span class="line">        is_prefill = seq_group.is_prefill()</span><br><span class="line"></span><br><span class="line">        scheduled_seq_group: ScheduledSequenceGroup = (</span><br><span class="line">            <span class="variable language_">self</span>._scheduled_seq_group_cache[</span><br><span class="line">                <span class="variable language_">self</span>.cache_id].get_object())</span><br><span class="line">        scheduled_seq_group.seq_group = seq_group</span><br><span class="line">        <span class="keyword">if</span> is_prefill:</span><br><span class="line">            scheduled_seq_group.token_chunk_size = num_running_tokens</span><br><span class="line">            prefill_seq_groups.append(scheduled_seq_group)</span><br><span class="line">            ret.prefill_seq_groups_list.append(seq_group)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            scheduled_seq_group.token_chunk_size = <span class="number">1</span></span><br><span class="line">            decode_seq_groups.append(scheduled_seq_group)</span><br><span class="line">            ret.decode_seq_groups_list.append(seq_group)</span><br><span class="line"></span><br><span class="line">        budget.add_num_batched_tokens(seq_group.request_id,</span><br><span class="line">                                        num_running_tokens)</span><br><span class="line"></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;优化：get_max_num_running_seqs()是计算昂贵的，对于默认调度阶段，如果enable_chunking==num_seqs在调用该方法前已更新，因此这里不再更新&#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">if</span> enable_chunking:</span><br><span class="line">            num_running_seqs = seq_group.get_max_num_running_seqs()</span><br><span class="line">            budget.add_num_seqs(seq_group.request_id, num_running_seqs)</span><br><span class="line">        <span class="keyword">if</span> curr_loras <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> seq_group.lora_int_id &gt; <span class="number">0</span>:</span><br><span class="line">            curr_loras.add(seq_group.lora_int_id)</span><br></pre></td></tr></table></figure></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_schedule_running</span>(<span class="params"></span></span><br><span class="line"><span class="params">    self,</span></span><br><span class="line"><span class="params">    budget: SchedulingBudget,</span></span><br><span class="line"><span class="params">    curr_loras: <span class="type">Optional</span>[<span class="type">Set</span>[<span class="built_in">int</span>]],</span></span><br><span class="line"><span class="params">    enable_chunking: <span class="built_in">bool</span> = <span class="literal">False</span>,</span></span><br><span class="line"><span class="params">    partial_prefill_metadata: <span class="type">Optional</span>[PartialPrefillMetadata] = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params"></span>) -&gt; SchedulerRunningOutputs:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Schedule sequence groups that are running.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Running queue should include decode and chunked prefill requests.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        budget: The scheduling budget. The argument is in-place updated</span></span><br><span class="line"><span class="string">            when any decodes are preempted.</span></span><br><span class="line"><span class="string">        curr_loras: Currently batched lora request ids. The argument is</span></span><br><span class="line"><span class="string">            in-place updated when any decodes are preempted.</span></span><br><span class="line"><span class="string">        enable_chunking: If True, seq group can be chunked and only a</span></span><br><span class="line"><span class="string">            chunked number of tokens are scheduled  if</span></span><br><span class="line"><span class="string">            `budget.num_batched_tokens` has not enough capacity to schedule</span></span><br><span class="line"><span class="string">            all tokens.</span></span><br><span class="line"><span class="string">        partial_prefill_metadata: information about the partial prefills</span></span><br><span class="line"><span class="string">        that are currently running</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        SchedulerRunningOutputs.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    ret: SchedulerRunningOutputs = <span class="variable language_">self</span>._scheduler_running_outputs_cache[</span><br><span class="line">        <span class="variable language_">self</span>.cache_id].get_object()</span><br><span class="line">    ret.blocks_to_swap_out.clear()</span><br><span class="line">    ret.blocks_to_copy.clear()</span><br><span class="line">    ret.decode_seq_groups.clear()</span><br><span class="line">    ret.prefill_seq_groups.clear()</span><br><span class="line">    ret.preempted.clear()</span><br><span class="line">    ret.swapped_out.clear()</span><br><span class="line"></span><br><span class="line">    ret.num_lookahead_slots = <span class="variable language_">self</span>._get_num_lookahead_slots(</span><br><span class="line">        is_prefill=<span class="literal">False</span>, enable_chunking=enable_chunking)</span><br><span class="line"></span><br><span class="line">    ret.decode_seq_groups_list.clear()</span><br><span class="line">    ret.prefill_seq_groups_list.clear()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Blocks that need to be swapped or copied before model execution.</span></span><br><span class="line">    blocks_to_swap_out: <span class="type">List</span>[<span class="type">Tuple</span>[<span class="built_in">int</span>, <span class="built_in">int</span>]] = ret.blocks_to_swap_out</span><br><span class="line">    blocks_to_copy: <span class="type">List</span>[<span class="type">Tuple</span>[<span class="built_in">int</span>, <span class="built_in">int</span>]] = ret.blocks_to_copy</span><br><span class="line"></span><br><span class="line">    decode_seq_groups: <span class="type">List</span>[ScheduledSequenceGroup] = ret.decode_seq_groups</span><br><span class="line">    prefill_seq_groups: <span class="type">List</span>[</span><br><span class="line">        ScheduledSequenceGroup] = ret.prefill_seq_groups</span><br><span class="line">    preempted: <span class="type">List</span>[SequenceGroup] = ret.preempted</span><br><span class="line">    swapped_out: <span class="type">List</span>[SequenceGroup] = ret.swapped_out</span><br><span class="line"></span><br><span class="line">    running_queue = <span class="variable language_">self</span>.running</span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">len</span>(<span class="variable language_">self</span>._async_stopped) == <span class="number">0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="variable language_">self</span>._scheduler_running_outputs_cache[<span class="variable language_">self</span>.next_cache_id].reset()</span><br><span class="line">    <span class="variable language_">self</span>._scheduled_seq_group_cache[<span class="variable language_">self</span>.next_cache_id].reset()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> ret</span><br></pre></td></tr></table></figure><h5 id="can_append_slotsblock_manager判断是否能为seq_group分配充足物理块做decode"><code>_can_append_slots</code>：block_+manager判断是否能为seq_group分配充足物理块做decode</h5><p>做decode时，给每个seq分配1个token的位置；那么running队列中，seq_group下的n个seqs在上1个推理阶段共生成了n个token。本次调度中，先为这n个token分配物理空间，存放其在本次调度中即将产生的KV值。</p><p>当往1个seq的物理块上添加1个token时，可能有两种情况： *之前的物理块已满，新分配一个物理块； *之前的物理块没满，直接添加在最后一个物理块的空槽位上；</p><p><strong>因此对于n个seqs来说，最坏的情况就是添加n个物理块</strong>。</p><p><strong>考虑最坏情况：判断当前可用的物理块数量，是否至少为n</strong><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">can_append_slots</span>(<span class="params">self, seq_group: SequenceGroup,</span></span><br><span class="line"><span class="params">                        num_lookahead_slots: <span class="built_in">int</span></span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">    num_touched_blocks = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> seq <span class="keyword">in</span> seq_group.get_seqs(status=SequenceStatus.RUNNING):</span><br><span class="line">        block_table = <span class="variable language_">self</span>.block_tables[seq.seq_id]</span><br><span class="line"></span><br><span class="line">        num_touched_blocks += (</span><br><span class="line">            block_table.get_num_blocks_touched_by_append_slots(</span><br><span class="line">                token_ids=block_table.get_unseen_token_ids(</span><br><span class="line">                    seq.get_token_ids()),</span><br><span class="line">                num_lookahead_slots=num_lookahead_slots,</span><br><span class="line">            ))</span><br><span class="line"></span><br><span class="line">    num_free_gpu_blocks = <span class="variable language_">self</span>.block_allocator.get_num_free_blocks(</span><br><span class="line">        Device.GPU)</span><br><span class="line">    <span class="keyword">return</span> num_touched_blocks &lt;= num_free_gpu_blocks    <span class="comment"># 判断：空闲物理块是否至少为n</span></span><br></pre></td></tr></table></figure></p><h3 id="块管理器blockmanager">块管理器<code>BlockManager</code></h3><h3 id="step完成一次调度"><code>step()</code>：完成一次调度</h3><p><code>step()</code>方法：<strong>执行一次解码迭代</strong>，并返回新生成的结果。</p><ol type="1"><li>调度在下一次迭代中执行的序列，以及需要交换、复制或移入/移出的 token块：</li></ol><ul><li>如果seqgroup中还有剩余的步骤，则不调用<code>Scheduler</code>，保证<code>Scheduler</code>只在当前batch完成后调用；</li><li>如果单个请求导致上一步引擎执行失败，那么<code>Scheduler</code>也会被跳过，之前的调度需要重新执行。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> <span class="variable language_">self</span>._has_remaining_steps(</span><br><span class="line">        seq_group_metadata_list</span><br><span class="line">) <span class="keyword">and</span> <span class="keyword">not</span> <span class="variable language_">self</span>._skip_scheduling_next_step:</span><br><span class="line">    <span class="comment"># Schedule iteration</span></span><br><span class="line">    (seq_group_metadata_list, scheduler_outputs,</span><br><span class="line">        allow_async_output_proc</span><br><span class="line">        ) = <span class="variable language_">self</span>.scheduler[virtual_engine].schedule()</span><br><span class="line"></span><br><span class="line">    ctx.seq_group_metadata_list = seq_group_metadata_list</span><br><span class="line">    ctx.scheduler_outputs = scheduler_outputs</span><br><span class="line"></span><br><span class="line">    finished_requests_ids = <span class="variable language_">self</span>.scheduler[</span><br><span class="line">        virtual_engine].get_and_reset_finished_requests_ids()</span><br><span class="line">    <span class="comment"># When n&gt;1, elements in self.seq_id_to_seq_group should be deleted</span></span><br><span class="line">    <span class="comment"># here, otherwise memory leaks.</span></span><br><span class="line">    <span class="keyword">for</span> finished_request_id <span class="keyword">in</span> finished_requests_ids:</span><br><span class="line">        <span class="keyword">if</span> finished_request_id <span class="keyword">in</span> <span class="variable language_">self</span>.seq_id_to_seq_group:</span><br><span class="line">            <span class="keyword">del</span> <span class="variable language_">self</span>.seq_id_to_seq_group[finished_request_id]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Maybe switch from async mode to sync mode</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> allow_async_output_proc <span class="keyword">and</span> <span class="built_in">len</span>(ctx.output_queue) &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="variable language_">self</span>._process_model_outputs(ctx=ctx)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (<span class="variable language_">self</span>.scheduler_config.is_multi_step</span><br><span class="line">            <span class="keyword">and</span> scheduler_outputs.num_lookahead_slots &gt; <span class="number">0</span>):</span><br><span class="line">        <span class="comment"># cache the scheduler outputs for the next iteration if we have</span></span><br><span class="line">        <span class="comment"># lookahead slots</span></span><br><span class="line">        <span class="variable language_">self</span>._cache_scheduler_outputs_for_multi_step(</span><br><span class="line">            virtual_engine, seq_group_metadata_list, scheduler_outputs,</span><br><span class="line">            allow_async_output_proc)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    finished_requests_ids = <span class="built_in">list</span>()</span><br></pre></td></tr></table></figure><ol start="2" type="1"><li><p>调用分布式执行器，<code>execute_model</code>执行模型：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> scheduler_outputs.is_empty():</span><br><span class="line">    <span class="comment"># Check if we have a cached last_output from the previous iteration.</span></span><br><span class="line">    <span class="comment"># For supporting PP this is probably the best way to pass the</span></span><br><span class="line">    <span class="comment"># sampled_token_ids, as a separate broadcast over all the PP stages</span></span><br><span class="line">    <span class="comment"># will cause one virtual engine&#x27;s microbatch to block the pipeline.</span></span><br><span class="line">    last_sampled_token_ids = \</span><br><span class="line">        <span class="variable language_">self</span>._get_last_sampled_token_ids(virtual_engine)</span><br><span class="line"></span><br><span class="line">    execute_model_req = ExecuteModelRequest(</span><br><span class="line">        seq_group_metadata_list=seq_group_metadata_list,</span><br><span class="line">        blocks_to_swap_in=scheduler_outputs.blocks_to_swap_in,</span><br><span class="line">        blocks_to_swap_out=scheduler_outputs.blocks_to_swap_out,</span><br><span class="line">        blocks_to_copy=scheduler_outputs.blocks_to_copy,</span><br><span class="line">        num_lookahead_slots=scheduler_outputs.num_lookahead_slots,</span><br><span class="line">        running_queue_size=scheduler_outputs.running_queue_size,</span><br><span class="line">        finished_requests_ids=finished_requests_ids,</span><br><span class="line">        <span class="comment"># We use ExecuteModelRequest to pass the last sampled_token_ids</span></span><br><span class="line">        <span class="comment"># to each of the non-last PP stages for in-place prepare_input.</span></span><br><span class="line">        last_sampled_token_ids=last_sampled_token_ids)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> allow_async_output_proc:</span><br><span class="line">        execute_model_req.async_callback = <span class="variable language_">self</span>.async_callbacks[</span><br><span class="line">            virtual_engine]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        outputs = <span class="variable language_">self</span>.model_executor.execute_model(</span><br><span class="line">            execute_model_req=execute_model_req)</span><br><span class="line">        <span class="variable language_">self</span>._skip_scheduling_next_step = <span class="literal">False</span></span><br><span class="line">    <span class="keyword">except</span> InputProcessingError <span class="keyword">as</span> e:</span><br><span class="line">        <span class="comment"># The input for this request cannot be processed, so we must</span></span><br><span class="line">        <span class="comment"># abort it. If there are remaining requests in the batch that</span></span><br><span class="line">        <span class="comment"># have been scheduled, they will be retried on the next step.</span></span><br><span class="line">        invalid_request_id = e.request_id</span><br><span class="line">        <span class="variable language_">self</span>._abort_and_cache_schedule(</span><br><span class="line">            request_id=invalid_request_id,</span><br><span class="line">            virtual_engine=virtual_engine,</span><br><span class="line">            seq_group_metadata_list=seq_group_metadata_list,</span><br><span class="line">            scheduler_outputs=scheduler_outputs,</span><br><span class="line">            allow_async_output_proc=allow_async_output_proc)</span><br><span class="line">        <span class="comment"># Raise so the caller is notified that this request failed</span></span><br><span class="line">        <span class="keyword">raise</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># We need to do this here so that last step&#x27;s sampled_token_ids can</span></span><br><span class="line">    <span class="comment"># be passed to the next iteration for PP.</span></span><br><span class="line">    <span class="keyword">if</span> <span class="variable language_">self</span>.scheduler_config.is_multi_step:</span><br><span class="line">        <span class="variable language_">self</span>._update_cached_scheduler_output(virtual_engine, outputs)</span><br></pre></td></tr></table></figure></p></li><li><p>处理输出</p></li></ol><h2 id="致谢">致谢</h2><p>部分图转自：</p><p><a href="https://zhuanlan.zhihu.com/p/706685260">vllm模型执行笔记:LLMEngine, Executor, Worker, ModelRunner</a></p><p><a href="https://mp.weixin.qq.com/s/UCdqQUM_9a36uXkO36wpSg">图解大模型计算加速系列：vLLM源码解析2，调度器策略(Scheduler)</a></p>]]></content>
      
      
      <categories>
          
          <category> Parallelism </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>《算法导论》笔记</title>
      <link href="/posts/abf55f5c.html"/>
      <url>/posts/abf55f5c.html</url>
      
        <content type="html"><![CDATA[<p>该篇为《算法导论》学习笔记，包含部分章节的理论阐释、典型问题、和代码实现。</p><h1 id="算法">算法</h1><h2 id="时间复杂度">时间复杂度</h2><h3 id="渐近符号">1.渐近符号：</h3><p>θ--渐近紧确界； f(n)=θ(g(n)):g(n)是f(n)的渐进紧确界.定义:存在c1,c2,n0,对任意n&gt;=n0,有：0&lt;=c1<em>g(n)&lt;=f(n)&lt;=c2</em>g(n).f(n)=θ(g(n)),当且仅当:f(n)=O(g(n))且f(n)=<a href="g(n)">欧姆</a>.O--渐近上界；[欧姆]--渐近下界 o--非紧确渐近上界；ω--非紧确渐近下界f(n)=O(g(n))中,0&lt;=f(n)&lt;c<em>g(n)对某个常量c&gt;0成立；f(n)=o(g(n))中,0&lt;=f(n)&lt;c</em>g(n)对所有常量c&gt;0成立.</p><h3 id="主定理求时间复杂度">2.主定理求时间复杂度:</h3><p>T(n)=a<em>T(n/b)+f(n). 比较n<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>和f(n):选择多项式意义上更大的。1.f(n)=O(n<sup>(logb(a)-ε)),则:T(n)=θ(n</sup>(logb(a)).2.f(n)=0(n<sup>(logb(a))),则:T(n)=θ(n</sup>(logb(a)</em>lgn). 3.f(n)=<a href="n%5E(logb(a)+ε)">欧姆</a>,则:T(n)=θ(f(n)).注意：T(n)=2T(n/2)+nlgn.nlgn非多项式意义大于n,落入2，3间隙,不适用主定理.</p><h2 id="快速幂质数">快速幂/质数</h2><h3 id="快速幂求ab.">1.快速幂：求a^b.</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">long</span> <span class="type">long</span> <span class="title function_">fpm</span><span class="params">(<span class="type">long</span> <span class="type">long</span> a,<span class="type">long</span> <span class="type">long</span> b)</span>&#123;</span><br><span class="line">    <span class="type">long</span> <span class="type">long</span> ans=<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">for</span>(;b!=<span class="number">0</span>;b&gt;&gt;=<span class="number">1</span>,a=a*a%M)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span>(b&amp;<span class="number">1</span>) ans=ans*a%M;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> ans;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>求矩阵n次幂:A<sup>n--θ(n</sup>3)-&gt;θ(n^2*logn). <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;bits/stdc++.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> maxn 205</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="type">long</span> <span class="type">long</span> ll;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> p = <span class="number">1e9</span> + <span class="number">7</span>;</span><br><span class="line">using namespace <span class="built_in">std</span>;</span><br><span class="line"><span class="type">int</span> n;</span><br><span class="line">ll k;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Martix</span>&#123;</span></span><br><span class="line">    ll a[maxn][maxn];</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">inline</span> Martix <span class="title function_">multiply</span><span class="params">(Martix x, Martix y)</span>&#123;</span><br><span class="line">    Martix z;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">1</span>;i &lt;= n;i++)&#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j = <span class="number">1</span>;j &lt;= n;j++)&#123;</span><br><span class="line">            z.a[i][j] = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">for</span>(<span class="type">int</span> k = <span class="number">1</span>;k &lt;= n;k++)&#123;</span><br><span class="line">                z.a[i][j] += x.a[i][k] * y.a[k][j];</span><br><span class="line">                z.a[i][j] %= p;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> z;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">inline</span> Martix <span class="title function_">fpow</span><span class="params">(Martix x, ll k)</span>&#123;</span><br><span class="line">    Martix y;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">1</span>;i &lt;= n;i++)&#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j = <span class="number">1</span>;j &lt;= n;j++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(i == j) y.a[i][j] = <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">else</span> y.a[i][j] = <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">while</span>(k)&#123;</span><br><span class="line">        <span class="keyword">if</span>(k &amp; <span class="number">1</span>) y = multiply(y, x);</span><br><span class="line">        x = multiply(x, x);</span><br><span class="line">        k &gt;&gt;= <span class="number">1</span>;</span><br><span class="line">    &#125; </span><br><span class="line">    <span class="keyword">return</span> y;</span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">int</span> t;</span><br><span class="line">    <span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>, &amp;t);</span><br><span class="line">    <span class="keyword">while</span>(t--)&#123;</span><br><span class="line">        <span class="built_in">scanf</span>(<span class="string">&quot;%d%&quot;</span>, &amp;n);k = n;</span><br><span class="line">        Martix x;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">1</span>;i &lt;= n;i++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="type">int</span> j = <span class="number">1</span>;j &lt;= n;j++)&#123;</span><br><span class="line">                <span class="built_in">scanf</span>(<span class="string">&quot;%lld&quot;</span>, &amp;x.a[i][j]);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        x = fpow(x, k);</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">1</span>;i &lt;= n;i++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="type">int</span> j = <span class="number">1</span>;j &lt;= n;j++)&#123;</span><br><span class="line">                <span class="built_in">printf</span>(<span class="string">&quot;%lld &quot;</span>, x.a[i][j]);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h3 id="分解质因数">2.分解质因数</h3><p>质数个数:O(n/logn). (1)朴素算法:遍历i. <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> a[N],p[N],k=<span class="number">0</span>;      <span class="comment">//p记录n的质因数;a记录n的质因数的指数;k为不同质因数个数</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">decompose</span><span class="params">(<span class="type">int</span> n)</span>&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">2</span>;i*i&lt;=n;i++)&#123;</span><br><span class="line">        <span class="keyword">if</span>(n%i==<span class="number">0</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            p[k]=i;a[k]=<span class="number">0</span>;</span><br><span class="line">            <span class="keyword">while</span>(n%i==<span class="number">0</span>) &#123;a[k]++;n/=i;&#125;</span><br><span class="line">            k++;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(n!=<span class="number">1</span>)&#123;</span><br><span class="line">        p[k]=n;a[k]=<span class="number">1</span>;k++;</span><br><span class="line">    &#125;   <span class="comment">//此时p[0],...,p[k-1]为最初n的k个质数</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>(2)优化：预先运用埃氏筛/欧氏筛打表出2~n的质数,改为遍历prime[i].</p><p>埃氏筛:O(n*loglogn) <img src="/posts/abf55f5c/image.png"> 欧式筛:O(n) <img src="/posts/abf55f5c/image-1.png"></p><h3 id="逆元若xy1mod-p则xy互为模p意义下的逆元.">3.逆元:若x*y=1(modp),则x,y互为模p意义下的逆元.</h3><pre><code>由费马小定理:x^(-1)=x^(p-2)(mod p),p为质数.求阶乘的逆元:    递推实现(i!)^(-1)=((i+1)!)^(-1)*(i+1)(mod p).    令:inv[i]表示i!的逆元,则:inv[i-1]=inv[i]*i(mod p).    O(logn)求n!的逆元,O(n)递推得所有数的逆元.</code></pre><h3 id="秦九韶算法快速计算sigmaaixii0n.">4.秦九韶算法:快速计算sigma(ai*x^i)(i=0~n).</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">long</span> <span class="type">long</span> a[<span class="number">30005</span>],b[<span class="number">30005</span>];</span><br><span class="line"><span class="meta">#<span class="keyword">define</span> E 10007</span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">int</span> n;<span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>,&amp;n);</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;=n;i++) <span class="built_in">scanf</span>(<span class="string">&quot;%lld&quot;</span>,&amp;a[i]);</span><br><span class="line">    <span class="type">int</span> m;<span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>,&amp;m);</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;=m;i++) <span class="built_in">scanf</span>(<span class="string">&quot;%lld&quot;</span>,&amp;b[i]);</span><br><span class="line">    <span class="type">int</span> q;<span class="type">long</span> <span class="type">long</span> x,y;<span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>,&amp;q);</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;q;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">scanf</span>(<span class="string">&quot;%lld%lld&quot;</span>,&amp;x,&amp;y);</span><br><span class="line">        x%=E;y%=E;</span><br><span class="line">        <span class="type">long</span> <span class="type">long</span> sum1=<span class="number">0</span>,mi=<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;=n;i++)</span><br><span class="line">        &#123;</span><br><span class="line">            sum1=(sum1%E+(a[i]%E)*(mi%E))%E;</span><br><span class="line">            mi=(mi*x)%E;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        mi=<span class="number">1</span>;</span><br><span class="line">        <span class="type">long</span> <span class="type">long</span> sum2=<span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;=m;i++)</span><br><span class="line">        &#123;</span><br><span class="line">            sum2=(sum2%E+(b[i]%E)*(mi%E))%E;</span><br><span class="line">            mi=(mi*y)%E;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="type">long</span> <span class="type">long</span> res=((sum1%E)*(sum2%E))%E;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%lld\n&quot;</span>,res);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="辗转相除法">5.辗转相除法:</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">gcd</span><span class="params">(<span class="type">int</span> a,<span class="type">int</span> b)</span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(a==<span class="number">0</span>||b==<span class="number">0</span>) <span class="keyword">return</span> a+b;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span>(a%b==<span class="number">0</span>) <span class="keyword">return</span> b;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">return</span> gcd(b,a%b);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="递推模拟">递推/模拟</h2><h3 id="卡特兰数">1.卡特兰数</h3><p><img src="/posts/abf55f5c/image-2.png"></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//卡特兰数存放在data中,进行n次查询</span></span><br><span class="line"><span class="type">long</span> <span class="type">long</span> data[<span class="number">1005</span>]=&#123;<span class="number">0</span>&#125;;</span><br><span class="line"><span class="meta">#<span class="keyword">define</span> MAX 998244353</span></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">calculate</span><span class="params">(<span class="type">int</span> num,<span class="type">int</span> *now)</span>&#123;</span><br><span class="line">    <span class="type">int</span> k=*now;</span><br><span class="line">    <span class="keyword">while</span>(num&gt;=k)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">long</span> <span class="type">long</span> sum=<span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;k;i++)</span><br><span class="line">        &#123;</span><br><span class="line">            sum=(((data[i]%MAX)*(data[k<span class="number">-1</span>-i]%MAX))%MAX+sum)%MAX;</span><br><span class="line">        &#125;</span><br><span class="line">        data[k]=sum%MAX;</span><br><span class="line">        k++;</span><br><span class="line">    &#125;</span><br><span class="line">    *now=k<span class="number">-1</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">int</span> n;<span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>,&amp;n);<span class="type">int</span> now=<span class="number">1</span>;</span><br><span class="line">    data[<span class="number">0</span>]=data[<span class="number">1</span>]=<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;n;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">int</span> num;<span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>,&amp;num);</span><br><span class="line">        <span class="keyword">if</span>(num&lt;=now) <span class="built_in">printf</span>(<span class="string">&quot;%lld\n&quot;</span>,data[num]);</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">        &#123;</span><br><span class="line">            calculate(num,&amp;now);</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;%lld\n&quot;</span>,data[num]);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="多项式相加">2.多项式相加</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//合并同类项:O(n)</span></span><br><span class="line"><span class="type">int</span> a[<span class="number">100005</span>],b[<span class="number">100005</span>],A[<span class="number">100005</span>],B[<span class="number">100005</span>],c[<span class="number">200005</span>],C[<span class="number">200005</span>];</span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">int</span> t,n,m;<span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>,&amp;t);</span><br><span class="line">    <span class="keyword">while</span>(t--)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>,&amp;n);</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;n;i++) <span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>,&amp;a[i]);     <span class="comment">//系数</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;n;i++) <span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>,&amp;A[i]);     <span class="comment">//指数,非负递增</span></span><br><span class="line">        <span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>,&amp;m);</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;m;i++) <span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>,&amp;b[i]);     <span class="comment">//系数</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;m;i++) <span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>,&amp;B[i]);     <span class="comment">//指数,非负递增</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">//(合并后,不会出现和为0的项)</span></span><br><span class="line">        <span class="type">int</span> i=<span class="number">0</span>,j=<span class="number">0</span>,k=<span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>(i&lt;n&amp;&amp;j&lt;m)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">if</span>(A[i]==B[j])</span><br><span class="line">            &#123;</span><br><span class="line">                C[k]=A[i];c[k++]=a[i++]+b[j++];</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span>(A[i]&lt;B[j])</span><br><span class="line">            &#123;</span><br><span class="line">                C[k]=A[i];c[k++]=a[i++];</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">            &#123;</span><br><span class="line">                C[k]=B[j];c[k++]=b[j++];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">while</span>(i&lt;n) &#123;C[k]=A[i];c[k++]=a[i++];&#125;</span><br><span class="line">        <span class="keyword">while</span>(j&lt;m) &#123;C[k]=B[j];c[k++]=b[j++];&#125;</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%d\n&quot;</span>,k);</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> t=<span class="number">0</span>;t&lt;k;t++) <span class="built_in">printf</span>(<span class="string">&quot;%d &quot;</span>,c[t]);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> t=<span class="number">0</span>;t&lt;k;t++) <span class="built_in">printf</span>(<span class="string">&quot;%d &quot;</span>,C[t]);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">memset</span>(a,<span class="number">0</span>,<span class="keyword">sizeof</span>(<span class="type">int</span>)*i);<span class="built_in">memset</span>(A,<span class="number">0</span>,<span class="keyword">sizeof</span>(<span class="type">int</span>)*i);</span><br><span class="line">        <span class="built_in">memset</span>(b,<span class="number">0</span>,<span class="keyword">sizeof</span>(<span class="type">int</span>)*j);<span class="built_in">memset</span>(B,<span class="number">0</span>,<span class="keyword">sizeof</span>(<span class="type">int</span>)*j);</span><br><span class="line">        <span class="built_in">memset</span>(c,<span class="number">0</span>,<span class="keyword">sizeof</span>(<span class="type">int</span>)*k);<span class="built_in">memset</span>(C,<span class="number">0</span>,<span class="keyword">sizeof</span>(<span class="type">int</span>)*k);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="大数乘法θmn">3.大数乘法:θ(m*n)</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">multiply</span><span class="params">(<span class="type">char</span>* a,<span class="type">char</span>* b)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> len1=<span class="built_in">strlen</span>(a);</span><br><span class="line">    <span class="type">int</span> len2=<span class="built_in">strlen</span>(b);</span><br><span class="line">    <span class="type">int</span> *res=(<span class="type">int</span> *)<span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="type">int</span>)*(len1+len2+<span class="number">1</span>));</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i=<span class="number">0</span>;i&lt;len1+len2;i++) res[i]=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;len1;i++)</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">0</span>;j&lt;len2;j++)</span><br><span class="line">            res[i+j+<span class="number">1</span>]+=(a[i]-<span class="string">&#x27;0&#x27;</span>)*(b[j]-<span class="string">&#x27;0&#x27;</span>);</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i=len1+len2<span class="number">-1</span>;i&gt;<span class="number">0</span>;i--)</span><br><span class="line">        <span class="keyword">if</span> (res[i]&gt;=<span class="number">10</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            res[i<span class="number">-1</span>]+=res[i]/<span class="number">10</span>;</span><br><span class="line">            res[i]%=<span class="number">10</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    <span class="type">int</span> i=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span>(res[i]==<span class="number">0</span>&amp;&amp;i&lt;len1+len2) i++;</span><br><span class="line">    <span class="keyword">if</span>(i==len1+len2) &#123;<span class="built_in">printf</span>(<span class="string">&quot;0\n&quot;</span>);<span class="keyword">return</span>;&#125;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> j=i;j&lt;len1+len2;j++) <span class="built_in">printf</span>(<span class="string">&quot;%c&quot;</span>,res[j]+<span class="string">&#x27;0&#x27;</span>);</span><br><span class="line">    <span class="comment">//for(int j=i;j&lt;=len1+len2+1;j++) printf(&quot;%c&quot;,res[j]+&#x27;0&#x27;);</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">    </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">char</span> A[<span class="number">2005</span>],B[<span class="number">2005</span>];</span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">int</span> T;<span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>,&amp;T);getchar();</span><br><span class="line">    <span class="keyword">while</span>(T--)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">memset</span>(A,<span class="string">&#x27;\0&#x27;</span>,<span class="keyword">sizeof</span>(<span class="type">char</span>)*<span class="number">2005</span>);<span class="built_in">memset</span>(B,<span class="string">&#x27;\0&#x27;</span>,<span class="keyword">sizeof</span>(<span class="type">char</span>)*<span class="number">2005</span>);</span><br><span class="line">        fgets(A,<span class="number">2004</span>,<span class="built_in">stdin</span>);fgets(B,<span class="number">2004</span>,<span class="built_in">stdin</span>);</span><br><span class="line">        <span class="type">int</span> lenA=<span class="built_in">strlen</span>(A);<span class="type">int</span> lenB=<span class="built_in">strlen</span>(B);<span class="comment">//printf(&quot;%d&quot;,lenA);</span></span><br><span class="line">        A[lenA<span class="number">-1</span>]=<span class="string">&#x27;\0&#x27;</span>;B[lenB<span class="number">-1</span>]=<span class="string">&#x27;\0&#x27;</span>;</span><br><span class="line">        <span class="comment">//printf(&quot;%s&quot;,A);printf(&quot;%s&quot;,B);</span></span><br><span class="line">        multiply(A,B);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="高精度除法">4.高精度除法</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">double</span> <span class="title function_">divide</span><span class="params">(<span class="type">long</span> numerator,<span class="type">long</span> denominator)</span>&#123;</span><br><span class="line">    <span class="type">double</span> offset=<span class="number">1.0</span>;</span><br><span class="line">    <span class="type">double</span> q=<span class="number">0.0</span>;</span><br><span class="line">    <span class="type">long</span> a=numerator;</span><br><span class="line">    <span class="type">long</span> b=denominator;</span><br><span class="line">    <span class="keyword">while</span>(b&gt;<span class="number">1</span>)&#123;</span><br><span class="line">        <span class="keyword">if</span>(a&gt;=b)&#123;</span><br><span class="line">            a=a-b;</span><br><span class="line">            q=q+offset;</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">            offset=offset*<span class="number">0.1</span>;</span><br><span class="line">            b=denominator*offset;</span><br><span class="line">            <span class="comment">//printf_s(&quot;%f\n&quot;,q);</span></span><br><span class="line">            <span class="comment">//printf_s(&quot;%d\n&quot;,b);</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> q;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="分治">分治</h2><h3 id="最大子数组问题寻找a的和最大的非空连续子数组.">1.最大子数组问题:寻找A的和最大的非空连续子数组.</h3><p>朴素：O(n^2)；分治：O(nlgn).--买一次股票问题. <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//分治思路:change数组储存相邻两天变化.change[low,high]的最大值(change[j]-change[i])来自:</span></span><br><span class="line"><span class="comment">//change[low,mid]最大值;change[mid+1,high]最大值;横跨mid的最大值.</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> INFINITY -2147483647</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">findMaxCrossingSubarray</span><span class="params">(<span class="type">int</span> *changes,<span class="type">int</span> low,<span class="type">int</span> mid,<span class="type">int</span> high)</span>&#123;</span><br><span class="line">    <span class="type">int</span> left_sum=INFINITY,right_sum=INFINITY,sum=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=mid;i&gt;=low;i--)</span><br><span class="line">    &#123;</span><br><span class="line">        sum+=changes[i];</span><br><span class="line">        <span class="keyword">if</span>(sum&gt;left_sum) left_sum=sum;</span><br><span class="line">    &#125;</span><br><span class="line">    sum=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> j=mid+<span class="number">1</span>;j&lt;=high;j++)</span><br><span class="line">    &#123;</span><br><span class="line">        sum+=changes[j];</span><br><span class="line">        <span class="keyword">if</span>(sum&gt;right_sum) right_sum=sum;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> left_sum+right_sum;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">int</span> <span class="title function_">findMaxSubarray</span><span class="params">(<span class="type">int</span> *changes,<span class="type">int</span> low,<span class="type">int</span> high)</span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(low==high) <span class="keyword">return</span> changes[low];</span><br><span class="line">    <span class="type">int</span> mid=(low+high)/<span class="number">2</span>;</span><br><span class="line">    <span class="type">int</span> leftSum=findMaxSubarray(changes,low,mid),rightSum=findMaxSubarray(changes,mid+<span class="number">1</span>,high),crossSum=findMaxCrossingSubarray(changes,low,mid,high);</span><br><span class="line">    <span class="keyword">if</span>(leftSum&gt;=rightSum&amp;&amp;leftSum&gt;=crossSum) <span class="keyword">return</span> leftSum;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span>(rightSum&gt;=leftSum&amp;&amp;rightSum&gt;=crossSum) <span class="keyword">return</span> rightSum;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">return</span> crossSum;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">maxProfit</span><span class="params">(<span class="type">int</span> *prices,<span class="type">int</span> pricesSize)</span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(pricesSize==<span class="number">0</span>||pricesSize==<span class="number">1</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    <span class="type">int</span> *changes=(<span class="type">int</span> *)<span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="type">int</span>)*(pricesSize<span class="number">-1</span>));</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;pricesSize<span class="number">-1</span>;i++) changes[i]=prices[i+<span class="number">1</span>]-prices[i];</span><br><span class="line">    <span class="keyword">return</span> findMaxSubarray(changes,<span class="number">0</span>,pricesSize<span class="number">-2</span>)&gt;<span class="number">0</span>?findMaxSubarray(changes,<span class="number">0</span>,pricesSize<span class="number">-2</span>):<span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h3 id="树状数组">2.树状数组:</h3><p>引入辅助数组C,C[i]管辖的元素个数：<span class="math inline">\(2^k\)</span>个（k为i的二进制末尾0的个数）.</p><p>求前缀和:求sum(A1+…+Am)：查询的m转为二进制，不断消除当前末尾1，直至全部为0停止。例：7(0111)[C7] -&gt; 6(0110)[C6] -&gt; 4(0100)[C4] -&gt; 0.故sum(A1+…+A7)=C4+C6+C7.</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">    <span class="comment">//如何求m的二进制表示的末尾1位置？</span></span><br><span class="line">    <span class="type">int</span> <span class="title function_">lowbit</span><span class="params">(<span class="type">int</span> m)</span>&#123;</span><br><span class="line">            <span class="keyword">return</span> m&amp;(-m);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//求前缀和：O(logn)</span></span><br><span class="line">    <span class="type">int</span> ans=<span class="number">0</span>;</span><br><span class="line">    <span class="type">int</span> <span class="title function_">getSum</span><span class="params">(<span class="type">int</span> m)</span>&#123;</span><br><span class="line">            <span class="keyword">while</span>(m&gt;<span class="number">0</span>)</span><br><span class="line">            &#123;</span><br><span class="line">                    ans+=C[m];</span><br><span class="line">                    m-=lowbit(m);</span><br><span class="line">            &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//单点更新a[i]：i转为二进制，不断对当前末尾1 +1，直至达到数组下标的最大值n结束.</span></span><br><span class="line">    <span class="comment">//例：更新A[2](+value)：</span></span><br><span class="line">        <span class="comment">//更新 (+value)(0010)-&gt;更新C[4](+value)(0100)-&gt;更新C[8](+value)(1000).</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">update</span><span class="params">(<span class="type">int</span> i,<span class="type">int</span> value)</span>&#123;</span><br><span class="line">    A[i]+=value;</span><br><span class="line">    <span class="keyword">while</span>(i&lt;=n)</span><br><span class="line">    &#123;</span><br><span class="line">        C[i]+=value;</span><br><span class="line">        i+=lowbit(i);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>例：求逆序对数目 <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//原数组A标记数i是否出现,A[i]=0未出现,A[i]=1出现.求前缀和,即为正序对数目</span></span><br><span class="line"><span class="type">int</span> lowbit[<span class="number">200010</span>];</span><br><span class="line"><span class="type">int</span> sum[<span class="number">200010</span>];        <span class="comment">//树状数组</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=<span class="number">200005</span>;i++) lowbit[i]=i&amp;(-i);</span><br><span class="line">    <span class="type">int</span> T,n,op;     <span class="comment">//T为数据组数，n为每组数据个数</span></span><br><span class="line">    <span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>,&amp;T);</span><br><span class="line">    <span class="keyword">while</span>(T--)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>,&amp;n);</span><br><span class="line">        <span class="built_in">memset</span>(sum,<span class="number">0</span>,<span class="keyword">sizeof</span>(<span class="type">int</span>)*<span class="number">200010</span>);</span><br><span class="line">        <span class="type">long</span> <span class="type">long</span> ans=<span class="number">0</span>;        <span class="comment">//ans记录逆序对数量之和</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;n;i++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>,&amp;op);        <span class="comment">//op为当前a[i]</span></span><br><span class="line">            <span class="type">long</span> <span class="type">long</span> nowsum=<span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">            <span class="comment">//原数组A标记数i是否出现,A[i]=0未出现,A[i]=1出现.sum为A对应树状数组</span></span><br><span class="line">            <span class="comment">//求A[1]~A[op]前缀和.</span></span><br><span class="line">            <span class="keyword">for</span>(<span class="type">int</span> j=op;j&gt;<span class="number">0</span>;j-=lowbit[j]) nowsum+=sum[j];</span><br><span class="line">            </span><br><span class="line">            ans+=i-nowsum;          <span class="comment">//a[i]前有i个数,nowsum为小于a[i]=op的数个数</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment">//更新数组:A[op]=1.</span></span><br><span class="line">            <span class="keyword">for</span>(<span class="type">int</span> j=op;j&lt;=<span class="number">200000</span>;j+=lowbit[j]) sum[j]++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%lld\n&quot;</span>,ans);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure> ### 3.归并排序:O(n*lgn).<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//归并过程中求逆序对</span></span><br><span class="line"><span class="type">long</span> <span class="type">long</span> <span class="title function_">merge</span><span class="params">(<span class="type">int</span> r[],<span class="type">int</span> s[],<span class="type">int</span> left,<span class="type">int</span> mid,<span class="type">int</span> right)</span><span class="comment">//将r数组分为两部分，排序后存到s数组中</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> i,j,k;</span><br><span class="line">    <span class="type">long</span> <span class="type">long</span> num = <span class="number">0</span>;</span><br><span class="line">    i=left;<span class="comment">//左数组的索引</span></span><br><span class="line">    j=mid+<span class="number">1</span>;<span class="comment">//右数组的索引</span></span><br><span class="line">    k=left;</span><br><span class="line">    <span class="keyword">while</span>((i&lt;=mid)&amp;&amp;(j&lt;=right))</span><br><span class="line">    &#123;       </span><br><span class="line">        <span class="keyword">if</span>(r[i]&lt;=r[j]) s[k++] = r[i++];<span class="comment">//左半边的元素进入新数组，所以不用交换</span></span><br><span class="line">        <span class="keyword">else</span><span class="comment">//右半边的元素进入新数组，要交换</span></span><br><span class="line">        &#123;</span><br><span class="line">            num += j - k;</span><br><span class="line">            s[k++]=r[j++];</span><br><span class="line">        &#125;        </span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">while</span>(i&lt;=mid) s[k++]=r[i++];</span><br><span class="line">    <span class="keyword">while</span>(j&lt;=right) s[k++]=r[j++];</span><br><span class="line">    <span class="keyword">return</span> num;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">long</span> <span class="type">long</span> <span class="title function_">merge_sort</span><span class="params">(<span class="type">int</span> r[],<span class="type">int</span> s[],<span class="type">int</span> left,<span class="type">int</span> right)</span><span class="comment">//r[] 是原始数组, s[] 是用于存储结果的临时数组</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">long</span> <span class="type">long</span> ans = <span class="number">0</span>;</span><br><span class="line">    <span class="type">int</span> mid;</span><br><span class="line">    <span class="type">int</span> t[<span class="number">100010</span>];<span class="comment">//一个用于临时存储数据的数组。</span></span><br><span class="line">    <span class="keyword">if</span>(left==right)<span class="comment">//如果 left 等于 right，说明子数组只包含一个元素，无需排序，直接将该元素放入 s 中</span></span><br><span class="line">    &#123;</span><br><span class="line">        s[left]=r[right];</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    &#123;</span><br><span class="line">        mid=(left+right)/<span class="number">2</span>;</span><br><span class="line">        ans+=merge_sort(r,t,left,mid);</span><br><span class="line">        ans+=merge_sort(r,t,mid+<span class="number">1</span>,right);</span><br><span class="line">        ans+=merge(t,s,left,mid,right);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> ans;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> T;</span><br><span class="line">    <span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>, &amp;T);</span><br><span class="line">    <span class="keyword">while</span>(T--)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">int</span> n, a[<span class="number">100010</span>];</span><br><span class="line">        <span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>, &amp;n);</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>, &amp;a[i]);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%lld\n&quot;</span>, merge_sort(a,a,<span class="number">0</span>,n<span class="number">-1</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure> ## 堆 ### 1.C语言实现 <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//1.维护堆的性质:</span></span><br><span class="line"><span class="comment">//A[i]左右子树都是最大堆,调整以A[i]为根结点的二叉树为最大堆</span></span><br><span class="line"><span class="comment">//时间复杂度:T(n)&lt;=T(2n/3)+theta(1),T(n)=O(lgn).</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">swap</span><span class="params">(<span class="type">int</span> *a,<span class="type">int</span> *b)</span>&#123;</span><br><span class="line">    <span class="type">int</span> tmp=*a;</span><br><span class="line">    *a=*b;</span><br><span class="line">    *b=tmp;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">void</span> <span class="title function_">max_heapify</span><span class="params">(<span class="type">int</span> *A,<span class="type">int</span> heapsize,<span class="type">int</span> i)</span>&#123;</span><br><span class="line">    <span class="type">int</span> l=<span class="number">2</span>*i,r=<span class="number">2</span>*i+<span class="number">1</span>,largest;</span><br><span class="line">    <span class="keyword">if</span>(l&lt;=heapsize&amp;&amp;A[l]&gt;A[i]) largest=l;</span><br><span class="line">    <span class="keyword">else</span> largest=i;</span><br><span class="line">    <span class="keyword">if</span>(r&lt;=heapsize&amp;&amp;A[r]&gt;A[largest]) largest=r;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span>(largest!=i)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">//交换A[i]与A[largest]</span></span><br><span class="line">        swap(&amp;A[i],&amp;A[largest]);</span><br><span class="line">        max_heapify(A,heapsize,largest);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//2.建堆:</span></span><br><span class="line"><span class="comment">//自底向上,用max_heapify将数组转为最大堆:A[len/2+1,...,len]为叶节点,每个叶节点看作一个元素的堆</span></span><br><span class="line"><span class="comment">//时间复杂度:非紧确界:O(n*lgn);紧确界:O(n).</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">build_maxHeap</span><span class="params">(<span class="type">int</span> *A,<span class="type">int</span> len)</span>&#123;</span><br><span class="line">    <span class="type">int</span> heapsize=len;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=len/<span class="number">2</span>;i&gt;=<span class="number">1</span>;i--) max_heapify(A,heapsize,i);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//3.堆排序(升序):</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">heapSort</span><span class="params">(<span class="type">int</span> *A,<span class="type">int</span> len)</span>&#123;</span><br><span class="line">    build_maxHeap(A,len);       <span class="comment">//建立初始最大堆</span></span><br><span class="line">    <span class="type">int</span> heapsize=len;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=len;i&gt;=<span class="number">2</span>;i--)</span><br><span class="line">    &#123;</span><br><span class="line">        swap(&amp;A[<span class="number">1</span>],&amp;A[i]);</span><br><span class="line">        heapsize-=<span class="number">1</span>;</span><br><span class="line">        max_heapify(A,heapsize,<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//4.最大优先队列,去除最大元素:</span></span><br><span class="line"><span class="comment">//时间复杂度:O(logn)</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">heap_extract_max</span><span class="params">(<span class="type">int</span> *A,<span class="type">int</span> *heapsize)</span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(*heapsize&lt;<span class="number">1</span>) <span class="keyword">return</span> <span class="number">-1</span>;       <span class="comment">//无效</span></span><br><span class="line">    <span class="type">int</span> max=A[<span class="number">1</span>];</span><br><span class="line">    A[<span class="number">1</span>]=A[*heapsize];</span><br><span class="line">    (*heapsize)--;</span><br><span class="line">    max_heapify(A,*heapsize,<span class="number">1</span>);</span><br><span class="line">    <span class="keyword">return</span> max;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//5.最大堆元素值增加后,调整最大堆</span></span><br><span class="line"><span class="comment">//时间复杂度:O(lgn)</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">heap_increase_key</span><span class="params">(<span class="type">int</span> *A,<span class="type">int</span> i,<span class="type">int</span> key)</span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(A[i]&gt;key) <span class="keyword">return</span>;</span><br><span class="line">    A[i]=key;</span><br><span class="line">    <span class="keyword">while</span>(i&gt;<span class="number">1</span>&amp;&amp;A[i/<span class="number">2</span>]&lt;A[i])</span><br><span class="line">    &#123;</span><br><span class="line">        swap(&amp;A[i/<span class="number">2</span>],&amp;A[i]);    <span class="comment">//上浮:与父节点交换</span></span><br><span class="line">        i=i/<span class="number">2</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//6.最大堆插入元素</span></span><br><span class="line"><span class="comment">//时间复杂度:O(lgn)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> INFINITY -10000</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">maxHeap_insert</span><span class="params">(<span class="type">int</span> *A,<span class="type">int</span> key,<span class="type">int</span> *heapsize)</span>&#123;</span><br><span class="line">    (*heapsize)++;</span><br><span class="line">    A[*heapsize]=INFINITY;</span><br><span class="line">    heap_increase_key(A,*heapsize,key);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> A[<span class="number">100005</span>];</span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">int</span> n,op,x,heapsize=<span class="number">0</span>;<span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>,&amp;n);</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;n;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>,&amp;op);</span><br><span class="line">        <span class="keyword">if</span>(op==<span class="number">1</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>,&amp;x);</span><br><span class="line">            maxHeap_insert(A,x,&amp;heapsize);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span>(op==<span class="number">2</span>) heap_extract_max(A,&amp;heapsize);</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span>(op==<span class="number">3</span>) <span class="built_in">printf</span>(<span class="string">&quot;%d\n&quot;</span>,A[<span class="number">1</span>]);</span><br><span class="line">    &#125;</span><br><span class="line">    qsort(&amp;A[<span class="number">1</span>],heapsize,<span class="keyword">sizeof</span>(<span class="type">int</span>),cmp);</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=heapsize;i++) <span class="built_in">printf</span>(<span class="string">&quot;%d &quot;</span>,A[i]);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure> ###2.C++实现:最大优先队列 最大优先队列:队首为最大元素 <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;queue&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;functional&gt;</span></span></span><br><span class="line">using namespace <span class="built_in">std</span>;</span><br><span class="line"><span class="comment">//最大优先队列(底层实现:heap)</span></span><br><span class="line"><span class="built_in">priority_queue</span>&lt;<span class="type">int</span>&gt;p;</span><br><span class="line"><span class="built_in">priority_queue</span>&lt;<span class="type">int</span>,<span class="built_in">vector</span>&lt;<span class="type">int</span>&gt;,less&lt;<span class="type">int</span>&gt;&gt;p;</span><br><span class="line"><span class="comment">//最小优先队列</span></span><br><span class="line"><span class="built_in">priority_queue</span>&lt;<span class="type">int</span>,<span class="built_in">vector</span>&lt;<span class="type">int</span>&gt;,greater&lt;<span class="type">int</span>&gt;&gt;q;</span><br><span class="line"><span class="comment">//成员函数:</span></span><br><span class="line">p.push(<span class="number">1</span>);          <span class="comment">//插入元素</span></span><br><span class="line"><span class="built_in">cout</span>&lt;&lt;p.top();      <span class="comment">//访问队首元素</span></span><br><span class="line">p.pop();            <span class="comment">//移除队首元素</span></span><br><span class="line"><span class="keyword">if</span>(p.empty())       <span class="comment">//检查是否为空</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//自定义比较函数:例--比较年龄</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Person</span>&#123;</span></span><br><span class="line">    <span class="built_in">string</span> name;</span><br><span class="line">    <span class="type">int</span> age;</span><br><span class="line">    Person(<span class="type">const</span> <span class="built_in">string</span> &amp;n,<span class="type">int</span> a):name(n),age(a)&#123;&#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">compareByAge</span>&#123;</span></span><br><span class="line"><span class="type">bool</span> <span class="title function_">operator</span><span class="params">()</span><span class="params">(<span class="type">const</span> Person&amp; p1,<span class="type">const</span> Person&amp; p2)</span><span class="type">const</span>&#123;</span><br><span class="line">    <span class="keyword">return</span> p1.age&gt;p2.age;       <span class="comment">//按年龄从小到大排序</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="built_in">priority_queue</span>&lt;Person,<span class="built_in">vector</span>&lt;Person&gt;,compareByAge&gt;q;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="快速排序">快速排序</h2><h3 id="性能分析">性能分析</h3><p>最坏划分：两子问题分别包括0和n-1个元素:T(n)=T(n-1)+θ(n),得T(n)=θ(n^2).最好划分：T(n)=2<em>T(n/2)+θ(n),得T(n)=θ(n</em>lgn).平衡划分:常数比例的划分,递归树深度为θ(lgn),每层工作量为O(n).总运行时间O(n<em>lgn).使用RANDOMIZED-PARTITION,在输入元素互异时,快排的期望运行时间为O(n</em>lgn).</p><h3 id="c语言实现">C语言实现</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//写法一:</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">quickSort</span><span class="params">(<span class="type">int</span> <span class="built_in">list</span>[],<span class="type">int</span> left,<span class="type">int</span> right,<span class="type">int</span> *cnt)</span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(left&gt;=right) <span class="keyword">return</span>;</span><br><span class="line">    <span class="type">int</span> last=left;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=left+<span class="number">1</span>;i&lt;=right;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        (*cnt)++;</span><br><span class="line">        <span class="keyword">if</span>(<span class="built_in">list</span>[i]&lt;<span class="built_in">list</span>[left]) swap(&amp;<span class="built_in">list</span>[++last],&amp;<span class="built_in">list</span>[i]);  <span class="comment">//list[left]作为基准值：将小于基准值的元素，换至last以前</span></span><br><span class="line">    &#125;</span><br><span class="line">    swap(&amp;<span class="built_in">list</span>[left],&amp;<span class="built_in">list</span>[last]);</span><br><span class="line">    quickSort(<span class="built_in">list</span>,left,last<span class="number">-1</span>,cnt);</span><br><span class="line">    quickSort(<span class="built_in">list</span>,last+<span class="number">1</span>,right,cnt);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//写法二:</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">partition</span><span class="params">(<span class="type">int</span> *A,<span class="type">int</span> p,<span class="type">int</span> r)</span>&#123;</span><br><span class="line">    <span class="type">int</span> x=A[r];     <span class="comment">//主元</span></span><br><span class="line">    <span class="type">int</span> i=p<span class="number">-1</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> j=p;j&lt;=r<span class="number">-1</span>;j++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span>(A[j]&lt;=x)</span><br><span class="line">        &#123;</span><br><span class="line">            i=i+<span class="number">1</span>;</span><br><span class="line">            swap(&amp;A[i],&amp;A[j]);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    swap(&amp;A[i+<span class="number">1</span>],&amp;A[r]);</span><br><span class="line">    <span class="keyword">return</span> i+<span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">Randomized_Partition</span><span class="params">(<span class="type">int</span> *A,<span class="type">int</span> p,<span class="type">int</span> r)</span>&#123;</span><br><span class="line">    <span class="type">int</span> i=p+rand()%(r-p);</span><br><span class="line">    swap(&amp;A[i],&amp;A[r]);</span><br><span class="line">    <span class="keyword">return</span> partition(A,p,r);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">quicksort</span><span class="params">(<span class="type">int</span> *A,<span class="type">int</span> p,<span class="type">int</span> r)</span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(p&lt;r)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">int</span> q=Randomized_Partition(A,p,r);</span><br><span class="line">        quicksort(A,p,q<span class="number">-1</span>);</span><br><span class="line">        quicksort(A,q+<span class="number">1</span>,r);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="求顺序统计量">求顺序统计量</h3><p>求A[p,r]中第i小的元素--期望时间:θ(n);最坏时间:θ(n^2).<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="type">void</span> <span class="title function_">swap</span><span class="params">(<span class="type">int</span> *a,<span class="type">int</span> *b)</span>&#123;</span><br><span class="line">    <span class="type">int</span> tmp=*a;</span><br><span class="line">    *a=*b;</span><br><span class="line">    *b=tmp;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">int</span> <span class="title function_">partition</span><span class="params">(<span class="type">int</span> *A,<span class="type">int</span> p,<span class="type">int</span> r)</span>&#123;</span><br><span class="line">    <span class="type">int</span> x=A[r];     <span class="comment">//主元</span></span><br><span class="line">    <span class="type">int</span> i=p<span class="number">-1</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> j=p;j&lt;=r<span class="number">-1</span>;j++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span>(A[j]&lt;=x)</span><br><span class="line">        &#123;</span><br><span class="line">            i=i+<span class="number">1</span>;</span><br><span class="line">            swap(&amp;A[i],&amp;A[j]);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    swap(&amp;A[i+<span class="number">1</span>],&amp;A[r]);</span><br><span class="line">    <span class="keyword">return</span> i+<span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">int</span> <span class="title function_">Randomized_Partition</span><span class="params">(<span class="type">int</span> *A,<span class="type">int</span> p,<span class="type">int</span> r)</span>&#123;</span><br><span class="line">    <span class="type">int</span> i=p+rand()%(r-p);           <span class="comment">//rand()返回0~32767间的随机数</span></span><br><span class="line">    swap(&amp;A[i],&amp;A[r]);</span><br><span class="line">    <span class="keyword">return</span> partition(A,p,r);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//A[p...r]中,找第i小的元素</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">Randomized_Select</span><span class="params">(<span class="type">int</span> *A,<span class="type">int</span> p,<span class="type">int</span> r,<span class="type">int</span> i)</span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(p==r) <span class="keyword">return</span> A[p];</span><br><span class="line">    <span class="type">int</span> q=Randomized_Partition(A,p,r);</span><br><span class="line">    <span class="comment">//int q= partition(A,p,r);</span></span><br><span class="line">    <span class="type">int</span> k=q-p+<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">if</span>(i==k) <span class="keyword">return</span> A[q];</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span>(i&lt;k) <span class="keyword">return</span> Randomized_Select(A,p,q<span class="number">-1</span>,i);</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">return</span> Randomized_Select(A,q+<span class="number">1</span>,r,i-k);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">int</span> A[<span class="number">10</span>]=&#123;<span class="number">0</span>,<span class="number">9</span>,<span class="number">4</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">5</span>,<span class="number">7</span>,<span class="number">6</span>,<span class="number">8</span>&#125;;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=<span class="number">10</span>;i++) <span class="built_in">printf</span>(<span class="string">&quot;%d &quot;</span>,Randomized_Select(A,<span class="number">0</span>,<span class="number">9</span>,i));</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="线性时间排序">线性时间排序</h2><h3 id="比较排序算法">1.比较排序算法</h3><pre><code>O(n*lgn)时间内排序n个数:    归并排序,堆排序--最坏情况达到θ(n*lgn);    快速排序--平均情况达到θ(n*lgn).</code></pre><p>排序算法下界:最坏情况下，任何比较排序算法都需要<a href="n*lgn">欧姆</a>次比较.推论:堆排序,归并排序都是渐近最优的比较排序算法.</p><h3 id="计数排序">2.计数排序</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//计数排序:n个元素为0~k之间的整数,当k=O(n)时,排序时间为O(n).</span></span><br><span class="line"><span class="comment">//A为原数组,B存放排序输出,C进行计数</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">countSort</span><span class="params">(<span class="type">int</span> *A,<span class="type">int</span> *B,<span class="type">int</span> n,<span class="type">int</span> k)</span>&#123;</span><br><span class="line">    <span class="type">int</span> *C=(<span class="type">int</span> *)<span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="type">int</span>)*(k+<span class="number">1</span>));</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;=k;i++) C[i]=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">0</span>;j&lt;n;j++) C[A[j]]+=<span class="number">1</span>;        <span class="comment">//C[i]记录等于i的元素个数</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=k;i++) C[i]=C[i]+C[i<span class="number">-1</span>]; <span class="comment">//C[i]记录小于等于i的元素个数</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> j=n<span class="number">-1</span>;j&gt;=<span class="number">0</span>;j--)</span><br><span class="line">    &#123;</span><br><span class="line">        B[C[A[j]]]=A[j];    <span class="comment">//C[A[j]]中为小于等于A[j]的元素个数,这些元素储存在下标0~C[A[j]]-1的位置</span></span><br><span class="line">        C[A[j]]--;          <span class="comment">//元素不完全互异时,将下一个等于A[j]的元素,置于A[j]前一个位置上</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="滑动窗口">滑动窗口</h2><pre><code>例:求序列的所有长度为k的连续子序列中,最大的数字种类数.</code></pre><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">const</span> <span class="type">int</span> N=<span class="number">1e5</span>+<span class="number">5</span>;</span><br><span class="line"><span class="type">int</span> n,k,cnt,ans,a[N];</span><br><span class="line"><span class="type">void</span> <span class="title function_">solve</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="built_in">cin</span>&gt;&gt;n&gt;&gt;k;</span><br><span class="line">    <span class="built_in">set</span>&lt;<span class="type">int</span>&gt; s;</span><br><span class="line">    <span class="built_in">map</span>&lt;<span class="type">int</span>,<span class="type">int</span>&gt; m;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=n;i++)&#123;</span><br><span class="line">        <span class="built_in">cin</span>&gt;&gt;a[i];</span><br><span class="line">        s.insert(a[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>((<span class="type">int</span>)s.size!=k) &#123;<span class="built_in">cout</span>&lt;&lt;<span class="string">&quot;-1&quot;</span>&lt;&lt;<span class="built_in">endl</span>;<span class="keyword">return</span>;&#125;</span><br><span class="line">    ans=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=n;i++)&#123;</span><br><span class="line">        m[a[i]]++;</span><br><span class="line">        <span class="keyword">if</span>(i&gt;k)</span><br><span class="line">        &#123;</span><br><span class="line">            m[a[i-k]]--;</span><br><span class="line">            <span class="keyword">if</span>(m[a[i-k]]==<span class="number">0</span>) m.erase(a[i-k]);</span><br><span class="line">        &#125;</span><br><span class="line">        ans=max(ans,(<span class="type">int</span>)m.size());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="动态规划">动态规划:</h2><p>1.最优子结构：可由子问题最优解，构造原问题的最优解。（子问题无关，不共享资源，结果互不影响）2.重叠子问题：反复求解相同的子问题，将解存入备忘录中。（分治：每一步生成全新的子问题） ###1.钢管切割：总长度固定，不同长度不同售价 r[n]=max(p[i]+r[n-i]).i=1~n.C语言实现:θ(n^2) <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> max(a,b) a&gt;b?a:b</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> INFINITY -2147483648</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">print_cut_rod_solution</span><span class="params">(<span class="type">int</span> *p,<span class="type">int</span> n,<span class="type">int</span> *s)</span>&#123;       <span class="comment">//打印长度为n的最优切割方案</span></span><br><span class="line">    <span class="keyword">while</span>(n&gt;<span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%d &quot;</span>,s[n]);</span><br><span class="line">        n-=s[n];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">    <span class="comment">//3.自底向上递归:θ(n^2)</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">bottom_up_cut_rod</span><span class="params">(<span class="type">int</span> *p,<span class="type">int</span> n)</span>&#123;</span><br><span class="line">    <span class="type">int</span> *r=(<span class="type">int</span> *)<span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="type">int</span>)*(n+<span class="number">1</span>));    <span class="comment">//辅助数组,r记录最大利润</span></span><br><span class="line">    <span class="type">int</span> *s=(<span class="type">int</span> *)<span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="type">int</span>)*(n+<span class="number">1</span>));    <span class="comment">//s记录切割方案</span></span><br><span class="line">    r[<span class="number">0</span>]=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">1</span>;j&lt;=n;j++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">int</span> q=INFINITY;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=j;i++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">if</span>(q&lt;p[i]+r[j-i])</span><br><span class="line">            &#123;</span><br><span class="line">                q=p[i]+r[j-i];</span><br><span class="line">                s[j]=i;     <span class="comment">//s[j]:规模为j的子问题中,第一段钢条的最优切割长度</span></span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//q=max(q,p[i]+r[j-i]);</span></span><br><span class="line">        &#125;</span><br><span class="line">        r[j]=q;</span><br><span class="line">    &#125;</span><br><span class="line">    print_cut_rod_solution(p,n,s);</span><br><span class="line">    <span class="keyword">return</span> r[n];        <span class="comment">//最大总利润</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">long</span> <span class="type">long</span> p[<span class="number">10005</span>];     <span class="comment">//p[i]:长度为i的钢管价格</span></span><br><span class="line">    <span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">int</span> n;<span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>,&amp;n);</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=n;i++) <span class="built_in">scanf</span>(<span class="string">&quot;%lld&quot;</span>,&amp;p[i]);</span><br><span class="line">    bottom_up_cut_rod(p,n);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure> #### 变式：每次切割固定成本c<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">modify_cut_rod</span><span class="params">(<span class="type">int</span> *p,<span class="type">int</span> n,<span class="type">int</span> c)</span>&#123;</span><br><span class="line">    <span class="type">int</span> *r=(<span class="type">int</span> *)<span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="type">int</span>)*(n+<span class="number">1</span>));</span><br><span class="line">    r[<span class="number">0</span>]=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">1</span>;j&lt;=n;j++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">int</span> q=p[j];         <span class="comment">//不切割,长度j整段出售</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=j<span class="number">-1</span>;i++) q=max(q,p[i]+r[j-i]-c);</span><br><span class="line">        r[j]=q;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> r[n];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure> ###2.矩阵链乘法:求完全括号化方案，使得计算A1A2...An所需标量乘法次数最少.括号化方案数量:卡特兰数 设:矩阵Ai的大小为：p[i-1]xp[i].m[i,j]=min(m[i,k]+m[k+1,j]+p[i-1]<em>p[k]</em>p[j]),i&lt;j. ####(1)自底向上 <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//1.自底向上</span></span><br><span class="line"><span class="comment">//p=&lt;p0,...,pn&gt;.</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> N 100</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> INFINITY_2 2147483647</span></span><br><span class="line"><span class="type">int</span> m[N][N],s[N][N];     <span class="comment">//m记录Ai...Aj结果,s[i][j]记录m[i][j]对应最优分割点k</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">matrix_chain_order</span><span class="params">(<span class="type">int</span> *p,<span class="type">int</span> n)</span>&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> l=<span class="number">2</span>;l&lt;=n;l++)       <span class="comment">//长度</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=n-l+<span class="number">1</span>;i++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="type">int</span> j=n-l+<span class="number">1</span>;    <span class="comment">//保持i~j长度为l</span></span><br><span class="line">            m[i][j]=INFINITY_2;</span><br><span class="line">            <span class="keyword">for</span>(<span class="type">int</span> k=i;k&lt;=j<span class="number">-1</span>;k++)</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="type">int</span> q=m[i][k]+m[k+<span class="number">1</span>][j]+p[i<span class="number">-1</span>]*p[k]*p[j];</span><br><span class="line">                <span class="keyword">if</span>(q&lt;m[i][j])</span><br><span class="line">                &#123;</span><br><span class="line">                    m[i][j]=q;</span><br><span class="line">                    s[i][j]=k;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> m[<span class="number">1</span>][n];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure> #### (2)带备忘的自顶向下 <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">lookup_chain</span><span class="params">(<span class="type">int</span> *p,<span class="type">int</span> i,<span class="type">int</span> j)</span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(m[i][j]&lt;INFINITY_2) <span class="keyword">return</span> m[i][j];      <span class="comment">//查询是否记录</span></span><br><span class="line">    <span class="keyword">if</span>(i==j) m[i][j]=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> k=i;k&lt;=j<span class="number">-1</span>;k++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="type">int</span> q=lookup_chain(p,i,k)+lookup_chain(p,k+<span class="number">1</span>,j)+p[i<span class="number">-1</span>]*p[k]*p[j];</span><br><span class="line">            <span class="keyword">if</span>(q&lt;m[i][j]) m[i][j]=q;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> m[i][j];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">memorized_matrix_chain</span><span class="params">(<span class="type">int</span> *p,<span class="type">int</span> n)</span>&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=n;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j=i;j&lt;=n;j++) m[i][j]=INFINITY_2;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> lookup_chain(p,<span class="number">1</span>,n);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure> ####构造最优解： <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//s[i][j]记录m[i][j]对应最优分割点k</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">print_optimal_parens</span><span class="params">(<span class="type">int</span> **s,<span class="type">int</span> i,<span class="type">int</span> j)</span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(i==j) &#123;<span class="built_in">printf</span>(<span class="string">&quot;A%d&quot;</span>,i);<span class="keyword">return</span>;&#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;(&quot;</span>);</span><br><span class="line">    print_optimal_parens(s,i,s[i][j]);</span><br><span class="line">    print_optimal_parens(s,s[i][j]+<span class="number">1</span>,j);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;)&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h3 id="流水线调度">3.流水线调度</h3><p>dp[i][j]:在流水线上完成第j个步骤时的最小时间。 for(intk=0;k&lt;3;k++) dp[i][j] =min(dp[i][j],(j&gt;=1?dp[k][j-1]+t[k][i]:0LL)+p[i][j]); <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line">using namespace <span class="built_in">std</span>;</span><br><span class="line"><span class="meta">#<span class="keyword">define</span> MAXN 12</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> MAXM 22</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="type">long</span> <span class="type">long</span> ll;</span><br><span class="line"><span class="type">const</span> ll inf = <span class="number">1e18</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> a[MAXN][MAXM], t[MAXN][MAXN];</span><br><span class="line"><span class="comment">//a[i][j]:流水线i处理j的时间; t[i][j]:流水线i-&gt;j的转移时间.</span></span><br><span class="line">ll dp[MAXN][MAXM],nxt[MAXN][MAXM]; <span class="comment">//dp[i][j]:在流水线i上完成j时的最小时间.</span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    ios::sync_with_stdio(<span class="literal">false</span>);</span><br><span class="line">    <span class="built_in">cin</span>.tie(<span class="number">0</span>);</span><br><span class="line">    <span class="type">int</span> tt;</span><br><span class="line">    <span class="built_in">cin</span> &gt;&gt; tt;</span><br><span class="line">    <span class="keyword">while</span> (tt--) &#123;</span><br><span class="line">        <span class="type">int</span> m,n;<span class="built_in">cin</span>&gt;&gt;m&gt;&gt;n;      <span class="comment">//n条流水线,m个步骤</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">1</span>; i &lt;= n; i++)</span><br><span class="line">            <span class="keyword">for</span>(<span class="type">int</span> j = <span class="number">1</span>; j &lt;= m; j++) <span class="built_in">cin</span> &gt;&gt; a[i][j];</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">1</span>; i &lt;= n; i++)</span><br><span class="line">            <span class="keyword">for</span>(<span class="type">int</span> j = <span class="number">1</span>; j &lt;= n; j++) <span class="built_in">cin</span> &gt;&gt; t[i][j];</span><br><span class="line">        <span class="comment">//for(int i = 1; i &lt;= n; i++) dp[i][m] = a[i][m];</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = m; j &gt;= <span class="number">1</span>; j--)    <span class="comment">//逆推:从终点出发,0开始计时,前往起点</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= n; i++)</span><br><span class="line">            &#123;</span><br><span class="line">                dp[i][j] = inf;             <span class="comment">//当前在第i条流水线完成j</span></span><br><span class="line">                <span class="keyword">for</span> (<span class="type">int</span> k = <span class="number">1</span>; k &lt;= n; k++)        <span class="comment">//遍历：在第k条流水线完成j+1.</span></span><br><span class="line">                &#123;</span><br><span class="line">                    ll p=(j&lt;=m<span class="number">-1</span>?dp[k][j+<span class="number">1</span>]+t[i][k]:<span class="number">0LL</span>)+a[i][j];</span><br><span class="line">                    <span class="keyword">if</span> (p &lt; dp[i][j])</span><br><span class="line">                    &#123;</span><br><span class="line">                        dp[i][j] = p;</span><br><span class="line">                        nxt[i][j] = k;      <span class="comment">//第i条上完成j后,下一步转移至第k条最佳.</span></span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        ll ans=dp[<span class="number">1</span>][<span class="number">1</span>],cur=<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=n;i++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">if</span>(ans&gt;dp[i][<span class="number">1</span>]) &#123;ans=dp[i][<span class="number">1</span>];cur=i;&#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">cout</span>&lt;&lt;ans&lt;&lt;<span class="string">&quot;\n&quot;</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=m;i++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="built_in">cout</span>&lt;&lt;<span class="string">&quot;Station&quot;</span>&lt;&lt;i&lt;&lt;<span class="string">&quot;: Line&quot;</span>&lt;&lt;cur&lt;&lt;<span class="string">&quot;\n&quot;</span>;</span><br><span class="line">            cur = nxt[cur][i];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>### 4.OBST(最优二叉搜索树）--区间dp关键字的升序序列：K=&lt;k1,...,kn&gt;,有：k1&lt;...&lt;kn.--概率pi.(内部节点)n+1个伪关键字：d0,...,dn.有：ki&lt;di&lt;k(i+1).--概率qi.(叶节点)有:sum(pi)+sum(qi)=1.搜索代价：E=sum[(depth(ki)+1)*pi]+sum[(depth(di)+1)*qi]=1+sum[depth(ki)*pi]+sum[depth(di)*qi].</p><p>设:e[i,j]表示:在包含关键字ki,...,kj的OBST中搜索一次的期望代价.w[i,j]表示:包含关键字ki,...,kj的子树,概率之和:w[i,j]=sum(pl)(l=i<sub>j)+sum(ql)(l=i-1</sub>j).root[i,j]表示包含关键字ki,...,kj的子树的根.</p><p>递归公式:e[i,j]=q[i-1] if j==i-1.=min{e[i,r-1]+e[r+1,j]+w(i,j)}(i&lt;=r&lt;=j) if i&lt;=j.</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> inf 2147483647</span></span><br><span class="line"><span class="type">int</span> e[MAXN+<span class="number">1</span>][MAXN+<span class="number">1</span>],w[MAXN+<span class="number">1</span>][MAXN+<span class="number">1</span>],root[MAXN+<span class="number">1</span>][MAXN+<span class="number">1</span>];</span><br><span class="line"><span class="comment">//e[1...n+1,0...n],w[1...n+1,0...n],root</span></span><br><span class="line"><span class="comment">//(p1,...,pn),(q0,...,qn)为概率,规模n.</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">OBST</span><span class="params">(<span class="type">int</span> *p,<span class="type">int</span> *q,<span class="type">int</span> n)</span>&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=n+<span class="number">1</span>;i++) &#123;e[i][i<span class="number">-1</span>]=w[i][i<span class="number">-1</span>]=q[i<span class="number">-1</span>];&#125;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> l=<span class="number">1</span>;l&lt;=n;l++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=n-l+<span class="number">1</span>;i++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="type">int</span> j=i+l<span class="number">-1</span>;e[i][j]=inf;</span><br><span class="line">            w[i][j]=w[i][j<span class="number">-1</span>]+p[j]+q[j];</span><br><span class="line">            <span class="keyword">for</span>(<span class="type">int</span> r=i;r&lt;=j;r++)</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="type">int</span> t=e[i][r<span class="number">-1</span>]+e[r+<span class="number">1</span>][j]+w[i][j];</span><br><span class="line">                <span class="keyword">if</span>(t&lt;e[i][j])&#123;e[i][j]=t;root[i][j]=r;&#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="最长公共子序列lcs--on2">5.最长公共子序列(LCS)--O(n^2)</h3><p>c[i][j]=0. if i==0||j==0. c[i-1][j-1]+1. ifi,j&gt;0&amp;&amp;x[i]=y[j]. max(c[i][j-1],c[i-1][j]). ifi,j&gt;0&amp;&amp;x[i]!=y[j].</p><p>θ(mn)个子问题. <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//c[i,j]记录:Xi,Yj的LCS长度.</span></span><br><span class="line"><span class="comment">//可按行主次序计算:先从左至右i第一行,再第二行...</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> max_M 100</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> max_N 100</span></span><br><span class="line"><span class="type">int</span> c[max_M+<span class="number">1</span>][max_N+<span class="number">1</span>],b[max_M][max_N],a[max_M+<span class="number">1</span>][max_N+<span class="number">1</span>];</span><br><span class="line">    <span class="comment">//a[i][j]记录:Xi,Yj的最长公共子串长度(字符连续).</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">print_LCS</span><span class="params">(<span class="type">char</span> *X,<span class="type">int</span> i,<span class="type">int</span> j)</span>&#123;        <span class="comment">//时间复杂度:O(m+n).</span></span><br><span class="line">    <span class="keyword">if</span>(i==<span class="number">0</span>||j==<span class="number">0</span>) <span class="keyword">return</span>;</span><br><span class="line">    <span class="keyword">if</span>(b[i][j]==<span class="number">-1</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        print_LCS(X,i<span class="number">-1</span>,j<span class="number">-1</span>);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%c&quot;</span>,X[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span>(b[i][j]==<span class="number">0</span>) print_LCS(X,i<span class="number">-1</span>,j);</span><br><span class="line">    <span class="keyword">else</span> print_LCS(X,i,j<span class="number">-1</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//空间复杂度:θ(mn).</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">LCS_length</span><span class="params">(<span class="type">char</span> *X,<span class="type">char</span> *Y,<span class="type">int</span> m,<span class="type">int</span> n)</span>&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=m;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">1</span>;j&lt;=n;j++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">if</span>(X[i]==Y[j])</span><br><span class="line">            &#123;</span><br><span class="line">                c[i][j]=c[i<span class="number">-1</span>][j<span class="number">-1</span>]+<span class="number">1</span>;b[i][j]=<span class="number">-1</span>;   <span class="comment">//LCS</span></span><br><span class="line">                a[i][j]=a[i<span class="number">-1</span>][j<span class="number">-1</span>]+<span class="number">1</span>;          <span class="comment">//最长公共子串</span></span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span>(c[i<span class="number">-1</span>][j]&gt;=c[i][j<span class="number">-1</span>])</span><br><span class="line">            &#123;</span><br><span class="line">                c[i][j]=c[i<span class="number">-1</span>][j];b[i][j]=<span class="number">0</span>;        <span class="comment">//LCS</span></span><br><span class="line">                a[i][j]=<span class="number">0</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">            &#123;</span><br><span class="line">                c[i][j]=c[i][j<span class="number">-1</span>];b[i][j]=<span class="number">1</span>;        <span class="comment">//LCS</span></span><br><span class="line">                a[i][j]=<span class="number">0</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    print_LCS(X,m,n);</span><br><span class="line">    <span class="keyword">return</span> c[m][n];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">char</span> A[<span class="number">2005</span>],B[<span class="number">2005</span>],C[<span class="number">2005</span>],D[<span class="number">2005</span>];</span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">int</span> T;<span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>,&amp;T);getchar();</span><br><span class="line">    <span class="keyword">while</span>(T--)&#123;</span><br><span class="line">        <span class="built_in">memset</span>(A,<span class="string">&#x27;\0&#x27;</span>,<span class="keyword">sizeof</span>(<span class="type">char</span>)*<span class="number">2005</span>);</span><br><span class="line">        <span class="built_in">memset</span>(B,<span class="string">&#x27;\0&#x27;</span>,<span class="keyword">sizeof</span>(<span class="type">char</span>)*<span class="number">2005</span>);</span><br><span class="line">        <span class="built_in">memset</span>(C,<span class="string">&#x27;\0&#x27;</span>,<span class="keyword">sizeof</span>(<span class="type">char</span>)*<span class="number">2005</span>);</span><br><span class="line">        <span class="built_in">memset</span>(D,<span class="string">&#x27;\0&#x27;</span>,<span class="keyword">sizeof</span>(<span class="type">char</span>)*<span class="number">2005</span>);</span><br><span class="line">        <span class="built_in">memset</span>(c,<span class="number">0</span>,<span class="keyword">sizeof</span>(<span class="type">int</span>)*<span class="number">2006</span>*<span class="number">2006</span>);</span><br><span class="line">        <span class="built_in">memset</span>(b,<span class="number">0</span>,<span class="keyword">sizeof</span>(<span class="type">int</span>)*<span class="number">2006</span>*<span class="number">2006</span>);</span><br><span class="line">        ans1=<span class="number">0</span>;ans2=<span class="number">0</span>;</span><br><span class="line">        </span><br><span class="line">        fgets(A,<span class="number">2003</span>,<span class="built_in">stdin</span>);</span><br><span class="line">        fgets(B,<span class="number">2003</span>,<span class="built_in">stdin</span>);</span><br><span class="line">        <span class="type">int</span> lenA=<span class="built_in">strlen</span>(A),lenB=<span class="built_in">strlen</span>(B);</span><br><span class="line">        <span class="keyword">if</span>(A[lenA<span class="number">-1</span>]==<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            A[lenA<span class="number">-1</span>]=<span class="string">&#x27;\0&#x27;</span>;</span><br><span class="line">            lenA--;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(B[lenB<span class="number">-1</span>]==<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            B[lenB<span class="number">-1</span>]=<span class="string">&#x27;\0&#x27;</span>;</span><br><span class="line">            lenB--;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">strcpy</span>(&amp;C[<span class="number">1</span>],A);<span class="built_in">strcpy</span>(&amp;D[<span class="number">1</span>],B);</span><br><span class="line">        <span class="comment">//printf(&quot;%d %d\n&quot;,lenA,lenB);</span></span><br><span class="line">        LCS_length(C,D,lenA,lenB);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%d %d\n&quot;</span>,ans2,ans1);</span><br><span class="line">    &#125;</span><br><span class="line">    ans1=c[m][n];</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=m;i++)&#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">1</span>;j&lt;=n;j++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(a[i][j]&gt;ans2) ans2=a[i][j];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure> ### 6.最长上升子序列(LIS)--O(n*logn)<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//时间复杂度:O(n*logn);空间复杂度:O(n).</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">LIS</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="type">int</span>&gt; &amp;nums)</span>&#123;</span><br><span class="line">    <span class="type">int</span> len=<span class="number">1</span>,n=(<span class="type">int</span>)nums.size();</span><br><span class="line">    <span class="keyword">if</span>(n==<span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="type">int</span>&gt; <span class="title function_">d</span><span class="params">(n+<span class="number">1</span>,<span class="number">0</span>)</span>;   <span class="comment">//d[i]:长度为i的LIS的末尾元素最小值</span></span><br><span class="line">    d[len]=nums[<span class="number">0</span>];</span><br><span class="line">    <span class="comment">//初始len=1,d[1]=nums[0].</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;n;i++)            <span class="comment">//将nums[i]加在序列末尾</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span>(nums[i]&gt;d[len]) d[++len]=nums[i];</span><br><span class="line">        <span class="keyword">else</span>&#123;</span><br><span class="line">            <span class="type">int</span> l=<span class="number">1</span>,r=len,pos=<span class="number">0</span>;</span><br><span class="line">            <span class="comment">//在d数组中二分查找,找到第一个(最大的)比nums[i]小的数d[k],更新:d[k+1]=nums[i].</span></span><br><span class="line">            <span class="keyword">while</span>(l&lt;=r)</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="type">int</span> mid=(l+r)&gt;&gt;<span class="number">1</span>;</span><br><span class="line">                <span class="keyword">if</span>(d[mid]&lt;nums[i]) &#123;pos=mid;l=mid+<span class="number">1</span>;&#125;</span><br><span class="line">                <span class="keyword">else</span> r=mid<span class="number">-1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            d[pos+<span class="number">1</span>]=nums[i];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> len;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure> 拓展：最长公共上升子序列 思路：f[i][j]表示:所有a[1 ~i]和b[1 ~ j]中以b[j]结尾的公共上升子序列的集合. <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= m; ++ i) &#123;</span><br><span class="line">        <span class="type">int</span> maxv = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">1</span>; j &lt;= n; ++ j) &#123;</span><br><span class="line">            f[i][j] = f[i - <span class="number">1</span>][j];</span><br><span class="line">            <span class="keyword">if</span> (a[i] == b[j]) f[i][j] = max(f[i][j], maxv);</span><br><span class="line">            <span class="keyword">if</span> (a[i] &gt; b[j]) maxv = max(maxv, f[i - <span class="number">1</span>][j] + <span class="number">1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">int</span> ans = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= n; ++ i) ans = max(f[n][i], ans);</span><br></pre></td></tr></table></figure></p><h3 id="背包问题">7.背包问题</h3><h4 id="背包一种物品使用一次">(1)0-1背包:一种物品使用一次</h4><p>压缩为一维:f[j]表示:背包容量不超过j时的最大价值. <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;bits/stdc++.h&gt;</span></span></span><br><span class="line">using namespace <span class="built_in">std</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> N=<span class="number">1005</span>;</span><br><span class="line"><span class="type">int</span> f[N],v[N],w[N]; <span class="comment">//w[i]是价值，v[i]是体积</span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> n,m;</span><br><span class="line">    <span class="built_in">cin</span>&gt;&gt;n&gt;&gt;m; <span class="comment">//n件物品和体积限制m</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=n;i++) <span class="built_in">cin</span>&gt;&gt;v[i]&gt;&gt;w[i];</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=n;i++)</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j=m;j&gt;=v[i];j--)              <span class="comment">//滚动数组,倒序优化</span></span><br><span class="line">            f[j] = max(f[j],f[j-v[i]]+w[i]); </span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;f[m]&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//二维动态规划</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span>&#123;</span></span><br><span class="line">    <span class="type">int</span> val;</span><br><span class="line">    <span class="type">int</span> weight;</span><br><span class="line">&#125;goods;</span><br><span class="line"><span class="meta">#<span class="keyword">define</span> N 1005</span></span><br><span class="line"><span class="comment">//#define max(a,b) a&gt;b?a:b</span></span><br><span class="line">goods all[N+<span class="number">1</span>];     <span class="comment">//all[1...n]记录商品</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">max</span><span class="params">(<span class="type">int</span> a,<span class="type">int</span> b)</span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(a&gt;b) <span class="keyword">return</span> a;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">return</span> b;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">Knapsack</span><span class="params">(<span class="type">int</span> n,<span class="type">int</span> W)</span>&#123;        <span class="comment">//n为商品数量,W为背包承载量</span></span><br><span class="line">    <span class="type">int</span> **K=(<span class="type">int</span> **)<span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="type">int</span> *)*(n+<span class="number">1</span>));</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;=n;i++) K[i]=(<span class="type">int</span> *)<span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="type">int</span>)*(W+<span class="number">1</span>));</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//K[i][j]表示:承载量为j的背包,装前i件物品,所得最大价值</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=n;i++) K[i][<span class="number">0</span>]=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">1</span>;j&lt;=W;j++) K[<span class="number">0</span>][j]=<span class="number">0</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=n;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">1</span>;j&lt;=W;j++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="comment">//是否将第i件商品装入背包</span></span><br><span class="line">            <span class="keyword">if</span>(j&lt;all[i].weight) K[i][j]=K[i<span class="number">-1</span>][j];      <span class="comment">//一定装不进</span></span><br><span class="line">            <span class="keyword">else</span> K[i][j]=max(K[i<span class="number">-1</span>][j],K[i<span class="number">-1</span>][j-all[i].weight]+all[i].val);     <span class="comment">//装/不装</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//return K;</span></span><br><span class="line">    <span class="keyword">return</span> K[n][W];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">int</span> T,n,V;<span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>,&amp;T);</span><br><span class="line">    <span class="keyword">while</span>(T--)&#123;</span><br><span class="line">        <span class="built_in">scanf</span>(<span class="string">&quot;%d%d&quot;</span>,&amp;n,&amp;V);</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=n;i++) <span class="built_in">scanf</span>(<span class="string">&quot;%d%d&quot;</span>,&amp;all[i].val,&amp;all[i].weight);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%d\n&quot;</span>,Knapsack(n,V));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure> #### (2)完全背包:每种物品可使用无限次 与0-1背包对比：二维:f[i][j] = max(f[i][j],f[i-1][j-v[i]]+w[i]); //01背包 f[i][j] =max(f[i][j],f[i][j-v[i]]+w[i]);//完全背包 一维:如代码. <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;bits/stdc++.h&gt;</span></span></span><br><span class="line">using namespace <span class="built_in">std</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> N=<span class="number">1005</span>;</span><br><span class="line"><span class="type">int</span> f[N],v[N],w[N]; <span class="comment">//w[i]是价值，v[i]是体积</span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> n,m;</span><br><span class="line">    <span class="built_in">cin</span>&gt;&gt;n&gt;&gt;m; <span class="comment">//n件物品和体积限制m</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=n;i++) <span class="built_in">cin</span>&gt;&gt;v[i]&gt;&gt;w[i];</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=n;i++)</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j=v[i];j&lt;=m;j++)              <span class="comment">//滚动数组,正序优化</span></span><br><span class="line">            f[j] = max(f[j],f[j-v[i]]+w[i]); </span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;f[m]&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>#### (3)多重背包:每件物品最多有si件. 无法优化为一维. f[i][j] =max(f[i][j], f[i - 1][j - k * v[i]] + k * w[i]);//和完全背包问题的朴素代码一样 <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;bits/stdc++.h&gt;</span></span></span><br><span class="line">using namespace <span class="built_in">std</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> N = <span class="number">110</span>;</span><br><span class="line"><span class="type">int</span> v[N],w[N],s[N];</span><br><span class="line"><span class="type">int</span> f[N][N];</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> n,m;</span><br><span class="line">    <span class="built_in">cin</span>&gt;&gt;n&gt;&gt;m;     <span class="comment">//n件物品和体积限制m</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=n;i++) <span class="built_in">cin</span>&gt;&gt;v[i]&gt;&gt;w[i]&gt;&gt;s[i];   <span class="comment">//s[i]:最多数量</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=n;i++)          <span class="comment">//枚举种数</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">0</span>;j&lt;=m;j++)         <span class="comment">//然后枚举体积，注意，这里不能从v[i]开始枚举</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="type">int</span> k=<span class="number">0</span>;k*v[i]&lt;=j&amp;&amp;k&lt;=s[i];k++)  <span class="comment">//最后枚举第i种物品的个数</span></span><br><span class="line">                f[i][j] = max(f[i][j],f[i<span class="number">-1</span>][j-k*v[i]]+k*w[i]);</span><br><span class="line">        &#125;</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;f[n][m]&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;```</span><br><span class="line"></span><br><span class="line">#### (<span class="number">4</span>)分组背包:同一组内物品最多选一个</span><br><span class="line">```C</span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;bits/stdc++.h&gt;</span></span></span><br><span class="line">using namespace <span class="built_in">std</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> N=<span class="number">110</span>;</span><br><span class="line"><span class="type">int</span> v[N][N],w[N][N];<span class="comment">//第i组第j个物品的体积和价值</span></span><br><span class="line"><span class="type">int</span> s[N];<span class="comment">//第i组物品的数量</span></span><br><span class="line"><span class="type">int</span> f[N];</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> n,m;</span><br><span class="line">    <span class="built_in">cin</span>&gt;&gt;n&gt;&gt;m;          <span class="comment">//n个组,背包容量m.</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=n;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">cin</span>&gt;&gt;s[i];              <span class="comment">//每组物品数量</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">0</span>;j&lt;s[i];j++)</span><br><span class="line">            <span class="built_in">cin</span>&gt;&gt;v[i][j]&gt;&gt;w[i][j];  <span class="comment">//第i组第j个物品的体积/价值</span></span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=n;i++)           <span class="comment">//枚举物品组</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j=m;j&gt;=<span class="number">0</span>;j--)       <span class="comment">//枚举体积</span></span><br><span class="line">            <span class="comment">//枚举决策，也就是选这个物品组的哪个物品</span></span><br><span class="line">            <span class="keyword">for</span>(<span class="type">int</span> k=<span class="number">0</span>;k&lt;s[i];k++)</span><br><span class="line">                <span class="keyword">if</span>(v[i][k]&lt;=j)</span><br><span class="line">                    f[j]=max(f[j],f[j-v[i][k]]+w[i][k]);</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;f[m]&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h3 id="一些记录">8.一些记录</h3><pre><code>长高问题：dp[0..k][0..n],dp[i][j]为:完成第j个点时,跳过i次深坑,得到的最大身高(应有:i&lt;=j)</code></pre><h2 id="贪心">贪心</h2><h3 id="活动选择">1.活动选择</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//贪心算法:局部最优解,导致全部最优解</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//1.活动选择问题:找最大兼容活动集</span></span><br><span class="line"><span class="comment">//动态规划:c[i,j]=max&#123;c[i,k]+c[k,j]+1&#125;--(ak属于Sij)</span></span><br><span class="line"><span class="comment">//贪心选择:反复选择结束时间最早的活动,保留兼容的活动</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> N 100005</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span>&#123;</span></span><br><span class="line">    <span class="type">long</span> <span class="type">long</span> start;</span><br><span class="line">    <span class="type">long</span> <span class="type">long</span> finish;</span><br><span class="line">&#125;act;</span><br><span class="line">act all[N];     <span class="comment">//储存所有活动的数组</span></span><br><span class="line">act ans[N];     <span class="comment">//答案数组</span></span><br><span class="line"><span class="type">int</span> n;          <span class="comment">//活动总个数</span></span><br><span class="line"><span class="type">int</span> cnt;        <span class="comment">//答案数组中活动个数</span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">cmp</span><span class="params">(<span class="type">const</span> <span class="type">void</span> *e1,<span class="type">const</span> <span class="type">void</span> *e2)</span>&#123;</span><br><span class="line">    act *p=(act *)e1,*q=(act *)e2;</span><br><span class="line">    <span class="keyword">return</span> p-&gt;finish-q-&gt;finish;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//qsort(&amp;all[1],n,sizeof(act),cmp);         //all数组按完成时间升序排序</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//求解时调用:recursive_activity_selector(0,n).</span></span><br><span class="line"><span class="comment">//(已排序时)时间复杂度:theta(n).</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">recursive_activity_selector</span><span class="params">(<span class="type">int</span> k,<span class="type">int</span> n)</span>&#123;      <span class="comment">//返回Sk的最大兼容活动集</span></span><br><span class="line">    <span class="type">int</span> m=k+<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">while</span>(m&lt;=n&amp;&amp;all[m].start&lt;all[k].finish) m=m+<span class="number">1</span>;      <span class="comment">//找与活动k兼容的,最早结束的活动</span></span><br><span class="line">    <span class="keyword">if</span>(m&lt;=n)</span><br><span class="line">    &#123;</span><br><span class="line">        ans[cnt++]=all[m];</span><br><span class="line">        recursive_activity_selector(m,n);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">int</span> T,n;<span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>,&amp;T);</span><br><span class="line">    <span class="keyword">while</span>(T--)&#123;</span><br><span class="line">        cnt=<span class="number">0</span>;</span><br><span class="line">        <span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>,&amp;n);</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=n;i++) &#123;<span class="built_in">scanf</span>(<span class="string">&quot;%lld%lld&quot;</span>,&amp;all[i].start,&amp;all[i].finish);all[i].finish+=all[i].start;&#125;</span><br><span class="line">        qsort(&amp;all[<span class="number">1</span>],n,<span class="keyword">sizeof</span>(act),cmp);         <span class="comment">//all数组按完成时间升序排序</span></span><br><span class="line">        recursive_activity_selector(<span class="number">0</span>,n);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%d\n&quot;</span>,cnt);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="huffman编码">2.Huffman编码</h3><p>变长编码,每个字符用唯一的一个二进制串表示(性质：没有任何码字是其他码字的前缀）问题：构造Huffman树，使得:B(T)=c.freq<em>d(c)最小,c.freq为点权重，d(c)为点深度贪心算法构造:n-1次合并,每次合并时:最小优先队列(最小堆实现)选取最小两个元素,合并为一个元素,插入队列--O(n</em>lgn)<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//每个不可分割钢条为叶节点,从树顶往下切割,非根节点为当前钢条长度,问题转为:求Huffman树的最小代价</span></span><br><span class="line"><span class="comment">//类Huffman树:选取当前长度最小的两个点,合并</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;bits/stdc++.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> maxn 200086</span></span><br><span class="line">using namespace <span class="built_in">std</span>;</span><br><span class="line"><span class="keyword">typedef</span> <span class="type">long</span> <span class="type">long</span> ll;</span><br><span class="line"><span class="type">int</span> n;</span><br><span class="line"><span class="built_in">priority_queue</span>&lt;ll, <span class="built_in">vector</span>&lt;ll&gt;, greater&lt;ll&gt; &gt; q;</span><br><span class="line">  </span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>, &amp;n);</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">1</span>;i &lt;= n;i++)&#123;</span><br><span class="line">        <span class="type">int</span> x;</span><br><span class="line">        <span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>, &amp;x);</span><br><span class="line">        q.push(x);</span><br><span class="line">    &#125;</span><br><span class="line">    ll ans = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">1</span>;i &lt; n;i++)&#123;</span><br><span class="line">        ll x = q.top();q.pop();</span><br><span class="line">        x += q.top();q.pop();</span><br><span class="line">        ans += x * <span class="number">2</span>;</span><br><span class="line">        q.push(x);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%lld&quot;</span>, ans);</span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure> ### 3.合法括号序列 <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//贪心策略填括号.先计算需要新填入的左/右括号数量,在不超过的前提下,优先填左括号.</span></span><br><span class="line"><span class="comment">//时间复杂度:O(n).</span></span><br><span class="line"></span><br><span class="line"><span class="type">char</span> S[<span class="number">100005</span>];</span><br><span class="line"><span class="type">int</span> l,r,no;</span><br><span class="line"><span class="type">int</span> left,right;     <span class="comment">//left,right记录当前位置之前的:左/右括号数量</span></span><br><span class="line"><span class="type">bool</span> <span class="title function_">judge</span><span class="params">(<span class="type">int</span> n)</span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(n%<span class="number">2</span>) <span class="keyword">return</span> <span class="literal">false</span>;   <span class="comment">//奇数长度,一定不能构成合法括号序列</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;n;i++)    <span class="comment">//初始化,统计左/右/待填括号数量</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span>(S[i]==<span class="string">&#x27;(&#x27;</span>) l++;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span>(S[i]==<span class="string">&#x27;)&#x27;</span>) r++;</span><br><span class="line">        <span class="keyword">else</span> no++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//printf(&quot;%d,%d,%d\n&quot;,l,r,no);</span></span><br><span class="line">    <span class="keyword">if</span>(l+no&lt;r||r+no&lt;l) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    l=n/<span class="number">2</span>-l;r=n/<span class="number">2</span>-r;        <span class="comment">//此时l,r为可新填入的左/右括号数量</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;n;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span>(left&lt;=right&amp;&amp;left!=<span class="number">0</span>) <span class="keyword">return</span> <span class="literal">false</span>;   <span class="comment">//left==right不满足:S任一非空且非自身前缀均不为合法括号序列</span></span><br><span class="line">        <span class="keyword">if</span>(S[i]==<span class="string">&#x27;(&#x27;</span>) left++;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span>(S[i]==<span class="string">&#x27;)&#x27;</span>) right++;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">if</span>(left&lt;n/<span class="number">2</span>&amp;&amp;l&gt;<span class="number">0</span>)    <span class="comment">//优先填左括号</span></span><br><span class="line">            &#123;</span><br><span class="line">                S[i]=<span class="string">&#x27;(&#x27;</span>;left++;l--;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">            &#123;</span><br><span class="line">                S[i]=<span class="string">&#x27;)&#x27;</span>;right++;r--;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//printf(&quot;%s\n&quot;,S);</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">int</span> n;<span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>,&amp;n);</span><br><span class="line">    <span class="built_in">scanf</span>(<span class="string">&quot;%s&quot;</span>,S);</span><br><span class="line">    <span class="type">int</span> len=<span class="built_in">strlen</span>(S);</span><br><span class="line">    <span class="keyword">if</span>(S[len<span class="number">-1</span>]==<span class="string">&#x27;\n&#x27;</span>) &#123;S[len<span class="number">-1</span>]=<span class="string">&#x27;\0&#x27;</span>;len--;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(!judge(n)) <span class="built_in">printf</span>(<span class="string">&quot;:(&quot;</span>);</span><br><span class="line">    <span class="keyword">else</span> <span class="built_in">printf</span>(<span class="string">&quot;%s&quot;</span>,S);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h3 id="求不超过n的最大回文串">4.求不超过n的最大回文串</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstring&gt;</span></span></span><br><span class="line">using namespace <span class="built_in">std</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> N = <span class="number">505</span>;</span><br><span class="line"><span class="type">char</span> a[N], b[N];</span><br><span class="line"><span class="type">int</span> n, mid;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">leq</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= n; i++)&#123;</span><br><span class="line">        <span class="keyword">if</span> (b[i] &lt; a[i]) <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">if</span> (b[i] &gt; a[i]) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">void</span> <span class="title function_">solve</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">scanf</span>(<span class="string">&quot;%s&quot;</span>, a + <span class="number">1</span>);</span><br><span class="line">    n = <span class="built_in">strlen</span>(a + <span class="number">1</span>);</span><br><span class="line">    mid = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>, j = n; i &lt;= j; i++, j--)</span><br><span class="line">    &#123;</span><br><span class="line">        b[i] = b[j] = a[i];</span><br><span class="line">        mid = i;</span><br><span class="line">    &#125;</span><br><span class="line">    b[n + <span class="number">1</span>] = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">if</span> (leq())</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%s\n&quot;</span>, b + <span class="number">1</span>);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    b[mid]--;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = mid; i &amp;&amp; b[i] &lt; <span class="string">&#x27;0&#x27;</span>; i--)</span><br><span class="line">    &#123;</span><br><span class="line">        b[i] += <span class="number">10</span>;</span><br><span class="line">        b[i - <span class="number">1</span>]--;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= mid; i++)</span><br><span class="line">        b[n - i + <span class="number">1</span>] = b[i];</span><br><span class="line">    <span class="keyword">if</span> (b[<span class="number">1</span>] != <span class="string">&#x27;0&#x27;</span> &amp;&amp; leq())</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%s\n&quot;</span>, b + <span class="number">1</span>);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt; n; i++)</span><br><span class="line">        b[i] = <span class="string">&#x27;9&#x27;</span>;</span><br><span class="line">    b[n] = <span class="number">0</span>;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%s\n&quot;</span>, b + <span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> T; <span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>, &amp;T);</span><br><span class="line">    <span class="keyword">while</span> (T--) solve();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="图论">图论</h2><h3 id="dfs">1.DFS</h3><h4 id="例n元数--依次选择每个数位上的数.">例:n元数--依次选择每个数位上的数.</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//各位的n次方之和等于该数,该数共n位.</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line">using namespace <span class="built_in">std</span>;</span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ll long long</span></span><br><span class="line"><span class="type">int</span> n;</span><br><span class="line">ll pw[<span class="number">10</span>],cnt[<span class="number">10</span>],bit[<span class="number">10</span>],ans;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">check</span><span class="params">(ll s)</span>&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;<span class="number">10</span>;i++) bit[i]=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span>(s&gt;<span class="number">0</span>)&#123;</span><br><span class="line">        bit[s%<span class="number">10</span>]++;</span><br><span class="line">        s/=<span class="number">10</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;<span class="number">10</span>;i++)&#123;</span><br><span class="line">        <span class="keyword">if</span>(cnt[i]!=bit[i]) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//ubound:可供选择的n次方最大的底数;num为当前的n次方之和</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">dfs</span><span class="params">(<span class="type">int</span> bound,ll num,ll limit)</span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(num&lt;limit/<span class="number">10</span>) <span class="keyword">return</span>;</span><br><span class="line">    ans+=check(num)*num;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;=bound;i++)&#123;</span><br><span class="line">        cnt[i]++;</span><br><span class="line">        dfs(i,num+pw[i],limit*<span class="number">10</span>);</span><br><span class="line">        cnt[i]--;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    ios::sync_with_stdio(<span class="literal">false</span>);</span><br><span class="line">    <span class="built_in">cin</span>.tie(<span class="number">0</span>);<span class="built_in">cout</span>.tie(<span class="number">0</span>);</span><br><span class="line">    <span class="type">int</span> T;<span class="built_in">cin</span>&gt;&gt;T;</span><br><span class="line">    <span class="keyword">while</span>(T--)&#123;</span><br><span class="line">        <span class="built_in">cin</span>&gt;&gt;n;         <span class="comment">//n次方</span></span><br><span class="line">        ans=<span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;<span class="number">10</span>;i++)&#123;</span><br><span class="line">            cnt[i]=<span class="number">0</span>;pw[i]=<span class="number">1</span>;</span><br><span class="line">            <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">0</span>;j&lt;n;j++) pw[i]*=i;</span><br><span class="line">        &#125;</span><br><span class="line">        dfs(<span class="number">9</span>,<span class="number">0</span>,<span class="number">1</span>);</span><br><span class="line">        <span class="built_in">cout</span>&lt;&lt;ans&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="bfs">2.BFS</h3><h4 id="例地图中每个格子有可向上下左右移动的步数求11-nm的最小次数.">例:地图中每个格子,有可向上下左右移动的步数,求(1,1)-&gt;(n,m)的最小次数.</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//[1,1]-&gt;[n,m]最小次数</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;queue&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;array&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ll long long</span></span><br><span class="line">using namespace <span class="built_in">std</span>;</span><br><span class="line"><span class="type">int</span> n,m;</span><br><span class="line"></span><br><span class="line"><span class="comment">//n为总行/列数;l为当前格子可向上/下/左/右移动的步数;</span></span><br><span class="line">ll <span class="title function_">calc</span><span class="params">(ll x,ll step,ll n,<span class="type">int</span> neg)</span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(n==<span class="number">1</span>) <span class="keyword">return</span> x;</span><br><span class="line">    <span class="keyword">if</span>(neg)&#123;</span><br><span class="line">        ll a=(x-step%(<span class="number">2</span>*n<span class="number">-2</span>)+(n<span class="number">-2</span>)+(<span class="number">2</span>*n<span class="number">-2</span>))%(<span class="number">2</span>*n<span class="number">-2</span>);</span><br><span class="line">        <span class="keyword">if</span>(a&gt;=n<span class="number">-2</span>) <span class="keyword">return</span> a-(n<span class="number">-2</span>);</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">return</span> (n<span class="number">-2</span>)-a;</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        ll a=(x+step%(<span class="number">2</span>*n<span class="number">-2</span>))%(<span class="number">2</span>*n<span class="number">-2</span>);     <span class="comment">//n+(n-1)=2n-2.</span></span><br><span class="line">        <span class="keyword">if</span>(a&gt;=n) <span class="keyword">return</span> <span class="number">2</span>*n<span class="number">-2</span>-a;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">return</span> a;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//由于每个格子处有不同的指定步数,且均可向上下左右移动,因此无法用dp.</span></span><br><span class="line"><span class="comment">//BFS访问,队列记录.</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    ios::sync_with_stdio(<span class="literal">false</span>);</span><br><span class="line">    <span class="built_in">cin</span>.tie(<span class="number">0</span>);</span><br><span class="line">    <span class="type">int</span> tt;<span class="built_in">cin</span>&gt;&gt;tt;</span><br><span class="line">    <span class="keyword">while</span>(tt--)&#123;</span><br><span class="line">        <span class="built_in">cin</span>&gt;&gt;n&gt;&gt;m;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="type">int</span>&gt;&gt;a (n,<span class="built_in">vector</span>&lt;<span class="type">int</span>&gt;(m));</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="type">bool</span>&gt;&gt;vis (n,<span class="built_in">vector</span>&lt;<span class="type">bool</span>&gt;(m));</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;n;i++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">0</span>;j&lt;m;j++) <span class="built_in">cin</span>&gt;&gt;a[i][j];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">queue</span>&lt;<span class="built_in">array</span>&lt;ll,<span class="number">3</span>&gt;&gt;q;</span><br><span class="line">        vis[<span class="number">0</span>][<span class="number">0</span>]=<span class="literal">true</span>;</span><br><span class="line">        q.push(&#123;<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>&#125;);</span><br><span class="line">        ll ans=<span class="number">-1</span>;</span><br><span class="line">        <span class="keyword">while</span>(!q.empty())&#123;</span><br><span class="line">            ll r=q.front()[<span class="number">0</span>],c=q.front()[<span class="number">1</span>],w=q.front()[<span class="number">2</span>];</span><br><span class="line">            q.pop();</span><br><span class="line">            <span class="keyword">if</span>(r==n<span class="number">-1</span>&amp;&amp;c==m<span class="number">-1</span>) &#123;ans=w;<span class="keyword">break</span>;&#125;</span><br><span class="line"></span><br><span class="line">            <span class="type">int</span> step=a[r][c];</span><br><span class="line">            ll nr,nc;</span><br><span class="line">            nr=calc(r,step,n,<span class="number">0</span>);nc=c;</span><br><span class="line">            <span class="keyword">if</span>(!vis[nr][nc]) &#123;vis[nr][nc]=<span class="literal">true</span>;q.push(&#123;nr,nc,w+<span class="number">1</span>&#125;);&#125;</span><br><span class="line">            nr=calc(r,step,n,<span class="number">1</span>);nc=c;</span><br><span class="line">            <span class="keyword">if</span>(!vis[nr][nc]) &#123;vis[nr][nc]=<span class="literal">true</span>;q.push(&#123;nr,nc,w+<span class="number">1</span>&#125;);&#125;</span><br><span class="line">            nr=r;nc=calc(c,step,m,<span class="number">0</span>);</span><br><span class="line">            <span class="keyword">if</span>(!vis[nr][nc]) &#123;vis[nr][nc]=<span class="literal">true</span>;q.push(&#123;nr,nc,w+<span class="number">1</span>&#125;);&#125;</span><br><span class="line">            nr=r;nc=calc(c,step,m,<span class="number">1</span>);</span><br><span class="line">            <span class="keyword">if</span>(!vis[nr][nc]) &#123;vis[nr][nc]=<span class="literal">true</span>;q.push(&#123;nr,nc,w+<span class="number">1</span>&#125;);&#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">cout</span>&lt;&lt;ans&lt;&lt;<span class="string">&#x27;\n&#x27;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="单源最短路问题">3.单源最短路问题</h3><h4 id="bellford可能包括负环">(1)Bellford:可能包括负环</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> N 2005</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> M 6005</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> inf 1e9</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> min(a,b) a&lt;b?a:b</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">edge</span>&#123;</span></span><br><span class="line">    <span class="type">int</span> u,v,w;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">edge</span> <span class="title">Edges</span>[<span class="title">M</span>];</span></span><br><span class="line"><span class="type">int</span> dis[N];     <span class="comment">//dis[i]记录:源点到点i的距离(i=1,...,n)</span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> n,m;    <span class="comment">//n个点,m条边</span></span><br><span class="line"></span><br><span class="line"><span class="type">bool</span> <span class="title function_">BellFord</span><span class="params">(<span class="type">int</span> s)</span>&#123;</span><br><span class="line">    fill(dis,dis+n+<span class="number">1</span>,inf);</span><br><span class="line">    dis[s]=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;n;i++)    <span class="comment">//每条边松弛n-1次</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">1</span>;j&lt;=m;j++)</span><br><span class="line">        &#123;</span><br><span class="line">            dis[Edges[j].v]=min(dis[Edges[j].v],dis[Edges[j].u]+Edges[j].w);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">1</span>;j&lt;=m;j++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span>(dis[Edges[j].v]&gt;dis[Edges[j].u]+Edges[j].w) <span class="keyword">return</span> <span class="literal">false</span>;    <span class="comment">//有负环</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> abyss</span></span><br><span class="line">    freopen(<span class="string">&quot;in.txt&quot;</span>, <span class="string">&quot;r&quot;</span>, <span class="built_in">stdin</span>);</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">    ios::sync_with_stdio(<span class="literal">false</span>);</span><br><span class="line">    <span class="built_in">cin</span>.tie(<span class="number">0</span>); <span class="built_in">cout</span>.tie(<span class="number">0</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="type">int</span> T;<span class="built_in">cin</span>&gt;&gt;T;</span><br><span class="line">    <span class="keyword">while</span>(T--)&#123;</span><br><span class="line">        <span class="built_in">cin</span>&gt;&gt;n&gt;&gt;m;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=m;i++) <span class="built_in">cin</span>&gt;&gt;Edges[i].u&gt;&gt;Edges[i].v&gt;&gt;Edges[i].w;  <span class="comment">//输入边</span></span><br><span class="line">        <span class="type">bool</span> ans=BellFord(<span class="number">1</span>);</span><br><span class="line">        <span class="keyword">if</span>(ans==<span class="literal">false</span>) <span class="built_in">cout</span>&lt;&lt;<span class="string">&quot;boo how\n&quot;</span>;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=n;i++) <span class="built_in">cout</span>&lt;&lt;dis[i]&lt;&lt;(i==n?<span class="string">&quot;\n&quot;</span>:<span class="string">&quot; &quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="dijkstra算法无向图无负环">(2)Dijkstra算法：无向图,无负环</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;queue&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cstring&gt;</span></span></span><br><span class="line">using namespace <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//无向图：单源最短路径问题</span></span><br><span class="line"><span class="comment">//无负边,无负环--Dijkstra</span></span><br><span class="line"><span class="comment">//1.已确定点集S,未确定点集T,初始化所有点属于T集合,dis(s)=0,其他点dis=inf;</span></span><br><span class="line"><span class="comment">//2.不断从T中选取dis最小的节点u,加入S中;</span></span><br><span class="line"><span class="comment">//3.对u的所有出边执行松弛操作.dis(v)=min(dis(v),dis(u)+w).</span></span><br><span class="line"><span class="comment">//贪心构建集合S;选取dis最小的点,用优先队列实现O(MlogM).</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//写法一:邻接表实现</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> inf 1e18</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Dijkstra</span>&#123;</span></span><br><span class="line">public:</span><br><span class="line">    <span class="type">int</span> n;</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="built_in">pair</span>&lt;<span class="type">int</span> ,<span class="type">long</span> <span class="type">long</span>&gt;&gt;&gt;g;      <span class="comment">//g[u]存储u的出边及权重构成的pair</span></span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="type">long</span> <span class="type">long</span>&gt;dis;</span><br><span class="line">    Dijkstra(<span class="type">int</span> k):n(k)&#123;</span><br><span class="line">        g.resize(n+<span class="number">1</span>);</span><br><span class="line">        dis.resize(n+<span class="number">1</span>,inf);</span><br><span class="line">        <span class="comment">//resize意义:如果n+1小于当前容器大小:保留,保留前n+1个元素,去除多余的值;</span></span><br><span class="line">        <span class="comment">//若n+1大于当前容器大小,在结尾插入一定数量的inf,使大小达标.</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">void</span> <span class="title function_">add</span><span class="params">(<span class="type">int</span> u,<span class="type">int</span> v,<span class="type">long</span> <span class="type">long</span> w)</span>&#123;</span><br><span class="line">        g[u].emplace_back(v,w);     <span class="comment">//加入u的出边</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">void</span> <span class="title function_">solve</span><span class="params">(<span class="type">int</span> s)</span>&#123;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="type">bool</span>&gt;vis(n+<span class="number">1</span>);</span><br><span class="line">        <span class="built_in">priority_queue</span>&lt;<span class="built_in">pair</span>&lt;<span class="type">long</span> <span class="type">long</span>,<span class="type">int</span>&gt;,<span class="built_in">vector</span>&lt;<span class="built_in">pair</span>&lt;<span class="type">long</span> <span class="type">long</span>,<span class="type">int</span>&gt;&gt;,greater&lt;<span class="built_in">pair</span>&lt;<span class="type">long</span> <span class="type">long</span>,<span class="type">int</span>&gt;&gt;&gt;q;</span><br><span class="line">            <span class="comment">//小根堆</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=n;i++) dis[i]=inf;       <span class="comment">//注意！再重新赋值一次</span></span><br><span class="line">        dis[s]=<span class="number">0</span>;</span><br><span class="line">        q.push(&#123;<span class="number">0</span>,s&#125;);</span><br><span class="line">        <span class="keyword">while</span>(!q.empty())&#123;</span><br><span class="line">            <span class="type">int</span> u=q.top().second;       <span class="comment">//q中存储&lt;dis,u&gt;对:u为点编号</span></span><br><span class="line">            q.pop();</span><br><span class="line">            <span class="keyword">if</span>(vis[u]) <span class="keyword">continue</span>;</span><br><span class="line">            vis[u]=<span class="literal">true</span>;        <span class="comment">//加入已访问的点集S</span></span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">auto</span> [v,w]:g[u])&#123;</span><br><span class="line">                <span class="keyword">if</span>(dis[v]&gt;dis[u]+w) dis[v]=dis[u]+w;</span><br><span class="line">                q.push(&#123;dis[v],v&#125;);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">//写法二：链式前向星实现</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Dijkstra2</span>&#123;</span></span><br><span class="line">public:</span><br><span class="line">    <span class="type">int</span> n;</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="type">int</span>&gt;head;                <span class="comment">//head[u]:点u的第一条出边编号</span></span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="type">int</span>&gt;nxt;                 <span class="comment">//nxt[i]:边i的下一条边编号</span></span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">pair</span>&lt;<span class="type">int</span>,<span class="type">long</span> <span class="type">long</span>&gt;&gt;to;  <span class="comment">//(v,w)</span></span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="type">long</span> <span class="type">long</span>&gt;dis;</span><br><span class="line">    Dijkstra2(<span class="type">int</span> k):n(k)&#123;</span><br><span class="line">        head.resize(n+<span class="number">1</span>,<span class="number">-1</span>);</span><br><span class="line">        dis.resize(n+<span class="number">1</span>,inf);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">void</span> <span class="title function_">add</span><span class="params">(<span class="type">int</span> u,<span class="type">int</span> v,<span class="type">long</span> <span class="type">long</span> w)</span>&#123;</span><br><span class="line">        <span class="type">int</span> cnt=nxt.size();</span><br><span class="line">        to.emplace_back(v,w);</span><br><span class="line">        nxt.push_back(head[u]);</span><br><span class="line">        head[u]=cnt;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">void</span> <span class="title function_">solve</span><span class="params">(<span class="type">int</span> s)</span>&#123;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="type">bool</span>&gt;vis(n+<span class="number">1</span>);</span><br><span class="line">        <span class="built_in">priority_queue</span>&lt;<span class="built_in">pair</span>&lt;<span class="type">long</span> <span class="type">long</span>,<span class="type">int</span>&gt;,<span class="built_in">vector</span>&lt;<span class="built_in">pair</span>&lt;<span class="type">long</span> <span class="type">long</span>,<span class="type">int</span>&gt;&gt;,greater&lt;<span class="built_in">pair</span>&lt;<span class="type">long</span> <span class="type">long</span>,<span class="type">int</span>&gt;&gt;&gt;q;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=n;i++) dis[i]=inf;</span><br><span class="line">        dis[s]=<span class="number">0</span>;</span><br><span class="line">        q.push(&#123;<span class="number">0</span>,s&#125;);</span><br><span class="line">        <span class="keyword">while</span>(!q.empty())&#123;</span><br><span class="line">            <span class="type">int</span> u=q.top().second;</span><br><span class="line">            q.pop();</span><br><span class="line">            <span class="keyword">if</span>(vis[u]) <span class="keyword">continue</span>;</span><br><span class="line">            vis[u]=<span class="literal">true</span>;</span><br><span class="line">            <span class="keyword">for</span>(<span class="type">int</span> i=head[u];i!=<span class="number">-1</span>;i=nxt[i])       <span class="comment">//遍历u的出边</span></span><br><span class="line">            &#123;</span><br><span class="line">                <span class="keyword">auto</span> [v,w]=to[i];</span><br><span class="line">                <span class="keyword">if</span>(dis[v]&gt;dis[u]+w) dis[v]=dis[u]+w;</span><br><span class="line">                q.push(&#123;dis[v],v&#125;);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"> </span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">int main()&#123;</span></span><br><span class="line"><span class="comment">    ios::sync_with_stdio(false);</span></span><br><span class="line"><span class="comment">    cin.tie(0);</span></span><br><span class="line"><span class="comment">    int n,m,s,x,y;      //n个点,m条边,s为源点</span></span><br><span class="line"><span class="comment">    long long t0,t;</span></span><br><span class="line"><span class="comment">    cin&gt;&gt;n&gt;&gt;m&gt;&gt;s&gt;&gt;t0;</span></span><br><span class="line"><span class="comment">    Dijkstra prob(n);</span></span><br><span class="line"><span class="comment">    for(int i=0;i&lt;m;i++)</span></span><br><span class="line"><span class="comment">    &#123;</span></span><br><span class="line"><span class="comment">        cin&gt;&gt;x&gt;&gt;y&gt;&gt;t;</span></span><br><span class="line"><span class="comment">        prob.add(x,y,t);        //无向图双向插入</span></span><br><span class="line"><span class="comment">        //prob.add(y,x,t);</span></span><br><span class="line"><span class="comment">    &#125;</span></span><br><span class="line"><span class="comment">    prob.solve(s);</span></span><br><span class="line"><span class="comment">    </span></span><br><span class="line"><span class="comment">    //输出:1.不可到达的点;2.时间大于t0的点</span></span><br><span class="line"><span class="comment">    int cnt=0;</span></span><br><span class="line"><span class="comment">    vector&lt;int&gt;ans;</span></span><br><span class="line"><span class="comment">    for(int i=1;i&lt;=n;i++)</span></span><br><span class="line"><span class="comment">    &#123;</span></span><br><span class="line"><span class="comment">        if(prob.dis[i]==inf||prob.dis[i]&gt;t0)</span></span><br><span class="line"><span class="comment">        &#123;</span></span><br><span class="line"><span class="comment">            cnt++;</span></span><br><span class="line"><span class="comment">            ans.push_back(i);</span></span><br><span class="line"><span class="comment">        &#125;</span></span><br><span class="line"><span class="comment">    &#125;</span></span><br><span class="line"><span class="comment">    cout&lt;&lt; cnt&lt;&lt;&#x27;\n&#x27;;</span></span><br><span class="line"><span class="comment">    for(auto i:ans) cout&lt;&lt;i&lt;&lt;&#x27; &#x27;&lt;&lt;(prob.dis[i]==inf?-1:prob.dis[i])&lt;&lt;&#x27;\n&#x27;;</span></span><br><span class="line"><span class="comment">    return 0;</span></span><br><span class="line"><span class="comment">&#125;*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//变式:E4.D</span></span><br><span class="line"><span class="comment">//求出1到n,且经过点&#123;p1,...,pk&#125;中至少一点的最短路径.</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">int main()&#123;</span></span><br><span class="line"><span class="comment">    ios::sync_with_stdio(false);</span></span><br><span class="line"><span class="comment">    cin.tie(0);</span></span><br><span class="line"><span class="comment">    int t;cin&gt;&gt;t;</span></span><br><span class="line"><span class="comment">    while(t--)&#123;</span></span><br><span class="line"><span class="comment">        int n,m,k;cin&gt;&gt;n&gt;&gt;m&gt;&gt;k;</span></span><br><span class="line"><span class="comment">        vector&lt;int&gt;mid(k);      //中间点集</span></span><br><span class="line"><span class="comment">        for(int i=0;i&lt;k;i++) cin&gt;&gt;mid[i];</span></span><br><span class="line"><span class="comment">        </span></span><br><span class="line"><span class="comment">        Dijkstra d(n);</span></span><br><span class="line"><span class="comment">        for(int i=0;i&lt;m;i++)</span></span><br><span class="line"><span class="comment">        &#123;</span></span><br><span class="line"><span class="comment">            int x,y;long long w;</span></span><br><span class="line"><span class="comment">            cin&gt;&gt;x&gt;&gt;y&gt;&gt;w;</span></span><br><span class="line"><span class="comment">            d.add(x,y,w);</span></span><br><span class="line"><span class="comment">            d.add(y,x,w);</span></span><br><span class="line"><span class="comment">        &#125;</span></span><br><span class="line"><span class="comment">        d.solve(1);         //求点1到所有点的最短距离</span></span><br><span class="line"><span class="comment">        vector&lt;long long&gt;d1(n+1);</span></span><br><span class="line"><span class="comment">        for(int i=1;i&lt;=n;i++) d1[i]=d.dis[i];</span></span><br><span class="line"><span class="comment">        d.solve(n);         //求点n到所有点的最短距离</span></span><br><span class="line"><span class="comment">        long long ans=inf;</span></span><br><span class="line"><span class="comment">        //分别求点1,点n到以中间点集中每个点的距离之和</span></span><br><span class="line"><span class="comment">        for(int i=0;i&lt;k;i++) ans=min(ans,d1[mid[i]]+d.dis[mid[i]]);</span></span><br><span class="line"><span class="comment">        cout&lt;&lt;(ans&lt;inf?ans:-1)&lt;&lt;&quot;\n&quot;;</span></span><br><span class="line"><span class="comment">    &#125;</span></span><br><span class="line"><span class="comment">    return 0;</span></span><br><span class="line"><span class="comment">&#125;</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure><h3 id="所有点间的最短路问题--floyd">4.所有点间的最短路问题--Floyd</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> N 305</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> M 100005</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> inf 1e18</span></span><br><span class="line"><span class="type">int</span> n,m,q;</span><br><span class="line"><span class="type">long</span> <span class="type">long</span> dis[N][N];        <span class="comment">//各顶点间最短距离</span></span><br><span class="line"><span class="type">int</span> u,v;</span><br><span class="line"><span class="type">long</span> <span class="type">long</span> w;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">floyd</span><span class="params">()</span>&#123;       <span class="comment">//O(V^3).</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> k=<span class="number">1</span>;k&lt;=n;k++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=n;i++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">1</span>;j&lt;=n;j++)</span><br><span class="line">            &#123;</span><br><span class="line">                dis[i][j]=min(dis[i][j],dis[i][k]+dis[k][j]);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="built_in">cin</span>&gt;&gt;n&gt;&gt;m;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;=n;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">0</span>;j&lt;=n;j++) dis[i][j]=inf;</span><br><span class="line">        dis[i][i]=<span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;m;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">cin</span>&gt;&gt;u&gt;&gt;v&gt;&gt;w;</span><br><span class="line">        dis[u][v]=min(dis[u][v],w);</span><br><span class="line">    &#125;</span><br><span class="line">    floyd();</span><br><span class="line">    <span class="built_in">cin</span>&gt;&gt;q;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;q;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">cin</span>&gt;&gt;u&gt;&gt;v;</span><br><span class="line">        <span class="keyword">if</span>(dis[u][v]&gt;inf/<span class="number">2</span>) <span class="built_in">cout</span>&lt;&lt;<span class="string">&quot;-1\n&quot;</span>;</span><br><span class="line">        <span class="keyword">else</span> <span class="built_in">cout</span>&lt;&lt;dis[u][v]&lt;&lt;<span class="string">&quot;\n&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="拓扑排序">5.拓扑排序</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;queue&gt;</span></span></span><br><span class="line"></span><br><span class="line">using namespace <span class="built_in">std</span>;</span><br><span class="line"><span class="comment">//A</span></span><br><span class="line"><span class="comment">//拓扑排序(对有向无环图):</span></span><br><span class="line"><span class="comment">//1.定义队列L,放入所有入度为0的点;</span></span><br><span class="line"><span class="comment">//2.取队首节点s,删除所有以s为起点的边,更新终点的入度,为0时加入队列L;</span></span><br><span class="line"><span class="comment">//3.重复处理,直至队列L为空.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//法一：链式向前星储存图</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">#define N 100005</span></span><br><span class="line"><span class="comment">#define M 400005</span></span><br><span class="line"><span class="comment">struct edge&#123;        //链式向前星储存图</span></span><br><span class="line"><span class="comment">    int to,next,weight;        //to为:边的终点;next:下一条边编号</span></span><br><span class="line"><span class="comment">&#125;;</span></span><br><span class="line"><span class="comment">edge G[M];     //G[i]表示:编号为i的下一条边编号</span></span><br><span class="line"><span class="comment">int head[N];       //head[u]表示:以u为起点的第一条边编号</span></span><br><span class="line"><span class="comment">int weight[M];</span></span><br><span class="line"><span class="comment">int cnt;        //边编号</span></span><br><span class="line"><span class="comment">int din[N];    //点的入度</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">//加入边:链表头插法--将当前边插入当前起点的第一条出边</span></span><br><span class="line"><span class="comment">//每次为当前边分配新编号(++cnt);获取当前起点的第一条出边编号,让当前边指向该边,起点的第一条出边更新为当前边</span></span><br><span class="line"><span class="comment">void add(int u,int v,int w)&#123;    //(u,v)为有向边,w为权重</span></span><br><span class="line"><span class="comment">    G[++cnt].next=head[u];</span></span><br><span class="line"><span class="comment">    head[u]=cnt;</span></span><br><span class="line"><span class="comment">    G[cnt].to=v;</span></span><br><span class="line"><span class="comment">&#125;</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">priority_queue&lt;int,vector&lt;int&gt;, less&lt;int&gt;&gt; L;       //拓扑序列(最大优先队列)--保证输出字典序最大的拓扑排序</span></span><br><span class="line"><span class="comment">//删除所有u的出边</span></span><br><span class="line"><span class="comment">void deleteEdge(int u)&#123;</span></span><br><span class="line"><span class="comment">    for(int i=head[u];i!=0;i=G[i].next)</span></span><br><span class="line"><span class="comment">    &#123;</span></span><br><span class="line"><span class="comment">        din[G[i].to]--;         //终点入度-1</span></span><br><span class="line"><span class="comment">        if(din[G[i].to]==0) L.push(G[i].to);     //入度为0的点加入队列L</span></span><br><span class="line"><span class="comment">    &#125;</span></span><br><span class="line"><span class="comment">&#125;</span></span><br><span class="line"><span class="comment">int main()&#123;</span></span><br><span class="line"><span class="comment">    int n,m,s,e;cin&gt;&gt;n&gt;&gt;m;      //n个点,m条有向边</span></span><br><span class="line"><span class="comment">    for(int i=0;i&lt;m;i++)</span></span><br><span class="line"><span class="comment">    &#123;</span></span><br><span class="line"><span class="comment">        cin&gt;&gt;s&gt;&gt;e;</span></span><br><span class="line"><span class="comment">        add(s,e,1);</span></span><br><span class="line"><span class="comment">        din[e]++;</span></span><br><span class="line"><span class="comment">    &#125;</span></span><br><span class="line"><span class="comment">    for(int i=1;i&lt;=n;i++)</span></span><br><span class="line"><span class="comment">    &#123;</span></span><br><span class="line"><span class="comment">        if(!din[i]) L.push(i);        //入度为0的点加入队列</span></span><br><span class="line"><span class="comment">    &#125;</span></span><br><span class="line"><span class="comment">    </span></span><br><span class="line"><span class="comment">    while(!L.empty())&#123;</span></span><br><span class="line"><span class="comment">        int cur=L.top();      //取队首元素</span></span><br><span class="line"><span class="comment">        L.pop();</span></span><br><span class="line"><span class="comment">        deleteEdge(cur);</span></span><br><span class="line"><span class="comment">        cout&lt;&lt;cur&lt;&lt;&quot; &quot;;</span></span><br><span class="line"><span class="comment">    &#125;</span></span><br><span class="line"><span class="comment">    return 0;</span></span><br><span class="line"><span class="comment">&#125;</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//法二：邻接表储存图</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> N 100005</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> M 400005</span></span><br><span class="line"><span class="type">int</span> n,m,din[N];</span><br><span class="line"><span class="built_in">vector</span>&lt;<span class="type">int</span>&gt; e[M];</span><br><span class="line"><span class="built_in">priority_queue</span>&lt;<span class="type">int</span>&gt; q;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">int</span> u,v;<span class="built_in">cin</span>&gt;&gt;n&gt;&gt;m;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;m;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">cin</span>&gt;&gt;u&gt;&gt;v;</span><br><span class="line">        e[u].push_back(v);</span><br><span class="line">        din[v]+=<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=n;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span>(din[i]==<span class="number">0</span>) q.push(i);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">while</span>(!q.empty())</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">int</span> u=q.top();q.pop();</span><br><span class="line">        <span class="built_in">cout</span>&lt;&lt;u&lt;&lt;<span class="string">&quot; &quot;</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">auto</span> v:e[u])</span><br><span class="line">        &#123;</span><br><span class="line">            din[v]-=<span class="number">1</span>;</span><br><span class="line">            <span class="keyword">if</span>(din[v]==<span class="number">0</span>) q.push(v);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="关键路径问题">关键路径问题</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//顶点间有依赖关系,同一时间可平行访问多个顶点,求访问完所有顶点的最小时间.</span></span><br><span class="line"><span class="comment">//链式前向星实现:</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">#define N 100005</span></span><br><span class="line"><span class="comment">#define M 200005</span></span><br><span class="line"><span class="comment">#define max(a,b) a&gt;b?a:b</span></span><br><span class="line"><span class="comment">#define min(a,b) a&lt;b?a:b</span></span><br><span class="line"><span class="comment">int head[N],nxt[M],to[M],cnt;   //head[u]:点u第一条出边编号; nxt[i]:边i的下一条边编号; to[i]:边i的终点</span></span><br><span class="line"><span class="comment">int inDegree[N];        //点i的入度</span></span><br><span class="line"><span class="comment">int fTime[N];           //fTime[u]:点u的完成时间</span></span><br><span class="line"><span class="comment">int n,m;</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">int q[N];       //队列</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">void addEdge(int u,int v)&#123;</span></span><br><span class="line"><span class="comment">    nxt[++cnt]=head[u];     //当前边的后继</span></span><br><span class="line"><span class="comment">    head[u]=cnt;            //更新u的第一条出边</span></span><br><span class="line"><span class="comment">    to[cnt]=v;</span></span><br><span class="line"><span class="comment">    inDegree[v]+=1;      //终点入度+=1.</span></span><br><span class="line"><span class="comment">&#125;</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">void solve()&#123;    //n个顶点,m条边</span></span><br><span class="line"><span class="comment">    for(int i=1;i&lt;=n;i++) head[i]=inDegree[i]=fTime[i]=0;   //初始化</span></span><br><span class="line"><span class="comment">    //memset(head,0,n+1);memset(inDegree,0,n+1);memset(fTime,0,n+1);cnt=0;  //使用会TLE?</span></span><br><span class="line"><span class="comment">    //memset(nxt,0,m+1);memset(to,0,m+1);</span></span><br><span class="line"><span class="comment">    int u,v;</span></span><br><span class="line"><span class="comment">    for(int i=0;i&lt;m;i++)</span></span><br><span class="line"><span class="comment">    &#123;</span></span><br><span class="line"><span class="comment">        cin&gt;&gt;u&gt;&gt;v;</span></span><br><span class="line"><span class="comment">        addEdge(u,v);</span></span><br><span class="line"><span class="comment">    &#125;</span></span><br><span class="line"><span class="comment">    </span></span><br><span class="line"><span class="comment">    int ans=0;cnt=0;</span></span><br><span class="line"><span class="comment">    </span></span><br><span class="line"><span class="comment">    queue&lt;int&gt; q;</span></span><br><span class="line"><span class="comment">    for(int i=1;i&lt;=n;i++)       //加入入度为0的点</span></span><br><span class="line"><span class="comment">    &#123;</span></span><br><span class="line"><span class="comment">        if(inDegree[i]==0) q.push(i);</span></span><br><span class="line"><span class="comment">    &#125;</span></span><br><span class="line"><span class="comment">    while(!q.empty())</span></span><br><span class="line"><span class="comment">    &#123;</span></span><br><span class="line"><span class="comment">        int x=q.front();</span></span><br><span class="line"><span class="comment">        q.pop();</span></span><br><span class="line"><span class="comment">        fTime[x]+=1;    //队首点x,完成</span></span><br><span class="line"><span class="comment">        ans=max(ans,fTime[x]);</span></span><br><span class="line"><span class="comment">        for(int i=head[x];i!=0;i=nxt[i])    //遍历x的出边</span></span><br><span class="line"><span class="comment">        &#123;</span></span><br><span class="line"><span class="comment">            fTime[to[i]]=max(fTime[to[i]],fTime[x]);</span></span><br><span class="line"><span class="comment">            if(--inDegree[to[i]]==0) q.push(to[i]);</span></span><br><span class="line"><span class="comment">        &#125;</span></span><br><span class="line"><span class="comment">    &#125;</span></span><br><span class="line"><span class="comment">    cout&lt;&lt;ans&lt;&lt;&quot;\n&quot;;</span></span><br><span class="line"><span class="comment">&#125;</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">int main()&#123;</span></span><br><span class="line"><span class="comment">    int T;cin&gt;&gt;T;</span></span><br><span class="line"><span class="comment">    while(T--)&#123;</span></span><br><span class="line"><span class="comment">        cin&gt;&gt;n&gt;&gt;m;</span></span><br><span class="line"><span class="comment">        solve();</span></span><br><span class="line"><span class="comment">    &#125;</span></span><br><span class="line"><span class="comment">    return 0;</span></span><br><span class="line"><span class="comment">&#125;*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//队列操作另一种写法:</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">int front=1,rear=0;</span></span><br><span class="line"><span class="comment">for(int i=1;i&lt;=n;i++)</span></span><br><span class="line"><span class="comment">&#123;</span></span><br><span class="line"><span class="comment">    if(inDegree[i]==0) q[++rear]=i;</span></span><br><span class="line"><span class="comment">&#125;</span></span><br><span class="line"><span class="comment">while(front&lt;=rear)</span></span><br><span class="line"><span class="comment">&#123;</span></span><br><span class="line"><span class="comment">    int x=q[front++];</span></span><br><span class="line"><span class="comment">    fTime[x]+=1;</span></span><br><span class="line"><span class="comment">    ans=max(ans,fTime[x]);</span></span><br><span class="line"><span class="comment">    for(int i=head[x];i!=0;i=nxt[i])    //遍历x的出边</span></span><br><span class="line"><span class="comment">    &#123;</span></span><br><span class="line"><span class="comment">        fTime[to[i]]=max(fTime[to[i]],fTime[x]);</span></span><br><span class="line"><span class="comment">        if(--inDegree[to[i]]==0) q[++rear]=to[i];</span></span><br><span class="line"><span class="comment">    &#125;</span></span><br><span class="line"><span class="comment">&#125;</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure><h3 id="最小生成树--kruskalomlogm">6.最小生成树--Kruskal:O(m*logm)</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;bits/stdc++.h&gt;</span></span></span><br><span class="line"></span><br><span class="line">using namespace <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">dsu</span> &#123;</span></span><br><span class="line">   public:</span><br><span class="line">    <span class="type">int</span> n;</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="type">int</span>&gt; p;</span><br><span class="line">    dsu(<span class="type">int</span> _n) : n(_n) &#123;</span><br><span class="line">        p.resize(n);</span><br><span class="line">        iota(p.begin(), p.end(), <span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">inline</span> <span class="type">int</span> <span class="title function_">find</span><span class="params">(<span class="type">int</span> x)</span> &#123; <span class="keyword">return</span> (x == p[x] ? x : (p[x] = find(p[x]))); &#125;</span><br><span class="line">    <span class="keyword">inline</span> <span class="type">bool</span> <span class="title function_">unite</span><span class="params">(<span class="type">int</span> x, <span class="type">int</span> y)</span> &#123;</span><br><span class="line">        x = find(x);</span><br><span class="line">        y = find(y);</span><br><span class="line">        <span class="keyword">if</span> (x != y) &#123;</span><br><span class="line">            p[x] = y;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    ios::sync_with_stdio(<span class="literal">false</span>);</span><br><span class="line">    <span class="built_in">cin</span>.tie(<span class="number">0</span>);</span><br><span class="line">    <span class="type">int</span> tt;</span><br><span class="line">    <span class="built_in">cin</span> &gt;&gt; tt;</span><br><span class="line">    <span class="keyword">while</span> (tt--) &#123;</span><br><span class="line">        <span class="type">int</span> n, m;</span><br><span class="line">        <span class="built_in">cin</span> &gt;&gt; n &gt;&gt; m;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">array</span>&lt;<span class="type">int</span>, <span class="number">3</span>&gt;&gt; e(m);</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; m; i++) &#123;</span><br><span class="line">            <span class="type">int</span> u, v, w;</span><br><span class="line">            <span class="built_in">cin</span> &gt;&gt; u &gt;&gt; v &gt;&gt; w;</span><br><span class="line">            --u; --v;</span><br><span class="line">            e[i] = &#123;u, v, w&#125;;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="type">int</span>&gt; <span class="title function_">p</span><span class="params">(m)</span>;</span><br><span class="line">        iota(p.begin(), p.end(), <span class="number">0</span>);</span><br><span class="line">        sort(p.begin(), p.end(), [&amp;](<span class="type">int</span> u, <span class="type">int</span> v) &#123;</span><br><span class="line">            <span class="keyword">return</span> e[u][<span class="number">2</span>] &lt; e[v][<span class="number">2</span>];</span><br><span class="line">        &#125;);</span><br><span class="line">        dsu d = dsu(n);</span><br><span class="line">        <span class="type">long</span> <span class="type">long</span> ans = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i : p) &#123;</span><br><span class="line">            <span class="type">int</span> u = e[i][<span class="number">0</span>], v = e[i][<span class="number">1</span>];</span><br><span class="line">            <span class="keyword">if</span> (d.unite(u, v)) &#123;</span><br><span class="line">                ans += e[i][<span class="number">2</span>];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; ans &lt;&lt; <span class="string">&#x27;\n&#x27;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="网络流--dinic算法">7.网络流--Dinic算法</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//Dinic算法:n点m边有向图,每条边有最大容量,求s到t的最大流</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;queue&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line">using namespace <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">const</span> <span class="type">long</span> <span class="type">long</span> inf=<span class="number">2005020600</span>;</span><br><span class="line"><span class="type">int</span> n,m,s,t,u,v;</span><br><span class="line"><span class="type">long</span> <span class="type">long</span> w,ans,dis[<span class="number">105</span>];</span><br><span class="line"><span class="type">int</span> tot=<span class="number">1</span>,now[<span class="number">105</span>],head[<span class="number">105</span>];</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">node</span> &#123;</span></span><br><span class="line">    <span class="type">int</span> to,net;</span><br><span class="line">    <span class="type">long</span> <span class="type">long</span> val;</span><br><span class="line">&#125; e[<span class="number">10010</span>];</span><br><span class="line"></span><br><span class="line"><span class="keyword">inline</span> <span class="type">void</span> <span class="title function_">add</span><span class="params">(<span class="type">int</span> u,<span class="type">int</span> v,<span class="type">long</span> <span class="type">long</span> w)</span> &#123;</span><br><span class="line">    e[++tot].to=v;</span><br><span class="line">    e[tot].val=w;</span><br><span class="line">    e[tot].net=head[u];</span><br><span class="line">    head[u]=tot;</span><br><span class="line">    </span><br><span class="line">    e[++tot].to=u;</span><br><span class="line">    e[tot].val=<span class="number">0</span>;</span><br><span class="line">    e[tot].net=head[v];</span><br><span class="line">    head[v]=tot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">inline</span> <span class="type">int</span> <span class="title function_">bfs</span><span class="params">()</span> &#123;  <span class="comment">//在残量网络中构造分层图</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=n;i++) dis[i]=inf;</span><br><span class="line">    <span class="built_in">queue</span>&lt;<span class="type">int</span>&gt; q;</span><br><span class="line">    q.push(s);</span><br><span class="line">    dis[s]=<span class="number">0</span>;</span><br><span class="line">    now[s]=head[s];</span><br><span class="line">    <span class="keyword">while</span>(!q.empty()) &#123;</span><br><span class="line">        <span class="type">int</span> x=q.front();</span><br><span class="line">        q.pop();</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=head[x];i;i=e[i].net) &#123;</span><br><span class="line">            <span class="type">int</span> v=e[i].to;</span><br><span class="line">            <span class="keyword">if</span>(e[i].val&gt;<span class="number">0</span>&amp;&amp;dis[v]==inf) &#123;</span><br><span class="line">                q.push(v);</span><br><span class="line">                now[v]=head[v];</span><br><span class="line">                dis[v]=dis[x]+<span class="number">1</span>;</span><br><span class="line">                <span class="keyword">if</span>(v==t) <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">inline</span> <span class="type">long</span> <span class="type">long</span> <span class="title function_">dfs</span><span class="params">(<span class="type">int</span> x,<span class="type">long</span> <span class="type">long</span> sum)</span> &#123;  <span class="comment">//sum是整条增广路对最大流的贡献</span></span><br><span class="line">    <span class="keyword">if</span>(x==t) <span class="keyword">return</span> sum;</span><br><span class="line">    <span class="type">long</span> <span class="type">long</span> k,res=<span class="number">0</span>;  <span class="comment">//k是当前最小的剩余容量</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=now[x];i&amp;&amp;sum;i=e[i].net) &#123;</span><br><span class="line">        now[x]=i;  <span class="comment">//当前弧优化</span></span><br><span class="line">        <span class="type">int</span> v=e[i].to;</span><br><span class="line">        <span class="keyword">if</span>(e[i].val&gt;<span class="number">0</span>&amp;&amp;(dis[v]==dis[x]+<span class="number">1</span>)) &#123;</span><br><span class="line">            k=dfs(v,min(sum,e[i].val));</span><br><span class="line">            <span class="keyword">if</span>(k==<span class="number">0</span>) dis[v]=inf;  <span class="comment">//剪枝，去掉增广完毕的点</span></span><br><span class="line">            e[i].val-=k;</span><br><span class="line">            e[i^<span class="number">1</span>].val+=k;</span><br><span class="line">            res+=k;  <span class="comment">//res表示经过该点的所有流量和（相当于流出的总量）</span></span><br><span class="line">            sum-=k;  <span class="comment">//sum表示经过该点的剩余流量</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> res;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">int</span> T;<span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>,&amp;T);</span><br><span class="line">    <span class="keyword">while</span>(T--)&#123;</span><br><span class="line">        <span class="built_in">scanf</span>(<span class="string">&quot;%d%d%d%d&quot;</span>,&amp;n,&amp;m,&amp;s,&amp;t);</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=m;i++) &#123;</span><br><span class="line">            <span class="built_in">scanf</span>(<span class="string">&quot;%d%d%lld&quot;</span>,&amp;u,&amp;v,&amp;w);</span><br><span class="line">            add(u,v,w);</span><br><span class="line">        &#125;</span><br><span class="line">        ans=<span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>(bfs()) &#123;</span><br><span class="line">            ans+=dfs(s,inf);  <span class="comment">//流量守恒（流入=流出）</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%lld\n&quot;</span>,ans);</span><br><span class="line">        tot=<span class="number">1</span>;ans=<span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;=n;i++) now[i]=head[i]=<span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="二分图匹配on3">8.二分图匹配:O(n^3)</h3><h4 id="无权">(1)无权</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;queue&gt;</span></span></span><br><span class="line">using namespace <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//无权二分图匹配--HK算法:DFS,若每次调用时,匹配成功,则匹配数+1;否则不变.</span></span><br><span class="line"><span class="comment">//总复杂度:O(mn).</span></span><br><span class="line"><span class="type">int</span> n;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HK</span>&#123;</span></span><br><span class="line">public:</span><br><span class="line">    <span class="type">int</span> n;</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="type">int</span>&gt;&gt; g;</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="type">int</span>&gt;match;</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="type">int</span>&gt;vis;</span><br><span class="line">    HK(<span class="type">int</span> _n):n(_n),g(_n+<span class="number">1</span>),match(_n+<span class="number">1</span>),vis(_n+<span class="number">1</span>)&#123;&#125;</span><br><span class="line">    <span class="type">void</span> <span class="title function_">add</span><span class="params">(<span class="type">int</span> u,<span class="type">int</span> v)</span> &#123;g[u].push_back(v);&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="type">bool</span> <span class="title function_">find</span><span class="params">(<span class="type">int</span> x)</span>&#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i:g[x])         <span class="comment">//遍历x所有出边的终点</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">if</span>(!vis[i])</span><br><span class="line">            &#123;</span><br><span class="line">                vis[i]=<span class="literal">true</span>;</span><br><span class="line">                <span class="keyword">if</span>(!match[i]||find(match[i]))</span><br><span class="line">                    <span class="comment">//若该点未匹配,进行匹配;</span></span><br><span class="line">                    <span class="comment">//若已匹配,递归该点左边匹配的点,看是否能换一个点匹配,若可以,返回匹配成功;否则,匹配失败.</span></span><br><span class="line">                &#123;</span><br><span class="line">                    match[i]=x;        <span class="comment">//match[y]=x表示:左边点x,匹配到右边点y.</span></span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">int</span> <span class="title function_">solve</span><span class="params">()</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">int</span> res=<span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=n;i++)</span><br><span class="line">        &#123;</span><br><span class="line">            fill(vis.begin(),vis.end(),<span class="literal">false</span>);</span><br><span class="line">            <span class="keyword">if</span>(find(i)) res+=<span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span>&#123;</span></span><br><span class="line">    <span class="type">int</span> first,second;</span><br><span class="line">&#125;male[<span class="number">405</span>],female[<span class="number">405</span>];</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    ios::sync_with_stdio(<span class="literal">false</span>);</span><br><span class="line">    <span class="built_in">cin</span>.tie(<span class="number">0</span>);</span><br><span class="line">    <span class="built_in">cin</span>&gt;&gt;n;</span><br><span class="line">    HK <span class="title function_">k</span><span class="params">(n)</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=n;i++) <span class="built_in">cin</span>&gt;&gt;male[i].first;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=n;i++) <span class="built_in">cin</span>&gt;&gt;male[i].second;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=n;i++) <span class="built_in">cin</span>&gt;&gt;female[i].first;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=n;i++) <span class="built_in">cin</span>&gt;&gt;female[i].second;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=n;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">1</span>;j&lt;=n;j++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">if</span>(male[i].first&gt;=female[j].second&amp;&amp;female[j].first&gt;=male[i].second) k.add(i,j);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;k.solve()&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="有权">(2)有权</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//E5.D</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cstring&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ll long long</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ul unsigned long long</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> pr pair<span class="string">&lt;ll,ll&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> MAX 250</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> inf 0x3f3f3f3f3f</span></span><br><span class="line">using namespace <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> n;          <span class="comment">//两部各n个点的二分图</span></span><br><span class="line">ll x,y;         <span class="comment">//点坐标</span></span><br><span class="line">pr from[MAX],to[MAX];       <span class="comment">//记录左/右点坐标</span></span><br><span class="line"><span class="type">int</span> match[MAX];     <span class="comment">//右点匹配的左点</span></span><br><span class="line"><span class="type">int</span> va[MAX],vb[MAX];    <span class="comment">//标记点是否在交替路中</span></span><br><span class="line">ll w[MAX][MAX];</span><br><span class="line">ll la[MAX],lb[MAX];     <span class="comment">//左/右顶标</span></span><br><span class="line">ll slack[MAX];          <span class="comment">//松弛数组</span></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">init</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="built_in">memset</span>(w,<span class="number">0xbf</span>,<span class="keyword">sizeof</span>(w));</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=n;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">1</span>;j&lt;=n;j++) w[i][j]=-<span class="built_in">abs</span>(from[i].first-to[j].first)-<span class="built_in">abs</span>(from[i].second-to[j].second);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">bool</span> <span class="title function_">dfs</span><span class="params">(<span class="type">int</span> x)</span>&#123;</span><br><span class="line">    va[x]=<span class="number">1</span>;            <span class="comment">//标记x在交替路中</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> y=<span class="number">1</span>;y&lt;=n;y++)           <span class="comment">//遍历点x的所有边:可以据情况改动.</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span>(vb[y]) <span class="keyword">continue</span>;</span><br><span class="line">        ll t=la[x]+lb[y]-w[x][y];</span><br><span class="line">        <span class="keyword">if</span>(t==<span class="number">0</span>)            <span class="comment">//相等子图</span></span><br><span class="line">        &#123;</span><br><span class="line">            vb[y]=<span class="number">1</span>;            <span class="comment">//标记y在交替路中</span></span><br><span class="line">            <span class="keyword">if</span>(match[y]==<span class="number">-1</span>||dfs(match[y]))</span><br><span class="line">            &#123;</span><br><span class="line">                match[y]=x;         <span class="comment">//找到增广路,更新匹配</span></span><br><span class="line">                <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> slack[y]=min(slack[y],t);      <span class="comment">//不在相等子图中,更新松弛数组</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">ll <span class="title function_">KM</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="built_in">memset</span>(match,<span class="number">-1</span>,<span class="keyword">sizeof</span>(match));         <span class="comment">//初始化match[y]=-1:未匹配</span></span><br><span class="line">    <span class="built_in">memset</span>(lb,<span class="number">0</span>,<span class="keyword">sizeof</span>(lb));                <span class="comment">//初始化右顶标为0.</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=n;i++)           <span class="comment">//初始化左顶标为与之相连边的最大权值</span></span><br><span class="line">    &#123;</span><br><span class="line">        la[i]=-inf;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">1</span>;j&lt;=n;j++) la[i]=max(la[i],w[i][j]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=n;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">memset</span>(slack,<span class="number">0x3f</span>,<span class="keyword">sizeof</span>(slack));</span><br><span class="line">        <span class="keyword">while</span>(<span class="literal">true</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="built_in">memset</span>(va,<span class="number">0</span>,<span class="keyword">sizeof</span>(va));</span><br><span class="line">            <span class="built_in">memset</span>(vb,<span class="number">0</span>,<span class="keyword">sizeof</span>(vb));</span><br><span class="line">            <span class="keyword">if</span>(dfs(i)) <span class="keyword">break</span>;           <span class="comment">//找到增广路,退出</span></span><br><span class="line">            ll d=inf;</span><br><span class="line">            <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">1</span>;j&lt;=n;j++)</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="keyword">if</span>(!vb[j]) d=min(d,slack[j]);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">1</span>;j&lt;=n;j++)       <span class="comment">//更新顶标</span></span><br><span class="line">            &#123;</span><br><span class="line">                <span class="keyword">if</span>(va[j]) la[j]-=d;     <span class="comment">//S中的点,左顶标-d.</span></span><br><span class="line">                <span class="keyword">if</span>(vb[j]) lb[j]+=d;     <span class="comment">//T中的点,右顶标+d.</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    ll ans=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=n;i++) ans+=w[match[i]][i];</span><br><span class="line">    <span class="keyword">return</span> ans;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">int</span> t;<span class="built_in">cin</span>&gt;&gt;t;</span><br><span class="line">    <span class="keyword">while</span>(t--)&#123;</span><br><span class="line">        <span class="built_in">cin</span>&gt;&gt;n;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=n;i++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="built_in">cin</span>&gt;&gt;x&gt;&gt;y;</span><br><span class="line">            from[i]=<span class="built_in">make_pair</span>(x,y);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;=n;i++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="built_in">cin</span>&gt;&gt;x&gt;&gt;y;</span><br><span class="line">            to[i]=<span class="built_in">make_pair</span>(x,y);</span><br><span class="line">        &#125;</span><br><span class="line">        init();             <span class="comment">//init()环节:计算权重矩阵</span></span><br><span class="line">        <span class="built_in">cout</span>&lt;&lt;-KM()&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="计算几何">计算几何</h2><h3 id="判断三点是否共线三维">1.判断三点是否共线(三维)</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Point</span> &#123;</span>  </span><br><span class="line">    <span class="type">double</span> x, y, z;  </span><br><span class="line">&#125;;  </span><br><span class="line">  </span><br><span class="line"><span class="type">bool</span> <span class="title function_">areThreePointsCollinear</span><span class="params">(<span class="keyword">struct</span> Point p1, <span class="keyword">struct</span> Point p2, <span class="keyword">struct</span> Point p3)</span> &#123;  </span><br><span class="line">    <span class="comment">// 计算向量 v1 = p2 - p1, v2 = p3 - p2  </span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">Point</span> <span class="title">v1</span> =</span> &#123;p2.x - p1.x, p2.y - p1.y, p2.z - p1.z&#125;;  </span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">Point</span> <span class="title">v2</span> =</span> &#123;p3.x - p2.x, p3.y - p2.y, p3.z - p2.z&#125;;  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">// 计算向量叉积 v1 × v2，如果叉积为0，则三点共线  </span></span><br><span class="line">    <span class="type">double</span> crossProduct[<span class="number">3</span>] = &#123;v1.y * v2.z - v1.z * v2.y,  </span><br><span class="line">                             v1.z * v2.x - v1.x * v2.z,  </span><br><span class="line">                             v1.x * v2.y - v1.y * v2.x&#125;;  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">// 如果叉积的绝对值小于一个很小的值（例如 1e-9），则可以认为叉积为0  </span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">fabs</span>(crossProduct[<span class="number">0</span>]) &lt; <span class="number">1e-9</span> &amp;&amp; <span class="built_in">fabs</span>(crossProduct[<span class="number">1</span>]) &lt; <span class="number">1e-9</span> &amp;&amp; <span class="built_in">fabs</span>(crossProduct[<span class="number">2</span>]) &lt; <span class="number">1e-9</span>;  </span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure><h3 id="判断两线段位置关系相交平行无关">2.判断两线段位置关系:相交/平行/无关</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="type">long</span> <span class="type">long</span> ll;</span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span>&#123;</span></span><br><span class="line">    ll x,y;</span><br><span class="line">&#125;P;</span><br><span class="line"></span><br><span class="line">ll <span class="title function_">direction</span><span class="params">(P pi,P pj,P pk)</span>&#123;</span><br><span class="line">    <span class="keyword">return</span> (pk.x-pi.x)*(pj.y-pi.y)-(pj.x-pi.x)*(pk.y-pi.y);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">bool</span> <span class="title function_">on_Segment</span><span class="params">(P pi,P pj,P pk)</span>&#123;        <span class="comment">//pk是否在线段pipj上.</span></span><br><span class="line">    <span class="keyword">if</span>(min(pi.x,pj.x)&lt;=pk.x&amp;&amp;pk.x&lt;=max(pi.x,pj.x)&amp;&amp;min(pi.y,pj.y)&lt;=pk.y&amp;&amp;pk.y&lt;=max(pi.y,pj.y)) <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">bool</span> <span class="title function_">parallel</span><span class="params">(P p1,P p2,P p3,P p4)</span>&#123;</span><br><span class="line">    <span class="keyword">if</span>((p2.y-p1.y)*(p4.x-p3.x)==(p4.y-p3.y)*(p2.x-p1.x)) <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">Segments_Intersect</span><span class="params">(P p1,P p2,P p3,P p4)</span>&#123;       <span class="comment">//判断线段p1p2和线段p3p4是否相交</span></span><br><span class="line">    ll d1=direction(p3,p4,p1);</span><br><span class="line">    ll d2=direction(p3,p4,p2);</span><br><span class="line">    ll d3=direction(p1,p2,p3);</span><br><span class="line">    ll d4=direction(p1,p2,p4);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span>(((d1&gt;<span class="number">0</span>&amp;&amp;d2&lt;<span class="number">0</span>)||(d1&lt;<span class="number">0</span>&amp;&amp;d2&gt;<span class="number">0</span>))&amp;&amp;((d3&gt;<span class="number">0</span>&amp;&amp;d4&lt;<span class="number">0</span>)||(d3&lt;<span class="number">0</span>&amp;&amp;d4&gt;<span class="number">0</span>))) <span class="built_in">cout</span>&lt;&lt;<span class="string">&quot;intersect\n&quot;</span>;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span>(d1==<span class="number">0</span>&amp;&amp;on_Segment(p3,p4,p1)) <span class="built_in">cout</span>&lt;&lt;<span class="string">&quot;intersect\n&quot;</span>;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span>(d2==<span class="number">0</span>&amp;&amp;on_Segment(p3,p4,p2)) <span class="built_in">cout</span>&lt;&lt;<span class="string">&quot;intersect\n&quot;</span>;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span>(d3==<span class="number">0</span>&amp;&amp;on_Segment(p1,p2,p3)) <span class="built_in">cout</span>&lt;&lt;<span class="string">&quot;intersect\n&quot;</span>;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span>(d4==<span class="number">0</span>&amp;&amp;on_Segment(p1,p2,p4)) <span class="built_in">cout</span>&lt;&lt;<span class="string">&quot;intersect\n&quot;</span>;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span>(parallel(p1,p2,p3,p4)) <span class="built_in">cout</span>&lt;&lt;<span class="string">&quot;parallel\n&quot;</span>;</span><br><span class="line">    <span class="keyword">else</span> <span class="built_in">cout</span>&lt;&lt;<span class="string">&quot;neither\n&quot;</span>;</span><br><span class="line">&#125;</span><br><span class="line">P p1,q1,p2,q2;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">int</span> t;<span class="built_in">cin</span>&gt;&gt;t;</span><br><span class="line">    <span class="keyword">while</span>(t--)&#123;</span><br><span class="line">        <span class="built_in">cin</span>&gt;&gt;p1.x&gt;&gt;p1.y&gt;&gt;q1.x&gt;&gt;q1.y;</span><br><span class="line">        <span class="built_in">cin</span>&gt;&gt;p2.x&gt;&gt;p2.y&gt;&gt;q2.x&gt;&gt;q2.y;</span><br><span class="line">        Segments_Intersect(p1,q1,p2,q2);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="求点到线段最小距离">3.求点到线段最小距离</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Pt</span>&#123;</span></span><br><span class="line">    <span class="type">double</span> x,y;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Segment</span>&#123;</span></span><br><span class="line">    Pt p1,p2;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="type">double</span> <span class="title function_">getDis</span><span class="params">(Pt p1,Pt p2)</span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">sqrt</span>(<span class="built_in">pow</span>(p2.x-p1.x,<span class="number">2</span>)+<span class="built_in">pow</span>(p2.y-p1.y,<span class="number">2</span>));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">double</span> <span class="title function_">disToSegment</span><span class="params">(Pt p,Segment l)</span>&#123;</span><br><span class="line">    <span class="type">double</span> len=getDis(l.p1, l.p2);</span><br><span class="line">    <span class="keyword">if</span> (len==<span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">return</span> getDis(p, l.p1);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">double</span> v = ((p.x - l.p1.x) * (l.p2.x - l.p1.x) + (p.y - l.p1.y) * (l.p2.y - l.p1.y)) / <span class="built_in">pow</span>(len, <span class="number">2</span>);</span><br><span class="line">    <span class="keyword">if</span> (v &lt;= <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">return</span> getDis(p, l.p1);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (v &gt;= <span class="number">1</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">return</span> getDis(p, l.p2);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    &#123;</span><br><span class="line">        Pt u=&#123; l.p1.x+v*(l.p2.x-l.p1.x),l.p1.y+v*(l.p2.y-l.p1.y)&#125;;</span><br><span class="line">        <span class="keyword">return</span> getDis(p,u);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">double</span> xa,ya,xp,yp,xq,yq;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="type">int</span> t;<span class="built_in">cin</span>&gt;&gt;t;</span><br><span class="line">    <span class="keyword">while</span>(t--)&#123;</span><br><span class="line">        <span class="built_in">cin</span>&gt;&gt;xa&gt;&gt;ya&gt;&gt;xp&gt;&gt;yp&gt;&gt;xq&gt;&gt;yq;</span><br><span class="line">        Pt p =&#123;xa,ya&#125;;</span><br><span class="line">        Segment l = &#123;&#123;xp,yp&#125;,&#123;xq,yq&#125;&#125;;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%.3f\n&quot;</span>,disToSegment(p,l));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="求凸包面积">4.求凸包面积</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;algorithm&gt;</span></span></span><br><span class="line">using namespace <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//E:计算凸包面积</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Vec</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">    <span class="type">long</span> <span class="type">long</span> x, y;</span><br><span class="line">    Vec() &#123;&#125;</span><br><span class="line">    Vec(<span class="type">long</span> <span class="type">long</span> x, <span class="type">long</span> <span class="type">long</span> y) &#123; this-&gt;x = x; this-&gt;y = y; &#125;</span><br><span class="line">    <span class="type">long</span> <span class="type">long</span> <span class="title function_">len2</span><span class="params">()</span> <span class="type">const</span> &#123; <span class="keyword">return</span> x * x + y * y; &#125;</span><br><span class="line">    <span class="type">void</span> <span class="title function_">read</span><span class="params">()</span> &#123; <span class="built_in">scanf</span>(<span class="string">&quot;%lld%lld&quot;</span>, &amp;x, &amp;y); &#125;</span><br><span class="line">    <span class="type">void</span> <span class="title function_">print</span><span class="params">()</span> &#123; <span class="built_in">printf</span>(<span class="string">&quot;%lld %lld\n&quot;</span>, x, y); &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">typedef</span> Vec Point;</span><br><span class="line"></span><br><span class="line">Vec operator + (<span class="type">const</span> Vec &amp;a, <span class="type">const</span> Vec &amp;b) &#123; <span class="keyword">return</span> Vec(a.x + b.x, a.y + b.y); &#125;</span><br><span class="line">Vec operator - (<span class="type">const</span> Vec &amp;a, <span class="type">const</span> Vec &amp;b) &#123; <span class="keyword">return</span> Vec(a.x - b.x, a.y - b.y); &#125;</span><br><span class="line">Vec operator * (<span class="type">long</span> <span class="type">long</span> a, <span class="type">const</span> Vec &amp;b) &#123; <span class="keyword">return</span> Vec(a * b.x, a * b.y); &#125;</span><br><span class="line"><span class="comment">// cross product</span></span><br><span class="line"><span class="type">long</span> <span class="type">long</span> operator * (<span class="type">const</span> Vec &amp;a, <span class="type">const</span> Vec &amp;b) &#123; <span class="keyword">return</span> a.x * b.y - b.x * a.y; &#125;</span><br><span class="line"><span class="comment">// inner product</span></span><br><span class="line"><span class="type">long</span> <span class="type">long</span> operator ^ (<span class="type">const</span> Vec &amp;a, <span class="type">const</span> Vec &amp;b) &#123; <span class="keyword">return</span> a.x * b.x + a.y * b.y; &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="built_in">vector</span> &lt;Point&gt; Polygon;</span><br><span class="line"><span class="keyword">typedef</span> Polygon Points;</span><br><span class="line"></span><br><span class="line"><span class="type">bool</span> <span class="title function_">onleft</span><span class="params">(<span class="type">const</span> Vec &amp;a, <span class="type">const</span> Vec &amp;b)</span> &#123; <span class="keyword">return</span> a * b &lt; <span class="number">0</span>; &#125;       <span class="comment">//cross product</span></span><br><span class="line"><span class="type">bool</span> <span class="title function_">onright</span><span class="params">(<span class="type">const</span> Vec &amp;a, <span class="type">const</span> Vec &amp;b)</span> &#123; <span class="keyword">return</span> a * b &gt; <span class="number">0</span>; &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//Graham扫描算法求凸包点集:函数返回逆时针排列的点集.</span></span><br><span class="line"><span class="comment">// c0 - c1 - ... - ck (- c0), counter-clockwise</span></span><br><span class="line">Polygon <span class="title function_">convex</span><span class="params">(Points p)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> sz = p.size();</span><br><span class="line">    sort(p.begin(), p.end(), [&amp;](<span class="type">const</span> Point &amp;a, <span class="type">const</span> Point &amp;b) &#123; <span class="keyword">return</span> a.x != b.x ? a.x &lt; b.x : a.y &lt; b.y; &#125;);                   <span class="comment">//先按x升序,再按y升序排列.</span></span><br><span class="line">    Polygon <span class="title function_">c</span><span class="params">(p.size() + <span class="number">1</span>)</span>;</span><br><span class="line">    <span class="type">int</span> n = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; sz; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">while</span> (n &gt; <span class="number">1</span> &amp;&amp; !onleft(p[i] - c[n - <span class="number">2</span>], c[n - <span class="number">1</span>] - c[n - <span class="number">2</span>])) n--;</span><br><span class="line">        c[n++] = p[i];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">int</span> t = n;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = sz - <span class="number">1</span>; i &gt;= <span class="number">0</span>; i--)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">while</span> (n &gt; t &amp;&amp; !onleft(p[i] - c[n - <span class="number">2</span>], c[n - <span class="number">1</span>] - c[n - <span class="number">2</span>])) n--;</span><br><span class="line">        c[n++] = p[i];</span><br><span class="line">    &#125;</span><br><span class="line">    c.resize(--n);</span><br><span class="line">    <span class="keyword">return</span> c;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//叉乘法求面积</span></span><br><span class="line"><span class="type">long</span> <span class="type">long</span> <span class="title function_">areadb</span><span class="params">(Polygon &amp;p)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">long</span> <span class="type">long</span> r = <span class="number">0</span>;</span><br><span class="line">    <span class="type">int</span> n = p.size();</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++)</span><br><span class="line">        r += (p[i] - p[<span class="number">0</span>]) * (p[(i + <span class="number">1</span>) % n] - p[i]);</span><br><span class="line">    <span class="keyword">return</span> r;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">long</span> <span class="type">long</span> <span class="title function_">diameter2</span><span class="params">(Polygon &amp;p)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">long</span> <span class="type">long</span> r = <span class="number">0</span>;</span><br><span class="line">    <span class="type">int</span> n = p.size();</span><br><span class="line">    <span class="type">int</span> a = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        Vec e = p[(i + <span class="number">1</span>) % n] - p[i];</span><br><span class="line">        <span class="keyword">while</span> (onleft(p[(a + <span class="number">1</span>) % n] - p[a % n], e) || a == i)</span><br><span class="line">        &#123;</span><br><span class="line">            r = max(&#123;r, (p[i] - p[a]).len2(), (p[(i + <span class="number">1</span>) % n] - p[a]).len2()&#125;);</span><br><span class="line">            a = (a + <span class="number">1</span>) % n;</span><br><span class="line">        &#125;</span><br><span class="line">        r = max(&#123;r, (p[i] - p[a]).len2(), (p[(i + <span class="number">1</span>) % n] - p[a]).len2()&#125;);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> r;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> n;</span><br><span class="line">Points p;       <span class="comment">//点集</span></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">solve</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>, &amp;n);</span><br><span class="line">    p.resize(n);</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++)</span><br><span class="line">        p[i].read();        <span class="comment">//依据函数void read(),读入两个数</span></span><br><span class="line">    p = convex(p);</span><br><span class="line">    <span class="type">long</span> <span class="type">long</span> r = areadb(p);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%lld.%lld\n&quot;</span>, r / <span class="number">2</span>, (r &amp; <span class="number">1</span>) * <span class="number">5</span>);      <span class="comment">//保留1位小数</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> T;</span><br><span class="line">    <span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>, &amp;T);</span><br><span class="line">    <span class="keyword">while</span> (T--)</span><br><span class="line">        solve();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="fft">FFT</h2><h3 id="dft模版--大数乘法">1.DFT模版--大数乘法</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cmath&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstring&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> N (1&lt;&lt;18)+5        <span class="comment">//超长整数位数</span></span></span><br><span class="line"><span class="type">const</span> <span class="type">double</span> pi=acosl(<span class="number">-1.0</span>);</span><br><span class="line">using namespace <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">complex</span>&#123;</span></span><br><span class="line">    <span class="type">double</span> r,i;</span><br><span class="line">    <span class="type">complex</span>()&#123;r=<span class="number">0</span>;i=<span class="number">0</span>;&#125;</span><br><span class="line">    <span class="type">complex</span>(<span class="type">double</span> re,<span class="type">double</span> im)&#123;r=re;i=im;&#125;</span><br><span class="line">    <span class="type">double</span> <span class="title function_">len2</span><span class="params">()</span><span class="type">const</span>&#123;<span class="keyword">return</span> r*r+i*i;&#125;</span><br><span class="line">    <span class="type">complex</span> <span class="title function_">bar</span><span class="params">()</span> <span class="type">const</span> &#123;<span class="keyword">return</span> <span class="type">complex</span>(r,-i);&#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="type">complex</span> operator + (<span class="type">const</span> <span class="type">complex</span> &amp;x,<span class="type">const</span> <span class="type">complex</span> &amp;y)&#123;<span class="keyword">return</span> <span class="type">complex</span>(x.r+y.r,x.i+y.i);&#125;</span><br><span class="line"><span class="type">complex</span> operator - (<span class="type">const</span> <span class="type">complex</span> &amp;x,<span class="type">const</span> <span class="type">complex</span> &amp;y)&#123;<span class="keyword">return</span> <span class="type">complex</span>(x.r-y.r,x.i-y.i);&#125;</span><br><span class="line"><span class="type">complex</span> operator * (<span class="type">double</span> k,<span class="type">const</span> <span class="type">complex</span> &amp;y)&#123;<span class="keyword">return</span> <span class="type">complex</span>(k*y.r,k*y.i);&#125;</span><br><span class="line"><span class="type">complex</span> operator * (<span class="type">const</span> <span class="type">complex</span> &amp;y,<span class="type">double</span> k)&#123;<span class="keyword">return</span> <span class="type">complex</span>(k*y.r,k*y.i);&#125;</span><br><span class="line"><span class="type">complex</span> operator * (<span class="type">const</span> <span class="type">complex</span> &amp;x,<span class="type">const</span> <span class="type">complex</span> &amp;y)&#123;<span class="keyword">return</span> <span class="type">complex</span>(x.r*y.r-x.i*y.i,x.r*y.i+x.i*y.r);&#125;</span><br><span class="line"><span class="type">complex</span> operator / (<span class="type">const</span> <span class="type">complex</span> &amp;x,<span class="type">double</span> y)&#123;<span class="keyword">return</span> <span class="type">complex</span>(x.r/y,x.i/y);&#125;</span><br><span class="line"><span class="type">complex</span> operator / (<span class="type">const</span> <span class="type">complex</span> &amp;x,<span class="type">const</span> <span class="type">complex</span> &amp;y)&#123;<span class="keyword">return</span> x*y.bar()/y.len2();&#125;</span><br><span class="line"><span class="type">const</span> <span class="type">double</span> pi=acosl(<span class="number">-1.0</span>);</span><br><span class="line"></span><br><span class="line"><span class="type">char</span> s[N],t[N];</span><br><span class="line"><span class="type">complex</span> a[N],b[N],v[N];</span><br><span class="line"><span class="type">int</span> rev[N],ans[N];</span><br><span class="line"><span class="type">int</span> lens,lent,len;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">DFT</span><span class="params">(<span class="type">complex</span> c[],<span class="type">int</span> inv=<span class="number">0</span>)</span>&#123;            <span class="comment">//由系数表达c,求点值表达v,重装回c中.</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;len;i++) v[rev[i]]=c[i];</span><br><span class="line">        <span class="comment">//c[0,2,...,2n-2]放在v[0,...,n-1];c[1,...,2n-3]放在v[n,...,2n-2].</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">2</span>;i&lt;=len;i&lt;&lt;=<span class="number">1</span>)           <span class="comment">//迭代实现</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">complex</span> <span class="title function_">wn</span><span class="params">(cosl(<span class="number">2</span>*pi/i),sinl(<span class="number">2</span>*pi/i))</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">0</span>;j&lt;len;j+=i)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="type">complex</span> <span class="title function_">w</span><span class="params">(<span class="number">1</span>,<span class="number">0</span>)</span>;</span><br><span class="line">            <span class="keyword">for</span>(<span class="type">int</span> k=<span class="number">0</span>;k&lt;(i&gt;&gt;<span class="number">1</span>);k++)</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="type">complex</span> x=v[j+k],y=v[j+k+(i&gt;&gt;<span class="number">1</span>)]*w;</span><br><span class="line">                v[j+k]=x+y;</span><br><span class="line">                v[j+k+(i&gt;&gt;<span class="number">1</span>)]=x-y;</span><br><span class="line">                w=w*wn;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(inv)             <span class="comment">//逆DFT:点值表达-&gt;系数表达</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;len;i++) v[i]=v[i]/len;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>,j=len<span class="number">-1</span>;i&lt;j;i++,j--) swap(v[i],v[j]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;len;i++) c[i]=v[i];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">multiple</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="built_in">scanf</span>(<span class="string">&quot;%s&quot;</span>,s);<span class="built_in">scanf</span>(<span class="string">&quot;%s&quot;</span>,t);</span><br><span class="line">    lens=<span class="built_in">strlen</span>(s);lent=<span class="built_in">strlen</span>(t);len=<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">while</span>(len&lt;=lens+lent) len&lt;&lt;=<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;len;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        a[i]=b[i]=<span class="type">complex</span>(<span class="number">0</span>,<span class="number">0</span>);ans[i]=<span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;lens;i++) a[i]=<span class="type">complex</span>(s[lens<span class="number">-1</span>-i]-<span class="string">&#x27;0&#x27;</span>,<span class="number">0</span>);</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;lent;i++) b[i]=<span class="type">complex</span>(t[lent<span class="number">-1</span>-i]-<span class="string">&#x27;0&#x27;</span>,<span class="number">0</span>);</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;len;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        rev[i]=<span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">1</span>,t=i;j&lt;len;j&lt;&lt;=<span class="number">1</span>,t&gt;&gt;=<span class="number">1</span>) &#123;rev[i]&lt;&lt;=<span class="number">1</span>;rev[i]+=t&amp;<span class="number">1</span>;&#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//rev[0]=0,</span></span><br><span class="line">    DFT(a);DFT(b);</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;len;i++) b[i]=a[i]*b[i];      <span class="comment">//点值相乘</span></span><br><span class="line">    DFT(b,<span class="number">1</span>);</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;len;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        ans[i]+=round(b[i].r);</span><br><span class="line">        ans[i+<span class="number">1</span>]+=ans[i]/<span class="number">10</span>;            <span class="comment">//十进制数--10;八进制数,这两行改为8.</span></span><br><span class="line">        ans[i]%=<span class="number">10</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">while</span>(len&gt;<span class="number">1</span>&amp;&amp;ans[len<span class="number">-1</span>]==<span class="number">0</span>) len-=<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=len<span class="number">-1</span>;i&gt;=<span class="number">0</span>;i--) <span class="built_in">cout</span>&lt;&lt;ans[i];</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;<span class="string">&quot;\n&quot;</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">int</span> T;<span class="built_in">cin</span>&gt;&gt;T;</span><br><span class="line">    <span class="keyword">while</span>(T--) multiple();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="逆dft">2.逆DFT</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//逆DFT:由点值表达-&gt;系数表达</span></span><br><span class="line"><span class="built_in">vector</span>&lt;<span class="type">int</span>&gt; <span class="title function_">computeRev</span><span class="params">(<span class="type">int</span> n)</span>&#123;</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="type">int</span>&gt;rev(n);</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;n;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        rev[i]=<span class="number">0</span>;</span><br><span class="line">        <span class="type">int</span> j,t;</span><br><span class="line">        <span class="keyword">for</span>(j=<span class="number">1</span>,t=i;j&lt;n;j&lt;&lt;=<span class="number">1</span>,t&gt;&gt;=<span class="number">1</span>) &#123;rev[i]&lt;&lt;=<span class="number">1</span>;rev[i]+=t&amp;<span class="number">1</span>;&#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> rev;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">vector</span>&lt;<span class="type">complex</span>&gt; <span class="title function_">inverseDFT</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="type">complex</span>&gt;y,<span class="type">int</span> n)</span>&#123;</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="type">int</span>&gt;rev=computeRev(n);</span><br><span class="line">    <span class="comment">//for(int i=0;i&lt;n;i++) cout&lt;&lt;rev[i]&lt;&lt;&quot; &quot;;</span></span><br><span class="line">    <span class="comment">//cout&lt;&lt;&quot;\n&quot;;</span></span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="type">complex</span>&gt; <span class="title function_">c</span><span class="params">(n)</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;n;i++) c[rev[i]]=y[i];</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">2</span>;i&lt;=n;i&lt;&lt;=<span class="number">1</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">complex</span> <span class="title function_">wn</span><span class="params">(cosl(<span class="number">2</span>*pi/i),sinl(<span class="number">2</span>*pi/i))</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">0</span>;j&lt;n;j+=i)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="type">complex</span> <span class="title function_">w</span><span class="params">(<span class="number">1</span>,<span class="number">0</span>)</span>;</span><br><span class="line">            <span class="keyword">for</span>(<span class="type">int</span> k=<span class="number">0</span>;k&lt;(i&gt;&gt;<span class="number">1</span>);k++)</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="type">complex</span> x=c[j+k],y=c[j+k+(i&gt;&gt;<span class="number">1</span>)]*w;</span><br><span class="line">                c[j+k]=x+y;</span><br><span class="line">                c[j+k+(i&gt;&gt;<span class="number">1</span>)]=x-y;</span><br><span class="line">                w=w*wn;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;n;i++) c[i]=c[i]/n;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>,j=n<span class="number">-1</span>;i&lt;j;i++,j--) swap(c[i],c[j]);</span><br><span class="line">    <span class="keyword">return</span> c;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">int</span> k;<span class="built_in">cin</span>&gt;&gt;k;<span class="type">int</span> n=<span class="built_in">pow</span>(<span class="number">2</span>,k);</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="type">complex</span>&gt; <span class="title function_">y</span><span class="params">(n)</span>;</span><br><span class="line">    <span class="type">double</span> a;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;n;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">cin</span>&gt;&gt;a;y[i]=<span class="type">complex</span>(a,<span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="type">complex</span>&gt;c=inverseDFT(y,n);</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;n;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span>(<span class="built_in">abs</span>(c[i].r<span class="number">-0</span>)&lt;<span class="number">0.005</span>) c[i].r=<span class="number">0</span>;       <span class="comment">//四舍五入保留两位小数时,-0.00写作0.00.</span></span><br><span class="line">        <span class="keyword">if</span>(<span class="built_in">abs</span>(c[i].i<span class="number">-0</span>)&lt;<span class="number">0.005</span>) c[i].i=<span class="number">0</span>;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%.2lf %.2lf\n&quot;</span>,c[i].r,c[i].i);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="啰嗦的解释">3.啰嗦的解释</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//FFT:多项式乘法--两个次数界为n的多项式,theta(n*lgn)时间内完成乘法</span></span><br><span class="line"><span class="comment">//1.系数表达:(a0,a1,...,a(n-1)).霍纳法则:A(x0)=a0+x0(a1+x0(a2+...+x0(a(n-2)+x0*a(n-1))...))--theta(n)完成求值运算</span></span><br><span class="line"><span class="comment">//2.点值表达:n个点值对的集合&#123;(x0,y0),...,(x(n-1),y(n-1))&#125;.所有xk各不相同,满足:yk=A(xk).</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//互逆运算:n个点的求值/插值运算</span></span><br><span class="line"><span class="comment">//由系数表达求点值表达:theta(n^2).</span></span><br><span class="line"><span class="comment">//插值(由点值表达求系数表达):</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//(系数形式)多项式快速相乘:</span></span><br><span class="line"><span class="comment">//朴素算法:系数表达--theta(n^2)</span></span><br><span class="line"><span class="comment">//点值表达--theta(n)</span></span><br><span class="line"><span class="comment">//解释:要插值获得次数界为2n的多项式C,需2n个点值对.</span></span><br><span class="line"><span class="comment">//扩展A:&#123;(x0,y0),...,(x(2n-1),y(2n-1))&#125;,扩展B:&#123;(x0,y0&#x27;),...,(x(2n-1),y(2n-1)&#x27;)&#125;</span></span><br><span class="line"><span class="comment">//C:&#123;(x0,y0*y0&#x27;),...,(x(2n-1),y(2n-1)*y(2n-1)&#x27;)&#125;,基于C(xk)=A(xk)*B(xk).</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//普通乘法:(a0,a1,...,a(n-1)),(b0,b1,...,b(n-1))-&gt;(c0,a1,...,c(2n-2))--theta(n^2).</span></span><br><span class="line"><span class="comment">//快速乘法:</span></span><br><span class="line"><span class="comment">//1.扩展为2n次:(a0,a1,...,a(n-1)),(b0,b1,...,b(n-1))-&gt;(a0,a1,...,a(n-1),0,...,0),(b0,b1,...,b(n-1),0,...,0)</span></span><br><span class="line"><span class="comment">//2,2n阶FFT计算2n阶点值表达:(A(w2n^0),...,A(w2n^(2n-1))),(B(w2n^0),...,B(w2n^(2n-1)))--theta(n*lgn).</span></span><br><span class="line"><span class="comment">//(精心选择的插值点:2n阶单位复根.</span></span><br><span class="line"><span class="comment">//3.点值乘法:得(C(w2n^0),...,C(w2n^(2n-1)))--theta(n).</span></span><br><span class="line"><span class="comment">//4.插值:对2n个点值计算其逆DFT,得(c0,c1,...,c(2n-2))--theta(n*lgn).</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//DFT:y=DFTn(a)--计算n次多项式A(x)在wn^0,...,wn^(n-1)这n个n次单位复根处的值.</span></span><br><span class="line"><span class="comment">//结果:y=(y0,...,y(n-1)),其中:yk=A(wn^k).</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//FFT:利用单位复根特殊性质，在theta(n*lgn)时间内，计算DFTn(a).（朴素算法：theta(n^2)）.</span></span><br></pre></td></tr></table></figure><h2 id="字符串">字符串</h2><h3 id="kmp">1.KMP</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;vector&gt;</span></span></span><br><span class="line">using namespace <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//3.KMP算法</span></span><br><span class="line"><span class="comment">//预处理时间:theta(m);匹配时间:theta(n).</span></span><br><span class="line"><span class="comment">//模式P的前缀函数:pi:&#123;1,2,...,m&#125;-&gt;&#123;0,1,...,m-1&#125;.满足:pi[q]=max&#123;k:k&lt;q且Pk是Pq的后缀&#125;.</span></span><br><span class="line"><span class="built_in">vector</span>&lt;<span class="type">int</span>&gt;prefix(<span class="built_in">string</span> s)&#123;</span><br><span class="line">    <span class="type">int</span> m=(<span class="type">int</span>)s.length();</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="type">int</span>&gt;pi(m);</span><br><span class="line">    pi[<span class="number">0</span>]=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;m;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">int</span> j=pi[i<span class="number">-1</span>];</span><br><span class="line">        <span class="keyword">while</span>(j&gt;<span class="number">0</span>&amp;&amp;s[i]!=s[j]) j=pi[j<span class="number">-1</span>];</span><br><span class="line">        <span class="keyword">if</span>(s[i]==s[j]) j++;</span><br><span class="line">        pi[i]=j;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> pi;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">kmp</span><span class="params">(<span class="built_in">string</span> T,<span class="built_in">string</span> P)</span>&#123;</span><br><span class="line">    <span class="type">int</span> n=(<span class="type">int</span>)T.length(),m=(<span class="type">int</span>)P.length();</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="type">int</span>&gt;pi=prefix(P);</span><br><span class="line">    </span><br><span class="line">    <span class="type">int</span> q=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;n;i++)&#123;</span><br><span class="line">        <span class="keyword">while</span>(q&gt;<span class="number">0</span>&amp;&amp;P[q]!=T[i]) q=pi[q];</span><br><span class="line">        <span class="keyword">if</span>(P[q]==T[i]) q+=<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">if</span>(q==m)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="built_in">cout</span>&lt;&lt;<span class="string">&quot;Pattern occurs with shift &quot;</span>&lt;&lt;i-m;</span><br><span class="line">            q=pi[q];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//判断长为i的前缀和后缀是否相同</span></span><br><span class="line"><span class="comment">//法一:求前缀数组</span></span><br><span class="line"><span class="comment">//从大到小考虑:字符串n为最大解;pi[n-1]为次大解;下一个解为pi[pi[n-1]-1].递推直至解为0,逆序输出</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">solve</span><span class="params">(<span class="built_in">string</span> &amp;s)</span>&#123;          <span class="comment">//加引用:因为此处string不是全局变量</span></span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="type">int</span>&gt;pi=prefix(s),ans;</span><br><span class="line">    <span class="type">int</span> x=s.length();</span><br><span class="line">    <span class="keyword">while</span>(x)&#123;</span><br><span class="line">        ans.push_back(x);</span><br><span class="line">        x=pi[x<span class="number">-1</span>];</span><br><span class="line">    &#125;</span><br><span class="line">    for_each(ans.rbegin(),ans.rend(),[](<span class="type">const</span> <span class="type">int</span> &amp;x)&#123;<span class="built_in">cout</span>&lt;&lt;x&lt;&lt;<span class="string">&#x27; &#x27;</span>;&#125;);      <span class="comment">//rbegin,rend为逆向迭代器</span></span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    ios::sync_with_stdio(<span class="literal">false</span>);</span><br><span class="line">    <span class="built_in">cin</span>.tie(<span class="number">0</span>);</span><br><span class="line">    <span class="type">int</span> t;<span class="built_in">cin</span>&gt;&gt;t;</span><br><span class="line">    <span class="built_in">string</span> s;</span><br><span class="line">    <span class="keyword">while</span>(t--)&#123;</span><br><span class="line">        <span class="built_in">cin</span>&gt;&gt;s;solve(s);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//初始T为空，两操作二选一：在T后添加一个字母;选择T的一前缀T&#x27;,连在T后.</span></span><br><span class="line"><span class="comment">//操作的最小次数.</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">int</span> T;<span class="built_in">cin</span>&gt;&gt;T;</span><br><span class="line">    <span class="keyword">while</span>(T--)&#123;</span><br><span class="line">        <span class="built_in">string</span> s;<span class="built_in">cin</span>&gt;&gt;s;</span><br><span class="line">        <span class="built_in">vector</span>&lt;<span class="type">int</span>&gt;pi=prefix(s);</span><br><span class="line">        <span class="type">int</span> n=(<span class="type">int</span>)s.length(),cnt=<span class="number">0</span>,q=<span class="number">0</span>;</span><br><span class="line">        <span class="type">int</span> i=n<span class="number">-1</span>;</span><br><span class="line">        <span class="keyword">while</span>(i&gt;=<span class="number">0</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            q=pi[i];</span><br><span class="line">            <span class="keyword">while</span>(<span class="number">2</span>*q&gt;i+<span class="number">1</span>) q=pi[q<span class="number">-1</span>];       <span class="comment">//避免产生重叠.</span></span><br><span class="line">            <span class="keyword">if</span>(q==<span class="number">0</span>) &#123;cnt+=<span class="number">1</span>;i-=<span class="number">1</span>;&#125;</span><br><span class="line">            <span class="keyword">else</span> &#123;cnt+=<span class="number">1</span>;i-=q;&#125;</span><br><span class="line">            <span class="comment">//cout&lt;&lt;q&lt;&lt;&quot; &quot;&lt;&lt;i&lt;&lt;&quot; &quot;&lt;&lt;cnt&lt;&lt;endl;</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">cout</span>&lt;&lt;cnt&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="状态机">2.状态机</h3><p>由字符串S构建的字符串匹配自动机共有n+1个状态，其中n为字符串S的长度。第i个状态表示接收到的字符串的最后i−1个字符（长度为i−1的后缀）恰能匹配S的前i−1个字符，第n+1个状态表示已经匹配上字符串S，为字符串匹配自动机的终态。<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">compute_Trans</span><span class="params">(<span class="built_in">string</span> &amp;s)</span>&#123;</span><br><span class="line">    <span class="type">int</span> n=(<span class="type">int</span>)s.length();</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="type">int</span>&gt;pi=prefix(s);</span><br><span class="line">    <span class="type">int</span> **Trans=(<span class="type">int</span> **)<span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="type">int</span> *)*n);</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;n;i++) Trans[i]=(<span class="type">int</span> *)<span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="type">int</span>)*<span class="number">10</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">0</span>;j&lt;<span class="number">10</span>;j++)&#123;</span><br><span class="line">        <span class="keyword">if</span>(s[<span class="number">0</span>]==<span class="string">&#x27;a&#x27;</span>+j) Trans[<span class="number">0</span>][j]=<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">else</span> Trans[<span class="number">0</span>][j]=<span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;n;i++)&#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">0</span>;j&lt;<span class="number">10</span>;j++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(s[i]==<span class="string">&#x27;a&#x27;</span>+j) &#123;Trans[i][j]=i+<span class="number">1</span>;<span class="keyword">continue</span>;&#125;</span><br><span class="line">            <span class="type">int</span> q=pi[i<span class="number">-1</span>];</span><br><span class="line">            <span class="keyword">while</span>(q&gt;<span class="number">0</span>&amp;&amp;s[q]!=<span class="string">&#x27;a&#x27;</span>+j) q=pi[q<span class="number">-1</span>];</span><br><span class="line">            <span class="keyword">if</span>(s[q]==<span class="string">&#x27;a&#x27;</span>+j) Trans[i][j]=q+<span class="number">1</span>;</span><br><span class="line">            <span class="keyword">else</span> Trans[i][j]=<span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;n;i++)&#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">0</span>;j&lt;<span class="number">10</span>;j++) <span class="built_in">printf</span>(<span class="string">&quot;%d &quot;</span>,Trans[i][j]);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h3 id="字符串映射">3.字符串映射</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//建立双向映射的哈希表</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> N 100005</span></span><br><span class="line"><span class="type">int</span> n;</span><br><span class="line"><span class="type">char</span> s[N],t[N];</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">int</span> T;<span class="built_in">cin</span>&gt;&gt;T;</span><br><span class="line">    <span class="keyword">while</span>(T--)&#123;</span><br><span class="line">        <span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>,&amp;n);</span><br><span class="line">        <span class="built_in">scanf</span>(<span class="string">&quot;%s&quot;</span>,s);<span class="built_in">scanf</span>(<span class="string">&quot;%s&quot;</span>,t);</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">unordered_map</span>&lt;<span class="type">char</span>,<span class="type">char</span>&gt;m1,m2;</span><br><span class="line">        <span class="built_in">unordered_map</span>&lt;<span class="type">char</span>,<span class="type">char</span>&gt;::iterator it1=m1.begin(),it2=m2.begin();</span><br><span class="line">        <span class="type">int</span> flag=<span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;n;i++)</span><br><span class="line">        &#123;</span><br><span class="line">            it1=m1.find(s[i]);it2=m2.find(t[i]);</span><br><span class="line">            <span class="keyword">if</span>(it1==m1.end()&amp;&amp;it2==m2.end())    <span class="comment">//找不到</span></span><br><span class="line">            &#123;</span><br><span class="line">                m1.insert(<span class="built_in">make_pair</span>(s[i],t[i]));</span><br><span class="line">                m2.insert(<span class="built_in">make_pair</span>(t[i],s[i]));</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span>(it1!=m1.end()&amp;&amp;it2==m2.end()) &#123;flag=<span class="number">1</span>;<span class="keyword">break</span>;&#125;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span>(it1==m1.end()&amp;&amp;it2!=m2.end()) &#123;flag=<span class="number">1</span>;<span class="keyword">break</span>;&#125;</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">            &#123;</span><br><span class="line">                <span class="keyword">if</span>(it1-&gt;second!=t[i]||it2-&gt;second!=s[i]) &#123;flag=<span class="number">1</span>;<span class="keyword">break</span>;&#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(flag==<span class="number">0</span>) <span class="built_in">printf</span>(<span class="string">&quot;Yes\n&quot;</span>);</span><br><span class="line">        <span class="keyword">else</span> <span class="built_in">printf</span>(<span class="string">&quot;No\n&quot;</span>);</span><br><span class="line">        <span class="built_in">memset</span>(s,<span class="string">&#x27;\0&#x27;</span>,<span class="keyword">sizeof</span>(<span class="type">char</span>)*n);</span><br><span class="line">        <span class="built_in">memset</span>(t,<span class="string">&#x27;\0&#x27;</span>,<span class="keyword">sizeof</span>(<span class="type">char</span>)*n);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="判断字符串是否相同--建立哈希映射">4.判断字符串是否相同--建立哈希映射</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="type">long</span> <span class="type">long</span> ll;</span><br><span class="line"><span class="meta">#<span class="keyword">define</span> N 100005</span></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> B=<span class="number">26</span>,M=<span class="number">998244353</span>;</span><br><span class="line"><span class="type">int</span> n;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">prepose</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=p[<span class="number">0</span>]=<span class="number">1</span>;i&lt;N;i++) p[i]=(ll)p[i<span class="number">-1</span>]*B%M;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    ios::sync_with_stdio(<span class="literal">false</span>);</span><br><span class="line">    <span class="built_in">cin</span>.tie(<span class="number">0</span>);</span><br><span class="line">    <span class="comment">//prepose();</span></span><br><span class="line">    <span class="built_in">unordered_map</span>&lt;ll,<span class="built_in">pair</span>&lt;<span class="built_in">string</span>,<span class="type">int</span>&gt;&gt;<span class="built_in">map</span>;</span><br><span class="line">    <span class="built_in">unordered_map</span>&lt;ll,<span class="built_in">pair</span>&lt;<span class="built_in">string</span>,<span class="type">int</span>&gt;&gt;::iterator it=<span class="built_in">map</span>.begin();</span><br><span class="line">    <span class="built_in">cin</span>&gt;&gt;n;</span><br><span class="line">    <span class="built_in">string</span> s;</span><br><span class="line">    <span class="type">int</span> maxsize=<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;n;i++)&#123;</span><br><span class="line">        <span class="built_in">cin</span>&gt;&gt;s;</span><br><span class="line">        <span class="type">int</span> m=(<span class="type">int</span>)s.size();</span><br><span class="line">        ll k=<span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">0</span>;j&lt;m;j++) k=(k*B+s[j])%M;</span><br><span class="line">        <span class="comment">//cout&lt;&lt;k&lt;&lt;&quot; &quot;;</span></span><br><span class="line">        it=<span class="built_in">map</span>.find(k);</span><br><span class="line">        <span class="keyword">if</span>(it==<span class="built_in">map</span>.end()) <span class="built_in">map</span>.insert(<span class="built_in">make_pair</span>(k,<span class="built_in">make_pair</span>(s,<span class="number">1</span>)));</span><br><span class="line">        <span class="keyword">else</span>&#123;</span><br><span class="line">            <span class="comment">//cout&lt;&lt;s&lt;&lt;&quot; &quot;&lt;&lt;it-&gt;second.first;</span></span><br><span class="line">            <span class="keyword">if</span>(s!=it-&gt;second.first) <span class="built_in">map</span>.insert(<span class="built_in">make_pair</span>(k,<span class="built_in">make_pair</span>(s,<span class="number">1</span>)));</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">            &#123;</span><br><span class="line">                it-&gt;second.second+=<span class="number">1</span>;</span><br><span class="line">                <span class="keyword">if</span>(it-&gt;second.second&gt;maxsize) maxsize=it-&gt;second.second;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//cout&lt;&lt;map.size()&lt;&lt;&quot; &quot;&lt;&lt;maxsize&lt;&lt;endl;</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;<span class="built_in">map</span>.size()&lt;&lt;<span class="string">&quot; &quot;</span>&lt;&lt;maxsize;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="结合的变式">5.1,2结合的变式</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//G--C,E结合的变式</span></span><br><span class="line"><span class="comment">//同一集合内字符串相似:</span></span><br><span class="line"><span class="comment">//1.对每个字符串的字符建立映射,哈希值与字符位置相关(设为m.size()+1),求整个字符串的哈希值;</span></span><br><span class="line"><span class="comment">//2.对所有字符串建立映射,每个字符串的哈希值由步骤1得出.</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="type">long</span> <span class="type">long</span> ll;</span><br><span class="line"><span class="meta">#<span class="keyword">define</span> N 100005</span></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> B=<span class="number">26</span>,M=<span class="number">998244353</span>;</span><br><span class="line"><span class="type">int</span> n;</span><br><span class="line"></span><br><span class="line">ll <span class="title function_">Hash</span><span class="params">(<span class="built_in">string</span> &amp;s)</span>&#123;</span><br><span class="line">    <span class="built_in">map</span>&lt;<span class="type">char</span>,<span class="type">int</span>&gt;m;</span><br><span class="line">    <span class="built_in">map</span>&lt;<span class="type">char</span>,<span class="type">int</span>&gt;::iterator it=m.begin();</span><br><span class="line">    <span class="type">int</span> len=(<span class="type">int</span>)s.size();</span><br><span class="line">    ll k=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">0</span>;j&lt;len;j++)&#123;</span><br><span class="line">        it=m.find(s[j]);</span><br><span class="line">        <span class="keyword">if</span>(it==m.end())</span><br><span class="line">        &#123;</span><br><span class="line">            m.emplace(s[j],m.size()+<span class="number">1</span>);</span><br><span class="line">            k=(k*B+m.size())%M;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> k=(k*B+it-&gt;second)%M;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> k;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    ios::sync_with_stdio(<span class="literal">false</span>);</span><br><span class="line">    <span class="built_in">cin</span>.tie(<span class="number">0</span>);</span><br><span class="line">    <span class="built_in">unordered_map</span>&lt;ll,<span class="type">int</span>&gt;whole_map;</span><br><span class="line">    <span class="built_in">unordered_map</span>&lt;ll,<span class="type">int</span>&gt;::iterator it1=whole_map.begin();</span><br><span class="line">    <span class="built_in">cin</span>&gt;&gt;n;<span class="type">int</span> maxsize=<span class="number">1</span>;</span><br><span class="line">    <span class="built_in">string</span> s;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;n;i++)&#123;</span><br><span class="line">        <span class="built_in">cin</span>&gt;&gt;s;</span><br><span class="line">        ll k=Hash(s);</span><br><span class="line">        <span class="comment">//cout&lt;&lt;k&lt;&lt;endl;</span></span><br><span class="line">        it1=whole_map.find(k);</span><br><span class="line">        <span class="keyword">if</span>(it1==whole_map.end()) whole_map.insert(<span class="built_in">make_pair</span>(k,<span class="number">1</span>));</span><br><span class="line">        <span class="keyword">else</span>&#123;</span><br><span class="line">            it1-&gt;second+=<span class="number">1</span>;</span><br><span class="line">            <span class="keyword">if</span>(it1-&gt;second&gt;maxsize) maxsize=it1-&gt;second;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;whole_map.size()&lt;&lt;<span class="string">&quot; &quot;</span>&lt;&lt;maxsize;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><hr><ol><li id="fn1"><p>logb(a)<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li></ol></section>]]></content>
      
      
      <categories>
          
          <category> Algorithms </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>纸翼传问平台：平台功能、CICD、降级服务、自动扩缩容展示</title>
      <link href="/posts/8b715a29.html"/>
      <url>/posts/8b715a29.html</url>
      
        <content type="html"><![CDATA[<p>该平台为北航2024年秋暑期软件工程实践项目。</p><h2 id="cicd部署">CICD部署</h2><div id="dplayer1" class="dplayer hexo-tag-dplayer-mark" style="margin-bottom: 20px;"></div><script>(function(){var player = new DPlayer({"container":document.getElementById("dplayer1"),"theme":"#FADFA3","loop":true,"video":{"url":"/posts/8b715a29/4-CICD.mp4","pic":"1.png"}});window.dplayers||(window.dplayers=[]);window.dplayers.push(player);})()</script><h2 id="降级服务">降级服务</h2><div id="dplayer2" class="dplayer hexo-tag-dplayer-mark" style="margin-bottom: 20px;"></div><script>(function(){var player = new DPlayer({"container":document.getElementById("dplayer2"),"theme":"#FADFA3","loop":true,"video":{"url":"/posts/8b715a29/4-自动扩缩容.mp4","pic":"1.png"}});window.dplayers||(window.dplayers=[]);window.dplayers.push(player);})()</script><h2 id="自动扩缩容">自动扩缩容</h2><div id="dplayer3" class="dplayer hexo-tag-dplayer-mark" style="margin-bottom: 20px;"></div><script>(function(){var player = new DPlayer({"container":document.getElementById("dplayer3"),"theme":"#FADFA3","loop":true,"video":{"url":"/posts/8b715a29/4-降级服务.mp4","pic":"1.png"}});window.dplayers||(window.dplayers=[]);window.dplayers.push(player);})()</script><h2 id="致谢">致谢</h2><p>致谢我的4位伙伴们，上合照：<img src="/posts/8b715a29/image.png"></p>]]></content>
      
      
      
        <tags>
            
            <tag> Web Platforms Display </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>纸翼学术成果分享平台：平台展示</title>
      <link href="/posts/39315f07.html"/>
      <url>/posts/39315f07.html</url>
      
        <content type="html"><![CDATA[<p>该平台为北航2024年秋软件系统分析与设计课程团队项目，致谢我的9位伙伴们，和Bug-捉迷藏小组。</p><h2 id="平台演示">平台演示</h2><div id="dplayer0" class="dplayer hexo-tag-dplayer-mark" style="margin-bottom: 20px;"></div><script>(function(){var player = new DPlayer({"container":document.getElementById("dplayer0"),"theme":"#FADFA3","loop":true,"video":{"url":"/posts/39315f07/1.mp4","pic":"1.png"}});window.dplayers||(window.dplayers=[]);window.dplayers.push(player);})()</script><h2 id="系统架构图">系统架构图</h2><figure><img src="/posts/39315f07/image.png" alt="alt text"><figcaption aria-hidden="true">alt text</figcaption></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Web Platforms Display </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>BUAA-OS Lab3 实验笔记</title>
      <link href="/posts/a9bcb957.html"/>
      <url>/posts/a9bcb957.html</url>
      
        <content type="html"><![CDATA[<p>上一篇中阐述了本实验中物理内存、虚拟内存的管理方式。</p><ul><li><p>物理内存：页控制块数组中，每一项代表一页物理内存；使用基于双向链表结构的空闲链表<code>page_free_list</code>管理空闲页面，实现页控制块的<strong>申请和释放</strong>，此时，<code>page_free_list</code>可视作一个资源池。</p></li><li><p>虚拟内存：当使用<code>kuseg</code>地址空间的虚拟地址访问内存时，CPU会<strong>通过TLB将其转换为物理地址</strong>；当TLB中查询不到对应的物理地址时，就会触发TLBMiss异常。这时将跳转到异常处理函数，执行TLB重填。</p></li></ul><p>现在，我们进入创建和调度进程的环节。</p><h2 id="进程">进程</h2><blockquote><p>我们编写的代码是一个存储在硬盘的静态文件，通过编译后生成⼆进制可执行文件；当我们运行该可执行文件时，它会被装载到内存中，接着CPU会执⾏程序中的每⼀条指令，那么这个运⾏中的程序，就被称为<strong>进程</strong>。进程的定义：<strong>进程是具有独立功能的程序在⼀个数据集合上运⾏的过程，是系统进行资源分配和调度的⼀个独立单位</strong>。</p></blockquote><p>在本实验中未实现线程，因此进程同时是基本的分配单元和执行单元。</p><h3 id="进程控制块env">进程控制块<code>Env</code></h3><blockquote><p>统通过<strong>进程控制块PCB</strong>描述进程的基本情况和运行状态，进而控制和管理进程。它是进程存在的<strong>唯一标识</strong>，包含以下信息：</p><ol type="1"><li>进程描述信息：进程标识符，用户标识符；</li><li>进程控制和管理信息：进程当前状态，进程优先级；</li><li>进程资源分配清单：有关内存地址空间或虚拟地址空间的信息，所打开⽂件的列表和所使⽤的I/O 设备信息；</li><li>CPU相关信息：当进程切换时，CPU寄存器的值都被保存在相应PCB中，以便CPU重新执⾏该进程时能从断点处继续执⾏。</li></ol><p><code>PCB</code>通常是通过<strong>链表</strong>的⽅式进⾏组织，把具有<strong>相同状态的进程链在⼀起，组成各种队列</strong>。</p></blockquote><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Env</span> &#123;</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Trapframe</span> <span class="title">env_tf</span>;</span> <span class="comment">// 进程切换前，保存的当前进程上下文环境</span></span><br><span class="line">LIST_ENTRY(Env) env_link; <span class="comment">// 类似于pp_link，用于构造：空闲进程链表env_free_list</span></span><br><span class="line">u_int env_id; <span class="comment">// 唯一进程标识符</span></span><br><span class="line">u_int env_asid; <span class="comment">// 进程的ASID</span></span><br><span class="line">u_int env_parent_id; <span class="comment">// 父进程ID</span></span><br><span class="line">u_int env_status; <span class="comment">// 进程状态：ENV_FREE；ENV_NOT_RUNNABLE；ENV_RUNNABLE</span></span><br><span class="line">Pde *env_pgdir; <span class="comment">// 进程页目录的内核虚拟地址</span></span><br><span class="line">TAILQ_ENTRY(Env) env_sched_link; <span class="comment">// 用于构造：调度队列 env_sched_list</span></span><br><span class="line">u_int env_pri; <span class="comment">// 进程的优先级</span></span><br><span class="line"></span><br><span class="line">......</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><blockquote><p>补充：</p><ol type="1"><li><code>Trapframe</code>结构体：在发生进程调度或陷入内核时，保存当前进程的上下文环境。</li></ol><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Trapframe</span> &#123;</span></span><br><span class="line"><span class="comment">/* Saved main processor registers. */</span></span><br><span class="line"><span class="type">unsigned</span> <span class="type">long</span> regs[<span class="number">32</span>];</span><br><span class="line"></span><br><span class="line"><span class="comment">/* Saved special registers. */</span></span><br><span class="line"><span class="type">unsigned</span> <span class="type">long</span> cp0_status;</span><br><span class="line"><span class="type">unsigned</span> <span class="type">long</span> hi;</span><br><span class="line"><span class="type">unsigned</span> <span class="type">long</span> lo;</span><br><span class="line"><span class="type">unsigned</span> <span class="type">long</span> cp0_badvaddr;</span><br><span class="line"><span class="type">unsigned</span> <span class="type">long</span> cp0_cause;</span><br><span class="line"><span class="type">unsigned</span> <span class="type">long</span> cp0_epc;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><ol start="2" type="1"><li><code>env_status</code>字段取值：<ul><li><code>ENV_FREE</code>：当前进程处于空闲状态，位于空闲链表中；</li><li><code>ENV_NOT_RUNNABLE</code>：当前进程处于<strong>阻塞状态</strong>，转为就绪状态后，才能被CPU调度；</li><li><code>ENV_RUNNABLE</code>：当前进程处于<strong>执行状态/就绪状态</strong>。</li></ul></li><li><code>env_sched_link</code>使用结构体<code>TAILQ_ENTRY</code>，实现双端队列。支持头部、尾部的插入和取出。</li></ol></blockquote><h3 id="进程的标识">进程的标识</h3><h4 id="进程标识符">进程标识符</h4><p>操作系统通过<strong>进程标识符</strong>来识别进程，对应<code>Env</code>结构体中的<code>env_id</code>域，在进程创建时被赋予。</p><blockquote><p>进程标识符的生成函数如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> LOG2NENV 10</span></span><br><span class="line">u_int <span class="title function_">mkenvid</span><span class="params">(<span class="keyword">struct</span> Env *e)</span> &#123;</span><br><span class="line"><span class="type">static</span> u_int i = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">return</span> ((++i) &lt;&lt; (<span class="number">1</span> + LOG2NENV)) | (e - envs);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>该函数在<code>env_alloc</code>中被调用：<code>e-&gt;env_id=mkenvid(e);</code>用于初始化进程块时，分配标识符</p></blockquote><h4 id="进程的asid">进程的ASID</h4><p><code>env_asid</code> 域记录进程的ASID，即<strong>进程虚拟地址空间的标识</strong>。</p><blockquote><p><strong>那么，为什么要额外引入ASID呢？</strong></p><p>系统中<strong>并发执行多个拥有不同虚拟地址空间的进程，分别具有不同的页表；</strong>而CPU 的 MMU 使用 TLB缓存虚拟地址映射关系，<strong>不同页表拥有不同的虚拟地址映射</strong>。</p><p>因此，<strong>不同进程的虚拟地址，可以对应相同的虚拟页号</strong>。</p><p>当 CPU 切换页表，TLB中仍可能缓存有之前页表的虚拟地址映射关系，为了避免这些无效映射关系导致错误的地址翻译，<strong>早期操作系统实现在CPU 每次切换页表时，无效化所有 TLB 表项。</strong></p><p>然而，这种实现导致频繁的 TLB Miss，影响处理器性能。现代的 CPU及操作系统，采用ASID 解决上述问题。ASID用于标识虚拟地址空间，同时并发执行的多个进程具有不同 ASID，以方便 TLB标识其虚拟地址空间。</p></blockquote><p>Lab2中提到：在<code>4Kc</code>中，TLB由⼀组Key +两组Data组成，<strong>构建映射：<code>&lt; VPN, ASID &gt;</code> TLB---&gt;<code>&lt; PFN, N, D, V, G &gt;</code></strong>。对于每一个进程，都有ASID标识的虚拟地址空间下的<strong>一套独立 TLB缓存</strong>。因此，切换页表时，操作系统不必再清空所有TLB表项。</p><p>那么，<strong>ASID何时分配和回收呢？</strong></p><ol type="1"><li><p><strong>初始化进程块时创建</strong>：在<code>env_alloc</code>函数中有：</p><p><code>if(asid_alloc(&amp;e-&gt;env_asid)==-E_NO_FREE_ENV) return -E_NO_FREE_ENV;</code></p><blockquote><p>ASID分配函数：<code>asid_alloc</code>（采用<strong>位图法</strong>：<strong>共256个可⽤的ASID,0~7位表示</strong>）</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">static</span> <span class="type">int</span> <span class="title function_">asid_alloc</span><span class="params">(u_int *asid)</span> &#123;</span><br><span class="line"><span class="keyword">for</span> (u_int i = <span class="number">0</span>; i &lt; NASID; ++i) &#123;</span><br><span class="line"><span class="type">int</span> index = i &gt;&gt; <span class="number">5</span>;</span><br><span class="line"><span class="type">int</span> inner = i &amp; <span class="number">31</span>;<span class="comment">//inner为i的低5位</span></span><br><span class="line"><span class="comment">//定义:static uint32_t asid_bitmap[NASID / 32] = &#123;0&#125;;</span></span><br><span class="line"><span class="comment">//asid_bitmap每个元素32位,对应32个ASID的分配状态</span></span><br><span class="line"><span class="keyword">if</span> ((asid_bitmap[index] &amp; (<span class="number">1</span> &lt;&lt; inner)) == <span class="number">0</span>) &#123;<span class="comment">//未分配</span></span><br><span class="line">asid_bitmap[index] |= <span class="number">1</span> &lt;&lt; inner;<span class="comment">//标为已分配</span></span><br><span class="line">*asid = i;</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> -E_NO_FREE_ENV;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></blockquote></li><li></li></ol>]]></content>
      
      
      <categories>
          
          <category> OS </category>
          
          <category> BUAA OS lab </category>
          
      </categories>
      
      
        <tags>
            
            <tag> C </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>模型并行计算</title>
      <link href="/posts/ca7e7de.html"/>
      <url>/posts/ca7e7de.html</url>
      
        <content type="html"><![CDATA[<p>该篇摘自<a href="https://huggingface.co/spaces/nanotron/ultrascale-playbook">TheUltra-Scale Playbook: Training LLMs on GPU Clusters</a>.</p><h2 id="在单个gpu上训练">在单个GPU上训练</h2><p>在单个GPU上训练，通常包括三个步骤： 1. forwardpass：将输入传入模型，产生输出； 2. backward pass：计算梯度； 3.optimization：使用梯度更新参数。</p><p><img src="/posts/ca7e7de/image.png"></p><h3 id="batch-size的影响">batch size的影响</h3><p>超参数<strong>batch size</strong>：小的batchsize在训练初期有助于快速完成训练过程，达到一个较优learningpoint；但在训练后期，小的batchsize导致梯度噪声增大，模型难以收敛至最优性能点；大的batchsize虽然能给出精确的梯度估计，但会降低每个训练样本的利用效率，从而导致收敛变慢，并可能浪费计算资源。</p><p>batch size影响在给定dataset上的训练时间：小的batchsize在相同数量样本上，需要更多的优化步骤（优化步骤是计算密集型的，导致训练时间比大的batchsize更长）。但是，batchsize大小通常可以在最优值附近大幅调整，而不会对模型的最终性能产生重大影响（前提是在最优值附近）。</p><p>在LLM的预训练中，batch size通常定义为：token的数量（bst：Batch SizeTokens），使得训练次数和训练中使用的输入序列长度基本独立。在单个机器上训练，<code>bs</code>（样本计数）和<code>bst</code>（token计数）可由下计算：<span class="math display">\[bst=bs * seq\]</span> 其中，<code>seq</code>为输入序列长度。</p><blockquote><p>近期 LLM 训练的理想批量大小通常在每批次 400 万到 6000 万个 token之间。批量大小和训练语料库的规模近年来一直在稳步增加：Llama 1的训练使用了大约 400 万个 token 的批量大小，训练了 1.4 万亿个 tokens，而DeepSeek 则使用了大约 6000 万个 token 的批量大小，训练了 14 万亿个tokens。</p></blockquote><p>然而，一个挑战是在将模型训练扩展到大的batchsize时，将遇到<strong>显存不足</strong>的问题：当 GPU的显存不足以容纳目标batch size的完整批次时，该怎么办？</p><h3 id="transformer上的内存使用">Transformer上的内存使用</h3><p>当训练一个神经网络时，将以下内容存储在内存中：模型权重、模型梯度、优化器状态、（用于计算梯度的）激活值。</p><p>以上内容作为<strong>tensor（张量）</strong>存储在内存中，分别对应不同的shapes和precisions。</p><p><img src="/posts/ca7e7de/image-1.png"></p><p>训练基本步骤：前向传播时，激活值迅速增加；反向传播时，梯度逐渐积累，且计算梯度的激活值会逐步被清除；最后，执行优化步骤，此时需要所有的梯度，并更新优化器状态；然后才开始下一次的前向传播。</p><blockquote><p>第一步和后续步骤明显不同的原因：激活值快速增加，再保持一段时间的平稳。在第一步中，torch的缓存分配器进行大量准备工作，预先分配内存；后续步骤不再需要寻找空闲内存块，从而加速）</p></blockquote><h4 id="weightsgradsoptimizer-state的内存">weights/grads/optimizerstate的内存</h4><p>对于一个简单的transformer LLM，参数数量如下： <span class="math display">\[N=h*v+L*(12*h^2+13*h)+2*h\]</span> <span class="math inline">\(h\)</span>是隐藏层维度，<span class="math inline">\(v\)</span>是词汇大小，<span class="math inline">\(L\)</span>是模型的层数；可以看到，当隐藏层维度较大时，主导项是<span class="math inline">\(h^2\)</span>项。</p><p>**内存需求：参数数量*每个参数的字节数**</p><blockquote><p>传统FP32训练中，参数、梯度均需4字节，优化器（例如Adam）需要存储动量和方差，为每个参数增加另外两个4字节。</p><p><span class="math inline">\(m_{params}=4*N\)</span></p><p><span class="math inline">\(m_{grad}=4*N\)</span></p><p><span class="math inline">\(m_{opt}=(4+4)*N\)</span></p><p>若使用高低混合精度训练，当前默认做法是：使用BF16进行大部分计算（每个参数、梯度分别需要2字节），额外复制一份模型权重和梯度为FP32，因此每个参数总共需要 12 字节。即：</p><p><span class="math inline">\(m_{params}=2*N\)</span></p><p><span class="math inline">\(m_{grad}=2*N\)</span></p><p><span class="math inline">\(m_{params_{fp32}}=4*N\)</span></p><p><span class="math inline">\(m_{opt}=(4+4)*N\)</span></p><p>混合精度本身并不会节省整体内存，它只是将内存在三个组件之间重新分配。在前向和反向传播中使用半精度计算可以：1. 在 GPU 上使用经过优化的低精度操作，这些操作更快； 2.减少前向传播过程中的激活内存需求，而激活内存占用了大量内存。</p><p>若使用 FP8 训练代替BF16，内存使用量会进一步减少（但它的稳定性较差）。</p><table><colgroup><col style="width: 18%"><col style="width: 45%"><col style="width: 36%"></colgroup><thead><tr><th>模型参数数量</th><th>FP32 或 BF16（不使用 FP32 梯度累积）</th><th>BF16（使用 FP32 梯度累积）</th></tr></thead><tbody><tr><td>1B</td><td>16 GB</td><td>20 GB</td></tr><tr><td>7B</td><td>112 GB</td><td>140 GB</td></tr><tr><td>70B</td><td>1120 GB</td><td>1400 GB</td></tr><tr><td>405B</td><td>6480 GB</td><td>8100 GB</td></tr></tbody></table><p>可以观察到，一旦达到 7B参数，权重和优化器的内存需求就会显著增加，并超过典型 GPU内存的大小。</p></blockquote><h4 id="activations的内存">activations的内存</h4><p>依赖于模型的输入。总内存如下： <span class="math display">\[m_{act}=L*seq*bs*h*(34+\frac{5*n_{heads}*seq}{h})\]</span> 其中，<span class="math inline">\(L\)</span>是层数，<span class="math inline">\(seq\)</span>是序列长度，<span class="math inline">\(bs\)</span>是batch size，<span class="math inline">\(h\)</span>是模型的隐藏维度，<span class="math inline">\(n_{heads}\)</span>是注意力头的数量。</p><p>可以观察到，内存使用量会随着批量大小线性增长，并随着序列长度的平方增长，那么：激活内存是最容易“膨胀”的部分。</p><p>对于短序列（或者小批量大小），激活几乎可以忽略不计；但从大约 2-4k 个token开始，它们就会占用大量内存，而参数、梯度和优化器状态的使用，则基本上与序列长度和批量大小无关。</p><h3 id="控制activation增长的策略">控制activation增长的策略</h3><h4 id="activation重计算gradient-checkpoints">activation重计算（gradientcheckpoints）</h4><p>也叫做：梯度检查点，重物化。在前向传播时，抛弃一些activations；在后向传播时，实时重新计算activations。</p><ul><li>Full（全量重计算）：在Transformer的每层transitionpoint上，设置activationscheckpoints：要求每层进行一次前向传播，即在反向传播过程中增加一次完整的前向传播。<ul><li>可以节省最多内存，但在计算上最昂贵。</li></ul></li><li>Selective（选择性重计算）：注意力激活值增长较多且在FLOP上计算便宜，因此抛弃他们。<ul><li>对于一个GPT-3（175B）模型，可以减少70%的激活内存，而计算成本仅为2.7%；DeepSeekV3使用“多头潜在注意力”（MLA）来优化激活内存。</li></ul></li></ul><p>当前大多数框架使用<strong>FlashAttention</strong>，在其优化策略中，原生集成了activation重计算：在反向传播中，计算（而非存储）注意力分数和矩阵。</p><blockquote><p>activation重计算略微增加FLOPs的数量；但显著减少内存开销。该策略对具备小型高速内存的硬件尤为有利（比如GPU）。</p></blockquote><h4 id="梯度累积gradient-accumulation">梯度累积（gradientaccumulation）</h4><p>梯度累积将batch拆分为若干个小的micro-batch；依次在每个micro-batch上进行前向、反向传播，计算梯度，在执行优化步骤前，将所有micro-batch梯度相加。实际上，优化步骤是基于梯度的平均值（而非总和）进行的，因此结果与梯度累积步骤的数量无关。有：<span class="math display">\[bs=gbs=mbs*grad_{acc}\]</span> 其中：每次前向传播的batch size为<span class="math inline">\(mbs\)</span>；每两个优化步骤之间的batchsize为<span class="math inline">\(gbs\)</span>。假设在每进行8次前向/反向传播后执行一次优化步骤，则<span class="math inline">\(gbs\)</span>将是<span class="math inline">\(mbs\)</span>的8倍。</p><p><img src="/posts/ca7e7de/image-2.png"></p><p>梯度累积的一个缺点：在每个优化步骤中，需要执行多个连续的前向/反向传播，从而增加计算开销，减慢计算速度。</p><p>然而，每个micro-batch的前向/反向传播可以并行运行。前向/反向传播是相互独立的，唯一的区别是输入样本。因此可以将训练扩展至多个GPU！</p><h2 id="并行策略">并行策略</h2><h3 id="数据并行data-parallelism">数据并行（Data Parallelism）</h3><p>思想：将模型复制到多个GPU上；在每个GPU上，对不同的microbatches执行前向/反向传播。</p><p><img src="/posts/ca7e7de/image-3.png"></p><p>在每个GPU上使用不同的microbatch，那么每个GPU上的梯度不同；为了保持不同GPU上的模型实例同步，使用<strong>all-reduce对模型实例的梯度进行平均</strong>，该过程在优化之前的反向传播中执行。</p><ul><li>all-reduce原语：处理 GPU 实例和节点之间的同步和通信。 <img src="/posts/ca7e7de/image-4.png"></li></ul><p>一个朴素的实现方式：等待反向传播完成所有的梯度计算；触发all-reduce操作，进行通信以同步这些梯度。然而，这会导致通信时GPU空闲，而我们希望通信和计算能并行。有哪些方法呢？</p><h4 id="优化策略">优化策略</h4><h5 id="优化一梯度同步通信与反向传播计算并行">优化一：梯度同步（通信）与反向传播（计算）并行</h5><p><img src="/posts/ca7e7de/image-5.png">一旦最后一层的反向传播计算完成，这些梯度可以立即被收集、求和；而反向传播计算会继续向左传播，计算更早层的梯度。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">register_backward_hook</span>(<span class="params">self, hook</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Registers a backward hook for all parameters of the model that </span></span><br><span class="line"><span class="string">    require gradients.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> <span class="variable language_">self</span>.module.parameters():</span><br><span class="line">        <span class="keyword">if</span> p.requires_grad <span class="keyword">is</span> <span class="literal">True</span>:</span><br><span class="line">            p.register_post_accumulate_grad_hook(hook)</span><br></pre></td></tr></table></figure><h5 id="优化二梯度分桶">优化二：梯度分桶</h5><p>GPU操作通常在大tensor上执行时效率更高；通信操作亦然。因此，可以通过将梯度分组到多个桶中，并为每个桶内的所有梯度启动一个单独的all-reduce 操作，（而不是为每个梯度执行独立的 all-reduce操作）。显著减少通信开销，加速通信操作。 <img src="/posts/ca7e7de/image-6.png"></p><h5 id="优化三配合梯度累积">优化三：配合梯度累积</h5><p>何时同步梯度？</p><p>在一个简单版本中，每次反向传播后，自动触发一个 all-reduce操作，这样效率较低：在最终步骤之后执行一次 reduce操作能达到相同效果，同时减少开销。</p><blockquote><p>在 PyTorch 中，通常在不需要进行梯度同步的反向传播上添加<code>model.no_sync()</code> 装饰器，来解决这个问题。</p></blockquote><p>加入DP和梯度累积参数后，global batch size更新如下： <span class="math display">\[bs=gbs=mbs*grad_{acc}*dp\]</span> 其中，<span class="math inline">\(grad_{acc}\)</span>是梯度累积的步数，<span class="math inline">\(dp\)</span>是DP中并行实例的数量。</p><blockquote><p>实际上，一般倾向于最大化DP中并行节点的数量：因为DP是并行的，梯度累积是顺序的。在数据并行扩展不足时，再加上梯度累积，以达到目标的globalbatch size。</p></blockquote><h4 id="dp步骤">DP步骤</h4><p>总结一下采用DP进行训练的配置步骤：</p><ol type="1"><li>确定最佳的global batch size(in tokens)；</li><li>选择训练的序列长度（2~8k个tokens当前结果不错）；</li><li>寻找单个GPU上最大的local batchsize(mbs)（不断增加，直到耗尽内存）；</li><li>确定DP使用的GPU数量：GBS 与 DP 的比值决定所需的梯度累积步数。</li></ol><blockquote><p>例子： 假设要训练一个global batchsize=4M的模型，序列长度为4k；则批量大小为1024个样本。</p><p>假设观察到单个 GPU 只能容纳 MBS=2 的内存，并且有 128 个 GPU可供训练。那么：通过4步梯度累积，将实现每个训练步骤 1024 个样本或 4Mtokens 的目标。</p><p>如果突然有 512 个 GPU 可用，仍然可以保持MBS=2，并将梯度累积步数设置为 1，从而实现更快的训练！</p><p>注意：在使用 512+ 个 GPU的规模时，取决于所使用的网络，通信操作将开始受到环延迟的限制，这会降低计算效率，并影响吞吐量。</p></blockquote><p>虽然DP将梯度同步的 all-reduce操作与反向传播计算重叠以节省时间，但这种好处在大规模下开始失效。为什么？因为随着添加更多的GPU（成百上千个），它们之间的协调开销会显著增加，导致网络需求变得过大，抵消了带来的好处。随着每个新GPU 加入，设置DP的效率将越来越低。</p><p><img src="/posts/ca7e7de/image-7.png"></p><h4 id="deepspeed-zero零冗余优化器">DeepSpeed ZeRO（零冗余优化器）</h4><p>在每个DPrank上对优化状态、梯度、参数进行赋值，将导致大量内存冗余。<strong>ZeRO通过在数据并行维度上，对优化器状态、梯度和参数进行分区来消除内存冗余</strong>，同时仍然允许使用完整的参数集进行计算。</p><blockquote><p>activations不参与分区：每个DPreplica接收不同的micro-batch，因此每个DP节点上的activations也不同，不参与复制。</p></blockquote><p>考虑如下场景：使用混合精度训练和Adam优化器时，假设模型参数量为 <span class="math inline">\(\psi\)</span>​，那么每张GPU中的显存内容分为两类：</p><ol type="1"><li>模型状态：<ul><li>模型参数（半精度，bf16/fp16）：<span class="math inline">\(2\psi\)</span></li><li>模型梯度（半精度，bf16/fp16）：<span class="math inline">\(2\psi\)</span></li><li>Adam优化器状态（FP32格式的模型参数备份、FP32的momentum和FP32的variance）：<span class="math inline">\(4\psi+4\psi+4\psi\)</span> Adam状态占比75%。</li></ul></li><li>剩余状态：除了模型状态之外的显存占用，包括activation、各种buffer以及无法使用的显存碎片（fragmentation）。</li></ol><blockquote><p>混合精度训练：同时存在fp16和fp32两种格式的数值，其中模型参数、模型梯度都是fp16，此外还有fp32的模型参数，如果优化器是Adam，则还有fp32的momentum和variance。、<img src="/posts/ca7e7de/image-8.png"></p></blockquote><p>假设显卡数量为<span class="math inline">\(N\)</span>，提出以下三种ZeRO算法： <img src="/posts/ca7e7de/image-9.png"></p><ul><li>ZeRO-1：<strong>只对优化器状态进行分片</strong>，每张卡保存<span class="math inline">\(\frac{1}{N}\)</span>​的状态量。此时，每张卡所需显存是<span class="math inline">\(4\psi+\frac{12\psi}{N}\)</span>字节，当<span class="math inline">\(N\)</span>较大时，趋向于<span class="math inline">\(4\psi\)</span>，记为<span class="math inline">\(P_{os}\)</span>；</li><li>ZeRO-2：<strong>对优化器状态和梯度进行分片</strong>，此时，每张卡所需显存是<span class="math inline">\(2\psi+\frac{2\psi+12\psi}{N}\)</span>字节，当<span class="math inline">\(N\)</span>较大时，趋向于<span class="math inline">\(2\psi\)</span>，记为<span class="math inline">\(P_{os+g}\)</span>；</li><li>ZeRO-3：<strong>将模型参数、梯度、优化器状态三者都进行分片</strong>，此时，每张卡所需显存是<span class="math inline">\(\frac{16\psi}{N}\)</span>字节，当<span class="math inline">\(N\)</span>较大时，趋向于<span class="math inline">\(0\)</span>，记为<span class="math inline">\(P_{os+g+p}\)</span>；<ul><li>ZeRO-3对应Pytorch FSDP</li></ul></li></ul><h5 id="zero-1zero-2zero-3通信量分析">ZeRO-1，ZeRO-2，ZeRO-3通信量分析</h5><blockquote><p>集群通信：</p><p>reduce-scatter: <img src="/posts/ca7e7de/image-10.png"> all-gather: <img src="/posts/ca7e7de/image-11.png"> Ringall-reduce:由reduce-scatter，all-gather两个步骤组成： <img src="/posts/ca7e7de/image-12.png"></p></blockquote><p>传统的DP在每一步计算梯度后，需要一次all-reduce操作计算梯度均值，当前常用Ringall-reduce，分为reduce-scatter和all-gather两步。</p><ul><li><p>ZeRO-1，ZeRO-2将all-reduce梯度通信改为：reduce-scatter操作，并在优化器步骤之后，增加了对所有参数的all-scatter操作。<img src="/posts/ca7e7de/image-13.png"></p><ul><li><span class="math inline">\(P_{os}\)</span>，<span class="math inline">\(P_{os+g}\)</span>和传统DP的通信量相同</li></ul></li><li><p>ZeRO-3：</p><ul><li>前向传播：依次通过各个layer，按需获取必要的参数；在参数不再需要时，立即从显存中清除。<img src="/posts/ca7e7de/image-14.png"></li><li>反向传播：生成梯度分片。 <img src="/posts/ca7e7de/image-15.png"></li></ul><p>需要在前向/反向传播中，持续执行all-gathers操作，那么与ZeRO-2相比，需要额外执行<span class="math inline">\(2*numLayers-1\)</span>次all-gather，每次操作都会带来一个小的基础延迟开销。</p><p><img src="/posts/ca7e7de/image-16.png"></p><p>在前向传播时，需要参数时执行all-gather操作，产生一个<span class="math inline">\(\psi\)</span>的通信开销，立即清除不需要的参数，因此反向传播时还需要一次all-gather操作；最后，与ZeRO-2相同，进行reduce-scatter操作处理梯度，产生<span class="math inline">\(\psi\)</span>的通信开销。总通信开销为：<span class="math inline">\(3\psi\)</span>（ZeRO-2的通信开销为<span class="math inline">\(2\psi\)</span>）</p></li></ul><p><img src="/posts/ca7e7de/image-17.png"></p><h5 id="zero-r">ZeRO-R</h5><p>在进行tensor并行时，前向传播中的activations会在各个GPU中重复存储，因此：ZeRO-R将所有的中间activations分片存储，即只对activationcheckpoints分片（其他activations已被抛弃）</p><p>见：<a href="####activation重计算（gradient%20checkpoints）">重计算</a></p><blockquote><p>正常情况：保存前向传播中，每一个activations，用于反向传播时计算梯度；每一个前向中的activation，到计算完对应梯度节点后，才能释放。</p><ul><li>缺点：需要保存大量的中间激活值，导致占用了大量显存，并且所需的显存是随着层数n线性增长的。</li></ul><p>优化一：将所有的中间激活值全部丢弃，反向传播需要时，再重新计算；</p><ul><li>缺点：训练速度慢，每个前向节点原本只需要计算一次，现在最多需要计算n次！</li></ul><p>折中做法：选取一些前向节点作为checkpoint，训练时，这些checkpoint节点的激活值会一直保存在显存中，而其他节点的激活值会被丢弃。</p><ul><li>优点：计算反向梯度节点时，只需要从离它最近的checkpoint节点开始计算，而不用把每个节点都重新计算一遍。</li></ul></blockquote><h5 id="zero-offload">ZeRO-Offload</h5><p>GPU显存不够用，则：<strong>将一部分计算和存储下放到CPU和内存</strong>，并且不让CPU和GPU之间的通信成为瓶颈，也不让CPU参与过多计算，避免CPU计算成为瓶颈。</p><p>Adma优化器中，每一层迭代如下： <img src="/posts/ca7e7de/image-19.png"></p><p>将数据流图切分成CPU和GPU两部分。ZeRO-Offload策略如下：它将<strong>计算复杂度较高的前向FWD和反向BWD放在GPU上</strong>；而<strong>参数更新和float2half这两个计算操作放在CPU上</strong>。因此，优化器状态也放在内存中，</p><p>述方法仅仅针对单卡场景。在多卡场景下，ZeRO-Offload利用ZeRO-2方法。ZeRO-2将优化器状态和梯度分片，每张卡只存储<span class="math inline">\(\frac{1}{N}\)</span>​，而ZeRO-Offload将这<span class="math inline">\(\frac{1}{N}\)</span><strong>个​优化器状态和梯度都下放到内存，只在CPU上进行参数更新</strong>.</p><p>更多内容参考：<a href="https://zhuanlan.zhihu.com/p/700525463">大模型并行训练技术（一）——ZeRO系列</a></p><h3 id="张量并行tensor-parallelism">张量并行（Tensor Parallelism）</h3><h4 id="数学原理">数学原理</h4><p><img src="/posts/ca7e7de/image-20.png"></p><p>在神经网络中，矩阵乘法常用以下方式表示：<span class="math inline">\(X\times W\)</span>，其中：</p><ul><li><span class="math inline">\(X\)</span>为activation的输入；</li><li><span class="math inline">\(W\)</span>为<code>nn.Linear</code>的权重。 <img src="/posts/ca7e7de/image-21.png"></li></ul><p>在TP中，tensors将被沿着一个特定维度分为N个shards，并分布在N个GPU上。矩阵可以按行/按列切分，分别对应行并行、列并行。</p><h5 id="column-linear">column-linear</h5><ol type="1"><li>运用<strong>broadcast</strong>操作，将输入矩阵复制到每个worker；</li><li>将每个权重矩阵切分为若干个列，分别与输入矩阵相乘，最后通过<strong>all-gather</strong>操作结合。</li></ol><p><img src="/posts/ca7e7de/image-22.png"></p><h5 id="row-linear">row-linear</h5><ol type="1"><li>运用<strong>scatter</strong>操作，将输入矩阵切分为若干个列；</li><li>将每个权重矩阵切分为若干行，分别与输入矩阵的各列相乘，最后通过<strong>all-reduce</strong>操作相加。</li></ol><h4 id="transformer-block内部的张量并行">TransformerBlock内部的张量并行</h4><p>一个Transformer由两个主要的block组成：前向反馈层（Feedbackforwardlayers，MLP）和多头注意力层（Multi-HeadAttention，MHA），可以同时运用TP。</p><h5 id="前向反馈层mlp">前向反馈层（MLP）</h5><p>MLP：先使用column-linear，再使用row-linear（现实训练中不需要broadcast操作，因为可以确保输入已经在TPranks之间同步） &gt;比先row-linear后column-linear更快，省去了中间的all-reduce操作。 <img src="/posts/ca7e7de/image-23.png"></p><h5 id="多头注意力层mha">多头注意力层（MHA）</h5><p>将 Q、K 和 V矩阵按列并行拆分，输出投影则沿着行维度拆分。在多头注意力的情况下，按列并行的方法有一个非常自然的解释：<strong>每个worker计算单个或一部分head的注意力</strong>。这种方法同样适用于多查询（MQA）或分组查询注意力（GQA），其中，<strong>keys和values在queries之间共享</strong>。<img src="/posts/ca7e7de/image-24.png"></p><blockquote><p>值得注意的是，<strong>张量并行度（TP degree）不应超过Q/K/V头的数量</strong>，因为需要保证每个 TPrank的head是完整的（否则无法在每个 GPU上独立计算注意力，需要额外的通信操作）。</p><p>如果使用 GQA，TP 幅度应该实际小于 K/V 头的数量。例如，LLaMA-3 8B模型有 8 个Key/Value heads，因此TP degree最好不要超过8；如果我们为这个模型使用 TP=16，那么我们需要在每个 GPU 上复制 K/V头，并确保它们保持同步。</p></blockquote><h4 id="tp性能">TP性能</h4><p>然而，TP也不是万全之策。需要在模型的计算路径中直接添加了多个分布式通信原语，因此这些通信操作很难完全隐藏或与计算重叠（就像在ZeRO中做的那样）。最终的性能将是计算和内存增益与额外通信开销之间的折中结果。举个例子：</p><p>MLP的操作流程图如下： <img src="/posts/ca7e7de/image-25.png"> 在每个decoderlayer的前向传播中，会遇到一个同步点（即all-reduce操作，无法与计算重叠）；该通信开销是必需的，在应用LayerNorm 之前，合并tensor-parallel ranks的结果。</p><ul><li>TP优点：TP有助于减少矩阵乘法的activationmemory，因为过程中间的activations被分片存储在不同的 GPU 上；</li><li>TP缺点：<ul><li>需要收集完整的activations以执行类似 LayerNorm的操作，这并没有完全利用内存的优势；</li><li>引入大量通信需求，严重依赖于网络基础设施。由于无法完全将这个特定的AllReduce 操作与计算重叠，它直接延长了前向传播的关键路径。</li></ul></li></ul><p>下图展示分布式训练中，计算效率和内存可用性之间的trade-off：<strong>随着TPdegree增加，虽然每个GPU的吞吐量减少（左图），但它能够处理更大的批量大小（右图）。</strong><img src="/posts/ca7e7de/image-26.png"> &gt; 实际上，正如左图所示：TP的通信开销在超越<strong>8 个 GPU</strong>时变得尤为显著：虽然在单节点内使用TP时，可以利用快速的 NVLink互连，但跨节点通信则依赖于较慢的网络连接；当从 TP=8 增加到 TP=16时，性能有显著下降；而从 TP=16 增加到 TP=32时，下降更加明显。在更高的并行度下，通信开销变得如此之高，以至于它迅速主导了计算时间。</p><h5 id="b大模型的内存使用量">70B大模型的内存使用量</h5><p><img src="/posts/ca7e7de/image-27.png"></p><p>是否有办法从TP中获得更多的好处呢？可以看到看到，层归一化（LayerNormalization）和Dropout仍然需要在每个 GPU上收集完整的activations，这在一定程度上抵消了内存节省。可以通过寻找方法将这些剩余操作也并行化，从而做得更好。</p><blockquote><ul><li>TP中的层归一化：由于每个 TP rank 在 all-gather之后看到的是相同的activations，因此层归一化的权重实际上不需要 all-reduce来同步它们的梯度。在反向传播之后，它们自然会在各个 rank上保持同步；</li><li>TP中的Dropout：必须确保跨 TP rank同步随机种子，以保持行为的确定性。</li></ul></blockquote><h4 id="一个小扩展序列并行sequence-parallelism">一个小扩展：序列并行（SequenceParallelism）</h4><p>SP切分TP未处理的activations和computations（例如：<strong>LayerNorm和Dropout</strong>），但是沿着inputsequence的维度（不是跨隐藏层的维度）。</p><p>上述操作<strong>需要访问完整的隐藏维度</strong>才能正确计算。例如：LayerNorm需要完整的隐藏维度，以计算均值和方差：<span class="math display">\[LayerNorm(x)=\gamma\cdot\frac{x-\mu}{\sqrt(\sigma^{2}+\epsilon)}+\beta\]</span> 其中，<span class="math inline">\(\mu=mean(x)\)</span>，<span class="math inline">\(\sigma^{2}=var(x)\)</span>是沿着隐藏层<span class="math inline">\(h\)</span>计算的。</p><p>尽管这些操作在计算上比较简单，但它们仍然需要大量的激活内存，因为它们需要完整的隐藏维度。SP允许我们沿着sequence维度拆分，来将这一内存负担分摊到多个GPU上。</p><p><img src="/posts/ca7e7de/image-28.png"></p><ul><li>前向传播：<ul><li>"f"是一个无操作（no-op），因为activations已经在不同的rank之间进行了复制；</li><li>"f*"是一次全归约（all-reduce），用于同步activations，并确保正确性。</li></ul></li><li>反向传播：<ul><li>"f*"是一个无操作（no-op），因为gradient已经在不同的rank之间进行了复制；</li><li>"f" 是一次全归约（all-reduce），用于同步gradient。</li></ul></li></ul><p>这些操作“f”和“f*”被称为共轭对，因为它们是互补的——在前向传播中，当一个是no-op时，另一个在反向传播中是all-reduce，反之亦然。&gt; 在SP中，避免使用all-reduce（需要收集完整的激活值）</p><p>事实上发生了什么呢？ * <strong>初始层归一化（SP区域）</strong> *输入张量 X1 和 X2（形状为 b, s/2,h）进入LayerNorm，已经沿sequence维度进行拆分每个GPU独立计算它们各自序列块的LayerNorm，得到 Y1 和 Y2； *<strong>第一次转换（SP → TP）</strong> * “g”操作（all-gather）将 Y1 和Y2 合并回完整的序列长度 恢复 Y（形状为 b, s, h） *<strong>第一次线性变换（TP区域）</strong> * A1层是column-linear，所以它沿隐藏维度拆分 Y；GeLU激活函数在每个GPU上独立应用 Z1，形状为 (b, s, h/2) *<strong>第二次线性变换（TP区域）</strong> * B1层是row-linear，它恢复隐藏维度 W1 形状为 (b, s, h) * <strong>最后转换（TP→ SP）</strong> *“g*”操作（reduce-scatter），在前一个row-linear层的进行dropout，同时在sequence维度上进行分散；W1形状为(b, s/2, h)</p><p><img src="/posts/ca7e7de/image-29.png"></p><p>SP：的一大优势是：它减小了需要存储的最大的activationsize。在仅使用TP时，需要在不同的点存储形状为（b, s,h）的activations。然而，使用SP后，最大的activation size减小到<span class="math inline">\(\frac{b\cdot s\cdot h}{tp}\)</span>（<span class="math inline">\(tp\)</span>是分割数），因为总是沿着序列维度或隐藏维度进行拆分。</p><p>以下表格描述：前向传播过程中，activations shape随着隐藏维度<span class="math inline">\(h\)</span>和序列维度<span class="math inline">\(s\)</span>的变化：</p><table><colgroup><col style="width: 21%"><col style="width: 39%"><col style="width: 38%"></colgroup><thead><tr><th>Region</th><th>TP only</th><th>TP with SP</th></tr></thead><tbody><tr><td>Enter TP (Column Linear)</td><td>h: sharded (weight_out is sharded)</td><td>h: sharded (weight_out is sharded) <br> s:<strong>all-gather</strong> to full</td></tr><tr><td>TP Region</td><td>h: sharded <br> s: full</td><td>h: sharded <br> s: full</td></tr><tr><td>Exit TP (Row Linear)</td><td>h: full (weight_out is full + all-reduce for correctness) <br> s:full</td><td>h: full (weight_out is full + <strong>reduce-scatter</strong> forcorrectness) <br> s: <strong>reduce-scatter</strong> to sharded</td></tr><tr><td>SP Region</td><td>h: full <br> s: full</td><td>h: full <br> s: sharded</td></tr></tbody></table><p>对于嵌入层：</p><table><colgroup><col style="width: 28%"><col style="width: 36%"><col style="width: 35%"></colgroup><thead><tr><th>Region</th><th>Vanilla TP</th><th>TP with SP</th></tr></thead><tbody><tr><td>Embedding Layer (Row Linear sharded on vocab)</td><td>h: full (weight_out is full + <strong>all-reduce</strong> forcorrectness) <br> s: full</td><td>h: full (weight_out is full + <strong>reduce-scatter</strong> forcorrectness) <br> s: <strong>reduce-scatter</strong> to sharded</td></tr></tbody></table><h5 id="b大模型的内存使用量-1">70B大模型的内存使用量</h5><p><img src="/posts/ca7e7de/image-30.png"></p><p>如上图，通过TP/SP=16，使得处理16k tokens成为可能。</p><blockquote><p>使用TP+SP是否会比传统的TP引入更多的通信开销？是和否都有可能。</p><p>在传统TP的前向传播过程中，每个Transformer块中有两个all-reduce操作；而在SP中，每个Transformer块中有两个all-gather和两个reduce-scatter操作。因此，SP的通信操作数量是TP的两倍。但由于all-reduce操作可以分解为all-gather+reduce-scatter。因此它们在通信开销上是等效的。同样的推理适用于反向传播，因为我们只需使用每个操作的共轭（no-op↔︎ all-reduce，all-gather ↔︎ reduce-scatter）。</p></blockquote><p>在每个layer中，讨论了4个通信操作（2个用于Attention，2个用于MLP）。以下为TP+SP时，MLP的性能分析情况：<img src="/posts/ca7e7de/image-31.png"></p><p>和TP相似，TP+SP难以与计算重叠，这使得吞吐量在很大程度上依赖于通信带宽。在这一点上，和传统TP一样，TP+SP通常只在单个节点内执行（将TPdegree保持在每个节点的GPU数量之下，例如TP≤8）。</p><h5 id="tpsp性能">TP+SP性能</h5><p>以下为使用TP+SP扩展时，对于一个3B模型和4096序列长度，吞吐量和内存利用率的变化：<img src="/posts/ca7e7de/image-32.png">再次观察到，计算效率（左图）和内存容量（右图）之间的trade-off。虽然较高的并行度通过减少activations的内存，能够处理<strong>更大的批次大小</strong>；但它们也<strong>降低了每个GPU的吞吐量</strong>，特别是当并行度超过节点内GPU数量的阈值时。</p><p>总结观察结果：</p><ul><li>对于这两种方法，在<strong>从TP=8到TP=16时，性能出现最大降幅</strong>：因为这是我们从仅在单个节点（NVLink）内进行通信，转变为跨节点通信（EFA）的时刻；</li><li>使用TP+SP时，相较于TP，帮助处理<strong>更大的批次</strong>；</li></ul><p>TP通过沿着<strong>隐藏维度</strong>拆分注意力和前馈操作，将activations分布在多个GPU上；而SP沿着<strong>序列维度</strong>拆分剩余的操作，进一步提高了activations的并行程度。</p><blockquote><p>由于SP区域中的LayerNorm操作在不同的序列部分上进行，因此它们的梯度会在不同TPranks之间有所不同。为了确保权重保持同步，我们需要在反向传播过程中，对它们的梯度进行all-reduce操作，类似于数据并行（DP）确保权重同步。然而，这只是一个小的通信开销，因为LayerNorm的参数相对较少。</p></blockquote><p>然而，TP和SP也有两个限制： 1.如果扩展序列长度，TP区域的activations内存仍然会膨胀； 2.如果模型太大，无法适应TP=8，那么由于节点间连接的瓶颈，将出现巨大的性能下降。</p><p>我们可以通过上下文并行（ContextParallelism）来解决问题1），通过流水线并行（PipelineParallelism）来解决问题2）。接下来，先来看看上下文并行！</p><h3 id="上下文并行context-parallelism解决长序列的activations爆炸">上下文并行（ContextParallelism）：解决长序列的activations爆炸</h3><p>通过张量并行（Tensor Parallelism）和序列并行（SequenceParallelism），我们可以显著减少每个GPU的内存需求，因为模型的weights和activations被分布到多个GPU上。然而，当我们训练更长的序列时（例如，当序列长度扩展到128k或更多tokens时），仍然可能超出单个节点的内存容量，因为在TP区域内，我们仍然需要处理完整的序列长度。</p><p>此外，即使我们完全重新计算activations（带来大约30%的计算开销），仍然需要在layerboundaries处保留一些activations，其内存需求也会随着序列长度的增加而线性增长。接下来，看看CP如何帮助我们解决这个问题：</p><p>SP沿着序列维度拆分输入；但现在，将<strong>这种拆分应用到整个模型</strong>，而不是仅仅应用于模型中的SP区域。</p><p><strong>拆分序列</strong>不会影响大多数模块，如MLP和LayerNorm（每个token都是独立处理的）。它也不需要像TP那样的昂贵通信（因为仅拆分输入，而不是权重矩阵）。就像DP一样，在计算梯度后，会<strong>启动一个all-reduce操作，来同步CP组中的梯度</strong>。</p><p>然而，一个重要的例外是：<strong>注意力模块</strong>。在注意力模块中，<strong>每个token需要访问所有其他序列token的键/值对</strong>（即使在causalattention中，也至少需要关注之前的所有token）；因此，注意力模块需要在GPU之间进行完全通信，以交换必要的keys/values。</p><p>这个想法是intuitivelyexpensive的。现在引入一个高效的key/value通信机制：<strong>RingAttention</strong>。</p><h4 id="ring-attention">Ring attention</h4><p>首先，每个GPU启动一个异步通信操作，将其key/valuepair发送至其他GPU；在等待其他GPU数据时，计算已存储在内存中数据的注意力分数。理想情况下，在计算完成之前，从另一个GPU接收到下一个key/valuepair，这样GPU就可以在完成第一轮计算后，立即开始下一轮计算。（等待与计算重叠）。</p><p>假设当前有4个GPU和一个4个token的输入。最初，输入序列沿着序列维度均匀拆分，因此每个GPU将只拥有一个token及其对应的Q/K/V值。假设Q1、K1和V1表示第一个token的query、key和value，这些数据位于第一个GPU上。注意力计算需要4个step才能完成。在每个step内，每个GPU执行以下三个连续操作：</p><ol type="1"><li>将当前key/value以非阻塞的方式发送到下一个机器（除了在最后一个step）；</li><li>本地计算注意力分数：运用当前的key/value值： <span class="math display">\[softmax(\frac{QK^{T}}{\sqrt{d}})*V\]</span></li><li>等待接收来自前一个GPU的key/value；返回第1步，更新当前的key/value为：刚从前一个GPU接收到的key/value。<img src="/posts/ca7e7de/image-33.png"></li></ol><p>然而，Ring Attention的简单实现，会导致一个问题：由causalattention矩阵形状引起的<strong>GPU负载不均</strong>。来看看casualattention mask的计算： <img src="/posts/ca7e7de/image-34.png"><strong>SoftMax是按行计算</strong>的，这说明：<strong>每当一个GPU接收到某行的所有token时，它就可以开始计算</strong>。可以看到，GPU1可以立即计算它，因为它从token1到token4开始，且GPU1实际上不需要从其他GPU接收任何信息；然而，GPU2需要等待第二轮，才能接收到token1-4，从而拥有token1-8的所有值。此外，GPU1似乎执行的工作远少于其他所有GPU。</p><p>用什么方式平衡GPU负载呢？</p><h5 id="zig-zag-ring-attention">Zig-Zag Ring Attention</h5><p>我们需要更好的方法来分配输入序列。这可以通过不完全按顺序将token分配给GPU，而是<strong>稍微混合一下顺序，使得每个GPU都有早期和晚期的token</strong>。这个方法被称为Zig-ZagAttention，在这种新的安排中，attentionmask将展现更均匀的计算分布，（数一数被标记的方块，发现计算已经在所有GPU之间平衡分配）</p><p>同时看到，为了完成所有行，每个GPU都需要从其他GPU获取信息。</p><p><img src="/posts/ca7e7de/image-35.png"></p><p>有两种常见方式来使计算和通信重叠，分别是： 1.执行一般的all-gather，将每个GPU上的所有同时KV重新收集（类似ZeRO-3）； 2.按需将每个GPU上的key/value pair，逐个从一个GPU收集到另一个GPU。</p><ul><li>all-gather实现：所有GPU同时收集来自其他所有GPU的完整KV对<ul><li>需要更多的临时内存，因为每个GPU必须同时存储完整的KV对；</li><li>通信一次性完成，但内存开销较大。 <img src="/posts/ca7e7de/image-37.png"></li></ul></li><li>All-to-All（Ring）实现：GPU以类似环形的模式交换KV对，一次交换一块<ul><li>更节省内存，因为每个GPU只需要临时存储一块额外的KV对；</li><li>通信被分散，与计算重叠 <img src="/posts/ca7e7de/image-36.png"></li></ul></li></ul><p>TP在跨节点时扩展性不好，如果模型权重无法轻松放入一个节点该怎么办呢？接下来，进入另一种并行方式：PipelineParallelism（流水线并行），来解决这个问题！</p><h3 id="流水线并行pipeline-parallelism">流水线并行（PipelineParallelism）</h3><p>在TP部分，我们看到，<strong>当尝试将TP扩展到超出单节点内GPU数量（通常为4或8）时，性能会受到一个低带宽网络——“节点间连接”的强烈影响</strong>。可以通过对集群中多个节点进行基准测试清晰地看到这一点（每个节点有8个GPU）：节点间通信带宽测量，展示了不同节点数下的AllReduce、AllGather和ReduceScatter操作的中位数（线）和5th-95th百分位范围（阴影区域）。<img src="/posts/ca7e7de/image-38.png"></p><p>SP和CP可以帮助处理长序列，但如果内存问题的根本原因不是序列长度，而是模型本身的大小，它们的帮助就不大了。<strong>对于大型模型（如70B+），仅仅模型权重的大小就足以超出单节点上4-8个GPU的限制</strong>。我们可以通过引入第四个（也是最后一个）并行维度：“流水线并行性（PipelineParallelism）”来解决这个问题。</p><p>PP是一种简单但强大的技术——我们<strong>将模型的层划分到多个GPU上</strong>！例如，如果我们有8个GPU，我们可以将第1-4层放在GPU1上，将第5-8层放在GPU2上，依此类推。这样，<strong>每个GPU只需要存储和处理模型的一部分层，显著减少了每个GPU的内存需求</strong>。让我们看看在一个8B模型上的流水线并行性如何影响内存使用情况：</p><p><img src="/posts/ca7e7de/image-39.png"></p><p>从上图可知：尽管模型参数在GPU之间得到了很好的分配，但<strong>每个GPU的activations内存仍然保持不变</strong>！（每个GPU仍然需要处理完整的批次数据，只不过它们处理的是不同的层）。<strong>一个GPU的层产生的activations会被传递到下一个GPU</strong>，以继续前向传播。</p><p>这引入了一种新的通信模式：与DP中通过ZeRO-3传递参数不同；现在通过Pipeline，在GPU之间顺序地传递activationtensors。</p><h4 id="在不同节点上拆分层">在不同节点上拆分层</h4><p>假设我们简单地将模型的层分布在多个设备上，例如：第一块GPU处理模型的前几层，第二块GPU处理模型的后几层，依此类推。这样，模型的前向传播过程转为：按顺序将数据批次传递给每个计算设备，从而依次使用每个设备进行计算。</p><blockquote><p>这种做法的直接优势之一是：所需的互联带宽较低，因为只在模型深度的几个位置传递中等大小的activations；（而TP中，通信发生在每一层的多个位置）</p></blockquote><p>然而，PP的主要挑战在于：如何高效地绕过PP的顺序性质，以确保GPU始终保持忙碌状态，即<strong>保持：计算与通信的重叠状态</strong>。<img src="/posts/ca7e7de/image-40.png">上图中，空闲时间用灰色表示，命名为“bubble”。bubble造成的时间损失是多少呢？</p><blockquote><p>假设<span class="math inline">\(t_f\)</span>, <span class="math inline">\(t_b\)</span>分别是前向和反向传播的时间，针对一个microbatch和管道的一个阶段进行测量（（一个简单的假设是：<span class="math inline">\(t_b=2*t_f\)</span>），如果实现完美的并行化，理想时间为：<span class="math inline">\(t_{id}=t_b+t_f\)</span>.</p><p>但是，考虑到bubble的存在，额外的时间为： <span class="math display">\[t_pb=(p-1)\times (t_b+t_f)\]</span> 其中，<span class="math inline">\(p\)</span>是pipeline并行度（GPU数量）。那么bubble时间和理想时间的比率为：<span class="math inline">\(p-1\)</span>。即：随着更多GPU的加入，bubble时间增加，GPU的时间利用率下降。</p></blockquote><p>有哪些减少bubble的方法呢？先看看第一个：all-forward-all-backward(AFAB) 调度。</p><h4 id="all-forward-all-backward-afab-调度改善activations的内存占用">all-forward-all-backward(AFAB) 调度：改善activations的内存占用</h4><p>将批次分成更小的部分，这些部分可以并行或几乎并行地处理（就像在DP中做的那样）。现在，当第二个GPU忙于处理microbatch1时，第一个GPU可以开始处理microbatch1。以下是使用8个microbatch的调度示例： <img src="/posts/ca7e7de/image-41.png"></p><p>首先执行所有的前向传播，然后仅执行所有的反向传播。其优点是：<strong>前向和反向步骤仍然是一般性的顺序操作</strong>，因此保留了模型训练代码的一般组织方式。AFAB是PP的最简单的实现之一。</p><blockquote><p>处理<span class="math inline">\(m\)</span>个microbatch的理想时间为：<span class="math inline">\(t_{id}=m\times(t_f+t_b)\)</span>；</p><p>bubble时间比率为：<span class="math inline">\(r_{bubble}=\frac{(p-1)\times(t_f+t_b)}{m\times(t_f+t_b)}=\frac{p-1}{m}.\)</span></p><p>通过增加更多的microbatch，可以减少bubble的大小，将其缩小<span class="math inline">\(m\)</span>倍。</p></blockquote><p>尽管bubble令人烦恼，但还有一个更大的问题：当前需要将所有的activations存储在内存中，直至到达反向传播阶段，这会导致在PP中快速出现内存爆炸。那么，我们能否做得更好？</p><h4 id="one-forward-one-backward1f1b调度-和-llama-3.1-schemes">One-forward-one-backward（1F1B）调度和 LLama 3.1 schemes</h4><p>1F1B的中间稳定状态为：<strong>交替执行一次前向传播和一次反向传播</strong>。其理念是尽早开始执行反向传播。调度如下图：<img src="/posts/ca7e7de/image-42.png">bubble的大小相同，因此训练效率没有显著提高。然而，<strong>只需要存储<span class="math inline">\(p\)</span>个microbatch的activations（<span class="math inline">\(p\)</span>为pipeline并行度）</strong>，无需存储<span class="math inline">\(m\)</span>个microbatch的activations。从而减小AFAB调度中的内存爆炸压力。<img src="/posts/ca7e7de/image-43.png"> 在左图中：</p><ul><li><span class="math inline">\(m\leqp-1\)</span>时，bubble的存在导致性能较低（即使扩展<span class="math inline">\(p\)</span>，性能也下降）；</li><li><span class="math inline">\(m=32&gt;&gt;p-1\)</span>时，可以改善低pipeline并行度下的性能。</li></ul><p>实际上，由于最终受限于global batchsize的影响，不能无限地增加microbatch的数量，以保持<span class="math inline">\(m&gt;&gt;p-1\)</span>的比例。</p><blockquote><p>可以观察到，在左图中（microbatch数量较少时），从一个节点（<span class="math inline">\(p=8\)</span>）扩展到两个节点（<span class="math inline">\(p=16\)</span>）时，性能仅下降14%；TP在类似跨节点场景下，性能下降约43%）。因此PP非常适合分布式训练。</p></blockquote><p>1F1B改善了activations的内存使用；但是由<span class="math inline">\(r_{bubble}=\frac{p-1}{m}\)</span>可知，bubble大小与<span class="math inline">\(p\)</span>成比例，GPU计算依然处于空闲状态，是否有更智能的调度策略呢？</p><h4 id="交错阶段interleaving-stages改善bubble大小">交错阶段（InterleavingStages）：改善bubble大小</h4><p>到目前为止，我们是通过沿模型深度维度简单地切分模型，例如将第 1-4层放在第一个 GPU 上，将第 5-8 层放在第二个 GPU上。但其实还有其他方式可以切分我们的层，例如将奇数层（1、3、5、7）放在第一个GPU 上，将偶数层（2、4、6、8）放在第二个 GPU 上。</p><p>这可以看作是一种“循环管道”的方式，其中microbatch将从一个 GPU移动到下一个 GPU，在模型的前向传播过程中不断循环。 <img src="/posts/ca7e7de/image-44.png"></p><p>随着模型在每个 GPU上多次经过，出现了额外的通信操作，这是因为之前只需要计算只需传递一次，现在需要传递多次。每个前向和反向传播过程被切分为<span class="math inline">\(v\)</span>个部分（<span class="math inline">\(v\)</span>是每个 GPU 上的stages或modelchunks的数量）。则有： <span class="math display">\[t_{pb}=\frac{(p-1)\times(t_f+t_b)}{v}\\r_{bubble}=\frac{1}{v}\frac{(p-1)\times(t_f+t_b)}{m\times(t_f+t_b)}=\frac{p-1}{v\timesm}\]</span>现在，我们通过增加microbatch数量和交错阶段数量，来减小bubble大小（当然，通信量也会增加一个因子<span class="math inline">\(v\)</span>）。 下图为<span class="math inline">\(p=8\)</span>时的bubble大小。其中：</p><ul><li><span class="math inline">\(m=1,v=1\)</span>：普通的流水线并行；</li><li><span class="math inline">\(v=1\)</span>：AFAB或1F1B；</li><li><span class="math inline">\(v\neq 1\)</span>：交错阶段。 <img src="/posts/ca7e7de/image-45.png"></li></ul><p>GPU调度是一个值得深入探讨的问题。有两种方式：</p><ol type="1"><li><strong>深度优先</strong>：优先让较早的micro-batches通过更靠后的layers：尽快关闭前向和反向循环，即尽快让batches从模型中输出；</li><li><strong>深度优先</strong>：优先让较后的micro-batches通过更靠前的layers：尽可能填满pipeline。</li></ol><blockquote><p>Llama3.1中的PP策略：1F1B+交错阶段，depth-first和bread-first可选。<img src="/posts/ca7e7de/image-46.png"></p></blockquote><p>然而，PP的策略优化依然进行中，在DeepSeekV3/R1中，提出了一种方法，将bubble大小降低至几乎为零！</p><h4 id="zero-bubble和双管道dualpipe">ZeroBubble和双管道（DualPipe）</h4><p>核心理念是：将涉及的操作划分得更精细，以最有效的方式进行交错。</p><p>Zero Bubble是DualPipe的前身。ZeroBubble的基本观察是，矩阵乘法的反向传播，涉及两个独立的操作：输入的反向操作（B）和权重的反向操作（W）：</p><p>输入的反向传播，是进行执行更低层反向传播的必要条件；然而，权重的反向传播则不是（只要在优化步骤之前执行即可），如下图所示：<img src="/posts/ca7e7de/image-47.png"></p><p>因此，权重的反向操作（W），可安排在对应B之后的任何位置；这<strong>允许策略性地安排W，以填补pipeline中的buble</strong>。</p><blockquote><p><img src="/posts/ca7e7de/image-48.png"> *1F1B调度：交替进行前向/反向传播，但反向传播为较粗粒度； *ZeroBubble的两个变种：<strong>将反向传播拆分为：B和W的细粒度操作</strong>（最后一个称为ZB-H2，是一个理论上的ZeroBubble调度）</p><p>DeepSeek 的 DualPipe 在其 V3技术报告中，引入了这一分解方法的扩展，增加了<strong>两个流从 PP维度的两端传播</strong>的情况，这些流被交替安排，以进一步最小化 GPU的空闲时间。如下图： <img src="/posts/ca7e7de/image-49.png"></p></blockquote><p>最后来到专家并行（ExpertParallelism），其提供高效训练大模型的并行策略。</p><h3 id="专家并行expert-parallelism">专家并行（Expert Parallelism）</h3><p><a href="https://huggingface.co/blog/moe">MoE框架介绍</a></p><p>MoE由两个关键部分组成：</p><ol type="1"><li>稀疏MoE层：替代Transformer中的前馈网络（FFN）层，包含若干个expert，每个expert本身是一个独立的神经网络。</li><li>gatenetwork和router：决定哪个tokens发送到哪个expert（可以将一个token发送给多个expert）。roter由学习得到的参数组成，与网络的其他部分一同预训练。<img src="/posts/ca7e7de/image-50.png"> &gt; MoE特点：（与稠密模型相比） &gt; *训练：预训练速度更快；但在微调阶段常面临泛化能力不足，易引发过拟合；&gt; *推理：由于只使用一部分参数，MoE推理速度快于相同参数量的稠密模型；但需要将所有expert加载至内存，对显存要求高。</li></ol><p>EP的理念是：运用MoE框架，实现expert维度上的并行。由于前馈层完全独立，可以<strong>将每个expert的前馈层，放在不同的worker上</strong>。（比TP更轻量，因为无需拆分矩阵乘法，只需将token的隐藏层通过router导引至相应expert）</p><p>现实中，EP通常与其他并行策略一起使用（例如DP），因为<strong>EP只影响MoE层，不拆分tokens</strong>（CP会沿着序列维度拆分tokens）。<img src="/posts/ca7e7de/image-51.png"></p><h2 id="d并行">5D并行</h2><p>当前，已经学习了扩展模型训练的5种并行策略：</p><ol type="1"><li>数据并行（DP）：沿着batch维度</li><li>张量并行（TP）：沿着隐藏层维度</li><li>序列/上下文并行（SP/CP）：沿着sequence维度</li><li>流水线并行（PP）：沿着model layers维度</li><li>专家并行（EP）：沿着MoE experts维度</li></ol><p>以及三种可以与DP结合使用的 ZeRO 策略，用于节省内存： * ZeRO-1 – 在 DP副本之间，对optimizer states分片 * ZeRO-2 – 在 DP 副本之间，对optimizerstates, gradients分片 * ZeRO-3 – 在 DP 副本之间，对optimizer states,gradients, parameters分片</p><p>我们应该如何高效地组合这些策略，哪些策略应该分开使用？</p><h3 id="pp-vs.-zero-3">PP vs. ZeRO-3</h3><p>PP和ZeRO-3都是将模型weights划分到多个GPU上，沿着模型深度轴，执行计算/通信（例如在ZeRO-3中，在计算时预取下一层）。这说明：<strong>完整的层操作都在每个设备上进行</strong>（而不像TP 或 EP ，在子层单元上执行计算）。</p><p>PP和ZeRO-3的区别如下：</p><table><colgroup><col style="width: 31%"><col style="width: 34%"><col style="width: 33%"></colgroup><thead><tr><th><strong>Aspect</strong></th><th><strong>ZeRO-3</strong></th><th><strong>Pipeline Parallelism (PP)</strong></th></tr></thead><tbody><tr><td><strong>每个计算单元存储</strong></td><td>layer的一部分</td><td>整个layer</td></tr><tr><td><strong>使用通信传输的内容</strong></td><td>权重</td><td>激活值</td></tr><tr><td><strong>协调</strong></td><td>与模型无关</td><td>与模型无关</td></tr><tr><td><strong>实现挑战</strong></td><td>复杂的模型分区和通信处理</td><td>复杂的调度策略</td></tr><tr><td><strong>扩展性</strong></td><td>偏好大批量和长序列，以隐藏通信</td><td>偏好较大<code>grad_acc</code>以隐藏bubble</td></tr></tbody></table><p>ZeRO-3 和 PP解决的是相同的挑战，但涉及不同的方法，其结合使用在实践中并不常见；ZeRO-1和 ZeRO-2 主要关注优化器状态和梯度，很容易地与PP结合。</p><h3 id="tpsp">TP（+SP）</h3><p>TP与SP是天然互补的，可以与PP和ZeRO-3结合使用。因为它依赖于矩阵乘法的分配性质，这使得<strong>weights和activations可以被分割并独立计算，之后再进行合并</strong>。<img src="/posts/ca7e7de/image-52.png"> 单独使用TP的两个限制：</p><ol type="1"><li><strong>通信开销</strong>：由于TP的通信操作是计算关键路径的一部分，因此它在某个点之后难以很好地扩展，此时通信开销开始占主导地位。</li><li>模型特定的分割要求：与ZeRO和PP不同，TP需要确定activations的切分策略—有时是在隐藏维度（TP区域），有时是在序列维度（SP区域）—这使得实现变得更加繁琐。</li></ol><p>因此，TP通常用于<strong>节点内部通信</strong>；ZeRO-3或PP用于<strong>跨节点并行</strong>（需要更少的带宽（对于PP），或更容易与计算重叠（对于ZeRO-3））。</p><h3 id="cpep">CP/EP</h3><p>CP和EP均有利于activations的切片，可视作TP的互补。CP解决了长序列的训练问题；EP支持分布式MoE训练。</p><p>CP通过沿着序列维度切分activations，并使之分布在不同GPU上，解决长序列的训练问题。虽然大多数操作（如MLP和LayerNorm）可以独立处理这些分割的序列；但<strong>注意力层则需要通信，因为每个token都需要访问来自整个序列的keys/values</strong>（通过<strong>RingAttention</strong>处理，使得计算和通信重叠）。 &gt;CP在扩展到极端序列长度（128k+tokens）时尤为价值：此时即使使用完全的activations重计算，单个GPU的内存需求也难以承受。</p><p><img src="/posts/ca7e7de/image-53.png"></p><p>EP专门解决训练MoE的挑战：<strong>将experts分布在多个GPU上；在计算期间，动态地将tokens导向相关的expert</strong>。关键通信操作是：all-to-all操作，即将token通过router导向分配的expert，并将结果收集回来。尽管当前操作引入通信开销，但它使得模型容量显著扩展：因为<strong>每个token在推理（和训练）过程中，只由总参数的一个较小部分处理</strong>。<img src="/posts/ca7e7de/image-54.png"> &gt;EP和DP在输入处理上具备相似性：因此通常将EP视为DP的一个子方法；区别在于：EP使用专门的expertrouting处理输入；而DP让所有GPU通过相同的模型副本处理输入。</p><h3 id="总结">总结</h3><p>总结以上并行策略对模型各个子部分的影响：</p><ul><li>TP（+SP）：通过切分weights和activations，影响<strong>整个模型</strong>的计算；</li><li>CP：主要影响<strong>注意力层</strong>（需要跨序列通信），其他层可以独立处理被分割序列；</li><li>EP：主要影响<strong>MoE层</strong>（替代了标准的MLP块），其他注意力层和组件保持不变；</li><li>PP和ZeRO：不特别针对任何子模块或组件（唯一的例外是：PP中modules和layers需要平衡，因此第一层和最后一层通常会因为附加的嵌入层而被特别处理）</li></ul><table><colgroup><col style="width: 43%"><col style="width: 28%"><col style="width: 27%"></colgroup><thead><tr><th><strong>TP+SP</strong></th><th><strong>CP</strong></th><th><strong>EP</strong></th></tr></thead><tbody><tr><td>在hidden/seq维度上分割weights和activations</td><td>在seq维度上分割activations</td><td>分割expert的weights和activations</td></tr><tr><td>用于矩阵乘法操作（column/row linears）的通信</td><td>用于注意力key/values的通信</td><td>用于token路由到expert的通信</td></tr><tr><td>针对模型特定实现</td><td>除注意力外，与模型无关</td><td>除MoE层外，与模型无关</td></tr><tr><td>偏好高带宽的节点内通信</td><td>偏好长序列长度</td><td>需要MoE模型</td></tr></tbody></table><p><img src="/posts/ca7e7de/image-55.png"></p><p><img src="/posts/ca7e7de/image-56.png"></p><table><colgroup><col style="width: 11%"><col style="width: 40%"><col style="width: 30%"><col style="width: 17%"></colgroup><thead><tr><th><strong>方法</strong></th><th><strong>内存节省</strong></th><th><strong>并行/切分维度</strong></th><th><strong>缺点</strong></th></tr></thead><tbody><tr><td>DP</td><td>Activations (降低local batch size)</td><td>Batch</td><td>受限于max batch size</td></tr><tr><td>PP</td><td>Model parameters</td><td>Model layers</td><td>bubble和复杂调度</td></tr><tr><td>TP/SP</td><td>Model parameters和activations</td><td>Hidden dimension / Sequence length</td><td>高带宽通信</td></tr><tr><td>CP</td><td>Activations</td><td>Sequence length</td><td>注意力模块增添额外通信</td></tr><tr><td>EP</td><td>Experts parameters</td><td>Expert dimension</td><td>需要MoE layers, 增添额外routing通信</td></tr><tr><td>ZeRO-1</td><td>Optimizer states</td><td>在DP副本之间切分</td><td>额外的参数通信</td></tr><tr><td>ZeRO-2</td><td>Optimizer states and gradients</td><td>在DP副本之间切分</td><td>额外的参数通信</td></tr><tr><td>ZeRO-3</td><td>Optimizer states, gradients, and model parameters</td><td>在DP副本之间切分</td><td>额外的参数通信</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> Parallelism </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>C++泛型算法</title>
      <link href="/posts/44ad5109.html"/>
      <url>/posts/44ad5109.html</url>
      
        <content type="html"><![CDATA[<p>本篇隶属C++Primer中C++标准库专题，当前关注<strong>范型算法</strong>。</p><p>标准库容器只定义了很少的操作；因此提供了一组范型算法，其中大多数独立于特定的容器，具备通用性。</p><h1 id="范型算法">范型算法</h1><h2 id="概述">概述</h2><p>大多数算法在头文件<code>algorithm</code>中；头文件<code>numeric</code>中定义了一组数值范型算法。</p><p>范型算法本身<strong>不会执行容器的操作；只会运行于迭代器之上，执行迭代器的操作</strong>。</p><h3 id="只读算法">只读算法</h3><p>只读取输入范围的元素，从不改变元素</p><h4 id="find">find</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> val=<span class="number">42</span>;</span><br><span class="line"><span class="keyword">auto</span> result=<span class="built_in">find</span>(vec.<span class="built_in">cbegin</span>(), vec.<span class="built_in">cend</span>(), val);</span><br></pre></td></tr></table></figure><ul><li><code>find</code>前两个参数：表示元素范围的迭代器；第三个参数：一个值。将范围中每个元素与给定值比较：<ul><li>返回指向第一个等于给定值元素的迭代器；</li><li>若范围内无匹配元素，返回第二个参数，表示搜索失败。</li></ul></li></ul><h4 id="accumulate">accumulate</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> sum=<span class="built_in">accumulate</span>(vec.<span class="built_in">cbegin</span>(), vec.<span class="built_in">cend</span>(), <span class="number">0</span>);<span class="comment">// 将sum设置为：vec中元素之和</span></span><br></pre></td></tr></table></figure><ul><li><p>第三个参数指定保存和的对象类型，在该类型上必须定义了"+"运算符</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 错误：const char*上没有定义+</span></span><br><span class="line">string sum=<span class="built_in">accumulate</span>(v.<span class="built_in">cbegin</span>(),v.<span class="built_in">end</span>(),<span class="string">&quot;&quot;</span>);</span><br></pre></td></tr></table></figure></li></ul><h4 id="equal">equal</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">euqal</span>(roster<span class="number">1.</span><span class="built_in">cbegin</span>(), roster<span class="number">1.</span><span class="built_in">cend</span>(), rster<span class="number">2.</span><span class="built_in">cbegin</span>());</span><br></pre></td></tr></table></figure><ul><li><code>equal</code>确定两个序列是否保存相同的值（三个参数均为迭代器）：前两个表示第一个序列中的元素范围；第三个表示第二个序列的首元素<ul><li>假设：第二个序列的长度，不小于第一个序列</li></ul></li></ul><blockquote><p>两个序列中元素类型，不要求严格匹配：构成两个序列的元素，可来自不同容器（例：第一个序列保存在<code>vector</code>中；第二个序列保存在<code>deque</code>中）</p></blockquote><h3 id="写容器元素的算法">写容器元素的算法</h3><p>要求：序列原大小不小于要写入的元素数目。</p><blockquote><p>算法不执行容器操作，因此不改变容器大小。</p></blockquote><ul><li><p>算法不检查写操作：例如<code>fill_n</code>假定写入操作安全，没有检查vec是否为空</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vector&lt;<span class="type">int</span>&gt; vec;<span class="comment">// 空vector</span></span><br><span class="line"><span class="built_in">fill_n</span>(vec.<span class="built_in">begin</span>(), vec.<span class="built_in">size</span>(), <span class="number">0</span>);<span class="comment">// 未定义操作</span></span><br></pre></td></tr></table></figure></li></ul><h4 id="back_inserter插入迭代器">back_inserter：插入迭代器</h4><p>定义在头文件<code>iterator</code>中。</p><p>通过此迭代器添加元素时，会调用<code>push_back</code>将一个具备给定值的元素添加到容器中。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vector&lt;<span class="type">int</span>&gt; vec;<span class="comment">// 空vector</span></span><br><span class="line"><span class="built_in">fill_n</span>(<span class="built_in">back_inserter</span>(vec), <span class="number">10</span>, <span class="number">0</span>);<span class="comment">// 合法</span></span><br></pre></td></tr></table></figure><h4 id="copy拷贝算法">Copy：拷贝算法</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> a1[]=&#123;<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>&#125;;</span><br><span class="line"><span class="type">int</span> a2[<span class="built_in">sizeof</span>(a1)/<span class="built_in">sizeof</span>(*a1)];<span class="comment">// a2与a1大小相同</span></span><br><span class="line"><span class="keyword">auto</span> ret=<span class="built_in">copy</span>(<span class="built_in">begin</span>(a1), <span class="built_in">end</span>(a1), a2);<span class="comment">// 将a1的内容拷贝给a2</span></span><br></pre></td></tr></table></figure><ul><li>返回值<code>ret</code>指向拷贝到<code>a2</code>尾元素之后的位置</li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">replace</span>(lst.<span class="built_in">begin</span>(), lst.<span class="built_in">end</span>(), <span class="number">0</span>, <span class="number">42</span>);<span class="comment">// 将所有值为0的元素，替换为42</span></span><br><span class="line"><span class="built_in">replace_copy</span>(lst.<span class="built_in">cbegin</span>(), lst.<span class="built_in">cend</span>(), <span class="built_in">back_inserter</span>(ivec), <span class="number">0</span>, <span class="number">42</span>);<span class="comment">// 保留lst不变，ivec包含lst的一份拷贝，但lst中为0的元素，在ivec中改为42</span></span><br></pre></td></tr></table></figure><h3 id="重排容器元素的算法">重排容器元素的算法</h3><h4 id="消除重复元素unique">消除重复元素：unique</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sort</span>(words.<span class="built_in">begin</span>(), words.<span class="built_in">end</span>());</span><br><span class="line"><span class="comment">// unique进行重排，返回指向不重复区域之后第一个位置的迭代器</span></span><br><span class="line"><span class="keyword">auto</span> end_unique=<span class="built_in">unique</span>(words.<span class="built_in">begin</span>(), words.<span class="built_in">end</span>());</span><br><span class="line">words.<span class="built_in">erase</span>(end_unique, words.<span class="built_in">end</span>());<span class="comment">// 要擦除的范围</span></span><br></pre></td></tr></table></figure><blockquote><p>标准库算法对迭代器操作，不对容器操作；因此无法添加、删除元素。</p></blockquote><h4 id="删除元素erase">删除元素：erase</h4><h2 id="定制操作">定制操作</h2><p><code>sort</code>算法默认使用元素类型的<strong>&lt;</strong>运算符。</p><h3 id="向算法传递函数使用谓词">向算法传递函数：使用谓词</h3><p>标准库算法使用两类谓词：一元谓词（接受单一参数）、二元谓词（接受两个参数）。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">bool</span> <span class="title">isShorter</span><span class="params">(<span class="type">const</span> string &amp;s1, <span class="type">const</span> string &amp;s2)</span></span>&#123;</span><br><span class="line">  <span class="keyword">return</span> s<span class="number">1.</span><span class="built_in">size</span>()&lt;s<span class="number">2.</span><span class="built_in">size</span>();</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">stable_sort</span>(words.<span class="built_in">begin</span>(), words.<span class="built_in">end</span>(), isShorter);</span><br><span class="line"><span class="comment">// stable_sort:稳定排序</span></span><br></pre></td></tr></table></figure><h3 id="lambda表达式">lambda表达式</h3><p>一个lambda表达式表示：一个可调用的代码单元，可理解为：一个未命名的内联函数。一个lambda具有：一个返回类型、一个参数列表、一个函数体，可定义在函数内部。形式如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[capture list](parameter list) -&gt; return type &#123;function body&#125;</span><br></pre></td></tr></table></figure><ul><li>捕获列表（capturelist）：<strong>使用的所在函数中的局部变量</strong></li></ul><p>若lambda函数体包含任何单一<code>return</code>语句之外的内容，且未指定返回类型，则返回<code>void</code>.</p><h4 id="向lambda传递参数">向lambda传递参数</h4><p>lambda不能有默认参数；其调用的实参数目永远与形参数目相等。</p><h4 id="调用find_if">调用find_if</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> wc=<span class="built_in">find_if</span>(words.<span class="built_in">begin</span>(), words.<span class="built_in">end</span>(), [sz](<span class="type">const</span> string &amp;a&#123;<span class="keyword">return</span> a.<span class="built_in">size</span>()&gt;=sz;&#125;));</span><br><span class="line"><span class="comment">// find_if返回一个迭代器，指向第一个长度不小于sz的元素；若不存在，则返回words.end()的一个拷贝</span></span><br></pre></td></tr></table></figure><h4 id="for_each算法">for_each算法</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">for_each(wc, words.<span class="built_in">end</span>(), [](cosnt string &amp;s)&#123;cout&lt;&lt;s&lt;&lt;<span class="string">&quot; &quot;</span>;&#125;);</span><br></pre></td></tr></table></figure><h3 id="lambda捕获和返回">lambda捕获和返回</h3><p>捕获列表只用于<strong>局部非static变量</strong>；lambda可直接使用局部static变量，和所在函数之外声明的名字。</p><p>当定义一个lambda时，编译器生成一个与lambda对应的新的（未命名的）类类型，以及该类型的一个对象。</p><h4 id="值捕获">值捕获</h4><ul><li>前提：<strong>变量可拷贝</strong>，被捕获的变量的值<strong>在lambda创建时拷贝</strong>，不是调用时拷贝</li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">fcn</span><span class="params">()</span></span>&#123;</span><br><span class="line">  <span class="type">size_t</span> v1=<span class="number">42</span>;</span><br><span class="line">  <span class="keyword">auto</span> f=[v1]&#123;<span class="keyword">return</span> v1;&#125;<span class="comment">// 被捕获的v1，在创建时拷贝，值为42</span></span><br><span class="line">  v1=<span class="number">0</span>;</span><br><span class="line">  <span class="keyword">auto</span> j=<span class="built_in">f</span>();<span class="comment">// j为42，f保存了创建时v1的拷贝，之后的修改不影响</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="引用捕获">引用捕获</h4><ul><li><p>在lambda函数体中使用捕获变量时，使用的是<strong>引用绑定的对象</strong>。</p><blockquote><p>用引用方式捕获变量时，必须保证：lambda执行时，引用所指的对象存在。</p></blockquote></li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">fcn2</span><span class="params">()</span></span>&#123;</span><br><span class="line">  <span class="type">size_t</span> v1=<span class="number">42</span>;</span><br><span class="line">  <span class="keyword">auto</span> f2=[&amp;v1]&#123;<span class="keyword">return</span> v1;&#125;</span><br><span class="line">  v1=<span class="number">0</span>;</span><br><span class="line">  <span class="keyword">auto</span> j=<span class="built_in">f2</span>();<span class="comment">// j为0，f2保存了v1的引用，而非拷贝</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="隐式捕获">隐式捕获</h4><ul><li>指示编译器：<strong>&amp;表示引用捕获，=表示值捕获</strong></li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">biggies</span><span class="params">(vector&lt;string&gt;&amp; words, vector&lt;string&gt;::size_type sz, ostream &amp;os=cout, <span class="type">char</span> c=<span class="string">&#x27; &#x27;</span>)</span></span>&#123;</span><br><span class="line">  <span class="comment">// os隐式捕获：引用捕获；c显式捕获：值捕获</span></span><br><span class="line">  for_each(words.<span class="built_in">begin</span>(), words.<span class="built_in">end</span>(), [&amp;, c](<span class="type">const</span> string &amp;s)&#123;os&lt;&lt;s&lt;&lt;c;&#125;);</span><br><span class="line">  <span class="comment">// os显式捕获：引用捕获；c隐式捕获：值捕获</span></span><br><span class="line">  for_each(words.<span class="built_in">begin</span>(), words.<span class="built_in">end</span>(), [=, &amp;os](<span class="type">const</span> string &amp;s)&#123;os&lt;&lt;s&lt;&lt;c;&#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="/posts/44ad5109/1c722e0403d48007201538138586c18.jpg"></p><h4 id="可变lambda">可变lambda</h4><p>值捕获：默认情况下，对于一个值被拷贝的变量，lambda内不改变其值；若要改变被捕获变量的值，须在参数列表首加关键字<strong>mutable</strong>：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">fcn3</span><span class="params">()</span></span>&#123;</span><br><span class="line">  <span class="type">size_t</span> v1=<span class="number">42</span>;</span><br><span class="line">  <span class="keyword">auto</span> f=[v1] ()<span class="keyword">mutable</span> &#123;<span class="keyword">return</span> ++v1;&#125;<span class="comment">// f能改变捕获的变量v1的值</span></span><br><span class="line">  v1=<span class="number">0</span>;</span><br><span class="line">  <span class="keyword">auto</span> j=<span class="built_in">f</span>();<span class="comment">// j为43</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>引用捕获：传递非const类型</p><h4 id="指定lambda返回类型">指定lambda返回类型</h4><p>默认情况下，若lambda体包含<code>return</code>之外的任何语句，编译器假定其返回<code>void</code>。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">transform</span>(vi.<span class="built_in">begin</span>(), vi.<span class="built_in">end</span>(), vi.<span class="built_in">begin</span>(), </span><br><span class="line">         [](<span class="type">int</span> i)&#123;<span class="keyword">return</span> i&lt;<span class="number">0</span>?-i:i;&#125;);<span class="comment">// 定义返回值为int</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 错误：非单一return语句，编译器推断的是void，和返回值int冲突</span></span><br><span class="line"><span class="built_in">transform</span>(vi.<span class="built_in">begin</span>(), vi.<span class="built_in">end</span>(), vi.<span class="built_in">begin</span>(), </span><br><span class="line">         [](<span class="type">int</span> i)&#123;<span class="keyword">if</span>(i&lt;<span class="number">0</span>) <span class="keyword">return</span> -i;<span class="keyword">else</span> <span class="keyword">return</span> i;);</span><br><span class="line">                   </span><br><span class="line"><span class="comment">// 应写为：尾置返回类型</span></span><br><span class="line"><span class="built_in">transform</span>(vi.<span class="built_in">begin</span>(), vi.<span class="built_in">end</span>(), vi.<span class="built_in">begin</span>(), </span><br><span class="line">         [](<span class="type">int</span> i) -&gt; <span class="type">int</span></span><br><span class="line">         &#123;<span class="keyword">if</span>(i&lt;<span class="number">0</span>) <span class="keyword">return</span> -i;<span class="keyword">else</span> <span class="keyword">return</span> i;&#125;);</span><br></pre></td></tr></table></figure><h3 id="参数绑定">参数绑定</h3><ul><li><p>若lambda的捕获列表为空，可以使用函数替代；</p></li><li><p>若lambda的捕获列表非空，用函数替换不方便（要捕获局部变量）</p></li></ul><h4 id="bind函数">bind函数</h4><p>头文件<code>functional</code>中定义函数<code>bind</code>：一个通用的函数适配器，接受一个可调用对象，<strong>生成一个新的可调用对象</strong>以适应原对象的参数列表。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">auto newCallable=bind(callable, arg_list);</span><br><span class="line">// arg_list包含：形如_n的名字，_1为newCallable的第一个参数</span><br></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> g=<span class="built_in">bind</span>(f, a, b, _2, c, _1);</span><br><span class="line"><span class="comment">// 这个bind调用将g(_1, _2)映射为f(a, b, _2, c, _1)</span></span><br></pre></td></tr></table></figure><p>例子：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 按单词长度从短到长排序：调用isShorter(A, B)</span></span><br><span class="line"><span class="built_in">sort</span>(words.<span class="built_in">begin</span>(), words.<span class="built_in">end</span>(), isShorter);</span><br><span class="line"><span class="comment">// 按单词长度从长到短排序：调用isShorter(B, A)</span></span><br><span class="line"><span class="built_in">sort</span>(words.<span class="built_in">begin</span>(), words.<span class="built_in">end</span>(), <span class="built_in">bind</span>(isShorter, _2, _1));</span><br></pre></td></tr></table></figure><ul><li><p>引用参数无法拷贝，应使用<code>ref</code></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">for_each(words.<span class="built_in">begin</span>(), words.<span class="built_in">end</span>(), [&amp;os, c](<span class="type">const</span> string &amp;s)&#123;os&lt;&lt;s&lt;&lt;c;&#125;);</span><br><span class="line"><span class="comment">// 要替换以上lambda，编写一个相同功能的函数：</span></span><br><span class="line"><span class="function">ostream &amp;<span class="title">print</span><span class="params">(ostream &amp;os, <span class="type">const</span> string &amp;s, <span class="type">char</span> c)</span></span>&#123;</span><br><span class="line">  <span class="keyword">return</span> os&lt;&lt;s&lt;&lt;c;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 错误：bind不能拷贝引用参数os</span></span><br><span class="line">for_each(words.<span class="built_in">begin</span>(),words.<span class="built_in">end</span>(),<span class="built_in">bind</span>(print, os, _1, <span class="string">&#x27; &#x27;</span>));</span><br><span class="line"><span class="comment">// 正确：使用ref函数，ref返回一个对象，包含给定的引用</span></span><br><span class="line">for_each(words.<span class="built_in">begin</span>(),words.<span class="built_in">end</span>(),<span class="built_in">bind</span>(print,<span class="built_in">ref</span>(os),_1, <span class="string">&#x27; &#x27;</span>));</span><br></pre></td></tr></table></figure></li></ul><h2 id="迭代器">迭代器</h2><p><code>iterator</code>中定义了以下迭代器：</p><ul><li>插入迭代器：绑定到一个容器上，用于向容器中插入元素；</li><li>流迭代器：绑定到输入/输出流上，用于遍历关联的IO流；</li><li>反向迭代器：向后移动，除了forward_list外都有反向迭代器；</li><li>移动迭代器</li></ul><h3 id="插入迭代器back_inserterfront_inserterinserter">插入迭代器：<code>back_inserter</code>，<code>front_inserter</code>，<code>inserter</code></h3><p>接受一个容器，生成一个迭代器，实现：向给定容器中添加元素。</p><p><img src="/posts/44ad5109/b5455e1ec6ccdcf5c47eca83ef48457.jpg"></p><p>三种类型，区别在于<strong>元素插入的位置</strong>：</p><ul><li><p><code>back_inserter</code>：创建一个使用<code>push_back</code>的迭代器；</p></li><li><p><code>front_inserter</code>：创建一个使用<code>push_front</code>的迭代器；</p></li><li><p><code>inserter</code>：创建一个使用<code>insert</code>的迭代器；</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// it是由inserter生成的迭代器</span></span><br><span class="line">*it=val;</span><br><span class="line"><span class="comment">// 以上等价于：</span></span><br><span class="line">it=c.<span class="built_in">insert</span>(it, val);<span class="comment">// it指向新插入的元素</span></span><br><span class="line">++it;<span class="comment">// 指向原元素</span></span><br><span class="line"></span><br><span class="line">list&lt;<span class="type">int</span>&gt; lst=&#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>&#125;;</span><br><span class="line">list&lt;<span class="type">int</span>&gt; lst2, lst3;<span class="comment">// 空lst</span></span><br><span class="line"><span class="comment">// 拷贝后：lst2包含4，3，2，1</span></span><br><span class="line"><span class="built_in">copy</span>(lst.<span class="built_in">cbegin</span>(), lst.<span class="built_in">cend</span>(), <span class="built_in">front_inserter</span>(lst2));</span><br><span class="line"><span class="comment">// 拷贝后：lst3包含4，3，2，1</span></span><br><span class="line"><span class="built_in">copy</span>(lst.<span class="built_in">cbegin</span>(), lst.<span class="built_in">cend</span>(), <span class="built_in">inserter</span>(lst3, lst.<span class="built_in">begin</span>()));</span><br></pre></td></tr></table></figure></li></ul><h3 id="流迭代器istream_iteratorostream_iterator">流迭代器：<code>istream_iterator</code>，<code>ostream_iterator</code></h3><h4 id="读取输入流istream_iterator">读取输入流：<code>istream_iterator</code></h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">issteram_iterator&lt;<span class="type">int</span>&gt; <span class="title">in_iter</span><span class="params">(cin)</span>, eof</span>;<span class="comment">// in_iter绑定至输入流cin，eof为默认初始化的尾后迭代器</span></span><br><span class="line"><span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">vec</span><span class="params">(in_iter, eof)</span></span>;<span class="comment">// 从cin中读取数据，直至遇到文件尾/不是int的数据为止：读取的数据用于构造vec</span></span><br></pre></td></tr></table></figure><p><img src="/posts/44ad5109/5e53230a7fc5c3b792bc0c03be9ea65.jpg"></p><ul><li><code>istream_iterator</code>允许lazy求值：绑定后，不保证立即从流中读取数据，可推迟；保证的是：在第一次解引用迭代器之前，从流中读取数据已完成</li></ul><h4 id="写入输出流ostream_iterator">写入输出流：<code>ostream_iterator</code></h4><p><img src="/posts/44ad5109/9f3a914f66c95e889f70aff636a8f35.jpg"></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">ostream_iterator&lt;<span class="type">int</span>&gt; <span class="title">out_iter</span><span class="params">(cout, <span class="string">&quot; &quot;</span>)</span></span>;</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">auto</span> e:vec)&#123;<span class="comment">// 将vec中的每个元素写到cout，每个元素后加一个空格</span></span><br><span class="line">  *out_iter++=e;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 或者：</span></span><br><span class="line"><span class="built_in">copy</span>(vec.<span class="built_in">begin</span>(), vec.<span class="built_in">end</span>(), out_iter);</span><br></pre></td></tr></table></figure><h3 id="反向迭代器">反向迭代器</h3><p>在容器中，从尾元素向首元素反向移动的迭代器（除了forward_list外，其他容器都支持）</p><p><img src="/posts/44ad5109/f5b5646db6dc97a0c23c3d29e018805.jpg"></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sort</span>(vec.<span class="built_in">begin</span>(), vec.<span class="built_in">end</span>());<span class="comment">// 升序排序</span></span><br><span class="line"><span class="built_in">sort</span>(vec.<span class="built_in">rbegin</span>(), vec.<span class="built_in">rend</span>());<span class="comment">// 降序排序</span></span><br></pre></td></tr></table></figure><ul><li>只能从同时支持++和--的迭代器定义反向迭代器：forward_list和流迭代器不行，因为不支持--</li></ul><h2 id="范型算法结构">范型算法结构</h2><h3 id="类迭代器">5类迭代器</h3><p><img src="/posts/44ad5109/6d069f9ff53d242048c3af51362a16d.jpg"></p><ul><li><p>输入迭代器：可读取序列中的元素，必须支持：</p><ul><li>比较运算符：==, !=</li><li>前置/后置递增运算符：++</li><li>解引用运算符*（读取元素）：只出现在赋值运算符右侧</li><li>箭头运算符，等价于(*it).member</li></ul><p>只能用于单遍扫描，<code>find</code>和<code>accumulate</code>支持输入迭代器；<code>istream_iterator</code>是输入迭代器</p></li><li><p>输出迭代器：只写不读元素，必须支持：</p><ul><li>前置/后置递增运算符：++</li><li>解引用运算符*（写入元素）：只出现在赋值运算符左侧</li></ul><p>只能用于单遍扫描，<code>copy</code>支持输入迭代器；<code>ostream_iterator</code>是输入迭代器</p></li><li><p>随机访问迭代器：提供<strong>在常量时间内访问序列中任意元素</strong>的能力，支持双向迭代器的所有功能，必须支持：</p><ul><li>比较相对位置的关系运算符：&lt;, &lt;=, &gt;, &gt;=</li><li>和整数值的加减运算，前进/后退给定整数个元素的位置：+, +=, -, -=</li><li>迭代器的-：两个迭代器距离</li><li>下标运算符：iter[n]</li></ul><p><code>sort</code>要求随机访问迭代器</p></li></ul><h3 id="算法形参模式">算法形参模式</h3><p><img src="/posts/44ad5109/20f43617b75ec6badac28cd94854517.jpg"></p><ul><li>接受单个目标迭代器的算法：<ul><li>假定：目标空间足够容纳写入的数据</li></ul></li><li>接受第二个输入序列的算法：<ul><li>假定：<code>beg2</code>开始的序列，与<code>beg</code>和<code>end</code>所表示的范围至少一样大</li></ul></li></ul><h3 id="算法命名规范">算法命名规范</h3><h4 id="使用重载形式传递一个谓词">使用重载形式，传递一个谓词</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">unique</span>(beg, end);<span class="comment">// 使用==运算比较元素</span></span><br><span class="line"><span class="built_in">unique</span>(beg, end, cmp);<span class="comment">// 使用cmp比较元素</span></span><br></pre></td></tr></table></figure><h4 id="if版本">_if版本</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">find</span>(beg, end, val);<span class="comment">// 查找范围中val第一次出现的位置</span></span><br><span class="line"><span class="built_in">find_if</span>(beg, end, pred);<span class="comment">// 查找第一个令pred为真的元素</span></span><br></pre></td></tr></table></figure><h4 id="拷贝不拷贝版本">拷贝&amp;不拷贝版本</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">reverse</span>(beg, end);<span class="comment">// 反转后，写回给定的输入序列</span></span><br><span class="line"><span class="built_in">reverse_copy</span>(beg, end, dest);<span class="comment">// 反转后，拷贝到dest</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 将偶数元素从v1拷贝到v2：v1不变</span></span><br><span class="line"><span class="built_in">remove_copy_if</span>(v<span class="number">1.</span><span class="built_in">begin</span>(), v<span class="number">1.</span><span class="built_in">end</span>(), <span class="built_in">back_inserter</span>(v2), </span><br><span class="line">              [](<span class="type">int</span> i)&#123;<span class="keyword">return</span> i%<span class="number">2</span>;&#125;);</span><br></pre></td></tr></table></figure><h2 id="特定容器算法">特定容器算法</h2><p><img src="/posts/44ad5109/1df79a84cf34ee98d5ca6028fa14e2f.jpg"></p><p><img src="/posts/44ad5109/89d22ea050dccb7dc7a711927aa04a5.jpg"></p><h4 id="splice成员"><code>splice</code>成员</h4><p><img src="/posts/44ad5109/f86f1f84cda1b1e31e0dd099648fc15.jpg"></p><ul><li>链表特有版本与通用版本的区别：链表版本改变底层的容器</li></ul><p>​例：通用版<code>merge</code>不改变两个原有输入参数序列；链表版<code>merge</code>销毁给定链表</p>]]></content>
      
      
      <categories>
          
          <category> C++ Primer </category>
          
          <category> C++ STL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> C++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>VLM-R1源码解析</title>
      <link href="/posts/ae5287f0.html"/>
      <url>/posts/ae5287f0.html</url>
      
        <content type="html"><![CDATA[<p>VLM-R1基于TRL框架。</p><h2 id="grop方法">GROP方法</h2><p>GRPO是一种在线学习算法，它通过使用训练模型本身在训练期间生成的数据进行迭代改进。其理念是：最大程度利用生成补全，同时确保模型始终接近参考策略。</p><p>分为4个步骤：生成补全、计算奖励、估计KL散度、计算损失。 <img src="/posts/ae5287f0/image.png"></p><h3 id="要点">要点</h3><h4 id="引入critic使用预测baseline改进奖励">引入critic：使用预测baseline改进奖励</h4><p>使用绝对奖励，单纯比较大小，会导致：奖励波动大，以及对部分改进的激励不足；因此<strong>引入Critic：使用“预测baseline”来改进奖励</strong></p><p>对于给定状态(<span class="math inline">\(s_t\)</span>)和动作(<span class="math inline">\(o_t\)</span>)，该baseline为<strong>价值函数<span class="math inline">\((V_\psi(s))\)</span></strong>；训练目标由单纯的reward，转为超过该baseline的程度，由优势函数表示为：<span class="math display">\[A_t=r_t-V_\psi(s_t)\]</span> 即训练中优化内容为： <span class="math display">\[\mathcal{J}_{adv}(\theta)=\mathbb{E}[A(o)]\\where A(o)=r(o)-V_\psi(o)\]</span>通过减去baseline，降低了训练中的方差，为超出预期的动作提供更高的梯度信号；并对未达标的动作进行惩罚。</p><h4 id="添加裁剪和最小值操作防止过度更新">添加裁剪和最小值操作：防止过度更新</h4><p>适度控制学习策略的更新程度：若单次更新太多，则可能走向极端值；若单次更新太少，则动力不足。应找到一个平衡点。</p><p>在Proximal Policy Optimization (PPO)中最大化以下目标函数： <span class="math display">\[\mathcal{J}_{adv}(\theta)=\mathbb{E}[q\sim P(Q),o\sim\pi_{\theta_{old}}(O|q)]\frac{1}{|o|}\sum_{t=1}^{|o|}\min[r_t(\theta)A_t,clip(r_t(\theta),1-\epsilon,1+\epsilon)A_t]\]</span> 其中： <span class="math display">\[r_t(\theta)=\frac{\pi_{\theta}(o_t|q,o_{&lt;t})}{\pi_{\theta_{old}}(o_t|q,o_{&lt;t})}\]</span> <span class="math inline">\(\pi_{\theta}\)</span>和<span class="math inline">\(\pi_{\theta_{old}}\)</span>分别是：当前策略模型、旧策略模型；<span class="math inline">\(q\)</span>和<span class="math inline">\(o\)</span>是从问题数据集和旧策略<span class="math inline">\(\pi_{\theta_{old}}\)</span>中采样的问题和输出；超参数<span class="math inline">\(\epsilon\)</span>用于稳定训练过程；优势<span class="math inline">\(A_i\)</span>通过广义优势估计（GAE）计算。</p><h4 id="防止作弊和极端策略使用kl散度">防止作弊和极端策略：使用KL散度</h4><p>如果只专注于最大化目标函数，可能会采用可疑手段，即生成有害或虚假内容，以人为提高某些奖励指标。为了减轻对奖励模型的过度优化，标准方法是：在每个标记的奖励中，<strong>添加一个来自参考模型（初始策略）的每个标记的KL惩罚</strong>，即：<span class="math display">\[r_t=r_\varphi(q,o_{\leqt})-\beta\log\frac{\pi_\theta(o_t|q,o_{&lt;t})}{\pi_{ref}(o_t|q,o_{&lt;t})}\]</span> 其中，<span class="math inline">\(r\)</span>是奖励模型，<span class="math inline">\(\pi_{ref}\)</span>是参考模型，通常是初始的监督微调（SFT）模型，而<span class="math inline">\(\beta\)</span>是KL惩罚项的系数。</p><p>然而，PPO中的<strong>Critic（值函数）通常是一个与Actor（策略模型）大小相当的模型</strong>，这带来了显著的内存和计算负担；此外，在LLMs的上下文中，Critic在训练过程中被用作优势计算中的Baseline，但通常只有最后一个token 会被奖励模型赋予奖励分数，这可能使得Critic的训练变得复杂。</p><p>为了解决这些问题，提出了 Group Relative Policy Optimization(GRPO)，不再需要像PPO那样加入额外的Critic近似，而是<strong>直接使用多个采样输出的平均奖励作为Baseline</strong>，显著减少了训练资源的使用。</p><p><img src="/posts/ae5287f0/image-2.png"></p><p>对于每个问题<span class="math inline">\(i\)</span>，GRPO从旧策略<span class="math inline">\(\pi_{\theta_{old}}\)</span>中，采样出一组输出{<span class="math inline">\(i_1\)</span>,...,<span class="math inline">\(i_A\)</span>}，通过最大化以下目标函数优化策略模型：<img src="/posts/ae5287f0/image-3.png"></p><p>其中，<span class="math inline">\(\epsilon\)</span> 和 <span class="math inline">\(\beta\)</span> 是超参数，<span class="math inline">\(\hat{A}_{i,t}\)</span>​是基于组内奖励的相对优势估计。</p><p>与 PPO 不同，GRPO： 1.直接使用奖励模型的输出来估计baseline，避免了训练一个复杂的Critic； 2.直接在损失函数中加入策略模型和参考模型之间的 KL散度来正则化，而不是在奖励中加入 KL 惩罚项，从而简化了训练过程。</p><p><img src="/posts/ae5287f0/image-4.png"></p><p>使用下面的无偏估计来估计 KL 散度： <img src="/posts/ae5287f0/image-5.png"></p><p>GRPO核心思想： 1. 无需为 Critic 设置单独的价值网络； 2.对同一问题或状态，从旧策略中采样多个输出； 3.将这些输出的平均奖励视为基准； 4.任何高于平均值的都产生“正优势”，任何低于平均值的都产生“负优势”。</p><p>同时，GRPO保留了 PPO 的裁剪和 KL 机制，以确保稳定、合规的更新。</p><h2 id="自定义训练器vlmgrpotrainer">自定义训练器<code>VLMGRPOTrainer</code></h2><p>基于 <code>Trainer</code> 类扩展，实现了 Group Relative PolicyOptimization (GRPO) 方法的训练，该方法首次在论文<a href="https://huggingface.co/papers/2402.03300">DeepSeekMath: Pushingthe Limits of Mathematical Reasoning in Open LanguageModels</a>中提出。</p><h3 id="初始化">初始化</h3><blockquote><p>默认： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">attn_implementation: <span class="built_in">str</span> = <span class="string">&quot;flash_attention_2&quot;</span>,</span><br><span class="line">torch_dtype: <span class="built_in">str</span> = <span class="string">&quot;bfloat16&quot;</span>,</span><br></pre></td></tr></table></figure></p></blockquote><ol type="1"><li><p><strong>加载预训练模型</strong>： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model_cls = <span class="variable language_">self</span>.vlm_module.get_model_class(model_id, model_init_kwargs)</span><br><span class="line">model = model_cls.from_pretrained(model_id, **model_init_kwargs)</span><br></pre></td></tr></table></figure></p></li><li><p><strong>PEFT配置</strong>:如果提供了 PEFT配置，查找<strong>模型中的所有线性层（不包括视觉模块）</strong>，并<strong>将它们应用于LoRA微调</strong>。 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> peft_config <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">  target_modules = find_all_linear_names(model, <span class="variable language_">self</span>.vision_modules_keywords)</span><br><span class="line">  peft_config.target_modules = target_modules</span><br><span class="line">  model = get_peft_model(model, peft_config)</span><br></pre></td></tr></table></figure></p></li></ol><blockquote><p>寻找Pytorch中的线性层： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">find_all_linear_names</span>(<span class="params">model, multimodal_keywords</span>):</span><br><span class="line">   cls = torch.nn.Linear</span><br><span class="line">   lora_module_names = <span class="built_in">set</span>()</span><br><span class="line">   <span class="keyword">for</span> name, module <span class="keyword">in</span> model.named_modules():</span><br><span class="line">       <span class="comment"># 不在视觉模块上应用LoRA微调</span></span><br><span class="line">       <span class="keyword">if</span> <span class="built_in">any</span>(mm_keyword <span class="keyword">in</span> name <span class="keyword">for</span> mm_keyword <span class="keyword">in</span> multimodal_keywords):</span><br><span class="line">           <span class="keyword">continue</span></span><br><span class="line">       <span class="keyword">if</span> <span class="built_in">isinstance</span>(module, cls):    <span class="comment"># 检查是否为线性层（全连接层）</span></span><br><span class="line">           lora_module_names.add(name)</span><br><span class="line">   <span class="keyword">for</span> m <span class="keyword">in</span> lora_module_names:  <span class="comment"># 移除嵌入层</span></span><br><span class="line">       <span class="keyword">if</span> <span class="string">&quot;embed_tokens&quot;</span> <span class="keyword">in</span> m:</span><br><span class="line">           lora_module_names.remove(m)</span><br><span class="line">   <span class="keyword">return</span> <span class="built_in">list</span>(lora_module_names)</span><br></pre></td></tr></table></figure></p></blockquote><ol start="3" type="1"><li><p><strong>冻结视觉模块</strong>：如果<code>freeze_vision_modules</code> 为<code>True</code>，冻结所有视觉模块的参数，<strong>不进行梯度更新</strong>；</p></li><li><p><strong>启用梯度检查点（如果需要）</strong>：<strong>在反向传播时，仅存储部分中间激活值，来减少训练过程中对内存的需求。</strong><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> args.gradient_checkpointing:</span><br><span class="line">    model = <span class="variable language_">self</span>._enable_gradient_checkpointing(model, args)</span><br></pre></td></tr></table></figure></p></li></ol><p>看看启用梯度检查点的函数：<code>_enable_gradient_checkpointing</code><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_enable_gradient_checkpointing</span>(<span class="params">self, model: PreTrainedModel, args: GRPOConfig</span>) -&gt; PreTrainedModel:</span><br><span class="line">  <span class="comment"># 1. 禁用cache：禁用缓存中间激活值</span></span><br><span class="line">  model.config.use_cache = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 2. 对于 PEFT 模型启用梯度检查点（PEFT 模型通常通过添加适配器层进行微调，其他大部分参数保持冻结）</span></span><br><span class="line">  <span class="keyword">if</span> is_peft_model(model):</span><br><span class="line">      model.base_model.gradient_checkpointing_enable()</span><br><span class="line">  <span class="comment"># 3. 对于非 PEFT 模型启用梯度检查点：</span></span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">      <span class="keyword">try</span>:</span><br><span class="line">          model.gradient_checkpointing_enable()</span><br><span class="line">      <span class="keyword">except</span>:</span><br><span class="line">          <span class="string">&#x27;&#x27;&#x27;首先尝试通过 model.gradient_checkpointing_enable() 启用梯度检查点。如果失败（例如，某些模型不支持该操作），则进行特定模型的特殊处理：</span></span><br><span class="line"><span class="string">            1. 启用 视觉模型 和其 编码器 的梯度检查点；</span></span><br><span class="line"><span class="string">            2. 在 InternVL 模型中，还需要禁用 gradient_checkpointing 参数，以避免出现不支持梯度检查点操作的错误。</span></span><br><span class="line"><span class="string">          &#x27;&#x27;&#x27;</span></span><br><span class="line">          model.language_model.config.use_cache = <span class="literal">False</span></span><br><span class="line">          model.vision_model.gradient_checkpointing = <span class="literal">True</span></span><br><span class="line">          model.vision_model.encoder.gradient_checkpointing = <span class="literal">True</span></span><br><span class="line">          model.language_model._set_gradient_checkpointing()</span><br><span class="line">          args.gradient_checkpointing = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 4. 启用梯度计算：若use_reentrant为True（默认为True），启用输入张量的梯度计算</span></span><br><span class="line">  gradient_checkpointing_kwargs = args.gradient_checkpointing_kwargs <span class="keyword">or</span> &#123;&#125;</span><br><span class="line">  use_reentrant = (</span><br><span class="line">      <span class="string">&quot;use_reentrant&quot;</span> <span class="keyword">not</span> <span class="keyword">in</span> gradient_checkpointing_kwargs <span class="keyword">or</span> gradient_checkpointing_kwargs[<span class="string">&quot;use_reentrant&quot;</span>]</span><br><span class="line">  )</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> use_reentrant:</span><br><span class="line">      model.enable_input_require_grads()</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure></p><ol start="5" type="1"><li><strong>加载参考模型</strong>： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> is_deepspeed_zero3_enabled():</span><br><span class="line">  <span class="variable language_">self</span>.ref_model = model_cls.from_pretrained(model_id, **model_init_kwargs)</span><br><span class="line"><span class="keyword">elif</span> peft_config <span class="keyword">is</span> <span class="literal">None</span>:   <span class="comment"># 不使用PEFT配置，从初始模型创建一个参考模型</span></span><br><span class="line">  <span class="comment"># If PEFT configuration is not provided, create a reference model based on the initial model.</span></span><br><span class="line">  <span class="variable language_">self</span>.ref_model = create_reference_model(model)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">  <span class="comment"># If PEFT is used, the reference model is not needed since the adapter can be disabled</span></span><br><span class="line">  <span class="comment"># to revert to the initial model.</span></span><br><span class="line">  <span class="variable language_">self</span>.ref_model = <span class="literal">None</span></span><br></pre></td></tr></table></figure></li></ol><p><code>create_reference_model</code>在<code>TRL</code>框架中定义：<strong>创建一个静态的参考模型（参考模型是原始模型的副本），其部分参数被冻结，以便在训练过程中不再更新</strong>。</p><blockquote><p>冻结参数： *<strong>冻结所有参数</strong>：如果没有指定共享层数（<code>num_shared_layers</code>为<code>None</code>），则函数会冻结所有的参数。这意味着参考模型的所有参数都不会在训练中被更新，通常这种方法用于构建一个固定的基准模型或用于知识蒸馏等场景。* <strong>冻结部分参数（共享层）</strong>：如果指定了<code>num_shared_layers</code>，则函数会根据该值冻结模型的前几个层（根据层数或指定的层名模式）。这意味着这些层的参数不会更新，从而让模型只对后面的层进行训练。</p></blockquote><p>我们一起看看：<a href="https://github.com/huggingface/trl/blob/d625c5533a6b1c84d3565c8080857f6bb81c538a/trl/models/modeling_base.py#L605">trl/trl/models/modeling_base.py</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">create_reference_model</span>(<span class="params"></span></span><br><span class="line"><span class="params">    model: PreTrainedModelWrapper, num_shared_layers: <span class="type">Optional</span>[<span class="built_in">int</span>] = <span class="literal">None</span>, pattern: <span class="type">Optional</span>[<span class="built_in">str</span>] = <span class="literal">None</span></span></span><br><span class="line"><span class="params"></span>) -&gt; PreTrainedModelWrapper:</span><br><span class="line">    <span class="comment"># 1. 兼容性检查：不支持DeepSpeed 的 ZeRO-3 模式</span></span><br><span class="line">    <span class="keyword">if</span> is_deepspeed_zero3_enabled():</span><br><span class="line">        <span class="keyword">raise</span> ValueError(</span><br><span class="line">            <span class="string">&quot;DeepSpeed ZeRO-3 is enabled and is not compatible with `create_reference_model()`. Please instantiate your reference model directly with `AutoModelForCausalLM.from_pretrained()`.&quot;</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    parameter_names = [n <span class="keyword">for</span> n, _ <span class="keyword">in</span> model.named_parameters()]</span><br><span class="line">    <span class="comment"># 2. 复制模型（深拷贝）</span></span><br><span class="line">    ref_model = deepcopy(model)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3. 如果没有共享层，则冻结所有参数并返回模型副本：（通常用于构建一个固定的基准模型，或用于知识蒸馏等场景）</span></span><br><span class="line">    <span class="keyword">if</span> num_shared_layers <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">for</span> param_name <span class="keyword">in</span> parameter_names:</span><br><span class="line">            param = ref_model.get_parameter(param_name)</span><br><span class="line">            param.requires_grad = <span class="literal">False</span></span><br><span class="line">        <span class="keyword">return</span> ref_model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 4. 如果有共享层，确定共享层的选择模式：</span></span><br><span class="line">    <span class="comment"># 如果指定了 pattern 参数，则使用该模式来选择共享层；否则，函数会遍历 LAYER_PATTERNS 中的模式，选择一个能够匹配参数名称的模式。</span></span><br><span class="line">    <span class="keyword">if</span> pattern <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        pattern = pattern.<span class="built_in">format</span>(layer=num_shared_layers)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">for</span> pattern_candidate <span class="keyword">in</span> LAYER_PATTERNS:</span><br><span class="line">            pattern_candidate = pattern_candidate.<span class="built_in">format</span>(layer=num_shared_layers)</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">any</span>(pattern_candidate <span class="keyword">in</span> name <span class="keyword">for</span> name <span class="keyword">in</span> parameter_names):</span><br><span class="line">                pattern = pattern_candidate</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> pattern <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">&quot;Layer pattern could not be matched.&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 5. 将参数分为共享和非共享两类：</span></span><br><span class="line">    shared_param_list = []</span><br><span class="line">    unshared_param_list = []</span><br><span class="line"></span><br><span class="line">    shared_parameter = <span class="literal">True</span></span><br><span class="line">    <span class="keyword">for</span> name, _param <span class="keyword">in</span> model.named_parameters():</span><br><span class="line">        <span class="keyword">if</span> pattern <span class="keyword">in</span> name:</span><br><span class="line">            shared_parameter = <span class="literal">False</span></span><br><span class="line">        <span class="keyword">if</span> shared_parameter:</span><br><span class="line">            shared_param_list.append(name)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            unshared_param_list.append(name)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 6. 冻结原始模型中所有属于共享层的参数：</span></span><br><span class="line">    <span class="keyword">for</span> param_name <span class="keyword">in</span> shared_param_list:</span><br><span class="line">        param = model.get_parameter(param_name)</span><br><span class="line">        param.requires_grad = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">        _ref_param = ref_model.get_parameter(param_name)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 7. 冻结参考模型中所有属于非共享层的参数：</span></span><br><span class="line">    <span class="keyword">for</span> param_name <span class="keyword">in</span> unshared_param_list:</span><br><span class="line">        param = ref_model.get_parameter(param_name)</span><br><span class="line">        param.requires_grad = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> pattern <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> <span class="built_in">len</span>(unshared_param_list) == <span class="number">0</span>:</span><br><span class="line">        logging.warning(<span class="string">&quot;Pattern passed or found, but no layers matched in the model. Check for a typo.&quot;</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 8. 返回参考模型</span></span><br><span class="line">    <span class="keyword">return</span> ref_model.<span class="built_in">eval</span>()</span><br></pre></td></tr></table></figure><ol start="6" type="1"><li><strong>处理类（<code>processing_class</code>）初始化</strong>：</li></ol><ul><li><p>如果<code>processing_class</code>参数为空：从<code>vlm_module</code>模块中获取相应的处理类，并从预训练模型中加载。</p></li><li><p>随后，处理类根据<code>kwargs</code>设置自定义的处理关键词：</p><ul><li>如果该处理类有 tokenizer，则设置其填充和结束标记 ID；</li><li>否则进行类型检查，确保该处理类是<code>PreTrainedTokenizerBase</code>类型。</li></ul></li></ul><ol start="7" type="1"><li><strong>对主模型、参考模型进行初始化</strong>：</li></ol><ul><li><code>Qwen2VLModule</code>无需处理；<code>InvernVLModule</code>需要从模型中提取并赋值到当前对象中，并且将图像上下文的token ID 处理并存储到模型。 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable language_">self</span>.vlm_module.post_model_init(model, processing_class)</span><br><span class="line"><span class="variable language_">self</span>.vlm_module.post_model_init(<span class="variable language_">self</span>.ref_model, processing_class)</span><br></pre></td></tr></table></figure></li></ul><ol start="8" type="1"><li><p><strong>奖励函数<code>reward_funcs</code>，奖励处理类<code>reward_processing_classes</code>初始化</strong></p></li><li><p><strong>处理奖励函数的 Tokenizer</strong> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i, (reward_processing_class, reward_func) <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="built_in">zip</span>(reward_processing_classes, reward_funcs)):</span><br><span class="line">  <span class="keyword">if</span> <span class="built_in">isinstance</span>(reward_func, PreTrainedModel):</span><br><span class="line">      <span class="keyword">if</span> reward_processing_class <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">          reward_processing_class = AutoTokenizer.from_pretrained(reward_func.config._name_or_path)</span><br><span class="line">      <span class="keyword">if</span> reward_processing_class.pad_token_id <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">          reward_processing_class.pad_token = reward_processing_class.eos_token</span><br><span class="line">      <span class="comment"># 计算输入序列中：最新non-padded token的奖励</span></span><br><span class="line">      reward_func.config.pad_token_id = reward_processing_class.pad_token_id</span><br><span class="line">      reward_processing_classes[i] = reward_processing_class</span><br><span class="line"><span class="variable language_">self</span>.reward_processing_classes = reward_processing_classes</span><br></pre></td></tr></table></figure></p></li><li><p><strong>训练参数的初始化</strong>： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable language_">self</span>.max_prompt_length = args.max_prompt_length</span><br><span class="line">  <span class="variable language_">self</span>.max_prompt_length = <span class="literal">None</span></span><br><span class="line">  <span class="keyword">if</span> args.max_prompt_length <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">      warnings.warn(<span class="string">&quot;Setting max_prompt_length is currently not supported, it has been set to None&quot;</span>)</span><br><span class="line"></span><br><span class="line">  <span class="variable language_">self</span>.max_completion_length = args.max_completion_length  <span class="comment"># = |o_i| in the GRPO paper</span></span><br><span class="line">  <span class="variable language_">self</span>.num_generations = args.num_generations  <span class="comment"># = G in the GRPO paper</span></span><br><span class="line">  <span class="variable language_">self</span>.generation_config = GenerationConfig(</span><br><span class="line">      max_new_tokens=<span class="variable language_">self</span>.max_completion_length,</span><br><span class="line">      do_sample=<span class="literal">True</span>,  </span><br><span class="line">      temperature=<span class="number">1</span>,</span><br><span class="line">      pad_token_id=pad_token_id,</span><br><span class="line">  )</span><br><span class="line">  <span class="keyword">if</span> <span class="built_in">hasattr</span>(<span class="variable language_">self</span>.vlm_module, <span class="string">&quot;get_eos_token_id&quot;</span>): <span class="comment"># For InternVL</span></span><br><span class="line">      <span class="variable language_">self</span>.generation_config.eos_token_id = <span class="variable language_">self</span>.vlm_module.get_eos_token_id(processing_class)</span><br><span class="line">      <span class="built_in">print</span>(<span class="number">222</span>, <span class="variable language_">self</span>.vlm_module.get_eos_token_id(processing_class))</span><br><span class="line">  <span class="variable language_">self</span>.beta = args.beta</span><br><span class="line">  <span class="variable language_">self</span>.epsilon = args.</span><br><span class="line">  </span><br><span class="line">  <span class="comment"># 多步</span></span><br><span class="line">  <span class="variable language_">self</span>.num_iterations = args.num_iterations  <span class="comment"># = 𝜇 in the GRPO paper</span></span><br><span class="line">  <span class="comment"># 迭代步数（前向+反向传播）</span></span><br><span class="line">  <span class="variable language_">self</span>._step = <span class="number">0</span>    </span><br><span class="line">  <span class="comment"># _buffered_inputs缓存批次中的输入，避免重复生成</span></span><br><span class="line">  <span class="variable language_">self</span>._buffered_inputs = [<span class="literal">None</span>] * args.gradient_accumulation_steps</span><br></pre></td></tr></table></figure></p></li><li><p><strong>设置随机种子</strong></p></li><li><p><strong>初始化参考模型<code>ref_model</code></strong></p></li><li><p><strong>准备奖励函数</strong></p></li></ol><h2 id="训练过程">训练过程</h2><p>从脚本<code>grpo_rec.sh</code>开始： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">torchrun --nproc_per_node=<span class="string">&quot;8&quot;</span> \     // 每个节点上运行的进程数：使用的 GPU 数量</span><br><span class="line">    --nnodes=<span class="string">&quot;1&quot;</span> \                  // 训练的节点数</span><br><span class="line">    --node_rank=<span class="string">&quot;0&quot;</span> \               // 当前节点的排名</span><br><span class="line">    --master_addr=<span class="string">&quot;127.0.0.1&quot;</span> \     // 主节点的 IP 地址</span><br><span class="line">    --master_port=<span class="string">&quot;12346&quot;</span> \         // 主节点监听的端口号</span><br><span class="line">    src/open_r1/grpo_rec.py \       // 实际运行的训练脚本路径</span><br><span class="line">    --deepspeed local_scripts/zero3.json \      // 使用 DeepSpeed 来优化训练</span><br><span class="line">    --output_dir output/<span class="variable">$RUN_NAME</span> \</span><br><span class="line">    --model_name_or_path Qwen/Qwen2.5-VL-3B-Instruct \</span><br><span class="line">    --dataset_name data_config/rec.yaml \</span><br><span class="line">    --image_root &lt;your_image_root&gt; \</span><br><span class="line">    --max_prompt_length 1024 \</span><br><span class="line">    --num_generations 8 \           // 每个输入生成的输出数量</span><br><span class="line">    --per_device_train_batch_size 1 \</span><br><span class="line">    --gradient_accumulation_steps 2 \</span><br><span class="line">    --logging_steps 1 \</span><br><span class="line">    --bf16 \                        // 使用 bfloat16 数据类型</span><br><span class="line">    --torch_dtype bfloat16 \        // 张量数据类型为 bfloat16</span><br><span class="line">    --data_seed 42 \</span><br><span class="line">    --report_to wandb \</span><br><span class="line">    --gradient_checkpointing <span class="literal">false</span> \</span><br><span class="line">    --attn_implementation flash_attention_2 \</span><br><span class="line">    --num_train_epochs 2 \</span><br><span class="line">    --run_name <span class="variable">$RUN_NAME</span> \</span><br><span class="line">    --save_steps 100 \</span><br><span class="line">    --save_only_model <span class="literal">true</span></span><br></pre></td></tr></table></figure></p><p><code>grpo_rec.py</code>入口函数：</p><ol type="1"><li><p><strong>加载VLM模型</strong>：<code>vlm_module_cls = get_vlm_module(model_args.model_name_or_path)</code>，支持：<code>Qwen2VLModule</code>和<code>InvernVLModule</code></p></li><li><p><strong>加载奖励函数</strong>： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">reward_funcs_registry = &#123;</span><br><span class="line">    <span class="string">&quot;accuracy&quot;</span>: vlm_module_cls.iou_reward,</span><br><span class="line">    <span class="string">&quot;format&quot;</span>: vlm_module_cls.format_reward_rec,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></li></ol><blockquote><p>检查模型输出格式：<code>format_reward_rec</code> *检查是否包含<code>think</code> 和 <code>answer</code> 标签； *<code>answer</code>标签中内容符合一个特定的边界框格式（如<code>[x, y, w, h]</code>）； * 符合格式的输出奖励为1.0，不符合格式的输出奖励为 0.0. <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">format_reward_rec</span>(<span class="params">completions, **kwargs</span>):</span><br><span class="line">   <span class="keyword">import</span> re</span><br><span class="line">   pattern = <span class="string">r&quot;&lt;think&gt;.*?&lt;/think&gt;\s*&lt;answer&gt;.*?\&#123;.*\[\d+,\s*\d+,\s*\d+,\s*\d+\].*\&#125;.*?&lt;/answer&gt;&quot;</span></span><br><span class="line">   completion_contents = [completion[<span class="number">0</span>][<span class="string">&quot;content&quot;</span>] <span class="keyword">for</span> completion <span class="keyword">in</span> completions]</span><br><span class="line">   matches = [re.search(pattern, content, re.DOTALL) <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">for</span> content <span class="keyword">in</span> completion_contents]</span><br><span class="line">   <span class="keyword">return</span> [<span class="number">1.0</span> <span class="keyword">if</span> <span class="keyword">match</span> <span class="keyword">else</span> <span class="number">0.0</span> <span class="keyword">for</span> <span class="keyword">match</span> <span class="keyword">in</span> matches]</span><br></pre></td></tr></table></figure></p></blockquote><ol start="3" type="1"><li><strong>加载数据集</strong>：<code>LazySupervisedDataset</code>（符合<code>Pytorch</code>格式）</li></ol><p>数据应为<code>.yaml</code>文件，文件内容包含一个<code>datasets</code>字段，其中<strong>列出了多个数据源的路径以及相应的采样策略</strong>，示例如下：<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">datasets:</span></span><br><span class="line">   <span class="bullet">-</span> <span class="attr">json_path:</span> <span class="string">xxxx1.json</span></span><br><span class="line">     <span class="attr">sampling_strategy:</span> <span class="string">first:1000</span></span><br><span class="line">   <span class="bullet">-</span> <span class="attr">json_path:</span> <span class="string">xxxx2.json</span></span><br><span class="line">     <span class="attr">sampling_strategy:</span> <span class="string">end:3000</span></span><br><span class="line">   <span class="bullet">-</span> <span class="attr">json_path:</span> <span class="string">xxxx3.json</span></span><br><span class="line">     <span class="attr">sampling_strategy:</span> <span class="string">random:999</span></span><br></pre></td></tr></table></figure></p><p>一共支持3种采样策略：</p><ul><li>"first"：取前 sampling_number 个样本；</li><li>"end"：取最后 sampling_number 个样本；</li><li>"random"：随机打乱数据并取前 sampling_number 个样本。</li></ul><h4 id="奖励函数iou_reward">奖励函数：<code>iou_reward</code></h4><h5 id="qwen2vlmodule的reward">Qwen2VLModule的reward</h5><p><strong>计算预测的边界框与真实边界框之间的IoU奖励</strong>:比较预测的边界框和真实边界框的重叠部分（交集）与它们的并集的比值</p><ol type="1"><li><p><code>IOU</code>函数定义：<code>inter</code>为交集面积；<code>union</code>为并集面积；比值为IOU<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">iou</span>(<span class="params">box1, box2</span>):</span><br><span class="line">    inter_x1 = <span class="built_in">max</span>(box1[<span class="number">0</span>], box2[<span class="number">0</span>])</span><br><span class="line">    inter_y1 = <span class="built_in">max</span>(box1[<span class="number">1</span>], box2[<span class="number">1</span>])</span><br><span class="line">    inter_x2 = <span class="built_in">min</span>(box1[<span class="number">2</span>]-<span class="number">1</span>, box2[<span class="number">2</span>]-<span class="number">1</span>)</span><br><span class="line">    inter_y2 = <span class="built_in">min</span>(box1[<span class="number">3</span>]-<span class="number">1</span>, box2[<span class="number">3</span>]-<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">if</span> inter_x1 &lt; inter_x2 <span class="keyword">and</span> inter_y1 &lt; inter_y2:</span><br><span class="line">        inter = (inter_x2-inter_x1+<span class="number">1</span>)*(inter_y2-inter_y1+<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        inter = <span class="number">0</span></span><br><span class="line">    union = (box1[<span class="number">2</span>]-box1[<span class="number">0</span>])*(box1[<span class="number">3</span>]-box1[<span class="number">1</span>]) + (box2[<span class="number">2</span>]-box2[<span class="number">0</span>])*(box2[<span class="number">3</span>]-box2[<span class="number">1</span>]) - inter</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">float</span>(inter)/union</span><br></pre></td></tr></table></figure></p></li><li><p>主要逻辑：<strong>遍历每个预测值，提取出边界框，计算预测和真实边界框的IoU 值作为奖励</strong> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从 completions 中提取出每个预测结果的 content 字段</span></span><br><span class="line">contents = [completion[<span class="number">0</span>][<span class="string">&quot;content&quot;</span>] <span class="keyword">for</span> completion <span class="keyword">in</span> completions]</span><br><span class="line">rewards = []  <span class="comment"># 存储每个预测的奖励值（IoU 值）</span></span><br><span class="line">current_time = datetime.now().strftime(<span class="string">&quot;%d-%H-%M-%S-%f&quot;</span>)</span><br><span class="line">answer_tag_pattern = <span class="string">r&#x27;&lt;answer&gt;(.*?)&lt;/answer&gt;&#x27;</span></span><br><span class="line">bbox_pattern = <span class="string">r&#x27;\[(\d+),\s*(\d+),\s*(\d+),\s*(\d+)]&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> content, sol <span class="keyword">in</span> <span class="built_in">zip</span>(contents, solution):</span><br><span class="line">    reward = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">      <span class="comment"># content_answer_match：查找 &lt;answer&gt;...&lt;/answer&gt; 标签，并提取其中的答案</span></span><br><span class="line">        content_answer_match = re.search(answer_tag_pattern, content, re.DOTALL)</span><br><span class="line">        <span class="keyword">if</span> content_answer_match:</span><br><span class="line">            content_answer = content_answer_match.group(<span class="number">1</span>).strip()</span><br><span class="line">            <span class="comment"># bbox_match：在答案中提取边界框，使用正则表达式 [x1, y1, x2, y2]</span></span><br><span class="line">            bbox_match = re.search(bbox_pattern, content_answer)</span><br><span class="line">            <span class="keyword">if</span> bbox_match:</span><br><span class="line">                bbox = [<span class="built_in">int</span>(bbox_match.group(<span class="number">1</span>)), <span class="built_in">int</span>(bbox_match.group(<span class="number">2</span>)), <span class="built_in">int</span>(bbox_match.group(<span class="number">3</span>)), <span class="built_in">int</span>(bbox_match.group(<span class="number">4</span>))]</span><br><span class="line">                <span class="comment"># if iou(bbox, sol) &gt; 0.5:</span></span><br><span class="line">                <span class="comment">#     reward = 1.0</span></span><br><span class="line">                <span class="comment"># reward = iou(bbox, sol)：计算预测的边界框 bbox 和真实边界框 sol 之间的 IoU 值，作为奖励</span></span><br><span class="line">                reward = iou(bbox, sol)</span><br><span class="line">    <span class="keyword">except</span> Exception:</span><br><span class="line">        <span class="keyword">pass</span>  </span><br><span class="line">            </span><br><span class="line">    rewards.append(reward)</span><br><span class="line">    <span class="keyword">if</span> os.getenv(<span class="string">&quot;DEBUG_MODE&quot;</span>) == <span class="string">&quot;true&quot;</span>:</span><br><span class="line">        log_path = os.getenv(<span class="string">&quot;LOG_PATH&quot;</span>)</span><br><span class="line">        <span class="comment"># local_rank = int(os.getenv(&quot;LOCAL_RANK&quot;, 0))</span></span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(log_path, <span class="string">&quot;a&quot;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(<span class="string">f&quot;------------- <span class="subst">&#123;current_time&#125;</span> Accuracy reward: <span class="subst">&#123;reward&#125;</span> -------------\n&quot;</span>)</span><br><span class="line">            f.write(<span class="string">f&quot;Content: <span class="subst">&#123;content&#125;</span>\n&quot;</span>)</span><br><span class="line">            f.write(<span class="string">f&quot;Solution: <span class="subst">&#123;sol&#125;</span>\n&quot;</span>)</span><br></pre></td></tr></table></figure></p></li></ol><h2 id="grpo-config参数">GRPO Config参数</h2><h3 id="数据预处理参数">数据预处理参数</h3><ul><li><code>remove_unused_columns (Optional[bool])</code>:如果设置为<code>True</code>，则仅保留数据集中的 "prompt" 列，默认值为<code>False</code>。用于计算自定义奖励函数；</li><li><code>max_prompt_length (Optional[int])</code>: prompt的最大长度，默认值为 <code>512</code>（如果 prompt长度超过此值，将会从左侧进行截断）</li><li><code>num_generations (Optional[int])</code>:每个 prompt生成的样本数量。全局批次大小（num_processes *per_device_batch_size）必须能被此值整除，默认值为 <code>8</code>;</li><li><code>temperature (Optional[float])</code>：采样的温度值。温度越高，生成样本的随机性越高，默认值为<code>0.9</code>；</li><li><code>max_completion_length (Optional[int])</code>:生成的完成部分的最大长度，默认值为<code>256</code>；</li><li><code>ds3_gather_for_generation (bool)</code>:针对 DeepSpeed ZeRO-3的设置。启用时，<strong>生成时会收集策略模型的权重，提升生成速度</strong>；如果禁用此选项，能够训练超过单个GPU VRAM 容量的模型，但生成速度会更慢，并且与 vLLM 生成不兼容。默认值为<code>True</code>。</li></ul><h3 id="生成加速相关参数vllm">生成加速相关参数（vLLM）</h3><ul><li><code>use_vllm (Optional[bool])</code>:是否使用vLLM（一个用于生成的加速库）进行生成，如果设置为<code>True</code>，则需要确保有一个 GPU用于生成，而不是训练；默认为<code>False</code></li><li><code>vllm_device (Optional[str])</code>:指定 vLLM生成将运行的设备，例如 "cuda:1"。如果设置为"auto"（默认值），系统会自动选择下一个可用的 GPU；</li><li><code>vllm_gpu_memory_utilization (float)</code>:该值指定要为 vLLM生成预留的 GPU 内存比例。数值范围为 0 到 1，较高的数值会增加 KV缓存大小，从而提高模型的吞吐量，但如果过高，可能会导致内存不足（OOM）错误。默认值为<code>0.9</code>；</li><li><code>vllm_dtype (Optional[str])</code>:设置 vLLM生成的数值类型。如果设置为 "auto"，将基于模型配置自动选择数据类型；</li><li><code>vllm_max_model_len (Optional[int])</code>:设置 vLLM使用的最大模型长度。这对于减少 <code>vllm_gpu_memory_utilization</code>的情况下，可能会减少 KV 缓存大小。如果未设置，vLLM将使用模型的上下文大小；</li><li><code>vllm_enable_prefix_caching (Optional[bool])</code>:是否启用vLLM 中的前缀缓存。若为<code>True</code>（默认），确保模型和硬件支持此功能；</li><li><code>vllm_guided_decoding_regex (Optional[str])</code>:用于 vLLM指导解码的正则表达式。如果为<code>None</code>（默认），则禁用指导解码。</li></ul><h3 id="训练控制参数">训练控制参数</h3><ul><li><code>learning_rate (float)</code>:初始学习率，使用 AdamW优化器。默认值为 <code>1e-6</code>，它替换了<code>transformers.TrainingArguments</code> 中的默认学习率；</li><li><code>beta (float)</code>:KL 系数。值为 <code>0.0</code>时，参考模型不会加载，从而减少内存使用和提高训练速度。默认值为<code>0.04</code>；</li><li><code>num_iterations (int)</code>:每个批次的迭代次数（在算法中表示为<span class="math inline">\(\mu\)</span>）。默认值为 1；</li><li><code>epsilon (float)</code>:用于裁剪的 epsilon 值。默认值为<code>0.2</code>；</li><li><code>reward_weights (Optional[list[float]])</code>:每个奖励函数的权重。如果为<code>None</code>，则所有奖励函数的权重均为 <code>1.0</code>，默认值为<code>None</code>；</li><li><code>sync_ref_model (bool)</code>:是否每<code>ref_model_sync_steps</code> 步同步参考模型和活动模型，使用<code>ref_model_mixup_alpha</code> 参数进行混合。默认值为<code>False</code>；</li><li><code>ref_model_mixup_alpha (float)</code>:参考模型更新时的 <span class="math inline">\(\alpha\)</span>参数，控制当前策略和前一个参考策略之间的混合。默认值为<code>0.6</code>。此参数必须与 <code>sync_ref_model=True</code>一起使用；</li><li><code>ref_model_sync_steps (int)</code>:确定当前策略与参考策略同步的频率，单位为步数。默认值为<code>512</code>，此参数必须与 <code>sync_ref_model=True</code>一起使用。</li></ul><h2 id="大规模grpo在多个节点上训练-70b-模型">大规模GRPO：在多个节点上训练70B+ 模型</h2><p>在训练 Qwen2.5-72B等大型模型时，需要进行几项关键优化，以提高训练效率并在多个 GPU和节点之间扩展。包括： ### DeepSpeed ZeRO 第 3 阶段利用<strong>数据并行</strong>性，在多个 GPU 和 CPU之间分配模型状态（权重、梯度、优化器状态）</p>]]></content>
      
      
      <categories>
          
          <category> Introduction to AI </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>详解变分自编码器</title>
      <link href="/posts/46623c6f.html"/>
      <url>/posts/46623c6f.html</url>
      
        <content type="html"><![CDATA[<h1 id="vae">VAE</h1><h2 id="信息论">信息论</h2><h3 id="信息量">信息量</h3><p><span class="math inline">\(I(x)=-\log{P(x)}\)</span>,描述事件x中包含的信息量。</p><h3 id="信息熵">信息熵</h3><p>设随机变量X~p(X),则X的熵被定义为： <span class="math display">\[H(p)=\mathbb{E}_{X\sim p(X)}[-\log p(X)].\]</span> 当X为离散随机变量时， <span class="math display">\[H(p)=-\sum_{i=1}^{n}p(x_i)\log p(x_i)\]</span> 熵的数学化理解：编码随机变量所需的<strong>最短平均编码长度</strong>即对于更大概率的事件，采用更短的编码(同Huffman编码思路一致)。</p><blockquote><p>证明： 假设编码的字符集大小为<span class="math inline">\(D\)</span>，若采用二进制编码，则<span class="math inline">\(D=2\)</span>. 假设存在需要编码的<span class="math inline">\(m\)</span>个事件，每个事件的编码长度为<span class="math inline">\(l_i\)</span>. 根据编码理论中的Kraft–McMillanInequality，在给定的码字字长下能够成功编码，当且仅当: <span class="math display">\[\sum_{i=1}^{m}D^{-l_i}\leq 1.\]</span> 转为如下优化问题： <span class="math display">\[\min_{l_i}\sum_{i=1}^{m}p(x_i)l_i\]</span> <span class="math display">\[\sum_{i=1}^{m}D^{-l_i}\leq1.\]</span> 利用Lagrangian multiplier进一步求解带约束的优化问题，即:<span class="math display">\[J=\sum_{i=1}^{m}p(x_i)l_i+\lambda(\sum_{i=1}^{m}D^{-l_i}-1).\]</span> 得: <span class="math display">\[l_i^{*}=-\log_Dp(x_i).\]</span> 若采用二进制编码，即： <span class="math display">\[\sum p(x_i)l_i^{*}=-\sum p(x_i)\log p(x_i)=H(p).\]</span> 其中，熵的单位为<code>bit</code>，若采用<span class="math inline">\(e\)</span>为底数，则熵的单位为<code>nat</code>.</p></blockquote><h3 id="交叉熵">交叉熵</h3><p>熵的定义： <span class="math display">\[H(p)=\mathbb{E}_{X\sim p(X)}[-\log p(X)],\]</span> 设<span class="math inline">\(p\)</span>为真实分布，<span class="math inline">\(q\)</span>为<span class="math inline">\(p\)</span>的近似分布，则交叉熵被定义为： <span class="math display">\[H(p,q)=\mathbb{E}_{X\sim p(X)}[-\log q(X)]\]</span> 熵<span class="math inline">\(H(p)\)</span>是随机变量<span class="math inline">\(X\)</span>的最优期望编码长度，有： <span class="math display">\[\mathbb{E}_{X\sim p(X)}[-\log p(X)]\leq \mathbb{E}_{X\sim p(X)}[-\logq(X)]\]</span></p><blockquote><p>转为证明： <span class="math display">\[\sum_{i=1}^{n}p(x_i)[\log p(x_i)-\log (q(x_i))]\geq 0.\]</span> 由于对任意<span class="math inline">\(x&gt;0\)</span>,有：<span class="math inline">\(\ln x\leq x-1\)</span>,所以<span class="math inline">\(-\log_{2}x\geq\frac{1-x}{\ln 2}\)</span> 因此<span class="math display">\[\sum_{i=1}^{n}p(x_i)[\log p(x_i)-\log (q(x_i))]\\=\sum_{i=1}^{n}p(x_i)[\log (\frac{p(x_i)}{q(x_i)})]\\\geq \frac{1}{\ln 2}\sum_{i=1}^{n}p(x_i)(1-\frac{q(x_i)}{p(x_i)})\\=\frac{1}{\ln 2}(\sum_{i=1}^{n}p(x_i)-\sum_{i=1}^{n}q(x_i))\\=0\]</span> 交叉熵在机器学习中，作为损失函数。利用<span class="math inline">\(q(x)\)</span>逼近<span class="math inline">\(p(x)\)</span>，使得交叉熵最小。</p></blockquote><h3 id="kl-divergence">KL Divergence</h3><p>对于离散随机变量，分布<span class="math inline">\(p\)</span>和<span class="math inline">\(q\)</span>的<span class="math inline">\(KL\)</span>散度定义如下： <span class="math display">\[D_{KL}(p\Vert q)=-\sum_{i=1}^{n}p(x_i)·\log \frac{q(x_i)}{p(x_i)}\]</span> 展开为： <span class="math display">\[D_{KL}(p\Vert q)=-\sum_{i=1}^{n}p(x_i)·\log \frac{q(x_i)}{p(x_i)}\\=-\sum_{i=1}^{n}p(x_i)·\log q(x_i)+\sum_{i=1}^{n}p(x_i)·\log p(x_i)\\=H(p,q)-H(p).\]</span> 含义为：利用<span class="math inline">\(q\)</span>编码<span class="math inline">\(X\)</span>导致的额外编码长度。恒有： <span class="math display">\[D_{KL}(p\Vert q)\geq 0.\]</span> <span class="math inline">\(KL\)</span>散度优化策略：</p><ol type="1"><li><p>若真实分布<span class="math inline">\(p\)</span>恒定，则优化<span class="math inline">\(KL\)</span>散度，等价于优化交叉熵；多出现于辨别模型，此时可直接优化交叉熵；</p></li><li><p>若真实分布<span class="math inline">\(p\)</span>不恒定，则优化<span class="math inline">\(KL\)</span>散度，会同时改变交叉熵和熵的值，使得<span class="math inline">\(p\)</span>和<span class="math inline">\(q\)</span>相互接近；多出现于生成模型，此时需要直接优化<span class="math inline">\(KL\)</span>散度。</p></li></ol><h2 id="估计方法">估计方法</h2><h3 id="最大似然估计mle">最大似然估计(MLE)</h3><p>假设有训练集<span class="math inline">\(X\)</span>,设其为离散随机变量，且其可能的取值为<span class="math inline">\(\{x_1,...,x_n\}\)</span>.目标是：寻找一个最优的<span class="math inline">\(\theta_{MLE}\)</span>，使得：<span class="math inline">\(P(X|\theta_{MLE})\)</span>最大化。即在参数<span class="math inline">\(\theta_{MLE}\)</span>下，训练集<span class="math inline">\(X\)</span>出现概率最大。</p><blockquote><p>有似然函数： <span class="math display">\[L(\theta)=P(X|\theta) \\=P(x_1|\theta)·P(x_2|\theta)···P(x_n|\theta) \\=\prod_{i=1}^{n}P(x_i|\theta).\]</span> 则有： <span class="math display">\[\theta_{MLE}=argmax_{\theta}L(\theta)\\=argmax_{\theta}\log L(\theta)\\=argmin_{\theta}-\log L(\theta)\\=argmin_{\theta}-\sum_{i=1}^{n}\log P(x_i|\theta).\]</span></p></blockquote><p>区分Probability和Likelihood:</p><ol type="1"><li><p>给定一个<span class="math inline">\(P(X|\theta)\)</span>，若称为Probability，则<span class="math inline">\(\theta\)</span>已知，<span class="math inline">\(X\)</span>是变量，<span class="math inline">\(P(X|\theta)\)</span>是一个关于<span class="math inline">\(X\)</span>的函数。关心的是：对任意的<span class="math inline">\(X\)</span>，其出现的概率；</p></li><li><p>给定一个<span class="math inline">\(P(X|\theta)\)</span>，若称为Likelihood，则<span class="math inline">\(X\)</span>已知，<span class="math inline">\(\theta\)</span>是变量，<span class="math inline">\(P(X|\theta)\)</span>是一个关于<span class="math inline">\(\theta\)</span>的函数。关心的是：寻找一个<span class="math inline">\(\theta\)</span>，使得在该<span class="math inline">\(\theta\)</span>下，<span class="math inline">\(X\)</span>出现的概率最大。</p></li></ol><h3 id="最大后验估计map">最大后验估计(MAP)</h3><p>对比：MLE通过优化参数<span class="math inline">\(\theta\)</span>,使得训练集<span class="math inline">\(X\)</span>出现的概率最大化。MAP嵌入先验知识。假设<span class="math inline">\(\theta\)</span>是服从某先验分布的随机变量，令：<span class="math inline">\(\theta_{MAP}=argmax_{\theta}P(\theta|X)\)</span>.在<span class="math inline">\(P(\theta|X)\)</span>中，<span class="math inline">\(X\)</span>是已观测到的随机变量，<span class="math inline">\(\theta\)</span>是未观测到的随机变量。使用贝叶斯公式：<span class="math display">\[\theta_{MAP}=argmax_{\theta}P(\theta|X)\\=argmax_{\theta}\frac{P(X|\theta)P(\theta)}{P(X)}\\=argmax_{\theta}P(X|\theta)P(\theta)\\=argmax_{\theta}P(\theta)\prod_{i=1}^{n}P(x_i|\theta)\\=argmax_{\theta}\log(P(\theta)\prod_{i=1}^{n}P(x_i|\theta))\\=argmax_{\theta}(\log(P(\theta))+\sum_{i=1}^{n}\log(P(x_i|\theta)))\\=argmin_{\theta}(-\log(P(\theta))-\sum_{i=1}^{n}\log(P(x_i|\theta))).\]</span> 注意点：</p><ol type="1"><li><p>若先验分布<span class="math inline">\(\theta\)</span>服从均匀分布，则<span class="math inline">\(P(\theta)\)</span>为常数，此时<span class="math inline">\(\theta_{MAP}=\theta_{MLE}\)</span>；</p></li><li><p>MAP可视作：MLE增加了一个关于参数的先验分布的正则项<span class="math inline">\(\log(P(\theta))\)</span>.</p></li></ol><h2 id="损失函数">3.损失函数</h2><h3 id="mse">3.1 MSE</h3><p>训练集中<span class="math inline">\(n\)</span>个样本，每个样本有<span class="math inline">\(d\)</span>个特征，那么样本<span class="math inline">\(i\)</span>的特征向量记为：<span class="math inline">\(\vec{x_i}\in\mathbb{R}^{d}\)</span>,标注记为：<span class="math inline">\(y_i\in\mathbb{R}.\)</span> 设模型参数<span class="math inline">\(\vec{w}\in\mathbb{R}^{d},b\in \mathbb{R}\)</span>.显然，模型对样本<span class="math inline">\(i\)</span>的输出为： <span class="math display">\[f(\vec{x_i})=\vec{w}·\vec{x_i}+b.\]</span> 损失函数为： <span class="math display">\[l(y_i,f(\vec{x_i}))=\frac{1}{2}{(y_i-f(\vec{x_i}))}^{2}.\]</span></p><ol type="1"><li><p>几何角度：最小化样本拟合值与真实值之间欧式距离的平方。模型会更加重视拟合效果差的样本点，因此异常值影响较大。</p></li><li><p>概率角度： 假设存在某<span class="math inline">\(\vec{w&#39;}\)</span>和<span class="math inline">\(b&#39;\)</span>，使得数据集中各样本<span class="math inline">\((\vec{x_i},y_i)\)</span>满足：<span class="math inline">\(y_i=\vec{w&#39;}·\vec{x_i}+b&#39;+\epsilon\)</span>。其中<span class="math inline">\(\epsilon\)</span>是随机变量，代表样本中的噪声分布。</p></li></ol><p>假设噪声服从高斯分布，即：<span class="math inline">\(\epsilon\sim\mathcal{N}(0,{\sigma}^{2})\)</span>.则：<span class="math inline">\(y_i\sim\mathcal{N}(\vec{w&#39;}·\vec{x_i}+b&#39;,{\sigma}^{2})\)</span>.那么： <span class="math display">\[p(y_i|\vec{x_i&#39;},\vec{w&#39;},b&#39;)=\frac{1}{\sqrt{2\pi{\sigma}^{2}}}\exp(-\frac{(y_i-{(\vec{w&#39;}·\vec{x_i}+b&#39;)}^{2})}{2{\sigma}^{2}}).\]</span></p><p>利用MLE估计<span class="math inline">\(\vec{w&#39;}\)</span>和<span class="math inline">\(b&#39;\)</span>的真值，则极大似然函数为： <span class="math display">\[L(\vec{w&#39;},b)=\prod_{i=1}^{n}p(y_i|\vec{x_i};\vec{w},b).\]</span> 有： <span class="math display">\[-\log{L(\vec{w&#39;},b)}=-\sum_{i=1}^{n}\log{p(y_i|\vec{x_i};\vec{w},b)}\\=-n·\log{\frac{1}{\sqrt{2\pi{\sigma}^{2}}}}+\frac{1}{2{\sigma}^{2}}\sum_{i=1}^{n}{(y_i-(\vec{w&#39;}·\vec{x_i}+b&#39;))}^{2}.\]</span> 此时，最小化<span class="math inline">\(-\log{L(\vec{w},b)}\)</span>等价于：最小化MSE.</p><h3 id="loss">0-1 Loss</h3><p>适用于二分类问题，假设数据标注：<span class="math inline">\(y_i\in\{-1,+1\}\)</span>.考虑如下0-1损失函数：<span class="math display">\[\mathcal{l}(y_i,f(\vec{x_i}))\begin{cases}0 &amp; if\quad y_i·f(\vec{x_i})&gt;0 \\1 &amp; if\quad y_i·f(\vec{x_i})\leq 0 \\\end{cases}\]</span> 即：<span class="math inline">\(y_i\)</span>与<span class="math inline">\(f(\vec{x_i})\)</span>同号时，视作模型预测正确，损失为0；否则，视作模型预测错误，损失为1.</p><p>数据集上的Empirical Risk是： <span class="math display">\[\mathcal{L}=\frac{1}{n}\sum_{i=1}^{n}\mathcal{l}(y_i,f(\vec{x_i}))\\=\frac{1}{n}\sum_{i=1}^{n}1_{\{y_i·f(\vec{x_i})\leq 0\}}.\]</span>由于该损失函数非凸，不连续，且无法应用基于梯度的优化方法。穷尽搜索的搜索空间大小为<span class="math inline">\(2^{n}\)</span>，此时，最小化0-1损失是一个NP-hard问题。</p><h3 id="logistic-loss">Logistic Loss</h3><blockquote><p>二分类场景中，假设<span class="math inline">\(y_i\)</span>服从关于<span class="math inline">\(\vec{x_i}\)</span>的伯努利分布，令：<span class="math inline">\(y_i\in\{0,1\}\)</span>，<span class="math inline">\(P(y_i=1|\vec{x_i})=p_i\)</span>，则：<span class="math inline">\(P(y_i=0|\vec{x_i})=1-p_i\)</span>.即： <span class="math display">\[P(y_i|\vec{x_i})=p_i^{y_i}·(1-p_i)^{1-y_i}.\]</span></p></blockquote><p>利用MLE估计未知参数<span class="math inline">\(p_i\)</span>有： <span class="math display">\[p_i^{*}=argmin_{p_i}-\sum_{i=1}^{n}\log{[p_i^{y_i}·(1-p_i)^{1-y_i}]}\\=argmin_{p_i}\frac{1}{n}\sum_{i=1}^{n}[-y_i·\log{p_i}-(1-y_i)·\log{(1-p_i)}].\]</span> 假设<span class="math inline">\(p_i\)</span>是一个关于<span class="math inline">\(\vec{x_i}\)</span>的函数，即：<span class="math inline">\(p_i=f(\vec{x_i})=P(y_i=1|\vec{x_i})\)</span>。假设：<span class="math inline">\(f(\vec{x_i})\)</span>是由未知参数<span class="math inline">\(\vec{w}\)</span>和<span class="math inline">\(b\)</span>参数化的，即：<span class="math inline">\(f(\vec{x_i};\vec{w},b)\)</span>.</p><p>则有损失函数： <span class="math display">\[\mathcal{l}(y_i,f(\vec{x_i};\vec{w},b))=-y_i·\log{f(\vec{x_i};\vec{w},b)}-(1-y_i)\log{[1-f(\vec{x_i};\vec{w},b)]}.\]</span> 最小化该损失函数，以求出最优参数<span class="math inline">\(\vec{w}^{*}\)</span>和<span class="math inline">\(b^{*}\)</span>，使得：数据集出现的概率最大化（经验风险最小化）。利用<span class="math inline">\(f(\vec{x_i};\vec{w}^{*},b^{*})\)</span>预测新样本的类别。</p><h4 id="logistic-function">Logistic Function:</h4><p><span class="math display">\[S(\vec{x_i};\vec{w},b)=\frac{1}{1+e^{-\vec{w}·\vec{x_i}+b}}.\]</span> 该函数满足以下要求： - <span class="math inline">\(f(\vec{x_i};\vec{w},b)\)</span>连续可导，可基于梯度来优化损失；- 值域在[0,1]之间。</p><p>令<span class="math inline">\(f(\vec{x_i};\vec{w},b)=S(\vec{x_i};\vec{w},b)\)</span>，则称得到的损失<span class="math inline">\(\mathcal{l}(y_i,f(\vec{x_i};\vec{w},b))\)</span>为<strong>LogisticLoss</strong>.</p><blockquote><p>对比： * MSE：假设<span class="math inline">\(y_i\)</span>服从关于<span class="math inline">\(\vec{x_i}\)</span>的高斯分布，通过MLE得到； *Logistic Loss：二分类场景，假设<span class="math inline">\(y_i\)</span>服从关于<span class="math inline">\(\vec{x_i}\)</span>的伯努利分布，通过MLE得到。</p></blockquote><h2 id="变分自编码器vae">变分自编码器(VAE)</h2><h3 id="动机">动机</h3><h4 id="主成分分析">主成分分析</h4><ol type="1"><li><p>原始数据标准化处理： 假设有<span class="math inline">\(n\)</span>个数据，<span class="math inline">\(m\)</span>个指标，第<span class="math inline">\(i\)</span>个评价对象的第<span class="math inline">\(j\)</span>个指标的取值为<span class="math inline">\(a_{ij}\)</span>。转为： <span class="math display">\[\tilde{a_{ij}}=\frac{a_{ij}-\mu_{j}}{s_j}, i=1,2,...,n;j=1,2,...,m.\]</span> 其中，<span class="math inline">\(\mu_j,s_j\)</span>分别为指标<span class="math inline">\(j\)</span>的均值和样本标准差。 称： <span class="math display">\[\tilde{x_j}=\frac{x_j-\mu_j}{s_j},j=1,2,...,m\]</span> 为标准化指标向量。</p></li><li><p>计算相关系数矩阵<span class="math inline">\(R=(r_{ij})_{n\timesm}\)</span>，有： <span class="math display">\[r_{ij}=\frac{\sum\limits_{k=1}^{n}\tilde{a_{ki}}·\tilde{a_{kj}}}{n-1},i,j=1,2,...,m.\]</span></p></li><li><p>计算特征值和特征向量。 计算相关系数矩阵<span class="math inline">\(R\)</span>的特征值<span class="math inline">\(\lambda_1\geq \lambda_2\geq ...\geq\lambda_m\geq0\)</span>，对应的特征向量<span class="math inline">\(\vec{w_1},\vec{w_2},...,\vec{w_m}\)</span>，其中：<span class="math inline">\(\vec{w_j}=\begin{pmatrix}w_{1j} \\  w_{2j} \\  \vdots \\  w_{mj}\end{pmatrix}\)</span>,由特征向量组成<span class="math inline">\(m\)</span>个新的指标变量： <span class="math display">\[y_1=(\tilde{x_1},\tilde{x_2},...,\tilde{x_m})·\vec{w_1}=w_{11}·\tilde{x_1}+w_{21}·\tilde{x_2}+...+w_{m1}·\tilde{x_m},\\y_2=(\tilde{x_1},\tilde{x_2},...,\tilde{x_m})·\vec{w_2}=w_{12}·\tilde{x_1}+w_{22}·\tilde{x_2}+...+w_{m2}·\tilde{x_m},\\\vdots \\y_m=(\tilde{x_1},\tilde{x_2},...,\tilde{x_m})·\vec{w_m}=w_{1m}·\tilde{x_1}+w_{2m}·\tilde{x_2}+...+w_{mm}·\tilde{x_m},\]</span> 式中：<span class="math inline">\(y_1\)</span>为第1主成分；<span class="math inline">\(y_2\)</span>为第2主成分；...；<span class="math inline">\(y_m\)</span>为第m主成分。</p></li><li><p>取前<span class="math inline">\(l\)</span>个最大特征根对应的特征向量<span class="math inline">\(w_1,...,w_l\)</span>，组成映射矩阵<span class="math inline">\(W\)</span>. 有： <span class="math display">\[{(y_1,...,y_l)}^{T}=(x_1,...,x_m)·W_{m\times l}\]</span></p></li><li><p>对每个<span class="math inline">\(m\)</span>维向量，按照如下方法进行降维： <span class="math display">\[(\vec{x})_{1\times m}(W)_{m\times l}=(\vec{y})_{1\times l}\]</span></p></li></ol><h4 id="自编码器autoencoder">自编码器(Autoencoder)</h4><p>记<span class="math inline">\(X\)</span>为整数个数据集的集合，<span class="math inline">\(x_i\)</span>是数据集中的一个样本。 - 编码器：<span class="math inline">\(z=g(X)\)</span>，输出<span class="math inline">\(z\)</span>的维度远小于输入<span class="math inline">\(X\)</span>的维度； - 解码器：<span class="math inline">\(\tilde{X}=f(z)\)</span>，通过编码<span class="math inline">\(z\)</span>还原出<span class="math inline">\(\tilde{X}\)</span>. - 损失函数：重构误差：<span class="math inline">\(\mathbb{l}={\lVert X-\tilde{X}\rVert}^{2}\)</span></p><p><img src="/posts/46623c6f/image-1.png"></p><p>例子：输入图片<span class="math inline">\(X\in \mathbb{R}^{C\timesH\times W}\)</span>，训练一个自编码器。</p><p>编码器<span class="math inline">\(z=g(X)\)</span>将每个图片编码成<span class="math inline">\(z\in \mathbb{R}^{d}\)</span>；</p><p>解码器利用<span class="math inline">\(z\)</span>将输入的图片重建为<span class="math inline">\(\tilde{X}\in\mathbb{R}^{C\times H\timesW}\)</span>.</p><p>将解码器<span class="math inline">\(g:\mathbb{R}^{d}\rightarrow\mathbb{R}^{C\timesH\times W}\)</span>视作生成模型：</p><p>输入低维向量<span class="math inline">\(z\)</span>，输出高维图片数据<span class="math inline">\(X\)</span>.</p><ol type="1"><li><p>对于绝大多数随机生成的<span class="math inline">\(z\)</span>，<span class="math inline">\(f(z)\)</span>只会生成无意义的噪声；</p></li><li><p>VAE思想：显性地对<span class="math inline">\(z\)</span>的分布<span class="math inline">\(p(z)\)</span>建模。</p></li></ol><h3 id="推导">推导</h3><p>生成数据的步骤：</p><ol type="1"><li><p>从先验分布<span class="math inline">\(p(z)\)</span>采样得到一个<span class="math inline">\(z_i\)</span>；</p></li><li><p>根据<span class="math inline">\(z_i\)</span>，从条件分布<span class="math inline">\(p(X|z_i)\)</span>中采样得到一个数据点.</p></li></ol><h4 id="decoder结构">Decoder结构</h4><p>目标：输入从<span class="math inline">\(\mathcal{N}(0,I)\)</span>中采样得到的<span class="math inline">\(z_i\)</span>，希望Decoder学会一个映射，输出<span class="math inline">\(z_i\)</span>对应的<span class="math inline">\(X\)</span>的分布<span class="math inline">\(p_\theta(X|z_i)\)</span>.</p><p><img src="/posts/46623c6f/image-2.png"></p><p>假设：给定任意<span class="math inline">\(z_i\)</span>后，对应的<span class="math inline">\(X\)</span>服从某个各维度独立的多元高斯分布，即：<span class="math display">\[p_\theta(X|z_i)=\mathcal{N}(X|{\mu_i}^{&#39;}(z_i;\theta),{\sigma_{i}^{&#39;}}^{2}(z_i;\theta)*I).\]</span> 那么有： <span class="math display">\[p_\theta(X)=\int_{z}p_\theta(X|z)p(z)dz\\\approx\frac{1}{m}\sum\limits_{j=1}^{m}p_\theta(X|z_j).\]</span> 因此，需要从<span class="math inline">\(p(z)=\mathcal{N}(z|0,I)\)</span>中大量采样<span class="math inline">\(z_i\)</span>，以计算<span class="math inline">\(p_\theta(X)\)</span>。</p><blockquote><p>例子：我们的图片集是世界上所有的猫；那么抽样得到的一个<span class="math inline">\(z_i\)</span>可能代表颜色为橘色，耳朵为立耳的猫；而下次抽样得到的另一个<span class="math inline">\(z_j\)</span>可能代表颜色为白色，耳朵为折耳的猫。</p><p>假设：这类立耳橘猫的图片像素值的分布<span class="math inline">\(X|z_i\)</span>服从一个多元高斯分布： > \mathcal{N}({\mu_i}^{'},{\sigma_i^{'}}^{2}*I)> 那么： 1. Decoder 通过神经网络，将 $z_i$ 变换为适当的${\mu_i}^{'}$ 和 ${{\sigma_i}^{'}}^{2}$，得到多元高斯分布； 2. 之后从$\mathcal{N}({\mu_i}^{'},{{\sigma_i}^{'}}^{2}*I)$ 中采样，生成立耳橘猫的图片。</p></blockquote><p>问题：直接采样代价极大。由于<span class="math inline">\(x_i\)</span>高维，因此<span class="math inline">\(z_i\)</span>维度不太低。对于某个<span class="math inline">\(x_i\)</span>，与之强相关的<span class="math inline">\(z_i\)</span>数量相对有限，因此需要进行大量的采样，才能知道：哪一些<span class="math inline">\(z_i\)</span>是与哪一些<span class="math inline">\(x_i\)</span>对应着的。解决思路：在Encoder中引入后验分布<span class="math inline">\(p_\theta(z|x_i)\)</span>.</p><h4 id="encoder引入后验分布">Encoder引入后验分布</h4><p>思路：假设当前有后验分布<span class="math inline">\(p_\theta(z|x_i)\)</span>： 1. 前向传播时，将<span class="math inline">\(x_i\)</span>喂给Encoder，计算<span class="math inline">\(z|x_i\)</span>服从的分布； 2.从该分布中采样出<span class="math inline">\(z_i\)</span>（采样得到的<span class="math inline">\(z_i\)</span>基本都与<span class="math inline">\(x_i\)</span>相关），喂给Decoder，得到<span class="math inline">\(X|z_i\)</span>的分布。</p><blockquote><p>计算<span class="math inline">\(p_\theta(z|x_i)\)</span>：尝试贝叶斯公式： <span class="math display">\[p_\theta(z|x_i)=\frac{p_\theta(x_i|z)p(z)}{p_\theta(x_i)}\\=\frac{p_\theta(x_i|z)p(z)}{\int_{z&#39;}p_\theta(x_i|z&#39;)p(z&#39;)dz&#39;}.\]</span> 要估计积分，需要从<span class="math inline">\(p(z)\)</span>中大量采样<span class="math inline">\(z_i\)</span>，代价大，不可行。</p></blockquote><p>解决思路：利用似然<span class="math inline">\(p_\theta(X|z)\)</span>和先验分布<span class="math inline">\(p(z)\)</span>都服从高斯分布的假设，可证明：真实的后验分布<span class="math inline">\(p_\theta(z|X)\)</span>也服从高斯分布。</p><p>令近似的后验分布<span class="math inline">\(q_\phi(z|x_i)\)</span>对任意<span class="math inline">\(x_i\)</span>都有： <span class="math display">\[q_\phi(z|x_i)=\mathcal{N}(z|\mu(x_i;\phi),\sigma^{2}(x_i,\phi)*I)\]</span> 也是一个各维度独立的多元高斯分布。</p><h4 id="整体架构">整体架构</h4><ol type="1"><li>输入一个数据点<span class="math inline">\(x_i\)</span>，通过Encoder，得到隐变量<span class="math inline">\(z\)</span>服从的近似后验分布<span class="math inline">\(q_\phi(z|x_i)\)</span>的参数；（将后验分布视作一个各维度独立的高斯分布，这里输出高斯分布的参数{{\sigma_i}^{2}}和\mu_i）</li><li>从对应的高斯分布采样一个<span class="math inline">\(z_i\)</span>，代表与<span class="math inline">\(x_i\)</span>相似的一类低维样本；</li><li>将采样的一个<span class="math inline">\(z_i\)</span>输入Decoder，得到似然的分布<span class="math inline">\(p_\theta(X|z_i)\)</span>；（将似然分布也视作一个各维度独立的高斯分布，输出参数{{{\sigma_i}^{'}}^{2}}和{\mu_i}^{'}；</li></ol><p><img src="/posts/46623c6f/image-3.png"></p><ol start="4" type="1"><li>从对应的分布中采样，生成<span class="math inline">\(x_i\)</span>对应的重建数据<span class="math inline">\(X_i\)</span>。</li></ol><h4 id="重参数化技巧">重参数化技巧</h4><p>起因：前向传播过程中，调用了“采样函数”，无法反向传播。解决方案：为了网络的正常训练，采样步骤改为： 获得后验分布<span class="math inline">\(q_\phi(z|x_i)\)</span>的参数<span class="math inline">\({\sigma_i}^{2}\)</span>和<span class="math inline">\(\mu_i\)</span>后，先从<span class="math inline">\(\mathcal{N}(0,I)\)</span>中采样得到一个<span class="math inline">\(\epsilon_i\)</span>，令： <span class="math display">\[z_i=\mu_i+\sigma_i\odot\epsilon_i\]</span> 得到的<span class="math inline">\(z_i\)</span>代表与<span class="math inline">\(x_i\)</span>相似的一类样本。 （<span class="math inline">\(\odot\)</span>代表逐元素相乘）</p><p><img src="/posts/46623c6f/image-4.png"></p><h4 id="计算损失">计算损失</h4><p>利用MLE最大化，确定参数<span class="math inline">\(\theta\)</span>，有： <span class="math display">\[\log p_\theta(X)=\int_z q_\phi(z|X)\log {p_\theta}(X)dz\\=\int_z q_{\phi}(z|X)\log{\frac{p_\theta(X,z)}{p_\theta(z|X)}}dz\\=\int_zq_\phi(z|X)\log(\frac{p_\theta(X,z)}{q_\phi(z|X)}·\frac{q_\phi(z|X)}{p_\theta(z|X)})dz\\=\int_z q_\phi(z|X)\log\frac{p_\theta(X,z)}{q_\phi(z|X)}dz+\int_zq_\phi(z|X)\log\frac{q_\phi(z|X)}{p_\theta(z|X)}dz\\=\mathcal{l}(p_\theta,q_\phi)+D_{KL}(q_\phi,p_\theta)\\\geq \mathcal{l}(p_\theta,q_\phi)\]</span></p><h5 id="elboevidence-lower-boud">ELBO(Evidence Lower Boud)</h5><p><span class="math inline">\(\mathcal{l}(p_\theta,q_\phi)\)</span>是<span class="math inline">\(\log{p_\phi(X)}\)</span>的一个下界。 有： <span class="math display">\[\mathcal{l}(p_\theta,q_\phi)=\int_zq_\phi(z|X)\log\frac{p_\theta(X,z)}{q_\phi(z|X)}dz\\=\int_zq_\phi(z|X)\log\frac{p_\theta(X,z)p(z)}{q_\phi(z|X)}dz  (贝叶斯定理)\\=\int_z q_\phi(z|X)\log\frac{p(z)}{q_\phi(z|X)}dz+\int_zq_\phi(z|X)\log{p_\theta(X,z)}dz\\=-D_{KL}(q_\phi,p)+\mathbb{E}_{q_\phi}[\log p_\theta(X,z)].\]</span></p><h5 id="latent-lossd_klq_phip">Latent Loss：<span class="math inline">\(D_{KL}(q_\phi,p)\)</span></h5><p>由于<span class="math inline">\(q_\phi(z|X)\)</span>和<span class="math inline">\(p(z)\)</span>均服从各维度独立的高斯分布的假设，得到<span class="math inline">\(D_{KL}(q_\phi,p)\)</span>的解析解： 一维上，有：\[D_{KL}(\mathcal{N}(\mu,{\sigma}^{2})\Vert\mathcal{N}(0,1))=\int_z\frac{1}{\sqrt{2\pi{\sigma}^{2}}}\exp(-\frac{({z-\mu}^{2})}{2{\sigma}^{2}})\log\frac{\frac{1}{\sqrt{2\pi{\sigma}^{2}}}\exp(-\frac{({z-\mu}^{2})}{2{\sigma}^{2}})}{\frac{1}{\sqrt{2\pi}}\exp(-\frac{{z}^{2}}{2})}dz\\=\int_z\mathcal{N}(\mu,{\sigma}^{2})(-\frac{({z-\mu}^{2})}{2{\sigma}^{2}}+\frac{{z}^{2}}{2}-\log{\sigma})dz\\=-\int_z\frac{({z-\mu}^{2})}{2{\sigma}^{2}}\mathcal{N}(\mu,{\sigma}^{2})dz+\int_z\frac{{z}^{2}}{2}\mathcal{N}(\mu,{\sigma}^{2})dz-\int_z\log{\sigma}\mathcal{N}(\mu,{\sigma}^{2})dz\\=-\frac{\mathbb{E}[{(z-\mu)}^{2}]}{2{\sigma}^{2}}+\frac{\mathbb{E}[{z}^{2}]}{2}-\log{\sigma}\\=\frac{1}{2}(-1+{\sigma}^{2}+{\mu}^{2}-\log{{\sigma}^{2}}).\] 当均为<span class="math inline">\(d\)</span>元高斯分布时，有： \[D_{KL}(q_\phi(z|X),p(z))=\sum_{j=1}^{d}\frac{1}{2}(-1+{\sigma^{{(j)}^{2}}}+{\mu^{{(j)}^{2}}}-\log{\sigma^{{(j)}^{2}}})\]其中：${a}^{{(j)}^{2}}$代表向量<span class="math inline">\(a\)</span>的第<span class="math inline">\(j\)</span>个元素的平方。</p><h5 id="reconstruction-lossmathbbe_q_philog-p_thetaxz">ReconstructionLoss：<span class="math inline">\(\mathbb{E}_{q_\phi}[\logp_\theta(X,z)]\)</span></h5><p>通常通过从<span class="math inline">\(q_\phi(z|X)\)</span>中采样多个<span class="math inline">\(z_i\)</span>来近似求解。即： <span class="math display">\[\mathbb{E}_{q_\phi}[\logp_\theta(X,z)]\approx\frac{1}{m}\sum\limits_{i=1}^{m}\log{p_\theta(X|z_i)}.\]</span> 其中，<span class="math inline">\(z_i\simq_\phi(z|x_i)=\mathcal{N}(z|\mu(x_i;\phi),{\sigma}^{2}(x_i;\phi)*I)\)</span></p>]]></content>
      
      
      <categories>
          
          <category> Introduction to AI </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>AI导论-2024春-总笔记</title>
      <link href="/posts/2bdc7f67.html"/>
      <url>/posts/2bdc7f67.html</url>
      
        <content type="html"><![CDATA[<p>这是北航2024春《人工智能导论》课的理论笔记，由笔者整理。</p><h2 id="绪论">绪论</h2><p>三种主流方法：符号主义、联结主义、行为主义</p><h2 id="机器学习">机器学习</h2><p>从数据中学习知识：f(x)=y</p><p>按数据标注情况分类： * 监督学习：数据有标签、直接反馈、预测结果 *无监督学习：数据无标签、无反馈、寻找数据规律 *半监督学习：部分数据有标签，部分反馈，预测结果 *强化学习：稀疏标签（奖励），稀疏反馈，适合做序列决策</p><h3 id="监督学习">监督学习</h3><h4 id="基本概念从标注数据学习输入到输出的潜在关系即函数映射">基本概念：从<strong>标注数据</strong>学习输入到输出的潜在关系，即函数映射</h4><ul><li><p>经验风险：训练集上损失函数值；期望风险：测试集上损失函数值<img src="/posts/2bdc7f67/17188833646829.png"></p></li><li><p>过拟合：经验风险小，期望风险大；欠拟合：经验风险大，期望风险大</p></li><li><p>过拟合的可能因素：数据过少；模型过于复杂</p></li><li><p>缓解过拟合：1.减小模型复杂度：正则化；减少深度学习模型层数；2.增加数据：数据增广</p></li></ul><h4 id="线性回归分类">线性回归/分类</h4><ul><li>回归：函数输出标量（连续）；分类：给定选项（类别），函数输出其中一个正确选项（离散）</li><li>对数机率回归：sigmoid激活函数，将回归模型转为线性分类模型；softmax函数将二分类拓展至多分类<img src="/posts/2bdc7f67/17188861987241.png"></li></ul><h5 id="一元线性回归">一元线性回归</h5><ul><li>学习模型：<code>f(xi)=w·xi+b</code></li><li>损失函数：<code>L(b,w)=sum(i=1~n)[yi-(w·xi+b)^2]</code>.</li><li>优化方法：最小二乘法，<code>L(b,w)</code>对<code>b</code>,<code>w</code>分别求偏导，设为0</li></ul><h5 id="多元线性回归">多元线性回归</h5><p><img src="/posts/2bdc7f67/17188840367880.png"></p><h5 id="对数机率回归logistic-regression">对数机率回归(LogisticRegression)</h5><p><img src="/posts/2bdc7f67/17188844361132.png"> <img src="/posts/2bdc7f67/17188837302105.png"> *学习模型：Sigmoid函数：y=1/(1+e^(-z)),其中：y属于{0,1} *损失函数：交叉熵函数 * 优化方法：梯度下降对L(θ)的θ求偏导 *从回归到分类（Softmax函数）：多分类交叉熵损失 <img src="/posts/2bdc7f67/17188853082578.png"></p><h6 id="从二分类到多分类softmax">从二分类到多分类：softmax</h6><p><img src="/posts/2bdc7f67/17188856969850.jpg"></p><h4 id="线性判别分析支持向量机">线性判别分析、支持向量机</h4><h5 id="fisher线性判别分析">Fisher线性判别分析</h5><ul><li>针对：二分类问题</li><li>基于监督学习的分类/降维：对一组具有标签信息的高维数据样本，将其线性投影到一个低维空间上</li><li>目标：类内方差小，类间方差大</li><li>目标函数最大化：f(w)=||m1-m2||<sup>2/(s1</sup>2+s2^2)</li><li>步骤：<ul><li>1.计算数据样本集中每个类别样本的均值；</li><li>2.计算类间散度矩阵<code>Sb</code>，类内散度矩阵<code>Sw</code>；<img src="/posts/2bdc7f67/17188880348973.png"> <img src="/posts/2bdc7f67/17188880609918.png"></li><li>3.求前r个最大特征值对应的特征向量(w1,...,wr)，构成矩阵W <img src="/posts/2bdc7f67/17188883237013.png"></li><li>4.通过矩阵W，将每个样本映射至低维空间。</li></ul></li></ul><h5 id="感知器模型">感知器模型</h5><p><img src="/posts/2bdc7f67/17188887270666.png"></p><h5 id="支持向量机">支持向量机</h5><ul><li>目标：最大化分类间隔（支持向量：与超平面距离最小的点） <img src="/posts/2bdc7f67/17188888305620.png"> <img src="/posts/2bdc7f67/17188889962450.png"></li><li>求解目标函数：拉格朗日乘子法 <img src="/posts/2bdc7f67/17188891732309.png"></li></ul><h6 id="正则项">正则项</h6><ul><li>线性不可分-松弛变量，软间隔与hinge损失函数 <img src="/posts/2bdc7f67/17188893150324.png"> <img src="/posts/2bdc7f67/17188894301544.png"></li></ul><h4 id="决策树">决策树</h4><h5 id="信息论概念">信息论概念</h5><h6 id="经验信息熵hy">经验信息熵：H(Y)</h6><p><img src="/posts/2bdc7f67/17188909907864.png"></p><h6 id="条件熵hya">条件熵：H(Y|a)</h6><p>已知随机变量a的条件下，随机变量Y的不确定性 <img src="/posts/2bdc7f67/17188914308159.png"></p><h5 id="划分度量">划分度量</h5><h6 id="信息增益ig">信息增益（IG）</h6><ul><li><code>IG(D,a)=H(Y)-H(Y|a)</code>，划分前后信息熵的差值</li><li>选择IG值最大的属性</li></ul><h6 id="信息增益率gain_ratio">信息增益率（Gain_ratio）</h6><h6 id="基尼系数">基尼系数</h6><ul><li>基本思想：自顶向下递归，以信息熵为度量，构建一颗熵值下降最快的树，到叶节点处信息熵为0</li><li>算法流程：<ul><li>1.训练：从空决策树开始，选择下一个最佳属性进行划分</li><li>2.测试</li></ul></li><li>停止条件：<ul><li>1.当前节点所含样本，均属同一类别；</li><li>2.当前属性集为空；</li><li>3.当前节点所含样本集合为空</li></ul></li></ul><h5 id="剪枝">剪枝</h5><ul><li>划分准则影响决策树的尺寸，但对泛化能力影响有限</li><li>解决分支过多，模型过拟合：剪枝</li></ul><h4 id="ada-boosting">Ada Boosting</h4><ul><li>思想：将多个弱分类器组合形成一个强分类器</li><li>核心问题：<ul><li>1.改变训练数据权重：提高上一轮中分类错误样本的权重；</li><li>2.改变弱分类器权重：提高分类误差小的弱分类器权重</li></ul></li><li>算法流程：<ul><li>1.初始化训练样本的权重：每个样本具有相同权重；</li><li>2.训练弱分类器：样本分类错误，该样本权重升高；反之降低。更新过的样本集，训练下一个分类器。</li><li>3.将所有弱分类器组合为强分类器：加大分类误差率小的弱分类器的权重。</li></ul></li></ul><h3 id="无监督学习">无监督学习</h3><h4 id="k均值聚类">K均值聚类</h4><ul><li>步骤：<ul><li>1.初始化k个聚类质心：C={c1,...,ck}，采样得到。</li><li>2.将每个未聚类数据xi，分别放入：与之距离最近聚类质心所在聚类集合：argmind(xi,cj)</li><li>3.更新聚类集合的质心位置；</li><li>4.重复步骤2，3.</li><li>5.终止条件：达到迭代次数上限；或者，多次迭代后，聚类质心基本不变。</li></ul></li><li>目标函数：</li><li><img src="/posts/2bdc7f67/17187791575445.png"> 最小化每个类簇的方差。</li><li>性质：<ul><li>1.目标函数严格单调递减；</li><li>2.目标函数在有限步内收敛。</li></ul></li><li>不足：<ul><li>1.需要事先确定聚类数目；</li><li>2.初始化的聚类质心影响结果；</li><li>3.欧式距离假设数据的各维度重要性相同。</li></ul></li></ul><h4 id="主成分分析">主成分分析</h4><ul><li>思想：降维，原始数据投影至一个新的坐标系，使得：投影后数据方差最大</li><li>目标函数：如何寻找映射矩阵W，使得：<ul><li>角度1：投影后数据方差最大；<img src="/posts/2bdc7f67/17187816460245.png"></li><li>角度2：重构误差最小 <img src="/posts/2bdc7f67/17187816959038.png"> <img src="/posts/2bdc7f67/17187820033370.png"></li></ul></li><li>步骤：<ul><li>1.数据预处理：X=(X-μ)/σ.</li><li>2.计算协方差矩阵：R=[X(T)X]/n-1. R是mxm维矩阵</li><li>3.求矩阵R的特征向量和特征根；</li><li>4.取前l个最大的特征根对应特征向量，组成映射矩阵W(mxl).</li></ul></li><li>将m维向量X，映射至l维向量Y：Y(1xl)=X(1xm)·W(mxl).</li><li>X(1xm)=Y(1xl)(W(T))(lxm). <img src="/posts/2bdc7f67/17187844841770.png"></li></ul><h5 id="基于特征人脸的降维">基于特征人脸的降维</h5><p>n个1024维人脸样本数据，降维至l维 * 定义： -人脸样本数据：32x32图像-&gt;1024x1列向量 -l个特征人脸：映射矩阵W(1024x1024)：每个特征向量均为1024x1的列向量，可还原成32x32的人脸图像，因此称为：特征人脸。- 人脸的新表达：<img src="/posts/2bdc7f67/17187961583304.png"></p><h4 id="局部线性嵌入lle">局部线性嵌入(LLE)</h4><ul><li>步骤：<ul><li>1.确定邻域大小：类似KNN算法，找到某个样本的k个最近邻；</li><li>2.确定目标损失函数：求解线性关系的权重系数W <img src="/posts/2bdc7f67/17187864918969.png"> <img src="/posts/2bdc7f67/17187870941670.png"></li><li>3.利用权重系数W，在低维里重构样本数据。 <img src="/posts/2bdc7f67/17187871670195.png"></li></ul></li></ul><p>即：<img src="/posts/2bdc7f67/17187873677764.png"></p><h2 id="深度学习">深度学习</h2><p>与机器学习区别：模型更复杂；能够自动学习特征表示；激活函数非线性</p><h4 id="线性回归和梯度下降">线性回归和梯度下降</h4><ul><li>训练步骤：<ul><li>1.定义带有未知参数的函数：y=b+w·x.(w,b是未知参数）</li><li>2.定义损失函数：MAE，MSE，交叉熵损失等 <img src="/posts/2bdc7f67/17187965386601.png"></li><li>3.优化：梯度下降 <img src="/posts/2bdc7f67/17187976554544.png">损失函数L分别关于参数w和b求偏导；迭代更新w和b <img src="/posts/2bdc7f67/17187974544753.png"></li></ul></li></ul><h4 id="前馈神经网络全连接网络多层感知机">前馈神经网络/全连接网络/多层感知机</h4><ul><li>性质：<ul><li>输入层、输出层和至少一层的隐藏层构成；</li><li>各个神经元接受前一级的输入，并输出到下一级，模型中<strong>没有反馈</strong>；</li><li>两个相邻层之间的神经元完全成对连接；但层内的神经元不相互连接。</li></ul></li><li>注意：参数不能初始化为相同的值<ul><li>如果参数被初始化为相同的值：在误差反向传播过程中，同一层的神经元所接收到的误差都相同，更新后这些参数的值仍然相同。</li><li>不管经过多少轮迭代，同一层神经元的参数保持相同，因此不同的神经元无法学习到不同特征的重要程度。<img src="/posts/2bdc7f67/17187998601157.png"></li></ul></li></ul><h5 id="激活函数">激活函数</h5><h6 id="sigmoid函数">sigmoid函数</h6><ul><li><p>激活函数：sigmoid函数<img src="/posts/2bdc7f67/17187982917137.png"><img src="/posts/2bdc7f67/17187990211326.png"> <img src="/posts/2bdc7f67/17187990059918.png"></p></li><li><p>损失函数：<img src="/posts/2bdc7f67/17187992226012.png"></p></li><li><p>优化：<img src="/posts/2bdc7f67/17187992895737.png"></p></li><li><p>sigmoid作为激活函数的不足：</p><ul><li>1.饱和点附近：梯度趋于0，经过链式法则后易使梯度流消失，零梯度传至下游的节点。</li><li>2.参数更新方向受限，更新效率较低。</li></ul></li></ul><h6 id="relu函数">ReLU函数</h6><p><img src="/posts/2bdc7f67/17187995964612.png"></p><h4 id="卷积神经网络">卷积神经网络</h4><ul><li>全连接网络参数量：W,b 例：假设输入图像大小为3 x 100 x100，分类类别数为1000个， 如果用一层全连接网络实现分类，需要多少参数?输入特征数量：3 x 100 x 100 输出特征数量：1000全连接层：每个输入特征都会连接到每个输出特征；每个输出特征一个偏置项；共30000 * 1000 + 1000 = 30,001,000个参数</li></ul><h5 id="卷积层">卷积层</h5><pre><code>原图像：W1 x H1 x D1，卷积核大小：F x F x D1，卷积核个数：K零扩展：Z步长：S- 输出尺寸：    W2=(W1+Z*2-F)/S+1.    H2=(H1+Z*2-F)/S+1.    D2=D1.</code></pre><p><img src="/posts/2bdc7f67/17188021763286.jpg"></p><pre><code>- 输出参数量：(F*F*D1+1)*K.</code></pre><p><img src="/posts/2bdc7f67/17188026006169.jpg"></p><ul><li>步骤：每个Filter扫过整张图做卷积<ul><li>每个感受野(Filter大小)对应一个神经元；</li><li>不同感受野的神经元共享参数（在不同感受野的filter相同,每个Filter扫过整张图做卷积）<img src="/posts/2bdc7f67/17188026997426.png"> <img src="/posts/2bdc7f67/17188031896529.jpg"></li></ul></li></ul><h5 id="池化层">池化层</h5><ul><li>定义：选择该区域内的元素最大值 <img src="/posts/2bdc7f67/17188034788269.jpg"></li></ul><p><img src="/posts/2bdc7f67/17188035096087.png"></p><h5 id="数据增广">数据增广</h5><ul><li>原因：CNN中的卷积操作，不满足尺度和旋转不变性</li></ul><h4 id="序列数据模型">序列数据模型</h4><ul><li>输入形式：向量集</li><li>输出形式：<img src="/posts/2bdc7f67/17188037210600.png"></li><li>建模上下文信息：</li></ul><h4 id="自注意力机制">自注意力机制</h4><ul><li>定义：将单个序列的不同位置关联起来，以计算同一序列的表示的注意机制。</li><li>思想：<ul><li>Attention机制：发生在Target的元素Query和Source中的所有元素之间；</li><li>Self-Attention机制：发生在Source内部元素之间，或者Target内部元素之间，也可以理解为Target=Source这种特殊情况下的注意力计算机制。（即Self-Attention只关注输入本身or只关注关注对象本身）</li></ul></li><li>优点：一组元素内部相互做注意力机制，可以建立全局的依赖关系，扩大图像的感受野。相比于CNN，其<strong>感受野更大，可以获取更多上下文信息</strong>。</li><li>缺点：通过筛选重要信息，过滤不重要信息实现的，这就导致其<strong>有效信息的抓取能力会比CNN小一些</strong>。只有在大数据的基础上才能有效地建立准确的全局关系，而在小数据的情况下，其效果不如CNN。</li><li>步骤：<ul><li><p>1.有矩阵Wq,Wk,Wv，对于每个输入的词向量a，分别计算其查询向量q、键向量k、值向量v。<img src="/posts/2bdc7f67/17188646390271.png"></p></li><li><p>2.计算当前单词的查询向量qi，与其它各个单词的键向量的内积；做softmanx处理，得到Score<img src="/posts/2bdc7f67/17188654985764.png"></p></li><li><p>3.用每个单词得到的score，和其值向量v的各个元素相乘，将向量相加并输出。<img src="/posts/2bdc7f67/17188655213159.png"> 总过程：<img src="/posts/2bdc7f67/17188666600691.png"></p></li></ul></li></ul><h5 id="引入位置编码">引入位置编码</h5><ul><li>原因：self-attention中缺失了位置信息.</li><li>解决方案：可以给每个位置赋予一个唯一的位置编码向量（可手工设计/从数据中学习）<img src="/posts/2bdc7f67/17188672459251.png"></li></ul><h4 id="模型训练策略">模型训练策略</h4><ul><li>训练损失大：区分欠拟合和优化问题<ul><li>从易优化的浅层网络（或传统方法）开始尝试</li><li>如果加深网络无法得到更小的训练损失，可以认为是优化问题</li></ul></li><li>训练损失小，测试损失大：过拟合<ul><li>过拟合：增加模型复杂度，测试损失不降反增<img src="/posts/2bdc7f67/17188677330344.png"></li></ul></li></ul><p><img src="/posts/2bdc7f67/17188674502275.png"></p><h2 id="生成式模型">生成式模型</h2><ul><li>目标：数据升维</li></ul><h4 id="自编码器">自编码器</h4><ul><li><p>目标：最小化重构误差 <img src="/posts/2bdc7f67/17188701611654.png"></p></li><li><p>单层自编码器与PCA不一致：</p><ul><li>PCA有正交约束；自编码器不需要</li></ul></li></ul><h4 id="变分自编码器vae">变分自编码器(VAE)</h4><ul><li>思想：最大化观测数据x的似然L <img src="/posts/2bdc7f67/17188818627898.png"><img src="/posts/2bdc7f67/17188818923162.png"> <img src="/posts/2bdc7f67/17188819037161.png"></li></ul><h4 id="扩散模型ddpm">扩散模型(DDPM)</h4><ul><li><p>与VAE对比：<img src="/posts/2bdc7f67/17188819912970.png"></p></li><li><p>过程：</p><ul><li><p>前向过程：加噪</p></li><li><p>后向过程：去噪</p></li></ul></li></ul><h4 id="对抗式生成网络gan">对抗式生成网络(GAN)</h4><h2 id="强化学习">强化学习</h2><ul><li>特征：<ul><li>与环境交互学习；</li><li>训练时间复杂度高，测试时间复杂度低；（训练难，测试易）</li><li>可解释性低</li></ul></li><li>输入/输出：<ul><li>输入：状态(State)</li><li>输出：动作(actor)，与环境交互，产生reward</li></ul></li><li>四个要素：状态，动作，环境，奖励</li><li>适用场景：稀疏标签（奖励）；稀疏反馈；序列决策</li></ul><p><img src="/posts/2bdc7f67/17186199635179.png"></p><h3 id="无模型强化学习">无模型强化学习</h3><p>分类：</p><ul><li>基于策略的强化学习（Policy-based）<ul><li>显式学习：策略函数</li><li>无价值函数</li></ul></li><li>基于价值的强化学习（Value-based）<ul><li>显式学习：价值函数</li><li>隐式得到：策略（可以通过价值函数得出策略）</li></ul></li><li>行动器-判别器方法（ Actor-Critic ）<ul><li>显式学习：策略函数和价值函数</li></ul></li></ul><h5 id="马尔可夫决策过程">马尔可夫决策过程</h5><p>通过MDP={S,A,Pr,R,γ}来刻画马尔科夫决策过程，包括：</p><ul><li>随机变量序列{St},t=0,1,2,...;(状态)</li><li>动作集合A</li><li>状态转移概率Pr(S(t+1)|St,at),其中at∈A.[可以是确定/随机概率性的]</li><li>奖励函数：R(St,at,S(t+1))</li><li>衰退系数：γ∈[0,1].</li></ul><h5 id="策略函数">策略函数</h5><ul><li>策略函数π:SxA-&gt;[0,1].其中π(S,A)的值表示：在<strong>状态S</strong>下采取<strong>动作A</strong>的<strong>概率</strong></li><li>确定的策略：给定s的情况下，有且仅有一个动作a，使得：π(s,a)=1.</li><li>如何进行策略学习：一个好的策略是，在当前状态下采取了一个行动后，能在未来收到最大化的回报Return：Gt=R[t+1]+γR[t+2]+γ^2·R[t+3]+...</li></ul><h4 id="基于策略的强化学习学习行动器actor">基于策略的强化学习：学习行动器(Actor)</h4><ul><li>步骤：<ul><li><p>1.定义带有未知参数的函数：输入：向量/矩阵形式的<strong>状态</strong>数据输出：每个神经元对应的<strong>动作</strong>，基于输出分数<strong>对动作采样</strong>（具备一定的随机性）<img src="/posts/2bdc7f67/17186205180396.png"></p></li><li><p>2.定义损失函数：最大化<strong>累积奖励</strong> <img src="/posts/2bdc7f67/17186206272045.png"> <img src="/posts/2bdc7f67/17186207044999.png"></p></li><li><p>3.优化：</p></li></ul></li><li>策略梯度法：直接学习策略函数π<ul><li>数据采集：在训练迭代过程的“for循环”内部完成；</li><li>每次模型的更新，需要重新采集整个训练数据集 损失：<img src="/posts/2bdc7f67/17186210250008.png"></li></ul></li></ul><p><img src="/posts/2bdc7f67/17183727473006.png"> * 在线/离线策略： -在线策略：待训练策略和交互策略相同 -离线策略：待训练策略和交互策略不同</p><h4 id="基于价值的强化学习学习评判器critic">基于价值的强化学习：学习评判器(Critic)</h4><h5 id="价值函数动作-价值函数">价值函数，动作-价值函数</h5><p><img src="/posts/2bdc7f67/17183737729141.png"></p><ul><li>价值函数：（注意与Return/Reward的区别）<ul><li>Reward奖励：R(St,at,S(t+1))，从状态St经过动作at转移至状态S(t+1)的奖励</li><li>Return回报：Gt=R[t+1]+γR[t+2]+γ^2·R[t+3]+...</li><li>价值函数取值与时间无关，只与以下因素相关：策略π、在策略π下从某个状态转移到其后续状态所取得的回报、在后续所得回报有关</li></ul></li><li>动作-价值函数：<ul><li>动作-价值函数取值同样与时间没有关系，而是与瞬时奖励和下一步的状态和动作有关。</li></ul></li><li>价值函数与动作-价值函数的关系 <img src="/posts/2bdc7f67/17183741776972.png"> <img src="/posts/2bdc7f67/17183744195399.png"></li></ul><h5 id="评判器">评判器</h5><ul><li>对于价值函数的评判器（Vπ(S)）：对于策略π，评判状态s的好坏；输出值与当前策略π有关</li><li>对于价值-动作函数的评判器(qπ(s,a))：</li></ul><h5 id="贝尔曼方程递推关系">贝尔曼方程：递推关系</h5><p><img src="/posts/2bdc7f67/17183745919854.png"></p><p><img src="/posts/2bdc7f67/17183752352733.png"></p><h5 id="策略优化根据vπ优化π">策略优化：根据Vπ优化π</h5><p><img src="/posts/2bdc7f67/17183756802002.png"> <img src="/posts/2bdc7f67/17183757583387.png"></p><h5 id="策略评估根据π计算vπqπ">策略评估：根据π计算Vπ/qπ</h5><h6 id="动态规划法">动态规划法</h6><ul><li>方法：迭代求解贝尔曼方程组</li><li>局限：<ul><li>1.要求状态转移概率已知；</li><li>2.无法处理状态集合大小无限的情况。 <img src="/posts/2bdc7f67/17185203773038.png"></li></ul></li></ul><h6 id="蒙特卡洛采样">蒙特卡洛采样</h6><p>大数定理指出：对于独立同分布的样本数据，当样本足够大的时候，样本平均值向期望值收敛。思想：采样；通过样本均值估计期望 *若为确定的策略，每个起点只有一个轨迹。 <img src="/posts/2bdc7f67/17185204809957.png"></p><h6 id="时序差分法">时序差分法</h6><p><img src="/posts/2bdc7f67/17185208293458.png"></p><h5 id="策略迭代">策略迭代</h5><ul><li>步骤：<ul><li>1.策略评估：从任意策略π开始，计算该策略下的价值函数Vπ(S)或动作-价值函数qπ(s,a)；</li><li>2.策略优化：根据价值函数Vπ(S)调整策略π；</li><li><ol start="3" type="1"><li>迭代上述步骤，直至策略收敛。</li></ol></li></ul></li></ul><h6 id="q-learning">Q-learning</h6><ul><li>基于动作-价值函数，Q Table存储：该状态下各种动作的qπ(s,a)</li><li>步骤：对当前状态s，<ul><li>1.策略优化：取动作a=argmaxqπ(s,a)，即状态s下的回报最大的动作a，执行a得到下一个状态s'.</li><li>2.策略评估：时序差分思想，更新qπ(s,a)</li><li>3.移至下一个状态s'（s'为终止状态时结束） <img src="/posts/2bdc7f67/17185213430321.png"></li></ul></li><li>ε贪心策略：在状态s，采样动作a时：以1-ε的概率选择带来最大回报的动作，以ε的概率随机选择一个动作。<ul><li>目标：达成探索和利用的平衡 <img src="/posts/2bdc7f67/17185215906298.png"> <img src="/posts/2bdc7f67/17185216211216.png"></li></ul></li></ul><h6 id="deep-q-learningdqn">Deep Q-learning(DQN)</h6><ul><li>原因：状态太多时，部分状态难以采样到</li><li>思想：用神经网络拟合 <img src="/posts/2bdc7f67/17187210927819.png"></li></ul><h3 id="基于环境模型的强化学习">基于环境模型的强化学习</h3>]]></content>
      
      
      <categories>
          
          <category> Introduction to AI </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>CMU15-445 Lecture#06 缓存池</title>
      <link href="/posts/7f49fcfe.html"/>
      <url>/posts/7f49fcfe.html</url>
      
        <content type="html"><![CDATA[<p>在冯诺依曼架构中，数据存储在磁盘上，但必须<strong>加载到内存</strong>中才能执行操作。因此，如果数据库管理系统希望处理大量数据，它就必须能够<strong>高效地在磁盘与内存之间移动数据</strong>。这个任务由<strong>缓冲池管理器（BufferPool Manager）</strong>完成。从高层来看，主要实现以下功能：</p><ol type="1"><li>将<strong>物理页（PhysicalPages）</strong>在内存的缓冲区与持久存储之间来回移动；</li><li>作为一个<strong>缓存（Cache）</strong>使用，将常用页面保留在内存中以便更快访问，而将不常用或冷却的页面逐出到磁盘上。</li></ol><p>从时间、空间两个角度看待：</p><ol type="1"><li><strong>空间上</strong>：应该将pages写入磁盘的哪个位置。目标是使得常被访问的页面，存储在相近的位置（空间局部性）</li><li><strong>时间上</strong>：何时将pages从磁盘读入内存；何时将内存中的pages写回磁盘。</li></ol><p><img src="/posts/7f49fcfe/image-19.png"></p><h2 id="缓冲池管理">缓冲池管理</h2><p>缓冲池（BufferPool）：位于<strong>内存中的页面缓存区</strong>，用于连接内存与磁盘之间的数据传输。它本质上是数据库内部分配的一块较大的内存区域，用来临时存储页面（Pages）。</p><p><strong>组织方式</strong>：BufferPool是内存中page的缓存，执行引擎请求page（引擎知道对应的数据在哪个page中），先去缓冲池中寻找：如果<strong>缓冲池中有该page，则读取</strong>；否则缓冲池将<strong>执行page的置换算法将请求的page加载到缓冲池中</strong>。这实际上跟操作系统中的cache有很大的相似之处。</p><blockquote><p>我们将缓冲池管理器视为一种<strong>回写型缓存</strong>（Write-BackCache），即对页面的<strong>更改不会立即写回磁盘，而是先缓存在内存中</strong>。这与直写型缓存（Write-ThroughCache）相反，后者会在每次修改后立即将变更写入磁盘。</p></blockquote><p>BufferPool将DBMS主动申请（由OS分配）的<strong>内存分为多个frame，每个frame实际上就是磁盘上的一个page的slot，执行时将会把磁盘上的page载入缓存池中的frame上</strong>。</p><p><strong>Page Directory（页目录）</strong>：将pageid映射到数据库文件中的具体位置。（所有对页面目录的更改都必须写入磁盘，以确保数据库在重启后能正确找到页面）</p><p><img src="/posts/7f49fcfe/image-20.png"></p><h3 id="缓冲池metadata">缓冲池Metadata</h3><p><strong>PageTable（页表）</strong>:一个位于<strong>内存中的哈希表</strong>，用于追踪当前已加载到内存中的pages。它将<strong>pageID映射到缓冲池中的frame位置</strong>。（由于缓冲池中pages的排列顺序不一定与磁盘上的顺序一致，因此这个额外的间接映射层使得系统能够正确定位页面在内存中的位置。）我们<strong>通过页表和pageid查看请求的page是否在缓存池中</strong>。另外，页表还为每个page维护了以下元信息：</p><ul><li><strong>脏标志（DirtyFlag）</strong>：每当一个线程<strong>修改page内容时，就会设置</strong>这个标志。这表示该<strong>page在被驱逐出缓冲池之前，必须先写回磁盘</strong>。</li><li><strong>固定/引用计数器（Pin/ReferenceCounter）</strong>：记录<strong>当前正在访问该页面的线程数</strong>（无论是读取还是修改）。每个线程在访问page之前，必须先将该计数器加一。如果某个page的“pincount”大于0，说明它<strong>正在被使用，那么缓冲池管理器不允许将该page驱逐出内存</strong>。（固定某个page，不会阻止其他事务同时访问它，即允许并发访问）</li></ul><p>如果缓冲池已满，且不存在未被固定的页面用于替换，则系统抛出<strong>OOM</strong>错误。</p><h3 id="页目录-页表">页目录 &amp; 页表</h3><p>页目录（PageDirectory）：将<strong>页面ID</strong>映射到<strong>数据库文件中实际位置</strong>的映射关系。</p><ul><li>所有对页目录的更改都必须写入磁盘，因为页目录需要告诉执行引擎数据在哪个page的slot，因此必须持久化，以确保数据库在重启后仍然能找到页面的位置。</li></ul><p>页面表（PageTable）：将<strong>页面ID</strong>映射到<strong>缓冲池中页面副本所在frame的位置</strong>的映射关系。</p><ul><li>这是一个仅存在于内存中的哈希表，不需要持久化存储在磁盘上（丢失了重建一个就好）</li></ul><p>简而言之：页目录是磁盘上的真实位置索引，持久化保存；页表是内存中的缓冲池映射表，临时使用。</p><h2 id="os-dbms">OS &amp; DBMS</h2><h3 id="locks-vs-latches">Locks vs Latches</h3><p><strong>Locks</strong>：<strong>更高级的逻辑原语</strong></p><ul><li>用于保护数据库中的逻辑内容，如元组（tuple）、表（table）、整个数据库等，防止其他事务并发访问或修改；</li><li>锁的持有时间是<strong>整个事务的持续时间</strong>；</li><li><strong>锁的存在对用户是可见的</strong>，例如运行查询时，数据库系统可以告诉你当前持有哪些锁；</li><li>因为事务可能会失败或被回滚，所以需要<strong>支持回滚更改</strong>。</li></ul><p><strong>Latches</strong>：<strong>底层的保护原语</strong>（可使用自旋锁）</p><ul><li>是一种<strong>底层的保护机制</strong>，用于<strong>保护数据库内部数据结构的关键区域</strong>，如哈希表、内存区域等，防止多个线程同时修改造成破坏。</li><li>用于保护数据库内部数据结构中的关键代码段，防止其他线程并发修改；</li><li>生命周期<strong>只持续到该操作完成</strong>，不需要长时间持有；</li><li>因为只保护内部状态，不涉及逻辑数据变更，<strong>不需要支持回滚</strong>。</li></ul><h2 id="为什么不使用os">为什么不使用OS？</h2><p>为什么不直接用 OS的页缓存（比如 mmap）来管理DBMS中的pages呢？</p><p>虽然 mmap 等系统调用能将文件直接映射到内存中，让 OS负责页面的加载/驱逐，但对于追求高性能与强事务一致性的数据库来说，存在以下严重问题：</p><ol type="1"><li><strong>事务安全性差</strong>：OS可能随时将脏页刷新到磁盘，打破事务的原子性和一致性；</li><li><strong>I/O延迟不可控</strong>：如果采用OS，那么DBMS无从得知哪些pages已经存入内存；一旦发生缺页，线程可能会因页面错误而被阻塞；</li><li><strong>错误处理复杂</strong>：如果访问非法页面，OS可能抛出<strong>SIGBUS信号</strong>，导致数据库必须额外处理底层异常；</li><li><strong>性能问题</strong>：操作系统内部数据结构可能产生竞争；页表更新引发的TLB shootdown 会降低多核系统性能。</li></ol><blockquote><p>为什么DBMS更倾向于自行管理内存？ 1.<strong>更好地控制脏页刷新顺序</strong>：保证事务日志优先、数据页随后写入；2. <strong>实现更智能的预取策略</strong>：基于访问模式预测数据； 3.<strong>更合理地调度线程/进程</strong>：控制并发与性能瓶颈。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Database </category>
          
          <category> CMU 14-445 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>CMU15-445 Lecture#05 存储模型和压缩</title>
      <link href="/posts/92773fb8.html"/>
      <url>/posts/92773fb8.html</url>
      
        <content type="html"><![CDATA[<p>本篇博客为CMU15-445（2024Fall）中存储模型与压缩技术部分的理论学习笔记。 ## 数据库工作负载 ###OLTP（在线事务处理）：写操作密集<strong>快速、短时间</strong>运行的操作，<strong>重复操作和简单查询</strong>，每次操作只处理一个实体。OLTP工作负载通常<strong>写操作比读操作多</strong>，每次只读/更新<strong>少量数据</strong>。*示例：亚马逊商店。用户可以将物品添加到购物车并进行购买，但这些操作只影响他们自己的账户。</p><h3 id="olap在线分析处理读操作密集">OLAP（在线分析处理）：读操作密集</h3><p><strong>长时间运行的复杂查询</strong>（通常涉及计算聚合）和对<strong>大量数据</strong>的读取。在OLAP 工作负载中，数据库系统通常会分析和推导来自 OLTP 端的数据。 * 示例:个性化的亚马逊购物广告。网站分析用户购物车和购买的数据，然后为不同的用户选择不同的广告。</p><h3 id="htap混合事务和分析处理">HTAP（混合事务和分析处理）</h3><p>OLTP 和 OLAP 工作负载在同一数据库实例中共存。 <img src="/posts/92773fb8/image-2.png"></p><h2 id="存储模型">存储模型</h2><p>DBMS的存储模型决定：元组在磁盘或内存上等物理介质上的组织形式。 ###N-元存储模型（NSM）：行存储 在 NSM中，DBMS将<strong>单个元组（行）的所有属性连续地存储在一个页面中</strong>，因此也称为“<strong>行存储</strong>”。</p><p><img src="/posts/92773fb8/image-3.png"></p><p>NSM 主要针对 <strong>OLTP</strong>场景，要求高性能的随机写入，每次访问大多是单个实体。这种方法的优点是，只需要一次读取就可以获取单个元组的所有属性。NSM页面通常是 4KB 硬件页面的常数倍。 <img src="/posts/92773fb8/image-4.png"></p><ul><li>优点：快速的插入、更新和删除；适用于需要整个元组的查询（OLTP）。可以使用面向索引的物理存储进行聚集。</li><li>缺点：扫描大量表数据和/或部分属性效率低；访问模式的内存局部性差；因为一个页面包含多个值域，所以很难应用压缩。</li></ul><h3 id="分解存储模型dsm列存储">分解存储模型（DSM）：列存储</h3><p>在DSM中，DBMS将<strong>所有元组的单个属性（列）</strong>存储在数据块中，因此也称为“列存储”。<img src="/posts/92773fb8/image-5.png"></p><p>DSM适合 OLAP工作负载，其中有许多只读查询，需要对表的子集进行大规模扫描。 <img src="/posts/92773fb8/image-6.png"></p><ul><li><p>优点：减少每次查询时浪费的 I/O，因为 DBMS只读取该查询所需的数据；更快的查询处理，数据的<strong>局部性和缓存重用率提高</strong>；更利于<strong>数据压缩</strong>。</p></li><li><p>缺点：对于点查询、插入、更新和删除来说较慢，因为需要拆分和重新组合元组。</p></li></ul><h4 id="重新组合元组的方法">重新组合元组的方法</h4><h5 id="固定长度偏移量">固定长度偏移量</h5><p>每个列中的数据元素（值）都会使用 <strong>固定长度</strong>来表示。这意味着每个属性在列中存储的每个值都占据相同的内存空间，不管这个属性的实际大小。</p><p>由于每个列中的值长度相同，DBMS 可以使用 偏移量（offset）来确定每个属性值在行中的位置。当 DBMS需要重建一个元组时，它可以利用每个属性的固定长度来准确计算该元组中每个属性值的位置。<img src="/posts/92773fb8/image-7.png"> *优点：简单高效，因为每个值的大小已知且固定；DBMS可以快速确定每个值在列中的位置。 *缺点：内存浪费；不适用于变化较大的数据类型（如字符串长度差异大的情况下）。</p><h5 id="嵌入元组-id">嵌入元组 ID</h5><p>每个列中的每个值都会<strong>附带一个元组ID</strong>，该元组ID（通常是主键或唯一标识符）指示该属性值属于哪个元组。</p><p><img src="/posts/92773fb8/image-8.png"> * 优点：适用于具有变动数据类型或长度的列 *缺点：存储开销较大，每个属性值都要附带一个元组ID；需要额外的索引或映射来解析这些元组ID。</p><h3 id="属性跨页分区pax">属性跨页分区（PAX）</h3><p>行按组水平分区；在每个行组内，属性按列垂直分区。</p><p>PAX文件包含一个全局头，其中包含指向文件的行组的偏移量的目录；每个行组维护自己的头，包含有关其内容的元数据。</p><p><img src="/posts/92773fb8/image-9.png"> *优点：获得<strong>列存储的处理速度优势</strong>，同时保持<strong>行存储的空间局部性优势</strong>。</p><h2 id="数据库压缩">数据库压缩</h2><p>压缩在基于磁盘的数据库管理系统（DBMS）中被广泛使用，因为磁盘 I/O几乎总是性能瓶颈。它在只读分析型工作负载的系统中尤为常见。DBMS可以预先压缩数据，这样在查询时可以更有效地获取有用的元组，尽管这会增加压缩和解压缩的计算开销。</p><p>内存数据库（In-memoryDBMS）更为复杂，因为它们不需要从磁盘加载数据进行查询。内存比磁盘要快得多，但压缩数据库可以减少内存（DRAM）需求并降低处理成本。它们需要在速度和压缩比之间找到平衡。压缩数据库减少了DRAM 的需求，可能还会在查询执行过程中减少 CPU 成本。</p><p>考虑到这些，我们希望数据库压缩方案具备以下属性： 1.必须产生<strong>固定长度的值</strong>（唯一的例外是存储在单独池中的可变长度数据）；2. <strong>允许 DBMS在查询执行过程中，尽可能延迟解压缩</strong>（延迟物化）； 3.<strong>无损</strong>（任何损失性压缩都必须在应用程序级别进行）。</p><p>如果数据集完全是随机的比特，则无法执行压缩。然而，现实世界数据集具有一些可压缩的关键特性：1. 属性值的高度偏斜分布（例如，布朗语料库中的 Zipf 分布）； 2.同一元组中属性之间的高度相关性（例如，邮政编码与城市、订单日期与发货日期之间的相关性）。</p><h3 id="压缩粒度">压缩粒度</h3><ol type="1"><li>块级别：对同一表的元组块进行压缩；</li><li>元组级别：对整个元组的内容进行压缩（仅限于 NSM）；</li><li>属性级别：对单个元组中的单个属性值进行压缩（可以针对同一元组的多个属性）；</li><li>列级别：对多个元组中存储的一个或多个属性值进行压缩（仅限于DSM）。允许使用更复杂的压缩方案。</li></ol><h3 id="原始压缩">原始压缩</h3><p>DBMS 使用通用压缩算法（如 gzip、LZO、LZ4、Snappy、Brotli、OracleOZIP、Zstd）对数据进行压缩。工程师通常选择<strong>压缩比低</strong>但<strong>压缩和解压缩速度快</strong>的算法。</p><p>一个使用原始压缩的例子是： MySQL 的 InnoDB。DBMS会压缩磁盘页面，将它们填充为 2KB的倍数，并将它们存储到缓冲池中。然而，每次 DBMS尝试读取或更新数据时，缓冲池中的压缩数据必须首先解压缩；对于盲写操作，不需要解压缩。</p><p>问题： 1.<strong>每次访问都需要解压缩数据</strong>（如果目标是整个表，每次访问压缩/解压缩不实际），客观上限制了压缩范围（MySQL将表拆分为较小的块再压缩）；</p><ol start="2" type="1"><li>原始压缩方案并未考虑数据的高层次意义或语义。因此，<strong>无法利用延迟物化</strong>，因为DBMS 无法知道何时可以延迟解压缩数据。</li></ol><h3 id="列式压缩">列式压缩</h3><h4 id="运行长度编码-run-length-encoding-rle">运行长度编码 (Run-LengthEncoding, RLE)</h4><p>RLE压缩将<strong>单列中相同值的连续实例</strong>压缩为三元组：（属性值，列段中的起始位置（偏移量），运行的元素数量（长度））<img src="/posts/92773fb8/image-10.png"></p><h4 id="位打包编码-bit-packing-encoding">位打包编码 (Bit-PackingEncoding)、</h4><p>当较高位数的编码用不上时，用更少的位数表示。 <img src="/posts/92773fb8/image-11.png"></p><h5 id="大多数编码-mostly-encoding">大多数编码 (Mostly Encoding)</h5><p>位打包的变体：当仅有少数值超过位数表示范围时，使用特殊标记来指示，并维护一个查找表来存储它们。<img src="/posts/92773fb8/image-12.png"></p><h4 id="位图编码-bitmap-encoding">位图编码 (Bitmap Encoding)</h4><p>DBMS为<strong>每个属性的每个唯一值</strong>存储<strong>一个单独的位图</strong>：其中向量中的偏移量对应于元组。位图中的第i位表示该元组在该属性中是否存在对应的值。位图通常被分割成多个块，以避免分配大块的连续内存。</p><p>因为位图的大小与属性值的基数成线性比例，这种方法只在值的基数较低时才实际可行。</p><p><img src="/posts/92773fb8/image-13.png"></p><blockquote><p>假设有1000,0000个元组，43,000个邮编：</p><p>10000000 × 32-bits = 40 MB</p><p>10000000 × 43000 = 53.75 GB</p><p>每当插入一个新元组时，DBMS必须扩展43,000 个位图单位空间，不划算！</p></blockquote><h4 id="增量编码-delta-encoding">增量编码 (Delta Encoding)</h4><p>增量编码不存储精确值，而是记录<strong>同一列中相邻值之间的差异</strong>。基准值可以内联存储，也可以存储在单独的查找表中。我们还可以对存储的增量使用RLE 进一步提高压缩比。 <img src="/posts/92773fb8/image-14.png"></p><h3 id="字典压缩">字典压缩</h3><p>最常见的数据库压缩方案是字典编码。DBMS用<strong>较小的编码替换频繁出现的模式值</strong>；字典将编码映射回原始值。字典压缩方案需要支持快速的编码/解码，并且要支持范围查询。</p><p><strong>保持顺序的编码</strong>：编码后的值，需要支持按照与原始值相同的顺序进行排序，以确保在<strong>压缩数据上与原始数据上执行的查询结果一致</strong>。<img src="/posts/92773fb8/image-15.png"></p><p>在某些查询（如字符串匹配）中，查询可以在压缩数据上执行得更快。</p>]]></content>
      
      
      <categories>
          
          <category> Database </category>
          
          <category> CMU 14-445 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>详解布隆过滤器（Bloom Filter）</title>
      <link href="/posts/d573e76f.html"/>
      <url>/posts/d573e76f.html</url>
      
        <content type="html"><![CDATA[<h2 id="背景">背景</h2><p>如果有一组结构化数据（通过记录ID标识），存储在一组数据文件中，如何确定哪个文件可能包含我们所需的数据呢？如果逐个读取文件，速度会极慢（尤其是要不断从磁盘将数据移入内存）。</p><p>一种解决方案是：构建一个索引表，其中每个数据文件对应一个索引，即将每个记录ID映射到数据文件中的偏移量（索引文件根据记录ID进行排序）。要搜索指定记录ID时，使用二分查找。但是，我们能做得更好吗？</p><h2 id="算法描述">算法描述</h2><p>使用Bloom过滤器快速<strong>测试元素是否为集合的成员</strong>。返回结果为：<strong>可能在集合</strong>中，或<strong>绝对不在集合</strong>中。可能误报（即搜索一个不存在的元素，返回值为“存在”）；不会出现漏报。随着过滤器中元素数量的增加，错误率也会增加。</p><p><img src="/posts/d573e76f/image-18.png">一个空的Bloom过滤器是一个位数组，包含<code>m</code>位，全部设置为0。还有<code>k</code>个不同的哈希函数：每个函数都将集合中的元素映射到<code>m</code>位位置中的一个。*添加元素：将其输入到哈希函数中，得到<code>k</code>个位位置，并将这些位置的位设置为1；* 测试元素是否在集合中：将其输入到哈希函数中，得到k个位位置。 *如果这些位置中的<strong>任何一个位是0</strong>，那么该元素肯定不在集合中；* 如果<strong>全部是1</strong>，那么该元素可能在集合中。</p><blockquote><p>为什么Bloom过滤器不能删除数据？</p><p>解答：无法判断待删除元素映射到的 k 位中，哪一个应该被清除。尽管将这 k位中的任何一个设置为零就足以删除该元素，但它也会删除碰巧映射到该位的任何其他元素。因此清除任何位都会引入漏报的可能性。</p><p>然而，不允许删除的机制会导致其中的无效元素可能会越来越多，即实际已经在磁盘删除中的元素，但在Bloom过滤器中还认为可能存在，造成越来越多的falsepositive。</p></blockquote><h2 id="空间和时间优势">空间和时间优势</h2><ul><li>存储空间：常数<code>（O(k)）</code>，因为其不需要存储实际数据项（适合有保密要求的场景）；</li><li>插入/查询时间：常数<code>（O(k)）</code>，不会随着元素增加而增加；</li><li>空间复杂度为<code>O(m)</code>：不会随着元素增加而增加，占用空间少</li></ul><blockquote><p>缺点：</p><ol type="1"><li>随着存入的元素数量增加，误报率随之增加；</li><li>一般情况下不能从布隆过滤器中删除元素。</li></ol></blockquote><h2 id="误报率">误报率</h2><ol type="1"><li><p>FN（FalseNegative）：集合里有某元素，查找结果是没有该元素（漏报）</p><ul><li>恒有：FN=0</li></ul></li><li><p>FP（FalsePositive）：集合里没有某元素，查找结果是有该元素（误报） <img src="/posts/d573e76f/image-20.png"></p><p>其中：n为插入元素的数量；k为哈希次数；m为Bloom过滤器的长度 &gt;极端情况下，当布隆过滤器没有空闲空间时（满），每一次查询都会返回 true。这也就意味着 m 的选择取决于期望预计添加元素的数量 n ，并且 m需要远远大于 n 。</p></li></ol><h2 id="哈希函数的最佳数量">哈希函数的最佳数量</h2><p>对于给定的 <code>m</code> 和 <code>n</code>，使假阳性概率最小的<code>k</code> 值为： <img src="/posts/d573e76f/image-22.png"></p><p>有： <img src="/posts/d573e76f/image-23.png"></p><p>即对于给定的假阳性概率 <code>ε</code>，布隆过滤器 <code>m</code>的长度与被过滤的元素数量<code>n</code>成正比，并且所需的哈希函数数量仅取决于目标假阳性概率<code>ε</code>。</p><p>因此： <img src="/posts/d573e76f/image-21.png"></p><h2 id="应用场景">应用场景</h2><h3 id="去重统计">去重统计</h3><blockquote><p>转载：https://blog.csdn.net/CrankZ/article/details/84928562</p></blockquote><p>网页爬虫对 URL 去重，避免爬取相同的 URL 地址，有以下几种思路： 1.用HashSet保存访问过的URL，只需接近O(1)的代价就可以查到一个URL是否被访问过了；*太消耗内存。随着URL的增多，占用的内存会越来越多。就算只有1亿个URL，每个URL只算50个字符，就需要5GB内存。2. URL经过MD5或SHA-1等单向哈希后再保存到HashSet或数据库； *于字符串经过MD5处理后的信息摘要长度只有128Bit，SHA-1处理后也只有160Bit，因此方法3比方法2节省了好几倍的内存。3. Bit-Map方法。建立一个BitSet，将每个URL经过一个哈希函数映射到某一位。*单一哈希函数发生冲突的概率太高。若要降低冲突发生的概率到1%，就要将BitSet的长度设置为URL个数的100倍。4. 使用Bloom过滤器。</p><h3 id="缓存穿透">缓存穿透</h3><p>缓存穿透：查询⼀个在缓存和数据库都不存在的数据，这个数据始终⽆法被缓存，导致<strong>每次请求都直接访问数据库</strong>，增加数据库的负载。典型的情况是攻击者可能通过构造不存在的key ⼤量访问缓存，导致对数据库的频繁查询。</p><p>解决方案：利用Bloom过滤器我们可以预先把数据查询的主键，比如用户 ID或文章 ID缓存到过滤器中。要查询时：首先去Bloom过滤器查询该key是否存在；若存在，则进行下一步处理；若不存在，直接返回，因此不会触发后续的数据库查询。</p><h2 id="实现google-guava">实现：Google Guava</h2><ul><li><p>导入Guava库 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">   &lt;groupId&gt;com.google.guava&lt;/groupId&gt;</span><br><span class="line">   &lt;artifactId&gt;guava&lt;/artifactId&gt;</span><br><span class="line">   &lt;version&gt;<span class="number">28.0</span>-jre&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure></p></li><li><p>新建一个 BloomFilterDemo 类，在 main 方法中我们通过BloomFilter.create 方法来创建一个布隆过滤器，初始化 1百万条数据到过滤器中；在原有的基础上增加 10000条数据，并判断这些数据是否存在布隆过滤器中： <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> com.google.common.base.Charsets;</span><br><span class="line"><span class="keyword">import</span> com.google.common.hash.BloomFilter;</span><br><span class="line"><span class="keyword">import</span> com.google.common.hash.Funnels;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">BloomFilterDemo</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">int</span> <span class="variable">total</span> <span class="operator">=</span> <span class="number">1000000</span>; <span class="comment">// 总数量</span></span><br><span class="line">        BloomFilter&lt;CharSequence&gt; bf = </span><br><span class="line">          BloomFilter.create(Funnels.stringFunnel(Charsets.UTF_8), total);</span><br><span class="line">        <span class="comment">// 初始化 1000000 条数据到过滤器中</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; total; i++) &#123;</span><br><span class="line">            bf.put(<span class="string">&quot;&quot;</span> + i);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 判断值是否存在过滤器中</span></span><br><span class="line">        <span class="type">int</span> <span class="variable">count</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; total + <span class="number">10000</span>; i++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (bf.mightContain(<span class="string">&quot;&quot;</span> + i)) &#123;</span><br><span class="line">                count++;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(<span class="string">&quot;已匹配数量 &quot;</span> + count);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>当以上代码运行后，控制台输出结果： <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">已匹配数量 1000309</span><br></pre></td></tr></table></figure> 误判率为：309/(1000000+ 10000) * 100 ≈ 0.030594059405940593</p></li><li><p>提高匹配精度：在创建布隆过滤器的时候设置误判率 fpp：<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">BloomFilter&lt;CharSequence&gt; bf = BloomFilter.create(</span><br><span class="line">  Funnels.stringFunnel(Charsets.UTF_8), total, <span class="number">0.0002</span></span><br><span class="line">);</span><br></pre></td></tr></table></figure> &gt; 在 BloomFilter 内部，误判率 fpp 的默认值是 0.03：&gt; <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// com/google/common/hash/BloomFilter.class</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> &lt;T&gt; BloomFilter&lt;T&gt; <span class="title function_">create</span><span class="params">(Funnel&lt;? <span class="built_in">super</span> T&gt; funnel, <span class="type">long</span> &gt; &gt; expectedInsertions)</span> &#123;</span><br><span class="line"> <span class="keyword">return</span> create(funnel, expectedInsertions, <span class="number">0.03D</span>);</span><br><span class="line">&gt;&#125;</span><br></pre></td></tr></table></figure></p></li></ul><p>误判率 fpp 的值越小，匹配的精度越高；当减少误判率 fpp的值，需要的存储空间也越大。在实际使用过程中，需要在误判率和存储空间之间权衡。</p>]]></content>
      
      
      <categories>
          
          <category> Database </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>CMU15-445 Lecture#03,#04 数据库存储</title>
      <link href="/posts/b2414a0b.html"/>
      <url>/posts/b2414a0b.html</url>
      
        <content type="html"><![CDATA[<p>本篇博客为CMU15-445（2024 Fall）中数据库存储部分的理论学习笔记。</p><h2 id="存储结构">存储结构</h2><p><img src="/posts/b2414a0b/image.png"> 存储层次结构的最上面是离 CPU最近的设备。这些设备速度最快，但也是最小且最贵的；随着距离 CPU的增加，存储设备变得更大，但更慢。每 GB 存储的成本也会下降。</p><h3 id="易失性设备">易失性设备</h3><ul><li><strong>易失性</strong>：如果拔掉机器的电源，数据将丢失；</li><li>易失性存储支持<strong>快速的随机访问</strong>，具有<strong>字节可寻址</strong>的地址。这意味着程序可以跳到任何字节地址并获取数据。</li></ul><h3 id="非易失性设备">非易失性设备</h3><ul><li><strong>非易失性</strong>：该存储设备不需要持续供电，就能保持它存储的位；</li><li><strong>块/页面可寻址</strong>：要读取某个特定偏移位置的值，程序必须先加载包含该值的4 KB 页面到内存中；</li><li>适合<strong>顺序访问</strong>（一次读取多个连续的数据块）。</li><li>我们将其称为“磁盘”，暂时不会区分固态存储（SSD）和旋转硬盘（HDD）。</li></ul><h3 id="持久内存">持久内存</h3><p>介于DRAM和磁盘之间，结合了 DRAM 的快速性和磁盘的持久性。 &gt;持久内存的设计目标是达到两者的最佳平衡。最著名的例子是 Optane。 &gt;&gt; NVMe 表示非易失性内存快车。这些 NVMe SSD并不是持久内存模块，而是通过改进的硬件接口连接的典型 NAND闪存驱动器。这种硬件接口的改进允许更快的传输，从而提升了 NAND闪存的性能。</p><h2 id="磁盘导向dbms概述">磁盘导向DBMS概述</h2><p>系统假设数据全存储在<strong>磁盘</strong>上，数据库文件中的<strong>数据组织成页面，第一页是目录页</strong>。DBMS的任务就是从磁盘到内存之间来回移动数据（因为系统不能直接对磁盘进行操作）。为了操作这些数据，DBMS需要将数据加载到内存中。它<strong>通过一个缓冲池，来管理数据在磁盘和内存之间的移动</strong>。</p><p>DBMS还有一个执行引擎来执行查询。执行引擎会请求缓冲池提供某个特定的页面，<strong>缓冲池会负责将该页面加载到内存中，并向执行引擎提供指向该页面的指针</strong>。缓冲池管理器将确保页面在内存中，执行引擎可以在该内存区域操作。<img src="/posts/b2414a0b/image-1.png"></p><h3 id="dbms与操作系统的关系">DBMS与操作系统的关系</h3><p>DBMS的一个高层设计目标是：<strong>支持超过可用内存的数据库</strong>。由于读写磁盘非常昂贵，必须小心管理磁盘的使用。我们不希望从磁盘获取数据的操作导致大的停顿，影响其他操作的执行；而希望DBMS 能在等待从磁盘获取数据时，继续处理其他查询。</p><p>这个高层设计目标类似于虚拟内存，其中有一个大的地址空间，操作系统可以从磁盘中读取页面。在DBMS 中实现虚拟内存的一种方式是：<strong>使用 mmap将文件的内容映射到进程的地址空间，这使得操作系统负责在磁盘和内存之间移动页面</strong>；mmap如果发生页面错误，将会阻塞进程。</p><blockquote><p>也通过一些指令来指导操作系统进行page的替换（madvise, mlock,msync）；</p><p>如果我们的数据库只需要读取数据的话，使用mmap实际上是可行的，但是问题在于我们并不仅仅需要读。如果有写操作，那么操作系统是不知道那些page需要在其他page执行前，从内存刷到磁盘上的，这将会与日志与并发控制的实现有关。因此若需要写入，则不应使用mmap。</p><p>总的来说，相比使用mmap，让DBMS自己管理page始终会是一个更加高效且安全的做法，可以更好地支持：1. 将脏页按照正确顺序刷新到磁盘； 2. 专门的预取规则； 3.缓冲区替换策略； 4. 线程与进程的调度</p></blockquote><h2 id="文件存储">文件存储</h2><p>实际上，除了专门定制了文件管理系统的DBMS（Oracle，DB2和SQLserver），大多数DBMS<strong>将数据库文件按照特定格式编码，存储为磁盘上的文件</strong>；通过操作系统提供的API读写，并由存储引擎去管理和维护。</p><p>DBMS的存储引擎负责管理数据库的文件。它<strong>将文件表示为页面的集合，每个页面有固定大小的块</strong>，并跟踪页面上的所有读写操作，以及页面中剩余的空闲空间。</p><h3 id="数据库页面">数据库页面</h3><p>DBMS将数据库组织成一个或多个文件，数据以<strong>固定大小的块（页面）</strong>进行存储。页面可以包含不同类型的数据（元组、索引等）；大多数系统不会将这些类型混合在同一页面内。&gt;有些系统要求页面是自包含的：即读取页面所需的所有信息都在页面本身上。</p><p>每个页面都有一个<strong>唯一的标识符（页面ID）</strong>。如果数据库只有一个文件，则页面 ID 可以是文件偏移量。页面ID 可以是每个 DBMS 实例、每个数据库或每个表唯一的。大多数 DBMS都有一个间接层，<strong>将页面 ID 映射到文件路径和偏移量</strong>。</p><p>在调用文件时：系统的上层会请求特定的页面编号；然后，存储管理器需要将页面编号转换为文件路径和偏移量，以便找到该页面。&gt;在文件整体移动后，只要知道整体文件的初始位置，依然可以通过相对位置（即pageID）找到某个文件某个位置的数据所对应的page。方便支持磁盘的压缩，以及使用另一块磁盘而不改变pageID。</p><p>大多数 DBMS使用<strong>固定大小</strong>的页面，以避免支持可变大小页面所带来的工程开销。例如，对于可变大小的页面，删除页面可能会在文件中产生一个空洞，DBMS无法轻松填充这些空洞。</p><h4 id="页面类型">页面类型</h4><p>DBMS有三个页面概念： 1. 硬件页面（通常为 4 KB）； *存储设备保证<strong>硬件页面的原子写入</strong>：如果硬件页面是 4KB，则系统尝试写入 4 KB数据时，要么全部写入，要么都不写入；这意味着：如果数据库页面大于硬件页面，DBMS必须采取额外措施来确保数据安全写入，因为在系统崩溃时，程序可能只写入了一部分数据库页面。2. 操作系统页面（4 KB，x64 2MB/1GB）； 3. 数据库页面（1-16 KB） <img src="/posts/b2414a0b/image-2.png"></p><blockquote><p>专门针对只读工作负载的 DBMS ，通常会使用较大的页面大小。</p></blockquote><h3 id="dbms文件组织方式">DBMS文件组织方式</h3><p>不同的 DBMS 以不同的方式管理磁盘上的页面文件： 1. 堆文件组织（HeapFile Organization） 2. 树形文件组织（Tree File Organization） 3.顺序/排序文件组织（ISAM，索引顺序访问方法） 4. 哈希文件组织（HashingFile Organization）</p><h4 id="堆文件组织">堆文件组织</h4><p>DBMS查找磁盘上页面的位置的一种方式：是使用<strong>堆文件</strong>组织。堆文件是一个<strong>无序的页面集合</strong>，其中元组以<strong>随机顺序</strong>存储。* 创建/读取/写入/删除页面 * 支持在所有页面上的迭代</p><p>DBMS 可以使用：链表或页面目录，来定位磁盘上的特定页面。 1.链表：头页面包含指向自由页面列表和数据页面列表的指针。但是，如果 DBMS想要查找特定页面，它必须在数据页面列表中进行<strong>顺序扫描</strong>，直到找到目标页面。<img src="/posts/b2414a0b/image-3.png"></p><ol start="2" type="1"><li>页面目录：DBMS维护特殊的页面，称为页面目录，用于跟踪数据页面的位置、每个页面上的空闲空间量、空闲/空页面的列表以及页面类型。这些特殊页面为<strong>每个数据库对象提供一个条目</strong>。<img src="/posts/b2414a0b/image-4.png"></li></ol><h2 id="元组布局tuple-oriented">元组布局（Tuple-oriented）</h2><p>元组本质上是<strong>字节序列</strong>（这些字节不一定是连续的）；DBMS的工作是解释这些字节，并将其转换为属性类型和值。 ### 元组头部元组头部包含元数据： * DBMS的并发控制协议中的可见性信息（例如，记录哪个事务创建/修改了该元组）； *NULL 值的位图。 &gt; 注意：DBMS 在这里不需要存储数据库模式的元数据。</p><h3 id="元组数据属性的实际数据">元组数据：属性的实际数据</h3><p>属性通常按照：<strong>创建表时指定的顺序</strong>存储。；大多数 DBMS不允许一个元组的大小超过页面大小。 <img src="/posts/b2414a0b/image-6.png"></p><h4 id="元组的唯一标识符">元组的唯一标识符</h4><p>每个元组在数据库中都有一个唯一标识符；最常见的方式是：页面 ID+（偏移量或插槽）。</p><p>应用程序不能依赖这些标识符来表示任何含义。</p><h4 id="去规范化元组数据">去规范化元组数据</h4><p>如果两个表是相关的，DBMS可以将它们“预先连接”在一起，使得它们存储在同一个页面上。这样可以加快读取速度，因为DBMS只需要加载一个页面，而不是两个单独的页面。然而，这样做会增加更新的成本，因为DBMS 需要为每个元组更多的存储空间。 <img src="/posts/b2414a0b/image-8.png"> <img src="/posts/b2414a0b/image-7.png"></p><h2 id="页面布局">页面布局</h2><p><img src="/posts/b2414a0b/image-5.png">每个页面都包括一个头部，用于记录页面内容的元数据： * 页面大小 * 校验和 *DBMS 版本 * 事务可见性（一些数据查询和修改的权限等） * 自包含性（例如Oracle 要求此项）。</p><p>一种简单的的数据布局方法是：跟踪 DBMS已存储在页面中的元组数，然后每次添加新的元组时将其附加到页面末尾。然而，当元组被删除或元组具有可变长度属性时，问题就出现了。</p><p>DBMS 中有两种主要的数据布局方法：插槽页、日志结构化。</p><h3 id="插槽页slotted-page">插槽页（Slotted-Page）</h3><p>页面头部跟踪：已使用插槽的数量；最后一个已使用插槽的起始位置的偏移量；一个插槽数组（将<strong>插槽</strong>映射至<strong>元组的起始位置偏移量</strong>）&gt; 每个元组可以通过：一个page id，一个slot id来定位。</p><p>要添加元组，插槽数组会从页面开始向末尾增长，而元组的数据将从页面末尾向前增长；当插槽数组和元组数据相遇时，页面被视为已满。<img src="/posts/b2414a0b/image-9.png"></p><h4 id="插入新元组">插入新元组</h4><ol type="1"><li>检查页面目录：找到<strong>具有空闲插槽的页面</strong>；<ul><li>（如果不在内存中）从磁盘中检索页面；</li></ul></li><li>检查插槽数组：找到<strong>页面中空闲的合适位置，插入新元组</strong>。</li></ol><h4 id="更新现有元组使用其记录id">更新现有元组（使用其记录ID）</h4><ol type="1"><li>检查页面目录以找到页面的位置；<ul><li>从磁盘中检索页面（如果不在内存中）</li></ul></li><li>检查插槽数组：找到页面中的偏移位置；</li><li>如果新数据适合，覆盖现有数据。<ul><li>否则，将现有元组标记为已删除，并在不同的页面中插入新版本。</li></ul></li></ol><h4 id="插槽页的几个问题">插槽页的几个问题</h4><p>基于Slotted-Page的元组导向架构存在几个问题： 1.<strong>碎片化</strong>：删除元组可能会在页面中留下空隙，导致页面不能被充分利用；2. <strong>无用磁盘I/O</strong>：由于非易失性存储的块导向特性，需要<strong>加载整个块来更新一个元组</strong>；3. <strong>随机磁盘 I/O</strong>：磁盘读取器可能需要跳到 20个不同的位置，来更新 20 个不同的元组，这会非常慢。</p><h4 id="索引组织存储">索引组织存储</h4><p>将表中元组存储为：索引的值（页面中依照元组的键排序） &gt;B+树提前支付维护成本，而 LSM 树则是稍后支付维护成本。 <img src="/posts/b2414a0b/image-15.png"></p><h3 id="日志结构存储log-structured-storage">日志结构存储（Log-StructuredStorage）</h3><p>假设我们正在处理一个只允许创建新页面、不允许覆盖的系统（例如HDFS、Google Colossus或一些对象存储），日志结构存储模型可以解决上述一些问题。</p><p>这种存储方式并不存储page的元组，而是去存储如何创建以及如何修改tuple的信息（即存储log信息）。这样做的好处有很多：首先是<strong>方便回滚</strong>，因为用了日志数据结构后，回滚只需要删除某些log即可完成；更重要的是高效，因为顺序读写比随机读写要快得多。</p><blockquote><p>场景：如果要更新10个元组，而这10个元组的信息存储在10个pages上，那么我们就要修改10个page的信息；但是如果是日志结构，就只需要把相关的更新语句存储在1个page上即可。</p></blockquote><h4 id="日志结构存储概述">日志结构存储概述</h4><p>日志结构存储基于：<strong>日志结构文件系统（LSFS）</strong>和<strong>日志结构合并树（LSMTree）</strong>。</p><p>与将元组存储在页面中并就地更新它们不同，DBMS<strong>只存储元组更改的日志记录</strong>。<strong>每条日志记录对应：一个元组的插入/删除操作</strong>。每条记录包括：元组的唯一标识符、操作类型（PUT/DELETE），对于PUT 操作，还包含元组的内容。</p><h4 id="步骤">步骤</h4><ol type="1"><li><p>将更改应用到内存数据结构（MemTable）； <img src="/posts/b2414a0b/image-10.png"></p></li><li><p>将更改按顺序写入SSTable； <img src="/posts/b2414a0b/image-11.png"></p></li><li><p>DBMS 在写入磁盘之前，会根据键的顺序将每个 SSTable排序；再将每个SSTable写入磁盘。 &gt;磁盘写入是顺序的，现有的页面是不可变的，这减少了随机磁盘I/O。这对追加式存储非常有利</p><p><img src="/posts/b2414a0b/image-12.png"></p></li></ol><p>DBMS将更改应用到内存数据结构（MemTable），然后将更改按顺序写入磁盘（SSTable）。记录包含元组的唯一标识符、操作类型（PUT/DELETE），对于PUT 操作，还包含元组的内容。实际上，DBMS 只跟踪每个键的最新值（最新的PUT/DELETE）。</p><p>显著地，<strong>就地更新</strong>应用到内存数据结构，因为这样更快，而磁盘写入是顺序的，现有的页面是不可变的，这减少了随机磁盘I/O，对追加式存储非常有利。DBMS 在写入磁盘之前，会根据键的顺序，将每个SSTable 排序。</p><h5 id="summarytable">SummaryTable</h5><p>出现背景：为了读取记录，DBMS 首先检查 MemTable 看是否存在该键；如果MemTable 中没有该键，DBMS 就需要检查每个级别的SSTable：暴力解决方案是扫描 SSTable，从最新到最旧，并在每个 SSTable内部进行二分查找，找到最最新的元组内容，这可能会很慢。</p><p>解决方案：DBMS 维持一个<strong>内存中的 SummaryTable</strong>，来<strong>跟踪每个 SSTable 的附加元数据，如每个 SSTable的最小/最大键和每个级别的键过滤器</strong>（例如，布隆过滤器）。 <img src="/posts/b2414a0b/image-13.png"></p><h4 id="压实">压实</h4><p>问题背景：在写入密集型的工作负载下，DBMS 会在磁盘上积累大量 SSTable。解决方案：DBMS定期使用<strong>排序合并</strong>算法来压实日志，保留每个元组的最新更改。这样可以减少浪费的空间并加快读取。<img src="/posts/b2414a0b/image-14.png"> 压实方法分类： 1. UniversalCompaction：任何日志文件都可以一起压实。 2. LevelCompaction：最小的文件是第 0 级文件，第 0 级文件可以压实以创建更大的第 1级文件，第 1 级文件可以压实为第 2 级文件，依此类推。 3. Tiering是另一种日志压实方法，在本课程中不做介绍。</p><h4 id="权衡">权衡</h4><p>使用日志结构存储的权衡如下： 1.<strong>顺序写入速度快</strong>，适合<strong>追加式存储</strong>； 2.方便写，不方便读； 3. 压实是昂贵的； 4.写放大效应（每个逻辑写入可能对应多个物理写入）。</p><h2 id="数据表示">数据表示</h2><p>元组中的数据本质上是：<strong>带有头部的字节数组</strong>，头部包含关于数据的元数据。它并不跟踪属性的数据类型，DBMS负责知道如何跟踪并解释这些字节。</p><h3 id="字节对齐">字节对齐</h3><p>DBMS 希望确保<strong>元组的字节对齐</strong>，以便 CPU可以高效访问它，而不产生任何意外行为或额外的工作。通常采用两种方式：填充和重新排序。#### 填充（Padding） 在属性后添加空位，确保元组字节对齐。 <img src="/posts/b2414a0b/image-16.png"> #### 重新排序（Reordering）改变物理布局中属性的顺序，确保它们对齐。 <img src="/posts/b2414a0b/image-17.png"></p><h3 id="种数据类型">5种数据类型</h3><p>元组中可以存储五种高层数据类型：整数、可变精度数字、定点精度数字、可变长度值和日期/时间。#### 整数 大多数 DBMS 使用其“本地”的 C/C++ 类型来存储整数，这些类型是由IEEE-754 标准指定的。这些值是固定长度的。例如：<code>INTEGER</code>、<code>BIGINT</code>、<code>SMALLINT</code>、<code>TINYINT</code>。</p><h4 id="可变精度数字">可变精度数字</h4><p>不精确的、可变精度的数字类型，使用 IEEE-754 标准指定的本地 C/C++类型存储。它们的长度也是固定的。例如：<code>FLOAT</code>、<code>REAL</code>、<code>DOUBLE</code>。 &gt;可变精度数字通常比固定精度数字的计算速度更快，因为 CPU 体系架构 (Xeon,Arm)有指令/寄存器支持专门的运算。</p><h4 id="固定精度数字">固定精度数字</h4><p>这些是具有任意精度和标度的数字数据类型。它们通常以不精确的、可变长度的<strong>二进制表示</strong>存储（几乎像字符串一样），并附加元数据来告诉系统数据的长度和小数点的位置。例如：<code>NUMERIC</code>、<code>DECIMAL</code>。 &gt;如果DBMS不提供任意精度，开销可降低。</p><h4 id="可变长度数据">可变长度数据</h4><p>任意长度的数据类型。它们通常以header的方式存储，header跟踪字符串的长度，以便跳到下一个值。它们可能还包含数据的校验和。例如：<code>VARCHAR</code>、<code>VARBINARY</code>、<code>TEXT</code>、<code>BLOB</code>。</p><h4 id="日期和时间">日期和时间</h4><p>日期/时间的表示方法在不同系统中有所不同。通常，它们表示为自 Unix纪元以来的某个单位时间（微秒/毫秒）。例如：<code>TIME</code>、<code>DATE</code>、<code>TIMESTAMP</code>。</p><h2 id="null-数据类型">Null 数据类型</h2><p>在 DBMS 中有三种常见的表示 <code>NULL</code> 的方法： *<code>NullColumnBitmapHeader</code>：在一个集中式的头部存储<strong>位图</strong>，指定哪些属性为<code>NULL</code>；（最常见的方法） * 特殊值：为数据类型指定一个值表示<code>NULL</code>（例如，INT32 MIN）。 *<code>Per-Attribute Null Flag</code>：为每个属性存储一个标志，表示该值为<code>NULL</code>。（它在内存上效率较低）</p><h2 id="大值">大值</h2><p>例如：<code>VARCHAR</code>、<code>VARBINARY</code>、<code>TEXT</code>、<code>BLOB</code>。大多数 DBMS 不允许元组的大小超过单个页面的大小。如何处理超出部分呢？</p><h3 id="溢出页">溢出页</h3><p>将数据存储在特殊的“溢出”页面上，并且元组会包含指向该页面的引用；这些溢出页面可以包含指向其他溢出页面的指针，直到所有数据都能存储为止。<img src="/posts/b2414a0b/image-19.png" alt="alt text">这样管理起来就是一些特殊的page，但在一些持久性等问题上，需要做特别的处理；这对于应用程序透明，你并不会知道自己是否使用了overflowpage。</p><h3 id="外部值">外部值</h3><p>一些系统允许将大值存储在外部文件中，通常将其视为 <code>BLOB</code>类型。 * Oracle：<code>BFILE</code> 数据类型 *Microsoft：<code>FILESTREAM</code> 数据类型 <img src="/posts/b2414a0b/image-18.png" alt="alt text">缺点：存储在外部文件中。这样实现简单，但是DBMS无法提供持久性保证和事务隔离能力。</p><h2 id="系统目录">系统目录</h2><p>DBMS维护一个内部目录，告诉它关于数据库的元数据。内容为： *数据库中的表和列信息，以及这些表上的索引； * 数据库用户及其权限； *表的统计信息，以及包含的内容（例如，某属性的最大值）。</p>]]></content>
      
      
      <categories>
          
          <category> Database </category>
          
          <category> CMU 14-445 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>C++顺序容器</title>
      <link href="/posts/7044b7aa.html"/>
      <url>/posts/7044b7aa.html</url>
      
        <content type="html"><![CDATA[<p>本篇隶属C++ Primer中C++标准库专题，当前集中于顺序容器。</p><p>容器是：一些特定类型对象的集合。顺序容器提供控制元素存储和访问顺序的能力。</p><h2 id="顺序容器概述">顺序容器概述</h2><p>标准库中有以下顺序容器：</p><table><thead><tr><th>顺序容器类型</th><th>数据结构</th><th>访问模式</th><th>插入/删除元素</th></tr></thead><tbody><tr><td>vector</td><td>可变大小数组</td><td>随机访问</td><td>尾部插入/删除</td></tr><tr><td>Deque</td><td>双端队列</td><td>随机访问</td><td>头/尾插入/删除</td></tr><tr><td>List</td><td>双向链表</td><td>双向顺序访问</td><td>任何位置插入/删除</td></tr><tr><td>forward_list</td><td>单向链表</td><td>单向顺序访问</td><td>任何位置插入/删除</td></tr><tr><td>Array</td><td>固定大小数组</td><td>随机访问</td><td>不能插入/删除</td></tr><tr><td>String</td><td>可变大小</td><td>随机访问</td><td>尾部插入/删除</td></tr></tbody></table><blockquote><p>String,vector：将元素保存在<strong>连续内存空间</strong>：随机访问快；插入/删除慢（需要移动之后的所有元素）</p><p>List,forward_list：插入/删除快；不支持随机访问（访问一个元素，需要遍历整个容器），开销大</p><p>Deque:随机访问快；在两端插入/删除快，在中间插入/删除慢</p><p>array：不支持插入/删除元素和改变容器大小（相较于内置数组）</p></blockquote><h3 id="容器使用准则">容器使用准则</h3><ul><li>随机访问元素：vector, deque</li><li>在容器中间插入/删除元素：list, forward_list</li><li>头尾插入/删除元素：deque</li></ul><h2 id="容器库概览">容器库概览</h2><h3 id="迭代器">迭代器</h3><h3 id="begin-end成员">begin, end成员</h3><p>Begin，end：生成指向容器第一个元素，尾元素之后位置的迭代器，从而形成一个包含容器中所有元素的迭代器范围。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">list&lt;string&gt;a=&#123;<span class="string">&quot;Anne&quot;</span>,<span class="string">&quot;Jane&quot;</span>&#125;;</span><br><span class="line"><span class="keyword">auto</span> it1=a.<span class="built_in">begin</span>();<span class="comment">// list&lt;string&gt;::iterator</span></span><br><span class="line"><span class="keyword">auto</span> it2=a.<span class="built_in">rbegin</span>();<span class="comment">// list&lt;string&gt;::reverse_iterator</span></span><br><span class="line"><span class="keyword">auto</span> it3=a.<span class="built_in">cbegin</span>();<span class="comment">// list&lt;string&gt;::const_iterator</span></span><br><span class="line"><span class="keyword">auto</span> it4=a.<span class="built_in">crbegin</span>();<span class="comment">// list&lt;string&gt;::const_reverse_iterator</span></span><br></pre></td></tr></table></figure><blockquote><p>当不需要写访问时，应使用cbegin, cend.</p></blockquote><h3 id="容器定义和初始化">容器定义和初始化</h3><p>每个容器类型都定义了一个<strong>默认构造函数</strong>：除array外，每个容器的默认构造函数都创建一个指定类型的空容器，接受指定大小和元素初始值的参数。</p><p><img src="/posts/7044b7aa/image-1.jpg"></p><h4 id="一个容器初始化为另一个容器的拷贝">一个容器初始化为：另一个容器的拷贝</h4><ul><li>一个容器初始化为另一个容器的拷贝时：两个容器的<strong>容器类型、元素类型必须相同</strong>；</li><li><strong>当传递迭代器参数来拷贝范围时</strong>，不要求容器类型、元素类型相同。</li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">list&lt;string&gt;a=&#123;<span class="string">&quot;Anne&quot;</span>,<span class="string">&quot;Jane&quot;</span>&#125;;</span><br><span class="line"></span><br><span class="line">list&lt;string&gt;<span class="built_in">list2</span>(a);<span class="comment">// 正确：类型匹配</span></span><br><span class="line"><span class="function">deque&lt;string&gt; <span class="title">aList</span><span class="params">(a)</span></span>;<span class="comment">// 错误：容器类型不匹配</span></span><br><span class="line"></span><br><span class="line"><span class="function">forward_list&lt;string&gt; <span class="title">a2</span><span class="params">(a.begin(),a.end())</span></span>;<span class="comment">// 正确：传入迭代器参数时，可以类型不匹配，只要能转化即可</span></span><br></pre></td></tr></table></figure><h4 id="列表初始化">列表初始化</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">list&lt;string&gt;a=&#123;<span class="string">&quot;Anne&quot;</span>,<span class="string">&quot;Jane&quot;</span>&#125;;</span><br></pre></td></tr></table></figure><h4 id="与顺序容器大小相关的构造函数">与顺序容器大小相关的构造函数</h4><p>构造函数接受：一个容器大小初始值，一个（可选的）元素初始值</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">ivec</span><span class="params">(<span class="number">10</span>,<span class="number">-1</span>)</span></span>;</span><br><span class="line"><span class="function">forward_list&lt;<span class="type">int</span>&gt; <span class="title">ivec</span><span class="params">(<span class="number">10</span>)</span></span>;<span class="comment">// 10个元素，每个初始化为0</span></span><br></pre></td></tr></table></figure><ul><li><p>如果元素类型是内置类型/具有默认构造函数的类类型：可以只提供大小参数；</p></li><li><p>如果没有元素类型没有默认构造函数：必须指定一个显式的元素初始值。</p></li></ul><blockquote><p>只有顺序容器的构造函数才接受大小参数；关联容器不支持。</p></blockquote><h4 id="array有固定大小">array有固定大小</h4><ul><li>array可执行数组拷贝</li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> digs[<span class="number">10</span>]=&#123;<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>&#125;;</span><br><span class="line"><span class="type">int</span> cpy[<span class="number">10</span>]=digs;<span class="comment">// 错误：内置数组不支持拷贝/赋值</span></span><br><span class="line">array&lt;<span class="type">int</span>, 10&gt;digits=&#123;<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>&#125;;</span><br><span class="line">array&lt;<span class="type">int</span>, 10&gt;copy=digits;<span class="comment">// 正确：只要数组类型匹配，即合法</span></span><br></pre></td></tr></table></figure><h3 id="赋值和swap">赋值和swap</h3><p><img src="/posts/7044b7aa/image-2.jpg"></p><h4 id="使用assign仅顺序容器">使用assign（仅顺序容器）</h4><p>assign运算符：要求左边、右边的运算对象具备相同的类型；将右边运算对象中的所有元素，拷贝到左边运算对象中。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">list&lt;string&gt; names;</span><br><span class="line">vector&lt;<span class="type">const</span> <span class="type">char</span>*&gt; oldstyle;</span><br><span class="line">names=oldstyle;<span class="comment">// 错误：容器类型不匹配</span></span><br><span class="line">names.<span class="built_in">assign</span>(oldstyle.<span class="built_in">cbegin</span>(), oldstyle.<span class="built_in">cend</span>()); <span class="comment">// 正确：将names中元素替换为迭代器指定范围中，元素的拷贝</span></span><br><span class="line"></span><br><span class="line">list&lt;string&gt;<span class="built_in">slist1</span>(<span class="number">1</span>);<span class="comment">// 1个元素，为空string</span></span><br><span class="line">slist<span class="number">1.</span><span class="built_in">assign</span>(<span class="number">10</span>, <span class="string">&quot;Hiya!&quot;</span>);<span class="comment">// 10个元素，每个都是&quot;Hiya!&quot;</span></span><br></pre></td></tr></table></figure><h4 id="使用swap">使用swap</h4><p><code>swap</code>交换两个相同类型容器的内容</p><blockquote><p>除array外：swap不执行对任何元素的拷贝、删除和插入操作，元素本身未交换，只交换两个容器内部的数据结构，因此：<strong>swap在常数时间内完成</strong>；</p><ul><li>元素不会移动：除string外，指向容器的迭代器、引用和指针都不会失效。</li></ul><p>array：swap会真正交换元素，<strong>所需时间与array中元素数目成正比</strong>。</p></blockquote><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">vector&lt;string&gt; <span class="title">svec1</span><span class="params">(<span class="number">10</span>)</span></span>;</span><br><span class="line"><span class="function">vector&lt;string&gt; <span class="title">svec2</span><span class="params">(<span class="number">24</span>)</span></span>;</span><br><span class="line"><span class="built_in">swap</span>(svec1, svec2);</span><br></pre></td></tr></table></figure><h3 id="容器大小操作">容器大小操作</h3><ul><li><p><code>size</code>：容器中元素数目</p></li><li><p><code>empty</code>：<code>size</code>为0时返回<code>true</code>；否则返回<code>false</code></p></li><li><p><code>max_size</code>：返回大于或等于该类型容器，所能容纳的最大元素值</p></li></ul><h3 id="关系运算符">关系运算符</h3><p>关系运算符左右两侧：相同类型的容器和元素</p><p>逐元素比较：取决于第一个不相等元素的比较结果；若一个容器是另一个容器的前缀子序列，则较小容器小于较大容器。</p><blockquote><p>使用容器关系运算符时，元素必须完成关系运算符的定义：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vector&lt;Sales_data&gt; storeA, storeB;</span><br><span class="line"><span class="keyword">if</span>(storeA&lt;storeB)<span class="comment">// 错误：Sales_data没有&lt;运算符</span></span><br></pre></td></tr></table></figure></blockquote><h2 id="顺序容器操作">顺序容器操作</h2><h3 id="添加元素">添加元素</h3><p><img src="/posts/7044b7aa/image-3.jpg"></p><h4 id="push_back">push_back</h4><p>除array和forward_list外，每个顺序容器（包括string）支持<code>push_back</code>.</p><blockquote><p>使用对象初始化容器/将对象插入到容器，放入的是<strong>对象值的一个拷贝</strong>，而非对象本身。</p></blockquote><h4 id="push_front">push_front</h4><p>list, forward_list,deque支持<code>push_front</code>。将元素插入到容器头部：</p><h4 id="insert">insert</h4><p>Vector, deque, list, string支持<code>insert</code>（forward_list提供特殊版的<code>insert</code>）</p><ul><li><p><code>insert</code>接受一个<strong>迭代器作为第一个参数</strong>：插入到该迭代器所指位置的前面（迭代器可以指向容器尾部不存在的位置）</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vector&lt;string&gt;svec;</span><br><span class="line">svec.<span class="built_in">insert</span>(svec.<span class="built_in">begin</span>(),<span class="string">&quot;hello!&quot;</span>);<span class="comment">// vector不支持push_front操作，使用insert代替</span></span><br></pre></td></tr></table></figure></li><li><p><code>insert</code>接受一个元素数目、一个值：将指定数量的元素，添加到指定位置之前</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">svec.<span class="built_in">insert</span>(svec.<span class="built_in">end</span>(),<span class="number">10</span>,<span class="string">&quot;Lisa&quot;</span>);</span><br></pre></td></tr></table></figure></li><li><p><code>insert</code>接受一对迭代器/一个初始化列表：将给定范围的元素，添加到指定位置之前</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vector&lt;string&gt; c=&#123;<span class="string">&quot;Anne&quot;</span>,<span class="string">&quot;Jane&quot;</span>,<span class="string">&quot;Mike&quot;</span>&#125;;</span><br><span class="line">slist.<span class="built_in">insert</span>(s.<span class="built_in">end</span>(),c.<span class="built_in">end</span>()<span class="number">-2</span>,c.<span class="built_in">end</span>());</span><br><span class="line">slist.<span class="built_in">insert</span>(s.<span class="built_in">end</span>(),&#123;<span class="string">&quot;Jack&quot;</span>&#125;);</span><br></pre></td></tr></table></figure><blockquote><p>传递的迭代器不能指向添加元素的目标容器：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">slist.<span class="built_in">insert</span>(slist.<span class="built_in">begin</span>(),slist.<span class="built_in">begin</span>(),slist.<span class="built_in">end</span>());<span class="comment">//运行时错误</span></span><br></pre></td></tr></table></figure></blockquote></li></ul><h5 id="insert返回值">insert返回值</h5><p><code>insert</code>返回的迭代器，指向插入的新元素：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">list&lt;string&gt; lst;</span><br><span class="line"><span class="keyword">auto</span> iter=lst.<span class="built_in">begin</span>();</span><br><span class="line"><span class="keyword">while</span>(cin&gt;&gt;word) iter=lst.<span class="built_in">insert</span>(iter, word);<span class="comment">// 每次循环将一个新元素插入到list首元素之前的位置</span></span><br></pre></td></tr></table></figure><h4 id="emplace">emplace</h4><p>三个操作：<code>emplace_front</code>, <code>emplace</code>,<code>emplace_back</code>，分别将元素放在容器头部、一个指定位置之前、容器尾部。</p><ul><li><p><code>emplace</code>函数在容器中<strong>直接构造元素</strong>；参数必须与元素类型的构造函数匹配。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">c.<span class="built_in">emplace_back</span>(<span class="string">&quot;978-0590&quot;</span>, <span class="number">25</span>, <span class="number">6</span>=<span class="number">5.99</span>);</span><br><span class="line"><span class="comment">// 等价于：</span></span><br><span class="line">c.<span class="built_in">push_back</span>(<span class="built_in">Sales_data</span>(<span class="string">&quot;978-0590&quot;</span>, <span class="number">25</span>, <span class="number">6</span>=<span class="number">5.99</span>));</span><br></pre></td></tr></table></figure></li><li><p><code>push</code>或<code>insert</code>会创建一个局部临时对象，再压入容器。</p></li></ul><h3 id="访问元素front和end">访问元素：front和end</h3><ul><li><code>front</code>：每个顺序容器都有，返回<strong>首元素的引用</strong></li><li><code>end</code>：除forward_list之外，每个顺序容器都有，返回<strong>尾元素的引用</strong></li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span>(!c.<span class="built_in">empty</span>())&#123;</span><br><span class="line">  <span class="keyword">auto</span> val=*c.<span class="built_in">begin</span>(), val2=c.<span class="built_in">front</span>();<span class="comment">// val, val2是第一个元素值的拷贝</span></span><br><span class="line">  <span class="keyword">auto</span> last=c.<span class="built_in">end</span>();</span><br><span class="line">  <span class="keyword">auto</span> val3=*(--last), val4=c.<span class="built_in">back</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="/posts/7044b7aa/image-4.jpg"></p><h4 id="访问成员函数返回的是引用">访问成员函数返回的是引用</h4><p>容器中访问元素的成员函数（front, back, 下标,at）返回的都是<strong>引用</strong>。</p><blockquote><p>若要改变元素的值，需要将变量定义为<strong>引用</strong>类型。</p></blockquote><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span>(!c.<span class="built_in">empty</span>())&#123;</span><br><span class="line">  c.<span class="built_in">front</span>()=<span class="number">42</span>;</span><br><span class="line">  <span class="keyword">auto</span> &amp;v=c.<span class="built_in">back</span>();<span class="comment">// 获取引用</span></span><br><span class="line">  v=<span class="number">1024</span>;<span class="comment">// 才能改变值</span></span><br><span class="line">  <span class="keyword">auto</span> v2=c.<span class="built_in">back</span>();<span class="comment">// 获取拷贝</span></span><br><span class="line">  v2=<span class="number">0</span>;<span class="comment">// 未改变c中的元素</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="删除元素">删除元素</h3><p><img src="/posts/7044b7aa/image-5.jpg"></p><h4 id="pop_front-pop_back">pop_front, pop_back</h4><blockquote><p>vector,string不支持push_front和pop_front；forward_list不支持pop_back.</p></blockquote><h4 id="erase">erase</h4><p>删除一个/多个元素</p><h4 id="特殊的forward_list操作">特殊的forward_list操作</h4><p><img src="/posts/7044b7aa/image-6.png"></p><p>forward_list是单向链表，删除元素时需关注两个迭代器：一个指向待处理的元素，另一个指向其前驱。</p><h3 id="改变容器大小">改变容器大小</h3><p><img src="/posts/7044b7aa/image-7.png"></p><h3 id="使迭代器失效的容器操作">使迭代器失效的容器操作</h3><p>添加元素：</p><ul><li>Vector, string：<ul><li>存储空间重新分配：指向容器的迭代器、指针、引用都失效；</li><li>存储空间未重新分配：插入位置之前的有效，插入位置之后的失效。</li></ul></li><li>deque：<ul><li>插入首尾位置之外的任何位置：都失效；</li><li>插入首尾位置：迭代器失效，指针、引用有效。</li></ul></li><li>list, forward_list：迭代器、指针、引用都有效。</li></ul><p>删除元素：</p><ul><li>Vector, string：被删元素之前的迭代器、指针、引用都有效；<ul><li>尾后迭代器一定失效。</li></ul></li><li>deque：<ul><li>删除首尾位置之外的任何位置：都失效；</li><li>删除尾元素：尾后迭代器失效，其他不受影响；</li><li>删除首元素：都不受影响。</li></ul></li><li>list,forward_list：迭代器、指针、引用都有效（包括首前迭代器、尾后迭代器）</li></ul><blockquote><p>使用失效的迭代器、指针、引用，是严重的<strong>运行时</strong>错误。</p></blockquote><h4 id="不要缓存end返回的迭代器">不要缓存end返回的迭代器</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> begin=v.<span class="built_in">begin</span>(),end=v.<span class="built_in">end</span>();</span><br><span class="line"><span class="keyword">while</span>(begin!=end)&#123;</span><br><span class="line">  ++begin;</span><br><span class="line">  begin=v.<span class="built_in">insert</span>(begin, <span class="number">4</span>);</span><br><span class="line">  ++begin;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>将<code>end</code>返回的迭代器，保存在一个名为<code>end</code>的局部变量中。在添加元素时，保存在<code>end</code>中的迭代器将失效，不再指向任何位置，导致未定义的行为。应该修改为：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span>(begin!=v.<span class="built_in">end</span>())&#123;</span><br><span class="line">  <span class="comment">// 每次插入操作后，重新计算end</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="vector容器实现与扩充">vector容器实现与扩充</h2><p>vector中元素存储在<strong>连续内存空间</strong>，容器大小可变。其分配策略为：通常分配比心的空间需求大的内存空间，作为备用。</p><h3 id="三个迭代器">三个迭代器</h3><ul><li><code>first</code>：指向vector对象的起始字节位置</li><li><code>last</code>：指向当前最后一个元素的末尾字节</li><li><code>end</code>：指向整个vector容器所用内存空间的末尾字节</li></ul><p><img src="/posts/7044b7aa/image-8.jpg"></p><h3 id="扩容过程">扩容过程</h3><p>如果集合已满，在新增数据的时候，就要分配⼀块更⼤的内存，将原来的数据复制过来，释放之前的内存，在插⼊新增的元素。</p><p>所以对vector的任何操作，<strong>⼀旦引起空间的新配置，指向原vector的所有迭代器就都失效了</strong>。</p><h4 id="管理容器的成员函数">管理容器的成员函数</h4><h4 id="capacity-和-size">capacity 和 size</h4><ul><li><code>size</code>：已经保存的元素数量</li><li><code>capacity</code>：不重新分配内存空间的前提下，最多可以保存的元素数量</li></ul><p>恒有<code>capacity&gt;size</code>；<code>capacity--size</code>时，vector扩容，<code>capacity</code>变大（翻倍）</p><h4 id="扩容机制">扩容机制</h4><h5 id="固定扩容">固定扩容</h5><p>每次扩容的时候在原 capacity 的基础上加上固定的容ᰁ，⽐如初始 capacity为100，扩容⼀次为 capacity + 20，再扩容仍然为 capacity + 20;</p><ul><li>缺点：考虑⼀种极端的情况，vector每次添加的元素数量刚好等于每次扩容固定增加的容量+1，就会造成⼀种情况：每添加⼀次元素就需要扩容⼀次，⽽扩容的时间花费⼗分⾼昂。所以固定扩容可能会⾯临多次扩容的情况，时间复杂度较⾼;</li><li>优点：固定扩容方式，空间利用率高。</li></ul><h5 id="加倍扩容">加倍扩容</h5><p>每次扩容的时候原 capacity 翻倍，⽐如初始capcity = 100, 扩容⼀次变为200, 再扩容变为 400;</p><ul><li>缺点：因为每次扩容空间翻倍，⽽很多空间没有利⽤上，空间利⽤率不如固定扩容。</li><li>优点：</li><li>⼀次扩容 capacity翻倍的⽅式使得正常情况下添加元素需要扩容的次数⼤⼤减少（预留空间较多），时间复杂度较低。</li></ul><h4 id="resize和reserve">resize和reserve</h4><p><img src="/posts/7044b7aa/image-9.jpg"></p><blockquote><p>resize：只改变容器中<strong>元素数目</strong>，不改变容器的容量。</p><ul><li>当resize(len)中len&gt;v.capacity()，数组中的size和capacity均设置为len；</li><li>当resize(len)中len&lt;=v.capacity()，则数组中的size设置为len，⽽capacity不变;</li></ul><p>reserve：不改变容器中元素数量，只影响vector<strong>预先分配的内存空间大小</strong>。</p><ul><li>如果reserve(len)的值 &gt;当前的capacity()，那么会᯿新分配⼀块能存len个对象的空间，然后把之前的对象通过copyconstrutor复制过来，销毁之前的内存;</li><li>当reserve(len)中len&lt;=当前的capacity()，则数组中的capacity不变，size不变，即不对容器做任何改变。</li></ul></blockquote><h2 id="额外的string操作">额外的string操作</h2><h3 id="string构造函数">string构造函数</h3><p><img src="/posts/7044b7aa/image-10.jpg"></p><p>如果pos大于size，抛出<code>out_of_range</code>异常。</p><h3 id="substr操作">substr操作</h3><p><img src="/posts/7044b7aa/image-11.jpg"></p><h3 id="append-replace函数">Append, replace函数</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">s.<span class="built_in">insert</span>(s.<span class="built_in">size</span>(),<span class="string">&quot;hello&quot;</span>);</span><br><span class="line">s.<span class="built_in">append</span>(<span class="string">&quot;hello&quot;</span>);<span class="comment">// 等价</span></span><br><span class="line"></span><br><span class="line">s<span class="number">2.</span><span class="built_in">replace</span>(<span class="number">11</span>,<span class="number">3</span>,<span class="string">&quot;fifth&quot;</span>);<span class="comment">// 删除了3个字符，在其位置插入了5个新字符</span></span><br></pre></td></tr></table></figure><p><img src="/posts/7044b7aa/image-12.jpg"></p><h3 id="string搜索">string搜索</h3><p><img src="/posts/7044b7aa/image-13.jpg"></p><h3 id="compare函数">compare函数</h3><p><img src="/posts/7044b7aa/image-14.jpg"></p><h3 id="数值转换">数值转换</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> i=<span class="number">42</span>;</span><br><span class="line">string s=<span class="built_in">to_string</span>(i);</span><br><span class="line"><span class="type">double</span> d=<span class="built_in">stod</span>(s);</span><br><span class="line"></span><br><span class="line">string s2=<span class="string">&quot;pi=3.14&quot;</span>;</span><br><span class="line"><span class="comment">// 转换s中以数字开始的第一个子串，结果d=3.14</span></span><br><span class="line">d=<span class="built_in">stod</span>(s<span class="number">2.</span><span class="built_in">substr</span>(s<span class="number">2.f</span>ind_first_of(<span class="string">&quot;+-.0123456789&quot;</span>)));</span><br></pre></td></tr></table></figure><blockquote><p>如果string不能转换为一个数值，这些函数抛出一个<code>invalid_argument</code>异常；如果转换得到的数值无法用任何类型表示，则抛出<code>out_of_range</code>异常。</p></blockquote><p><img src="/posts/7044b7aa/image-15.jpg"></p><h2 id="容器适配器">容器适配器</h2><p>三个顺序容器适配器：<code>stack</code>, <code>queue</code>,<code>priority_queue</code></p><p>默认情况下：<code>stack</code>,<code>queue</code>基于<code>deque</code>实现；<code>priority_queue</code>基于<code>vector</code>实现。</p><p><img src="/posts/7044b7aa/image-16.jpg"></p><h3 id="定义一个适配器">定义一个适配器</h3><p>默认构造函数：创建一个空对象，接受一个容器的构造函数，拷贝该容器来初始化适配器。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">stack&lt;<span class="type">int</span>&gt; <span class="title">stk</span><span class="params">(deq)</span></span>;<span class="comment">// 从deq拷贝元素到stk</span></span><br></pre></td></tr></table></figure><h3 id="栈适配器">栈适配器</h3><p><code>stack</code>要求：<code>push_back</code>,<code>pop_back</code>,<code>back</code></p><ul><li>可以使用除array, forward_list的任何容器类型，来构造适配器</li></ul><p><img src="/posts/7044b7aa/image-17.jpg"></p><h3 id="队列适配器">队列适配器</h3><p><code>queue</code>要求：<code>back</code>, <code>push_back</code>,<code>front</code>, <code>push_front</code></p><ul><li>可以使用list, deque,不能使用vector（不支持front相关操作）</li></ul><p><code>priority_queue</code>要求：<code>front</code>,<code>push_back</code>, <code>pop_back</code>，随机访问能力</p><ul><li>可以使用vector,deque,不能使用list</li></ul><p><img src="/posts/7044b7aa/image-18.jpg"></p>]]></content>
      
      
      <categories>
          
          <category> C++ Primer </category>
          
          <category> C++ STL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> C++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>BUAA-OS Lab2 实验笔记</title>
      <link href="/posts/34b35821.html"/>
      <url>/posts/34b35821.html</url>
      
        <content type="html"><![CDATA[<p>继上一篇,我们已经跳转到了<code>init/init.c</code>中的<code>mips_init</code>函数,即内核初始化的入口点,一起回顾一下:<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">ifdef</span> MOS_INIT_OVERRIDDEN</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;generated/init_override.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line"><span class="type">void</span> <span class="title function_">mips_init</span><span class="params">(u_int argc, <span class="type">char</span> **argv, <span class="type">char</span> **penv, u_int ram_low_size)</span> &#123;</span><br><span class="line">printk(<span class="string">&quot;init.c:\tmips_init() is called\n&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// lab2:</span></span><br><span class="line"><span class="comment">//mips_detect_memory(ram_low_size);</span></span><br><span class="line"><span class="comment">//mips_vm_init();</span></span><br><span class="line"><span class="comment">//page_init();</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br></pre></td></tr></table></figure> 那么后续有哪些初始化操作呢?</p><h2 id="内核程序启动">内核程序启动</h2><h3 id="探测硬件可用内存mips_detect_memory函数">探测硬件可用内存:<code>mips_detect_memory</code>函数</h3><p><code>mips_detect_memory()</code>的实现位于<code>kern/pmap.c</code>，作用是探测硬件可用内存，并初始化一些内存管理相关的变量。</p><blockquote><p>记得吗?QEMU模拟器提供bootloader的启动功能,已经帮助完成可用<strong>物理内存</strong>的探测,通过<code>ram_low_size</code>传入.</p><p>函数中变量意义: * <code>memsize</code>:<strong>总物理内存</strong>对应的字节数; *<code>npage</code>:<strong>总物理页数</strong>.(每一个物理页,大小为1024字节)<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">mips_detect_memory</span><span class="params">(u_int _memsize)</span> &#123;</span><br><span class="line"><span class="comment">/* Step 1: Initialize memsize. */</span></span><br><span class="line">memsize = _memsize;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* Step 2: Calculate the corresponding &#x27;npage&#x27; value. */</span></span><br><span class="line"><span class="comment">/* Exercise 2.1: Your code here. */</span></span><br><span class="line">npage=memsize/PAGE_SIZE;</span><br><span class="line">printk(<span class="string">&quot;Memory size: %lu KiB, number of pages: %lu\n&quot;</span>, memsize / <span class="number">1024</span>, npage);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></blockquote><h3 id="进行内存管理的空间分配-mips_init函数">进行内存管理的空间分配:<code>mips_init</code>函数</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">mips_vm_init</span><span class="params">()</span> &#123;</span><br><span class="line">pages = (<span class="keyword">struct</span> Page *)alloc(npage * <span class="keyword">sizeof</span>(<span class="keyword">struct</span> Page), PAGE_SIZE, <span class="number">1</span>);</span><br><span class="line">printk(<span class="string">&quot;to memory %x for struct Pages.\n&quot;</span>, freemem);</span><br><span class="line">printk(<span class="string">&quot;pmap.c:\t mips vm init success\n&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>在进入<code>alloc</code>函数前,我们先看看CPU指令的访存机制:</p><p>在实际程序中,CPU发出的访存、跳转、取指等指令的目标地址都是<strong>虚拟地址</strong>.在<code>4Kc</code>上,**软件访存的虚拟地址会先被MMU硬件映射到物理地址;再使用物理地址访问内存或其他外设。映射与内存布局如下: <img src="/posts/34b35821/image.png"></p><ul><li><code>kseg0</code>(虚拟地址:<code>0x80000000~0x9fffffff</code>):<strong>存放内核代码与数据</strong><ul><li>虚拟地址-&gt;物理地址:最高位置0</li></ul></li><li><code>kseg1</code>(虚拟地址:<code>0xa0000000~0xbfffffff</code>):<strong>访问外设</strong><ul><li>虚拟地址-&gt;物理地址:最高3位置0</li></ul></li><li><code>kuseg</code>(虚拟地址:<code>0x00000000~0x7fffffff</code>):<strong>存放用户程序代码与数据</strong><ul><li>虚拟地址-&gt;物理地址:通过 TLB 转换</li></ul></li></ul></blockquote><p>现在,我们进入<code>mips_init</code>中调用的<code>alloc</code>函数,其意义如下:1.分配<code>npage * sizeof(struct Page)</code>字节的物理内存,并返回初始的虚拟地址,同时将地址按照<code>PAGE_SIZE</code>字节对齐;2. 将对应内存空间清0(<code>clear</code>);</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> *<span class="title function_">alloc</span><span class="params">(u_int n, u_int align, <span class="type">int</span> clear)</span> &#123;</span><br><span class="line"><span class="keyword">extern</span> <span class="type">char</span> end[];</span><br><span class="line"><span class="comment">//end定义在kernel.lds中:. = 0x80400000;end = . ;</span></span><br><span class="line"><span class="comment">//在kseg0中:0x80400000映射至0x400000(虚拟地址最高位清0，转为物理地址)</span></span><br><span class="line"><span class="comment">//从0x400000开始分配物理内存</span></span><br><span class="line">u_long alloced_mem;</span><br><span class="line"></span><br><span class="line"><span class="comment">//表示:小于freemem的物理地址均已被分配(不再分配)</span></span><br><span class="line"><span class="keyword">if</span> (freemem == <span class="number">0</span>) &#123;</span><br><span class="line">freemem = (u_long)end; <span class="comment">// end</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* Step 1: freemem向上对齐 */</span></span><br><span class="line">freemem = ROUND(freemem, align);</span><br><span class="line"></span><br><span class="line"><span class="comment">/* Step 2: 保存空闲物理空间的起始地址 */</span></span><br><span class="line">alloced_mem = freemem;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* Step 3: 更新. */</span></span><br><span class="line">freemem = freemem + n;</span><br><span class="line"></span><br><span class="line">panic_on(PADDR(freemem) &gt;= memsize);</span><br><span class="line"><span class="comment">//PADDR(x)定义在include/mmu.h中</span></span><br><span class="line"><span class="comment">//PADDR(x)返回虚拟地址x对应物理地址的宏(x需为kseg0中的虚拟地址)</span></span><br><span class="line"><span class="comment">//KADDR(x)返回物理地址x位于kseg0的虚拟地址</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* Step 4: 内存空间清0. */</span></span><br><span class="line"><span class="keyword">if</span> (clear) &#123;</span><br><span class="line"><span class="built_in">memset</span>((<span class="type">void</span> *)alloced_mem, <span class="number">0</span>, n);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* Step 5: 返回虚拟地址起始地址. */</span></span><br><span class="line"><span class="keyword">return</span> (<span class="type">void</span> *)alloced_mem;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>总结<code>alloc</code>的功能:从物理地址<code>0x400000</code>开始,分配并清空<code>npage * sizeof(struct Page)</code>字节的物理内存;返回对应的虚拟内存起始地址.</p><blockquote><p>分配的这段物理内存位于<code>kseg0</code>中,使用两个宏完成地址转换:</p><ul><li><code>PADDR(x)</code>:由虚拟地址<code>x</code>,得物理地址(最高位清0)<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> ULIM 0x80000000</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> PADDR(kva)(&#123;</span></span><br><span class="line">    <span class="keyword">if</span> (_a &lt; ULIM) panic(<span class="string">&quot;PADDR called with invalid kva %08lx&quot;</span>, _a);</span><br><span class="line">    _a - ULIM;</span><br><span class="line">)&#125;</span><br></pre></td></tr></table></figure></li><li><code>KADDR(x)</code>:由物理地址<code>x</code>,得虚拟地址;<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"> <span class="meta">#<span class="keyword">define</span> KADDR(pa)(&#123;</span></span><br><span class="line"> u_long _ppn = PPN(pa);</span><br><span class="line"> <span class="keyword">if</span> (_ppn &gt;= npage) &#123; </span><br><span class="line">     panic(<span class="string">&quot;KADDR called with invalid pa %08lx&quot;</span>, (u_long)pa);</span><br><span class="line"> &#125;</span><br><span class="line">(pa) + ULIM; )&#125;</span><br></pre></td></tr></table></figure></li></ul></blockquote><p>从<code>alloc</code>返回<code>mips_vm_init</code>可知: <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">mips_vm_init</span><span class="params">()</span> &#123;</span><br><span class="line">pages = (<span class="keyword">struct</span> Page *)alloc(npage * <span class="keyword">sizeof</span>(<span class="keyword">struct</span> Page), PAGE_SIZE, <span class="number">1</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><code>pages</code>为虚拟内存的起始地址.</p><p>在回到<code>mips_init</code>函数后,继续执行<code>page_init</code>函数之前,让我们先转移视线,看看物理内存管理的方式和数据结构.</p><h2 id="物理内存管理">物理内存管理</h2><p>MOS中的采取<strong>页式内存管理</strong>，采用<strong>链表</strong>管理空闲物理页框。&gt; 在实验里，内存管理的代码位于 <code>kern/pmap.c</code>中。函数的声明位于 <code>include/pmap.h</code> 中。</p><h3 id="链表数据结构">链表数据结构</h3><p>一起瞧瞧不同链表的形式吧!</p><h4 id="头部结构体">头部结构体</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//单向链表：</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> SLIST_HEAD(name, type)                                          </span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">name</span> &#123;</span>                                                           </span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">type</span> *<span class="title">slh_first</span>;</span> <span class="comment">/* first element */</span>                     </span><br><span class="line">&#125;</span><br><span class="line"> <span class="comment">//双向链表：</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> LIST_HEAD(name, type)                                           </span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">name</span> &#123;</span>                                                           </span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">type</span> *<span class="title">lh_first</span>;</span>  <span class="comment">/* first element */</span>                     </span><br><span class="line">&#125;</span><br><span class="line"> <span class="comment">//循环链表：</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CIRCLEQ_HEAD(name, type)                                        </span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">name</span> &#123;</span>                                                           </span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">type</span> *<span class="title">cqh_first</span>;</span>         </span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">type</span> *<span class="title">cqh_last</span>;</span>          </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="链表项结构体">链表项结构体</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//单向链表：链表项包含⼀个指向下⼀个元素的指针sle_next.</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> SLIST_ENTRY(type)                                               </span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">type</span> *<span class="title">sle_next</span>;</span> <span class="comment">/* next element*/</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//双向链表：链表项包含指向下⼀个元素的指针le_next,和指向前⼀个链表项le_next的指针`le_prev`.</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> LIST_ENTRY(type)                                                </span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">type</span> *<span class="title">le_next</span>;</span>   <span class="comment">/* next element */</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">type</span> **<span class="title">le_prev</span>;</span>  <span class="comment">/* address of previous next element */</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//循环链表：链表项包含指向前⼀个和下⼀个元素的指针cqe_prev,cqe_next.</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CIRCLEQ_ENTRY(type)</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span>&#123;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">type</span> *<span class="title">cqe_next</span>;</span>  <span class="comment">/* next element */</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">type</span> *<span class="title">cqe_prev</span>;</span>  <span class="comment">/* previous element */</span> </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="链表操作">链表操作</h4><ul><li><p>单向链表 <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment">//只能在指定节点后插⼊，不能在之前插⼊</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> SLIST_INSERT_AFTER(slistelm, elm, field) do &#123;                   </span></span><br><span class="line">    (elm)-&gt;field.sle_next = (slistelm)-&gt;field.sle_next;             </span><br><span class="line">    (slistelm)-&gt;field.sle_next = (elm);                             </span><br><span class="line">&#125; <span class="keyword">while</span> (<span class="comment">/*CONSTCOND*/</span><span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"> <span class="comment">//移除：</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> SLIST_REMOVE(head, elm, type, field) do &#123;                       </span></span><br><span class="line"><span class="comment">//判断是否为头节点</span></span><br><span class="line">    <span class="keyword">if</span> ((head)-&gt;slh_first == (elm)) &#123;</span><br><span class="line">        SLIST_REMOVE_HEAD((head), field);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">struct</span> type *curelm = (head)-&gt;slh_first;</span><br><span class="line">        <span class="comment">//要删除指定节点时，需从头节点开始遍历，找到该节点的前序节点</span></span><br><span class="line">        <span class="keyword">while</span>(curelm-&gt;field.sle_next != (elm)) curelm = curelm-&gt;field.sle_next;</span><br><span class="line">    &#125; <span class="keyword">while</span> (<span class="comment">/*CONSTCOND*/</span><span class="number">0</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></li><li><p>循环链表：链表项包含指向前⼀个和下⼀个元素的指针<code>cqe_prev</code>,<code>cqe_next</code>.<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//节点后插⼊：</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CIRCLEQ_INSERT_AFTER(head,listelm,elm,field) do &#123;</span></span><br><span class="line">    (elm)-&gt;field.cqe_next=(listelm)-&gt;field.cqe_next;</span><br><span class="line">    (elm)-&gt;field.cqe_prev = (listelm);</span><br><span class="line">    <span class="comment">//注意listelm是否为尾节点：若是，更新尾节点为elm.</span></span><br><span class="line">    <span class="keyword">if</span> ((listelm)-&gt;field.cqe_next == (<span class="type">void</span> *)(head)) </span><br><span class="line">        (head)-&gt;cqh_last = (elm);</span><br><span class="line">    <span class="keyword">else</span> </span><br><span class="line">        (listelm)-&gt;field.cqe_next-&gt;field.cqe_prev = (elm);         </span><br><span class="line">    (listelm)-&gt;field.cqe_next = (elm); </span><br><span class="line">&#125;<span class="keyword">while</span> (<span class="comment">/*CONSTCOND*/</span><span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"> <span class="comment">//节点前插⼊：</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CIRCLEQ_INSERT_BEFORE(head, listelm, elm, field) do &#123;</span></span><br><span class="line">        (elm)-&gt;field.cqe_next = (listelm);</span><br><span class="line">        (elm)-&gt;field.cqe_prev = (listelm)-&gt;field.cqe_prev;</span><br><span class="line">        <span class="comment">//若listelm为头节点：若是，更新头节点为elm.</span></span><br><span class="line">        <span class="keyword">if</span> ((listelm)-&gt;field.cqe_prev == (<span class="type">void</span> *)(head))            </span><br><span class="line">            (head)-&gt;cqh_first = (elm);   </span><br><span class="line">        <span class="keyword">else</span>                                                           </span><br><span class="line">            (listelm)-&gt;field.cqe_prev-&gt;field.cqe_next = (elm);     </span><br><span class="line">        (listelm)-&gt;field.cqe_prev = (elm);                            </span><br><span class="line"> &#125; <span class="keyword">while</span> (<span class="comment">/*CONSTCOND*/</span><span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"> <span class="comment">//移除：</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CIRCLEQ_REMOVE(head, elm, field) do &#123;                          </span></span><br><span class="line">        <span class="comment">//若被移除元素elm是尾节点：</span></span><br><span class="line">        <span class="keyword">if</span> ((elm)-&gt;field.cqe_next == (<span class="type">void</span> *)(head))                  </span><br><span class="line">            (head)-&gt;cqh_last = (elm)-&gt;field.cqe_prev;            </span><br><span class="line">        <span class="keyword">else</span>                                                       </span><br><span class="line">            (elm)-&gt;field.cqe_next-&gt;field.cqe_prev =(elm)-&gt;field.cqe_prev;</span><br><span class="line">        <span class="comment">//若被移除元素elm是头节点：</span></span><br><span class="line">        <span class="keyword">if</span> ((elm)-&gt;field.cqe_prev == (<span class="type">void</span> *)(head))                   </span><br><span class="line">                (head)-&gt;cqh_first = (elm)-&gt;field.cqe_next;             </span><br><span class="line">        <span class="keyword">else</span>                                                           </span><br><span class="line">                (elm)-&gt;field.cqe_prev-&gt;field.cqe_next =(elm)-&gt;field.cqe_next; </span><br><span class="line"> &#125; <span class="keyword">while</span> (<span class="comment">/*CONSTCOND*/</span><span class="number">0</span>)</span><br></pre></td></tr></table></figure></p></li><li><p>双向链表：链表项包含指向下⼀个元素的指针<code>struct type *le_next</code>,和指向前⼀个链表项<code>struct type **le_next</code>的指针<code>le_prev</code>.</p></li></ul><p><img src="/posts/34b35821/image-0.png"></p><table><thead><tr><th>操作</th><th>单向链表</th><th>循环链表</th><th>双向链表</th></tr></thead><tbody><tr><td>链表头部插入</td><td>O(1)</td><td>O(1)</td><td>O(1)</td></tr><tr><td>链表尾部插入</td><td>O(n)</td><td>O(1)</td><td>O(1)</td></tr><tr><td>指定位置插入</td><td>O(n)</td><td>O(n)</td><td>O(n)</td></tr><tr><td>删除头节点</td><td>O(1)</td><td>O(n)</td><td>O(1)</td></tr><tr><td>删除尾节点</td><td>O(n)</td><td>O(1)</td><td>O(1)</td></tr><tr><td>删除指定节点</td><td>O(n)</td><td>O(n)</td><td>O(n)</td></tr></tbody></table><blockquote><p>C++中可以使用<code>std::stack&lt;T&gt;</code>定义一个类型为<code>T</code>的栈，Java中可以使用<code>HashMap&lt;K,V&gt;</code>定义一个键类型为K且值类型为V的哈希表。这种模式称为泛型，C语言并没有泛型的语法，因此需要通过宏另辟蹊径来实现泛型。</p><p>⽤宏实现链表的好处：</p><ul><li><p><strong>代码复⽤性增强</strong>：宏是预处理器指令，在编译前插⼊代码。因此可在多个地⽅复⽤。</p></li><li><p><strong>提⾼性能</strong>：宏在编译时展开，在运⾏时没有额外的函数调⽤开销。</p></li><li><p><strong>跨平台兼容性</strong>：宏是C/C++等编程语⾔的⼀部分，在Window、Linux等操作系统上，只要编译器⽀持宏，就可以使⽤宏操作链表。</p></li></ul></blockquote><h3 id="页式内存管理采用若干个页控制块">页式内存管理：采用若干个页控制块</h3><h4 id="物理页结构体-struct-page">物理页结构体:<code>struct Page</code></h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="title function_">LIST_ENTRY</span><span class="params">(Page)</span> Page_LIST_entry_t;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Page</span> &#123;</span></span><br><span class="line">Page_LIST_entry_t pp_link; <span class="comment">/* free list link */</span><span class="comment">//链表项</span></span><br><span class="line">u_short pp_ref;<span class="comment">//这一页物理内存被引用的次数:有多少虚拟页映射到该物理页</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p><code>npage</code> 个 <code>Page</code> 和 <code>npage</code>个物理⻚⾯⼀⼀顺序对应。（分配<code>npage * sizeof(struct Page)</code>字节的物理内存）* 若⾸个<code>Page</code> 的地址为 P，则 <code>P[i]</code> 对应从0开始计数的第<code>i</code>个物理⻚⾯。</p><h4 id="空闲链表struct-page_list-page_free_list">空闲链表：<code>struct Page_list page_free_list;</code></h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Page_list</span>&#123;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> &#123;</span>_alloc</span><br><span class="line">        <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">            <span class="class"><span class="keyword">struct</span> <span class="title">Page</span> *<span class="title">le_next</span>;</span></span><br><span class="line">            <span class="class"><span class="keyword">struct</span> <span class="title">Page</span> **<span class="title">le_prev</span>;</span></span><br><span class="line">        &#125; pp_link;      <span class="comment">//双向链表项</span></span><br><span class="line">        u_short pp_ref;     <span class="comment">//当前物理页的引用次数</span></span><br><span class="line">    &#125;* lh_first;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Page_list</span> <span class="title">page_free_list</span>;</span></span><br></pre></td></tr></table></figure><p>当一个进程需要分配内存时：将<strong>空闲链表头部的页控制块</strong>对应的那一页物理内存分配出去，将该页控制块从空闲链表中删去；</p><p>当一页物理内存被使用完毕（引用次数为0）时：将其对应的<strong>页控制块重新插入到空闲链表的头部</strong>。</p><h4 id="相关函数">相关函数</h4><h5 id="物理页面管理初始化page_init">物理页面管理初始化：<code>page_init</code></h5><p>初始化+页对齐后： * 已使用的页控制块引用次数全部标1； *剩下的物理页面的引用次数全部标为0，并将它们对应的页控制块插入到<code>page_free_list</code>.</p><p>已分配的页面：<code>0~(index-1)</code></p><p>未分配的页面：<code>index~(npage-1)</code> <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">page_init</span><span class="params">(<span class="type">void</span>)</span> &#123;</span><br><span class="line"><span class="comment">/* Step 1: Initialize page_free_list. */</span></span><br><span class="line">LIST_INIT(&amp;page_free_list);</span><br><span class="line"></span><br><span class="line"><span class="comment">/* Step 2: Align `freemem` up to multiple of PAGE_SIZE. */</span></span><br><span class="line">freemem=ROUND(freemem, PAGE_SIZE);</span><br><span class="line"></span><br><span class="line"><span class="comment">/* Step 3: Mark all memory below `freemem` as used (set `pp_ref` to 1) */</span></span><br><span class="line"><span class="type">int</span> index=(freemem-KSEG0)/PAGE_SIZE;</span><br><span class="line"><span class="keyword">while</span>(index--) pages[index].pp_ref=<span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* Step 4: Mark the other memory as free. */</span></span><br><span class="line"><span class="keyword">for</span>(index=(freemem-KSEG0)/PAGE_SIZE;index&lt;npage;index++)&#123;</span><br><span class="line">pages[index].pp_ref=<span class="number">0</span>;</span><br><span class="line">LIST_INSERT_HEAD(&amp;page_free_list,&amp;pages[index],pp_link);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h5 id="页面分配page_alloc函数">页面分配：<code>page_alloc</code>函数</h5><ul><li><p>如果空闲链表没有可用页，返回异常返回值；</p><blockquote><p>一般的操作系统中，当物理页全部被映射（所有内存空间均被占用），若需要申请新的物理页，则需要将一些在内存中的物理页置换到硬盘中，采用FIFO算法或LRU算法等等。</p></blockquote></li><li><p>如果空闲链表有可用的页，取出链表头部的一页；初始化后，将该页对应的页控制块的地址放到调用者指定的地方。<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">page_alloc</span><span class="params">(<span class="keyword">struct</span> Page **new)</span> &#123;</span><br><span class="line"><span class="comment">/* Step 1: Get a page from free memory. If fails, return the error code.*/</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Page</span> *<span class="title">pp</span>;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//取出空闲块链表page_free_list头部的页控制块，并从链表中移除</span></span><br><span class="line"><span class="keyword">if</span>(LIST_EMPTY(&amp;page_free_list)) <span class="keyword">return</span> -E_NO_MEM;</span><br><span class="line">pp=LIST_FIRST(&amp;page_free_list);</span><br><span class="line"></span><br><span class="line">LIST_REMOVE(pp, pp_link);</span><br><span class="line"></span><br><span class="line"><span class="comment">/* Step 2: Initialize this page with zero.</span></span><br><span class="line"><span class="comment"> * Hint: use `memset`. */</span></span><br><span class="line"><span class="comment">//page2kva(pp):KADDR(page2pa(pp));</span></span><br><span class="line"><span class="comment">//KADDR(x)将物理地址x翻译为kseg0中的虚拟地址,memset第一个参数使用虚拟地址</span></span><br><span class="line"><span class="comment">//(void*)转为字节类型</span></span><br><span class="line"><span class="built_in">memset</span>((<span class="type">void</span> *)page2kva(pp),<span class="number">0</span>,PAGE_SIZE);</span><br><span class="line">*new = pp;<span class="comment">//将pp指向的空间，赋值为该页控制块的地址</span></span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></li></ul><h5 id="减少物理页面引用page_decref函数">减少物理页面引用：<code>page_decref</code>函数</h5><ul><li>令 <code>pp</code> 对应页控制块的引用次数减少 1;<ul><li>如果引用次数为 0,调用<code>page_free</code>函数将对应物理页面重新设置为空闲页面 <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">page_decref</span><span class="params">(<span class="keyword">struct</span> Page *pp)</span> &#123;</span><br><span class="line">assert(pp-&gt;pp_ref &gt; <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">/* If &#x27;pp_ref&#x27; reaches to 0, free this page. */</span></span><br><span class="line"><span class="keyword">if</span> (--pp-&gt;pp_ref == <span class="number">0</span>) &#123;</span><br><span class="line">page_free(pp);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul></li></ul><h5 id="回收物理页面page_free函数">回收物理页面：<code>page_free</code>函数</h5><ul><li>将<code>pp</code>指向的页控制块，重新插入到<code>page_free_list</code>中头部<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">page_free</span><span class="params">(<span class="keyword">struct</span> Page *pp)</span> &#123;</span><br><span class="line">assert(pp-&gt;pp_ref == <span class="number">0</span>);</span><br><span class="line"><span class="comment">/* Just insert it into &#x27;page_free_list&#x27;. */</span></span><br><span class="line">LIST_INSERT_HEAD(&amp;page_free_list,pp,pp_link);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h2 id="虚拟内存管理">虚拟内存管理</h2><ul><li>对于<code>kseg0</code>：<code>PADDR</code>,<code>KADDR</code>完成虚拟地址和对应的物理地址的转换；</li><li>对于<code>kuseg</code>：两级页表结构完成地址转换。</li></ul><h3 id="两级页表结构">两级页表结构</h3><p><img src="/posts/34b35821/image-1.png" alt="alt text"> &gt;两个宏以快速获取偏移量：<code>PDX(va)</code>可以获取虚拟地址<code>va</code>的31-22位，<code>PTX(va)</code>可以获取虚拟地址 <code>va</code> 的21-12 位。 &gt; <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> PDSHIFT 22</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> PDX(va) ((((u_long)(va)) &gt;&gt; PDSHIFT) &amp; 0x03FF)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> PGSHIFT 12</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> PTX(va) ((((u_long)(va)) &gt;&gt; PGSHIFT) &amp; 0x03FF)</span></span><br></pre></td></tr></table></figure></p><p>每个页表均由1024个页表项组成；每个页表项由32位组成：包括20位物理页号以及12位标志位。* 12位标志位包含高6位硬件标志位，与低6位软件标志位： *高6位硬件标志位：存入EntryLo寄存器中，供硬件使用（例如标志位<code>PTE_V</code>、<code>PTE_D</code>就分别对应 EntryLo 中的 V、D 标志位）； * 低6位软件标志位：不会被存入TLB 中，仅供软件使用（例如标志位PTE_COW、PTE_LIBRARY不对应任何硬件标志位，仅在页表的部分操作中被操作系统软件利用）。</p><blockquote><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// ⻚表项的物理⻚号部分:31~12位,也即:物理⻚基地址</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> PTE_ADDR(pte) (((u_long)(pte)) &amp; ~0xFFF)</span></span><br><span class="line"> <span class="comment">// ⻚表项的权限位部分:11~0位</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> PTE_FLAGS(pte) (((u_long)(pte)) &amp; 0xFFF)</span></span><br></pre></td></tr></table></figure></blockquote><blockquote><p>常用权限位： *<code>PTE_V</code>：有效位，若某页表项的有效位为1，则该页表项有效，其中高20位是对应的物理页号；*<code>PTE_D</code>：可写位，若某页表项的可写位为1，则允许经由该页表项对物理页进行<strong>写操作</strong>；*<code>PTE_C_CACHEABLE</code>：可缓存位，配置对应页面的访问属性为可缓存（通常对于所有物理页面，都将其配置为可缓存，以允许CPU使用cache加速对这些页面的访存请求）* <code>PTE_G</code>：全局位，若某页表项的全局位为1，则<strong>TLB仅通过虚页号匹配页表项，而不匹配ASID</strong>（Lab3 中，用于映射 pages 和 envs 到用户空间） *<code>PTE_COW</code>：写时复制位（在 Lab4 中用到，用于实现 fork的写时复制机制） * <code>PTE_LIBRARY</code>：共享页面位</p></blockquote><h3 id="页表相关函数">页表相关函数</h3><h4 id="二级页表检索函数pgdir_walk函数">二级页表检索函数：<code>pgdir_walk</code>函数</h4><ul><li>给定⼀个虚拟地址<code>va</code> ,在⼀级页表基地址<code>pgdir</code>指向的页⽬录中，查找该虚拟地址<code>va</code>对应的二级页表项,将其地址写⼊<code>*ppte</code>.<ul><li>如果<code>create</code>不为0，且对应的二级页表不存在：使用<code>page_alloc</code>函数分配一页物理内存，用于存放二级页表；如果分配失败则返回错误码</li></ul></li><li>过程：找到⼀级页表项-&gt;读出物理页号，找到⼆级页表基地址-&gt;找到⼆级页表项<img src="/posts/34b35821/image-2.png"> <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">static</span> <span class="type">int</span> <span class="title function_">pgdir_walk</span><span class="params">(Pde *pgdir, u_long va, <span class="type">int</span> create, Pte **ppte)</span> &#123;</span><br><span class="line">Pde *pgdir_entryp;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Page</span> *<span class="title">pp</span>;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//1.pgdir_entryp指向va对应的⼀级⻚表项:</span></span><br><span class="line"><span class="comment">//pgdir为⼀级⻚表基地址，PDX(va)为⼀级⻚表偏移量</span></span><br><span class="line"><span class="comment">//*pgdir_entryp为⻚表项内容(32位：20位物理⻚号+12位权限位）</span></span><br><span class="line">pgdir_entryp=pgdir+PDX(va);</span><br><span class="line"></span><br><span class="line"> <span class="comment">//2.处理对应⼀级⻚表项⽆效的情况:</span></span><br><span class="line"> <span class="comment">//int page_alloc(struct Page **new)     //申请空闲的物理⻚块，其地址存⼊new.</span></span><br><span class="line"><span class="keyword">if</span>(!(*pgdir_entryp &amp; PTE_V))&#123;<span class="comment">//对应⼆级⻚表不存在/有效位为0.</span></span><br><span class="line"><span class="keyword">if</span>(create)&#123;</span><br><span class="line"><span class="keyword">if</span>(page_alloc(&amp;pp)==-E_NO_MEM)&#123;<span class="comment">//pp指向分配的空闲⻚控制块</span></span><br><span class="line"><span class="comment">//分配空闲物理⻚失败，超出内存</span></span><br><span class="line">*ppte=<span class="literal">NULL</span>;</span><br><span class="line"><span class="keyword">return</span> -E_NO_MEM;</span><br><span class="line">&#125;</span><br><span class="line">pp-&gt;pp_ref++;<span class="comment">//申请到的物理⻚的引⽤次数+1</span></span><br><span class="line"><span class="comment">//更新⼀级⻚表项pgdir_entryp:</span></span><br><span class="line"><span class="comment">//page2pa(pp)获得:⻚控制块pp对应物理基地址</span></span><br><span class="line">*pgdir_entryp=page2pa(pp) | PTE_C_CACHEABLE | PTE_V;</span><br><span class="line">&#125;<span class="keyword">else</span>&#123;</span><br><span class="line">*ppte=<span class="literal">NULL</span>;<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//3.将⼆级⻚表项的虚拟地址，写⼊*ppte</span></span><br><span class="line"><span class="comment">//⼆级⻚表基地址：PTE_ADDR(*pgdir_entryp)；PTX(va)为⼆级⻚表偏移量</span></span><br><span class="line"><span class="comment">//(⻚表在内核kseg0中,⽤KADDR转为虚拟地址)</span></span><br><span class="line">*ppte=(Pte *)KADDR(PTE_ADDR(*pgdir_entryp)+PTX(va)*<span class="number">4</span>);</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h4 id="增加地址映射函数pgdir_insert函数">增加地址映射函数：<code>pgdir_insert</code>函数</h4><ul><li>给定⼀个虚拟地址<code>va</code>，在⼀级页表基地址<code>pgdir</code>指向的⻚⽬录中，<strong>将虚拟地址<code>va</code>映射⾄页控制块<code>pp</code>对应的物理页面</strong>。<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">page_insert</span><span class="params">(Pde *pgdir, u_int asid, <span class="keyword">struct</span> Page *pp, u_long va, u_int perm)</span> &#123;</span><br><span class="line">Pte *pte;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1.获取va对应的⼆级⻚表项</span></span><br><span class="line"><span class="comment">// [1]检查是否va已经存在映射?</span></span><br><span class="line">pgdir_walk(pgdir, va, <span class="number">0</span>, &amp;pte);<span class="comment">// 不存在,返回NULL;存在,*pte为该虚拟地址对应的⼆级⻚表项</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (pte &amp;&amp; (*pte &amp; PTE_V)) &#123;<span class="comment">// 存在且有效</span></span><br><span class="line"><span class="comment">// [2]现有映射的⻚，和待插⼊的⻚，是否⼀致？</span></span><br><span class="line"><span class="comment">//*(&amp;pte)=pte⾥存储⼆级⻚表项的地址，pte为(Pte *)类型，*pte为⼆级⻚表项内容</span></span><br><span class="line"><span class="comment">//pa2page()由⼆级⻚表项内容,找到pages中对应的⻚控制块</span></span><br><span class="line"><span class="keyword">if</span> (pa2page(*pte) != pp) &#123;</span><br><span class="line">page_remove(pgdir, asid, va);<span class="comment">//不⼀样，移除现有映射</span></span><br><span class="line">&#125; <span class="keyword">else</span> &#123;<span class="comment">//⼀样：更新映射的权限位</span></span><br><span class="line">tlb_invalidate(asid, va);<span class="comment">//(1)删掉TLB中缓存的⻚表项</span></span><br><span class="line">*pte = page2pa(pp) | perm | PTE_C_CACHEABLE | PTE_V;</span><br><span class="line"><span class="comment">//(2)更新内存中的⻚表项：下次加载va所在⻚时，TLB从⻚表中加载该项</span></span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2. 删掉TLB中缓存的va对应⻚表项</span></span><br><span class="line">tlb_invalidate(asid,va);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 3. 重新获取/申请va对应的⼆级⻚表项pte</span></span><br><span class="line"><span class="keyword">if</span>(pgdir_walk(pgdir,va,<span class="number">1</span>,&amp;pte)==-E_NO_MEM)&#123;</span><br><span class="line"><span class="comment">//create=1,允许申请新的页控制块,将va对应的二级页表项地址存入pte</span></span><br><span class="line"><span class="keyword">return</span> -E_NO_MEM;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 4. 填写二级页表项:物理页号(由新映射的pp页控制块决定)+权限位</span></span><br><span class="line">*pte=page2pa(pp)| perm | PTE_C_CACHEABLE | PTE_V;</span><br><span class="line">pp-&gt;pp_ref++;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h4 id="寻找映射的物理地址函数page_lookup函数">寻找映射的物理地址函数：<code>page_lookup</code>函数</h4><ul><li>在⼀级⻚表基地址<code>pgdir</code>指向的页⽬录中，返回虚拟地址<code>va</code> 映射的物理页面的页控制块；将<code>ppte</code>指向的页表项内容，设为对应的二级页表项地址。 <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> Page *<span class="title function_">page_lookup</span><span class="params">(Pde *pgdir, u_long va, Pte **ppte)</span> &#123;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Page</span> *<span class="title">pp</span>;</span></span><br><span class="line">Pte *pte;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1. 寻找是否存在这一页表项？</span></span><br><span class="line">pgdir_walk(pgdir, va, <span class="number">0</span>, &amp;pte);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 若页表项不存在或无效：返回空指针</span></span><br><span class="line"><span class="keyword">if</span> (pte == <span class="literal">NULL</span> || (*pte &amp; PTE_V) == <span class="number">0</span>) &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 获取页表项*pte对应页控制块pp</span></span><br><span class="line">pp = pa2page(*pte);</span><br><span class="line"><span class="keyword">if</span> (ppte) &#123;</span><br><span class="line">*ppte = pte;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> pp;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h4 id="取消地址映射函数page_remove函数">取消地址映射函数：<code>page_remove</code>函数</h4><ul><li>在⼀级⻚表基地址<code>pgdir</code>指向的页⽬录中，删除<code>va</code>虚拟地址va对物理地址的映射。<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">page_remove</span><span class="params">(Pde *pgdir, u_int asid, u_long va)</span> &#123;</span><br><span class="line">Pte *pte;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1. 查找va对应的页控制块：如果查找失败，说明不存在这一映射，在这一映射，</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Page</span> *<span class="title">pp</span> =</span> page_lookup(pgdir, va, &amp;pte);</span><br><span class="line"><span class="keyword">if</span> (pp == <span class="literal">NULL</span>) &#123;</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2. 查找成功，则解除其被va的映射</span></span><br><span class="line">page_decref(pp);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 清空对应的二级页表项，和该映射在TLB中的缓存</span></span><br><span class="line">*pte = <span class="number">0</span>;</span><br><span class="line">tlb_invalidate(asid, va);</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><blockquote><p>补充：<code>include/pmap.h</code>中定义的地址和页控制块转换函数：<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">extern</span> <span class="class"><span class="keyword">struct</span> <span class="title">Page</span> *<span class="title">pages</span>;</span></span><br><span class="line"><span class="keyword">extern</span> <span class="class"><span class="keyword">struct</span> <span class="title">Page_list</span> <span class="title">page_free_list</span>;</span></span><br><span class="line"><span class="comment">// 页表项pp的物理页号：</span></span><br><span class="line"><span class="type">static</span> <span class="keyword">inline</span> u_long <span class="title function_">page2ppn</span><span class="params">(<span class="keyword">struct</span> Page *pp)</span> &#123;</span><br><span class="line"><span class="keyword">return</span> pp - pages;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 页控制块pp,对应物理⻚的基地址:（填充pte常⽤）</span></span><br><span class="line"><span class="comment">// 获取物理页号page2ppn(pp),左移12位</span></span><br><span class="line"><span class="type">static</span> <span class="keyword">inline</span> u_long <span class="title function_">page2pa</span><span class="params">(<span class="keyword">struct</span> Page *pp)</span> &#123;</span><br><span class="line"><span class="keyword">return</span> page2ppn(pp) &lt;&lt; PGSHIFT;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 获取物理地址pa,对应页控制块:（读取pte）</span></span><br><span class="line"><span class="type">static</span> <span class="keyword">inline</span> <span class="keyword">struct</span> Page *<span class="title function_">pa2page</span><span class="params">(u_long pa)</span> &#123;</span><br><span class="line"><span class="comment">// 物理页号PPN(pa)</span></span><br><span class="line"><span class="keyword">if</span> (PPN(pa) &gt;= npage) &#123;</span><br><span class="line">panic(<span class="string">&quot;pa2page called with invalid pa: %x&quot;</span>, pa);</span><br><span class="line">&#125;</span><br><span class="line"> <span class="keyword">return</span> &amp;pages[PPN(pa)];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 页控制块pp,对应物理页虚拟地址</span></span><br><span class="line"><span class="type">static</span> <span class="keyword">inline</span> u_long <span class="title function_">page2kva</span><span class="params">(<span class="keyword">struct</span> Page *pp)</span> &#123;</span><br><span class="line"><span class="comment">// KADDR:物理地址-&gt;虚拟地址</span></span><br><span class="line"><span class="keyword">return</span> KADDR(page2pa(pp));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 虚拟地址va,对应物理⻚地址pa</span></span><br><span class="line"><span class="type">static</span> <span class="keyword">inline</span> u_long <span class="title function_">va2pa</span><span class="params">(Pde *pgdir, u_long va)</span> &#123;</span><br><span class="line">Pte *p;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1. pgdir更新为:指向对应一级页表项</span></span><br><span class="line"><span class="comment">//pgdir指向页目录基地址,PDX(va)为一级页表偏移量</span></span><br><span class="line">pgdir = &amp;pgdir[PDX(va)];<span class="comment">//或写为:pgdir=pgdir+PDX(va);</span></span><br><span class="line"><span class="keyword">if</span> (!(*pgdir &amp; PTE_V)) &#123;<span class="comment">//检查⻚表项是否有效(是否映射⾄物理⻚)</span></span><br><span class="line"><span class="keyword">return</span> ~<span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2. p指向二级页表基地址:</span></span><br><span class="line"><span class="comment">// PTE_ADDR(*pgdir)获取物理⻚基地址;KADDR(pa)转为虚拟地址</span></span><br><span class="line"><span class="comment">//KADDR(pa)转为虚拟地址</span></span><br><span class="line">p = (Pte *)KADDR(PTE_ADDR(*pgdir));</span><br><span class="line"><span class="keyword">if</span> (!(p[PTX(va)] &amp; PTE_V)) &#123;</span><br><span class="line"><span class="keyword">return</span> ~<span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 3. p[PTX(va)]指向va对应的二级页表项,获取物理页地址</span></span><br><span class="line"><span class="comment">// PTX(va)为⼆级页表偏移量</span></span><br><span class="line"><span class="keyword">return</span> PTE_ADDR(p[PTX(va)]);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></blockquote><h2 id="访问内存与tlb重填">访问内存与TLB重填</h2><p>在<code>4Kc</code>中，TLB由⼀组Key +两组Data 组成。</p><ul><li>映射：<code>&lt; VPN, ASID &gt;</code> TLB−−−→<code>&lt; PFN, N, D, V, G &gt;</code></li></ul><ol type="1"><li>TLB 采⽤奇偶⻚的设计，即使⽤ VPN 中的⾼ 19 位与 ASID 作为Key，⼀次查找到两个Data （⼀对相邻⻚⾯的两个⻚表项）；</li><li>⽤ VPN 中的最低 1 位在两个 Data 中选择命中的结果。 &gt;在对TLB进行维护（无效化、重填）时，除了维护目标页面，同时还需要维护目标页面的邻居页面。</li></ol><h3 id="tlb组成">TLB组成</h3><p><img src="/posts/34b35821/image-3.png"></p><ul><li>Key（EntryHi）：<ul><li>VPN：Virtual Page Number<ul><li>当 <strong>TLB 缺失</strong>（CPU 发出虚拟地址，TLB查找对应物理地址但未查到）时，<strong>EntryHi 中的 VPN自动（由硬件）填充为对应虚拟地址的虚页号</strong>。</li><li>当需要填充或检索TLB表项时，软件需要将VPN段填充为对应的虚拟地址。</li></ul></li><li>ASID：Address Space IDentifier<ul><li>用于区分不同的地址空间。<strong>查找TLB表项时，除了需要提供VPN，还需要提供ASID</strong>（同一虚拟地址在不同的地址空间中通常映射到不同的物理地址）。</li></ul></li></ul></li><li>Data（EntryLo）：<ul><li>PFN：Physical Frame Number<ul><li><strong>软件通过填写PFN，接着使用TLB写指令，才可以将此时EntryHi中的Key与EntryLo中的 Data 写入 TLB</strong>。</li></ul></li><li>C：Cache Coherency Attributes 标识页面的 cache访问属性。PTE_C_CACHEABLE 与PTE_C_UNCACHEABLE 宏可用于填充该段。</li><li>D：Dirty。事实上是可写位。当该位为1时，对应的页可写；否则对相应页的任何写操作都将引发TLB异常。</li><li>V：Valid。如果该位为 0，则任何访问对应页的操作都将引发TLB异常。</li><li>G：Global。如果该位为1，则CPU发出的虚拟地址只需要与该表项的VPN匹配，即可与此TLB项匹配成功（不需要检查ASID是否匹配）。</li></ul></li></ul><blockquote><p>ASID的必要性： ASID(Address SpaceIdentifier)是地址空间标识符，⽤于在多进程操作系统中<strong>标识不同进程的虚拟地址空间</strong>。</p><ul><li>隔离不同进程的地址空间：在多进程环境中，每个进程有相互独⽴的虚拟地址空间，通过ASID进行隔离；</li><li>避免TLB污染：当多个进程共享同⼀个TLB时，若⽆ASID区分，可能出现⼀个进程的地址翻译结果覆盖另⼀个进程的翻译结果的情况，即所谓的“TLB污染”，导致错误的内存访问。通过ASID，操作系统可以将每个进程的地址翻译结果分别存储在TLB中，避免了这种污染。</li><li>优化性能：当进程切换时，操作系统可以通过ASID，清除或标记与当前进程⽆关的TLB条⽬，确保当前进程快速获取其地址翻译结果。</li></ul><p>在<code>MIPS 4Kc</code>中，ASID字段的位数通常是 8 位。这意味着可以有<span class="math inline">\(2^8=256\)</span>个不同的ASID。但是由于TLB的大小是固定的，因此可以容纳的不同地址空间的最大数量受到TLB的大小限制。MIPS4Kc中的TLB共有 <span class="math inline">\(64\)</span>个条目。每个TLB条目可以映射一个虚拟地址到一个物理地址。</p><p>因此即使ASID有 <span class="math inline">\(256\)</span>个不同的取值，但实际上，<code>MIPS 4Kc</code>可以同时支持的不同地址空间的最大数量仍然是<span class="math inline">\(64\)</span> 个。</p></blockquote><h3 id="tlb维护流程">TLB维护流程</h3><ol type="1"><li>更新页表中虚拟地址对应的页表项的同时，将TLB中对应的旧表项无效化；</li><li>在下一次访问该虚拟地址时，硬件会触发TLB重填异常，此时操作系统对TLB进行重填。</li></ol><h4 id="tlb旧表项无效化tlb_invalidate函数">TLB旧表项无效化：<code>tlb_invalidate</code>函数</h4><p><img src="/posts/34b35821/image-4.png"> <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//⽣成⼀个从 l（低位）到 h（⾼位）的位掩码:</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> GENMASK(h, l) (((~0UL) <span class="string">&lt;&lt; (l)) &amp; (~0UL &gt;</span>&gt; (BITS_PER_LONG - 1 - (h))))</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> NASID 256</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//TLB旧表项⽆效化:删除进程asid对应的虚拟地址va,在TLB中的旧表项</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">tlb_invalidate</span><span class="params">(u_int asid, u_long va)</span> &#123;</span><br><span class="line"><span class="comment">//(va &amp; ~GENMASK(PGSHIFT, 0)) :将va的低PGSHIFT位清零</span></span><br><span class="line"><span class="comment">//(NASID - 1)⽣成⼀个位掩码，⽤于确保asid的值在有效范围内(0~255)</span></span><br><span class="line"> <span class="comment">//新的Entryhi值：VPN+ASID</span></span><br><span class="line">tlb_out((va &amp; ~GENMASK(PGSHIFT, <span class="number">0</span>)) | (asid &amp; (NASID - <span class="number">1</span>)));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p><code>tlb_invalidate</code>函数调用MIPS汇编文件<code>tlb_asm.S</code> 中的叶函数 <code>tlb_out</code>： &gt;因流水线设计架构原因，<code>tlbp</code>指令的前后都应各插入一个<code>nop</code>以解决数据冒险。<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">LEAF(tlb_out)       </span><br><span class="line"><span class="comment">/* 关闭MIPS汇编器的指令重排优化，确保指令按特定顺序执⾏ */</span></span><br><span class="line">.<span class="built_in">set</span> noreorder      </span><br><span class="line"><span class="comment">/* 将协处理器 0 中寄存器 CP0_ENTRYHI 中的数据写入到通用寄存器 t0 中  */</span></span><br><span class="line">mfc0    t0, CP0_ENTRYHI    </span><br><span class="line"><span class="comment">/* 将通用寄存器 a0（旧表项的Key：即VPN+ASID） 中的数据写入到协处理器 0 中寄存器 CP0_ENTRYHI 中 */</span></span><br><span class="line">mtc0    a0, CP0_ENTRYHI    </span><br><span class="line"><span class="comment">/* 添加空指令避免数据冲突 */</span></span><br><span class="line">nop</span><br><span class="line"></span><br><span class="line"><span class="comment">/* 根据 EntryHi 中的 Key 查找对应的旧表项，将表项的索引存⼊ Index */</span></span><br><span class="line">tlbp       </span><br><span class="line">nop</span><br><span class="line"></span><br><span class="line"><span class="comment">/* 将协处理器 0 中寄存器 CP0_INDEX 中的数据写入到通用寄存器 t1 中 */</span></span><br><span class="line">mfc0    t1, CP0_INDEX      </span><br><span class="line"></span><br><span class="line"><span class="comment">/* 告诉汇编器恢复对指令的重新排序 */</span></span><br><span class="line">.<span class="built_in">set</span> reorder</span><br><span class="line"><span class="comment">/* 检查TLB查询效果是否无效：若t1&lt;0,跳转⾄NO_SUCH_ENTRY标签处 */</span></span><br><span class="line">bltz    t1, NO_SUCH_ENTRY  </span><br><span class="line"><span class="comment">/* 告诉汇编器禁止对指令重新排序 */</span></span><br><span class="line">.<span class="built_in">set</span> noreorder</span><br><span class="line">    <span class="comment">/* 如果t1&gt;0(TLB中存在Key对应的表项),清除TLB条⽬: 将CP0_ENTRYHI,CP0_ENTRYLO0,CP0_ENTRYLO1置0. */</span> </span><br><span class="line">mtc0    zero, CP0_ENTRYHI</span><br><span class="line">mtc0    zero, CP0_ENTRYLO0</span><br><span class="line">mtc0    zero, CP0_ENTRYLO1</span><br><span class="line">nop</span><br><span class="line"></span><br><span class="line"><span class="comment">/* 以 Index 寄存器中的值为索引将 EntryHi 与 EntryLo 中的数据写入到 TLB 中对应表项 */</span></span><br><span class="line">tlbwi      </span><br><span class="line">.<span class="built_in">set</span> reorder</span><br><span class="line">NO_SUCH_ENTRY:</span><br><span class="line"><span class="comment">/* 将通用寄存器 t0 的内容（原始ENTRYHI值）写回到协处理器 0 中的寄存器 CP0_ENTRYHI 中 */</span></span><br><span class="line">mtc0    t0, CP0_ENTRYHI    </span><br><span class="line"><span class="comment">/* 跳转回ra（返回地址）寄存器指定的地址 */</span></span><br><span class="line">j       ra             </span><br><span class="line"><span class="title function_">END</span><span class="params">(tlb_out)</span></span><br></pre></td></tr></table></figure></p><h4 id="tlb重填do_tlb_refill函数">TLB重填：<code>do_tlb_refill</code>函数</h4><p>由于<code>4Kc</code>中存在的奇偶页设计，该过程需重填触发异常的页面，及其邻居页面。将两个页面对应的页表项先写入EntryLo寄存器，再填入TLB。<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">NESTED(do_tlb_refill, <span class="number">24</span>, zero)</span><br><span class="line"><span class="comment">/* 读取异常相关寄存器:</span></span><br><span class="line"><span class="comment">CP0_BADVADDR：存储了发生 TLB 缺失异常时访问的虚拟地址（即导致异常的地址）；</span></span><br><span class="line"><span class="comment">CP0_ENTRYHI：存储了 TLB 匹配的高位部分，包括虚拟页号（VPN）和 ASID */</span></span><br><span class="line">mfc0    a1, CP0_BADVADDR</span><br><span class="line">mfc0    a2, CP0_ENTRYHI</span><br><span class="line">andi    a2, a2, <span class="number">0xff</span> <span class="comment">/* CP0_ENTRYHI 的低 8 位存储 ASID */</span></span><br><span class="line">.globl do_tlb_refill_call;</span><br><span class="line">do_tlb_refill_call:</span><br><span class="line"><span class="comment">/* addi sp, sp, -24：在栈上分配 24 字节空间，用于存储：</span></span><br><span class="line"><span class="comment">3 个参数（Pte *, u_int, u_int）</span></span><br><span class="line"><span class="comment">2 个返回值（偶页表项、奇页表项）</span></span><br><span class="line"><span class="comment">1 个返回地址（ra）*/</span></span><br><span class="line">addi    sp, sp, <span class="number">-24</span> </span><br><span class="line"><span class="comment">/* 保存当前函数的返回地址 ra */</span></span><br><span class="line">sw      ra, <span class="number">20</span>(sp) </span><br><span class="line"><span class="comment">/* a0 传递 sp + 12 的地址，_do_tlb_refill 会将返回值存储到 sp+12 及 sp+16 */</span></span><br><span class="line">addi    a0, sp, <span class="number">12</span> </span><br><span class="line"><span class="comment">/* 调用 _do_tlb_refill 函数，该函数负责查找触发异常的地址对应的页表项 */</span></span><br><span class="line">jal     _do_tlb_refill </span><br><span class="line"><span class="comment">/* 取回 _do_tlb_refill 返回的页表项：取出偶数页表项到 a0，奇数页表项到 a1 */</span></span><br><span class="line">lw      a0, <span class="number">12</span>(sp) </span><br><span class="line">lw      a1, <span class="number">16</span>(sp) </span><br><span class="line"><span class="comment">/* 恢复 ra */</span></span><br><span class="line">lw      ra, <span class="number">20</span>(sp) </span><br><span class="line"><span class="comment">/* 释放栈空间，恢复 sp */</span></span><br><span class="line">addi    sp, sp, <span class="number">24</span> </span><br><span class="line"><span class="comment">/* 将寄存器值写入 CP0 */</span></span><br><span class="line">mtc0    a0, CP0_ENTRYLO0 </span><br><span class="line">mtc0    a1, CP0_ENTRYLO1 </span><br><span class="line">nop</span><br><span class="line"><span class="comment">/* 随机选择一个 TLB 表项，并将 CP0_ENTRYHI、CP0_ENTRYLO0 和 CP0_ENTRYLO1 的值写入 TLB */</span></span><br><span class="line">tlbwr</span><br><span class="line">jr      ra</span><br><span class="line"><span class="title function_">END</span><span class="params">(do_tlb_refill)</span></span><br></pre></td></tr></table></figure></p><p>预留参数和返回值空间后，调用<code>_do_tlb_refill</code>函数：根据虚拟地址和ASID查找页表，将对应的奇偶页表项写回其第一个参数所指定的地址。<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> _do_tlb_refill(u_long *pentrylo, u_int va, u_int asid) &#123;</span><br><span class="line">tlb_invalidate(asid, va);</span><br><span class="line">Pte *ppte;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* 调用&#x27;page_lookup&#x27;以查找虚拟地址va，在当前进程页表中对应的页表项&#x27;*ppte&#x27;：</span></span><br><span class="line"><span class="comment">1. 如果&#x27;page_lookup&#x27;返回&#x27;NULL&#x27;，表明&#x27;*ppte&#x27;找不到，使用&#x27;passive_alloc&#x27;为va所在的虚拟页面分配物理页面，直至&#x27;page_lookup&#x27;返回不为&#x27;NULL&#x27;则退出循环。 */</span> </span><br><span class="line"><span class="keyword">while</span>(page_lookup(cur_pgdir,va,&amp;ppte)==<span class="literal">NULL</span>)&#123;</span><br><span class="line">passive_alloc(va,cur_pgdir,asid);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">ppte = (Pte *)((u_long)ppte &amp; ~<span class="number">0x7</span>);</span><br><span class="line">pentrylo[<span class="number">0</span>] = ppte[<span class="number">0</span>] &gt;&gt; <span class="number">6</span>;</span><br><span class="line">pentrylo[<span class="number">1</span>] = ppte[<span class="number">1</span>] &gt;&gt; <span class="number">6</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="总流程图">总流程图</h2><p><img src="/posts/34b35821/image-5.png"></p><p>内存管理部分已经完成啦！下一个Lab，将实现进程调度和中断异常处理。</p>]]></content>
      
      
      <categories>
          
          <category> OS </category>
          
          <category> BUAA OS lab </category>
          
      </categories>
      
      
        <tags>
            
            <tag> C </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CMU 14-445 Project#0(2024 Fall) C++ Primer</title>
      <link href="/posts/428c6b54.html"/>
      <url>/posts/428c6b54.html</url>
      
        <content type="html"><![CDATA[<h1 id="lab0-c-primerprimer">Lab0 C++ PrimerPrimer</h1><h2 id="写在开头">写在开头</h2><p>首先致谢CMU-db无私将这门质量极高、资源极齐全的数据库课程，以及相关基础设施（GradeScope,Discord）和课程资料（Lectures, Notes,Homework）完全开源,让一个在本科数据库课程上只学会了抽象理念和SQL语句的孩子，能踏上一条自学之路（手动狗头）其次,感谢<a href="https://csdiy.wiki/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/15445/">CS自学指南</a>,将计算机领域的众多好课分享给我们.</p><p>本专题将详尽地记录2024 Fall对应Lecture和Lab的学习经历.</p><h3 id="课程链接">课程链接</h3><p><strong>课程主页</strong>:<a href="https://15445.courses.cs.cmu.edu/fall2024/">https://15445.courses.cs.cmu.edu/fall2024/</a><strong>Discord</strong>:<a href="https://discord.com/channels/724929902075445281/752529819148877904">https://discord.com/channels/724929902075445281/752529819148877904</a><strong>Gradescope</strong>:<a href="https://www.gradescope.com/courses/817458">https://www.gradescope.com/courses/817458</a>Entry Code: <code>WWWJZ5</code> (学校记得改成CMU) &gt; In exchange formaking this available to the public, we ask that you DO NOT make yourproject implementations public on Github or other source coderepositories.</p><p><strong>让我们开始吧.</strong></p><p>本篇博客记录Lab概览和<code>Project #0</code>.</p><h3 id="lab概览">Lab概览</h3><blockquote><p>以下摘自CS指南:</p></blockquote><p>这门课的亮点在于 <code>CMU Database Group</code>专门为此课开发了一个教学用的关系型数据库<code>bustub</code>，并要求你对这个数据库的组成部分进行修改，实现上述部件的功能。</p><p>具体来说，在 <code>15-445</code> 中,你需要在四个 <code>Project</code>的推进中，实现一个面向磁盘的传统关系型数据库 Bustub中的部分关键组件。</p><p>包括 <code>Buffer Pool Manager</code> (内存管理),<code>B Plus Tree</code> (存储引擎),<code>Query Executors &amp; Query Optimizer</code> (算子们 &amp;优化器), <code>Concurrency Control</code> (并发控制)，分别对应<code>Project #1</code> 到 <code>Project #4</code>。</p><p>值得一提的是，同学们在实现的过程中可以通过 <code>shell.cpp</code>编译出 <code>bustub-shell</code>来实时地观测自己实现部件的正确与否，正反馈非常足。</p><p>此外 <code>bustub</code> 作为一个 <code>C++</code>编写的中小型项目涵盖了程序构建、代码规范、单元测试等众多要求，可以作为一个优秀的开源项目学习。</p><p>本篇从<code>Project #0</code>开始.</p><h3 id="project-0-2024-fall">Project #0 (2024 Fall)</h3><p>2024Fall的预实验,集中于理解和实现一个基于概率统计的<strong>大数据基数统计</strong>算法--HyperLoglog;在此过程中,熟悉<code>C++</code>的基本应用.</p><p><code>C++</code>的基本知识可见以下两篇博客: <a href="/post1/">C++中的引用、移动语义、模板、包装类、迭代器和命名空间</a><a href="/post2/">C++标准库：容器、动态内存、同步原语</a></p><p>我们从HyperLogLog的算法理论开始.</p><h4 id="hyperloglog算法">HyperLogLog算法</h4><h5 id="什么情景产生了hyperloglog">什么情景产生了HyperLogLog？</h5><p>假设您有一个大型元素数据集，其中包含从一组基数 n中选择的重复条目，并且想要查找n，即<strong>基数（不同元素的数量）</strong>。例如，我们希望计算在给定的一周内访问过Facebook的不同用户数量，其中每个人每天登录多次。这将产生<strong>具有许多重复项的大型数据集</strong>。显而易见的方法（例如对元素进行排序，或简单地维护所看到的唯一元素集）是不切实际的，因为它们要么计算量太大，要么需要太多内存。如何处理呢？让我们逐步思考：</p><h5 id="一个简单的估计器">一个简单的估计器</h5><p>我们需要一个输出估计值的算法（误差在合理范围内）。首先，生成一个具有重复条目的假设数据集如下：1. 生成 n 个均匀分布在 0 和 1 之间的数字； 2.将一些数字随机复制任意次数； 3. 对上述数据集，随机排序。使用哈希函数（哈希值被规范化并在 0 和 1之间均匀分布），设最小的哈希值为<span class="math inline">\(y_{min}=hash(x)\)</span>，<strong>将唯一条目的数量估计为1/y_{min}.</strong><img src="/posts/428c6b54/image-4.png">然而，估计结果依赖于最小哈希值，而最小哈希值可能恰好太小，从而夸大了我们的估计。因此该方法具有高度可变性。</p><h5 id="概率计数">概率计数</h5><p>为了减少之前方法中的高可变性，我们可以通过<strong>计算哈希值二进制表示中，开头的零位数</strong>来改进。<img src="/posts/428c6b54/image-5.png"> 平均而言，每<span class="math inline">\(2^k\)</span>个不同条目，将出现<span class="math inline">\(k\)</span>个连续的零序列，因此转为记录：最长的连续零序列的长度。即：</p><p>集合{<span class="math inline">\({x_1,...,x_M}\)</span>}的基数为<span class="math inline">\(2^R\)</span>，其中：<span class="math inline">\(R=max\)</span>{<span class="math inline">\(\rho(x_1),...,\rho(x_M)\)</span>}，<span class="math inline">\(\rho(x_1)\)</span>为<span class="math inline">\(hash(x_i)\)</span>的二进制表示中，前导0的数目。</p><p>此方法有两个缺点： 1. 只能提供基数的 2的幂估计，即结果只可能是：1，2，4，8，... 2.如果恰巧遇到一个有太多连续前导0的条目，将产生极不准确的基数估计。</p><h5 id="提高准确性loglog采用多个估计量">提高准确性：LogLog，采用多个估计量</h5><p>上一个方法中，只采用了一个估计量，即：最大连续前导零数。为了改进，我们<strong>采用多个独立估计器，并对结果取平均</strong>，以减少单个估计器的方差。<img src="/posts/428c6b54/image-6.png"> 可以通过使用<span class="math inline">\(m\)</span>个独立的哈希函数实现这点，分别计算出<span class="math inline">\(R_1,...,R_m\)</span>，取算数平均，作为<span class="math inline">\(R\)</span>的估计值。</p><p>但是该方法对于每个条目，均需计算其相对于每个哈希函数的哈希值，计算上太昂贵。能不能采用单个哈希函数解决呢？</p><p>学者们提出的一个解决方案是：<strong>使用哈希值的前k位作为桶的索引；计算剩余部分的最长连续0 序列</strong>。</p><p>如下图，假设我们传入数据的哈希值为<code>1011 011101101100000</code>。1.使用最左边的四个位<code>(k=4)</code>作为桶索引，它告诉我们要更新哪个存储桶（十进制为= 11）； 2. 在剩余部分中，获取右侧的最长连续 0序列，此时该序列长度为 5；3. 因此，使用 16 个存储桶，将存储桶编号 11 更新为值 5，如下所示。 <img src="/posts/428c6b54/image-7.png"></p><p>通过拥有<span class="math inline">\(m\)</span>个桶，我们模拟了拥有<span class="math inline">\(m\)</span>个不同哈希函数的情况。基数估计公式如下：</p><p><span class="math inline">\(CARDINALITY_{LogLog}=constant · m ·2^{\frac{1}{m}\sum_{j=1}^{N}R_j}\)</span></p><p>对于 m 个桶，这会将估计器的标准误差降低到大约 <span class="math inline">\(\frac{1.3}{\sqrt{m}}\)</span>。 &gt;对于2048个桶，每个桶5位（最多可以记录32个连续0），则足以记录高达<span class="math inline">\(2^{27}\)</span>的基数，只占用2048*5=1.2KB的内存（平均错误率大约2.8%）</p><p>更多可见以下文章: <a href="https://zhuanlan.zhihu.com/p/110364156">https://zhuanlan.zhihu.com/p/110364156</a></p><h4 id="lab整体实现思路">Lab整体实现思路</h4><p>在实际应用中，一些系统将最左侧的 1位的位置存储在寄存器中（MSB），而另一些系统则存储最右侧连续零的个数（LSB）。在这个项目中：* Task 1 采用前者;Task 2 采用后者.</p><h5 id="task-1">Task 1</h5><p><code>HyperLoglog</code>定义如下: <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** @brief Cardinality value. */</span>  </span><br><span class="line"><span class="type">size_t</span> cardinality_;</span><br><span class="line"></span><br><span class="line"><span class="comment">/** @brief Number of bits. */</span></span><br><span class="line"><span class="type">int16_t</span> num_bits_;</span><br><span class="line"></span><br><span class="line"><span class="comment">/** @brief Number of Registers. */</span></span><br><span class="line"><span class="type">uint16_t</span> num_registers_;</span><br><span class="line"></span><br><span class="line"><span class="comment">/** @brief Registers. */</span> </span><br><span class="line">std::vector&lt;<span class="type">uint64_t</span>&gt; registers_;</span><br></pre></td></tr></table></figure> *初始化<code>HyperLogLog&lt;KeyType&gt;::HyperLogLog(int16_t n_bits)</code>传入的<code>n_bits</code>是寄存器索引位数,寄存器总数为<code>2^n_bits</code>.* 将哈希值转为64位二进制表示; * 哈希值表示中: *寄存器索引:从高到底的前<code>n_bits</code>位:即<code>[BITSET_CAPACITY-num_bits_, BITSET_CAPACITY-1]</code>;*计算左侧第一个1的位置,需从:<code>BITSET_CAPACITY - num_bits_ - 1</code>开始,从高位向低位查找;*寄存器当前索引对应元素的更新逻辑:如果"左侧第一个1的位置"比当前元素大,则更新.</p><h5 id="task2-presto实现密集结构">Task2 Presto实现:密集结构</h5><p>使用两个桶,即将最右侧连续零的数量这一数据,拆成两部分存储: *<code>Dense Bucket</code>（密集桶）:一个固定大小的数组，存储最低位的几个比特（leading bits） *<code>Overflow Bucket</code>（溢出桶）:一个哈希表:键为桶索引(和密集桶索引相同),值为超出密集桶最大容量的高位比特信息，避免溢出。<img src="/posts/428c6b54/image-9.png">如上图：如果某个值的二进制表示中，右侧连续<code>0</code>的数量为<code>33</code>，其二进制形式为<code>0100001</code>。在这种情况下，会将其拆分成两部分，首先是3个<code>MSB</code>（最高有效位）<code>010</code>，接着是4个<code>LSB</code>（最低有效位）<code>0001</code>。<code>0001</code>将存储在密集桶（DenseBucket）中，而<code>MSB</code>部分<code>010</code>将存储在溢出桶（OverflowBucket）中。</p><p><code>HyperLogLogPresto</code>中定义如下: <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** @brief Capacity of the bitset stream. */</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> BITSET_CAPACITY 64</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/** @brief Dense bucket size. */</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> DENSE_BUCKET_SIZE 4</span></span><br><span class="line"><span class="comment">/** @brief Overflow bucket size. */</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> OVERFLOW_BUCKET_SIZE 3</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/** @brief Number of leading bits. */</span></span><br><span class="line"><span class="type">int16_t</span> n_leading_bits_;</span><br><span class="line"></span><br><span class="line"><span class="comment">/** @brief Number of Buckets. */</span></span><br><span class="line"><span class="type">uint16_t</span> num_buckets_;</span><br><span class="line"></span><br><span class="line"><span class="comment">/** @brief Structure holding dense buckets (or also known as registers). */</span></span><br><span class="line">std::vector&lt;std::bitset&lt;DENSE_BUCKET_SIZE&gt;&gt; dense_bucket_;</span><br><span class="line"></span><br><span class="line"><span class="comment">/** @brief Structure holding overflow buckets. */</span></span><br><span class="line">std::unordered_map&lt;<span class="type">uint16_t</span>, std::bitset&lt;OVERFLOW_BUCKET_SIZE&gt;&gt; overflow_bucket_;</span><br><span class="line"></span><br><span class="line"><span class="comment">/** @brief Storing cardinality value */</span></span><br><span class="line"><span class="type">uint64_t</span> cardinality_;</span><br></pre></td></tr></table></figure></p><p>桶中元素的更新如下: <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 如果当前的连续0数量更大：更新桶的值</span></span><br><span class="line"><span class="keyword">if</span> ((dense_bucket_[bucket_index].<span class="built_in">to_ullong</span>() + ((overflow_bucket_[bucket_index].<span class="built_in">to_ullong</span>()) &lt;&lt; <span class="number">4</span>)) &lt;</span><br><span class="line">    num_trailing_zeros) &#123;</span><br><span class="line">    <span class="function">std::bitset&lt;OVERFLOW_BUCKET_SIZE&gt; <span class="title">overflow_value</span><span class="params">(num_trailing_zeros &gt;&gt;</span></span></span><br><span class="line"><span class="params"><span class="function">                                                     DENSE_BUCKET_SIZE)</span></span>;  <span class="comment">// 取后4位之前的部分（转为二进制表示）</span></span><br><span class="line">    <span class="function">std::bitset&lt;DENSE_BUCKET_SIZE&gt; <span class="title">dense_value</span><span class="params">(num_trailing_zeros &amp;</span></span></span><br><span class="line"><span class="params"><span class="function">                                               ((<span class="number">1</span> &lt;&lt; DENSE_BUCKET_SIZE) - <span class="number">1</span>))</span></span>;  <span class="comment">// 取后4位（转为二进制表示）</span></span><br><span class="line"></span><br><span class="line">    dense_bucket_[bucket_index] = dense_value;</span><br><span class="line">    overflow_bucket_[bucket_index] = overflow_value;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h4 id="关键细节和易错点">关键细节和易错点</h4><h5 id="无符号有符号整型的处理">无符号/有符号整型的处理</h5><p>极易出错!!!疯狂踩坑(哭泣).计算<code>cardinality</code>:头文件<code>registers_</code>中声明的是<code>vector&lt;uint64_t&gt;</code>,运用其中的元素<code>reg</code>计算:<code>z += pow(2, -reg);</code></p><p>这里<code>pow(2, -reg)</code>会变成<code>inf</code>,即出现了<strong>整数下溢</strong>的bug.警惕:无符号类型不能为负!</p><p>因此应使用<code>z += 1.0/pow(2, reg);</code></p><h5 id="边界">边界</h5><ol type="1"><li>样例<code>EdgeTest1</code>测试了构造函数中传入的实参<code>n_bits</code>为负的情况:</li></ol><p>寄存器数目为负数是无意义的.因此构造函数应写为: <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HyperLogLog&lt;KeyType&gt;::<span class="built_in">HyperLogLog</span>(<span class="type">int16_t</span> n_bits) : <span class="built_in">cardinality_</span>(<span class="number">0</span>), <span class="built_in">num_bits_</span>(n_bits &gt; <span class="number">0</span> ? n_bits : <span class="number">0</span>)</span><br></pre></td></tr></table></figure></p><ol start="2" type="1"><li>样例<code>EdgeTest2</code>,<code>PrestoCase2</code>测试了<code>n_bits</code>或<code>n_leading_bits</code>为0的情况:</li></ol><p>这时寄存器数组<code>registers_</code>长度为<code>1&lt;&lt;0=1</code>,注意计算寄存器索引/桶索引时: <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int16_t</span> register_index =</span><br><span class="line">      num_bits_ == <span class="number">0</span> ? <span class="number">0</span> : <span class="built_in">static_cast</span>&lt;<span class="type">int16_t</span>&gt;((bset.<span class="built_in">to_ullong</span>()) &gt;&gt; (BITSET_CAPACITY - num_bits_));</span><br><span class="line"><span class="type">int16_t</span> bucket_index =</span><br><span class="line">      n_leading_bits_ == <span class="number">0</span> ? <span class="number">0</span> : <span class="built_in">static_cast</span>&lt;<span class="type">int16_t</span>&gt;((bset.<span class="built_in">to_ullong</span>()) &gt;&gt; (BITSET_CAPACITY - n_leading_bits_));</span><br></pre></td></tr></table></figure> <code>bset.to_ullong()</code>返回一个 <code>unsigned long long</code> 类型的值，这个类型通常是<code>64</code> 位. <code>num_bits_=0</code>时会溢出.</p><h4 id="测试提交流程">测试提交流程</h4><h5 id="本地测试">本地测试</h5><ol type="1"><li><p>创建开发环境 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">mkdir</span> build</span><br><span class="line">$ <span class="built_in">cd</span> build</span><br><span class="line">$ cmake -DCMAKE_BUILD_TYPE=Debug ..</span><br><span class="line">$ make -j`<span class="built_in">nproc</span>`</span><br></pre></td></tr></table></figure></p></li><li><p>本地测试 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> build</span><br><span class="line">$ make -j$(<span class="built_in">nproc</span>) hyperloglog_test</span><br><span class="line">$ ./test/hyperloglog_test</span><br></pre></td></tr></table></figure> <img src="/posts/428c6b54/image-10.png"></p></li></ol><h5 id="打包">打包</h5><ol type="1"><li><code>build</code>目录下输入:<code>make submit-p0</code>,生成zip文件;</li><li>到上一层目录,执行<code>python3 gradescope_sign.py</code>,生成打分文件;</li></ol><p>这里会遇到一个问题:压缩包里的内容,正常应该是用于覆盖源文件的两个<code>.h</code>文件和<code>.cpp</code>文件(即我们写的),但压缩包里似乎并不是.</p><p>此时是build打包时出了问题,我们去看看它的<code>Makefile</code>,找到<code>submit-p0</code>对应的文件路径:<img src="/posts/428c6b54/image-11.png">去<code>CMakeFiles/submit-p0.dir/build.make</code>里找到真正打包的东西,改成我们想要的:<img src="/posts/428c6b54/image-12.png"></p><h5 id="格式检查">格式检查</h5><p>这一步必须,否则不符合标准代码风格,提交到Gradescope也是0分:<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">make format</span><br><span class="line">make check-lint</span><br><span class="line">make check-clang-tidy-p0</span><br></pre></td></tr></table></figure> 记出现过的报错:</p><h6 id="变量命名readability-identifier-naming">变量命名(readability-identifier-naming)</h6><p>根据常见的 C++编码规范，变量应该使用小写字母并采用下划线分隔（即蛇形命名法）.<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">long</span> <span class="type">double</span> z = <span class="number">0.0</span>;  <span class="comment">// 将 Z 修改为 z</span></span><br><span class="line"><span class="function">std::bitset&lt;OVERFLOW_BUCKET_SIZE&gt; <span class="title">overflow_value</span><span class="params">(num_trailing_zeros &gt;&gt; <span class="number">4</span>)</span></span>;  <span class="comment">// 将 overflow_value_ 修改为 overflow_value</span></span><br></pre></td></tr></table></figure></p><h6 id="类型名重复modernize-use-auto">类型名重复(modernize-use-auto)</h6><p>原本使用了显式的类型名<code>std::bitset&lt;BITSET_CAPACITY&gt;</code>,而<code>Clang-Tidy</code> 建议使用 <code>auto</code>来简化代码,避免显式重复类型名: <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> bset = std::<span class="built_in">bitset</span>&lt;BITSET_CAPACITY&gt;(hash);  <span class="comment">// 使用 auto 来推导类型</span></span><br></pre></td></tr></table></figure></p><h6 id="register-与关键字冲突readability-identifier-naming">register与关键字冲突（readability-identifier-naming）</h6><p>在 C++ 中，<code>register</code>是一个关键字，不能作为变量名。因此，<code>register_</code>是一个不推荐的命名方式;将其修改为 <code>reg</code>: <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">long</span> <span class="type">double</span> z = <span class="number">0.0</span>;  <span class="comment">// 修改 Z 为 z</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">auto</span> &amp;reg : registers_) &#123;  <span class="comment">// 修改 register_ 为 reg</span></span><br><span class="line">    <span class="comment">// 其他代码</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="结尾">结尾</h2><p><code>Project#0</code>终于完成啦!为C++的语法特性困扰了好久,呜呜呜.</p><p>不过完成是一个好的开始,继续前进!</p>]]></content>
      
      
      <categories>
          
          <category> Database </category>
          
          <category> CMU 14-445 </category>
          
          <category> C++ Primer </category>
          
      </categories>
      
      
        <tags>
            
            <tag> C++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>C++面向对象程序设计</title>
      <link href="/posts/d43f49ad.html"/>
      <url>/posts/d43f49ad.html</url>
      
        <content type="html"><![CDATA[<p>本篇隶属C++ Primer中类设计工具专题，当前集中于面向对象程序设计。</p><h1 id="什么是面向对象编程">什么是面向对象编程？</h1><p>在面向对象编程（缩写为OOP）中，重点是创建程序定义的数据类型，<strong>这些数据类型既包含属性，也包含一组定义明确的行为</strong>。OOP中的“对象”一词，是指我们可以从此类类型中<strong>实例化</strong>的对象。面向对象编程的核心理念是：<strong>数据抽象，继承和动态绑定</strong>。</p><h2 id="继承">继承</h2><h3 id="概述">概述</h3><p><strong>基类</strong>：位于层次关系中的根部，定义所有类共同的成员变量和成员函数；<strong>派生类</strong>：通过继承自动接收基类的成员函数和成员变量；可添加想要的其他函数或成员变量。</p><ul><li><strong>类派生列表</strong>：明确指出当前派生类是从哪个基类继承而来，示例：</li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Bulk_Quote</span> : <span class="keyword">public</span> Quote&#123;<span class="comment">// Bulk_Quote继承Quote</span></span><br><span class="line"><span class="keyword">public</span>: </span><br><span class="line"><span class="function"><span class="type">double</span> <span class="title">net_price</span><span class="params">()</span> <span class="type">const</span> <span class="keyword">override</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="定义基类和派生类">定义基类和派生类</h3><h4 id="定义基类">定义基类</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Quote</span>&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line"><span class="built_in">Quote</span>()=<span class="keyword">default</span>;</span><br><span class="line"><span class="built_in">Quote</span>(cosn std::string &amp;book, <span class="type">double</span> sales_price):<span class="built_in">bookNo</span>(book),<span class="built_in">price</span>(sales_price)&#123;&#125;</span><br><span class="line"><span class="function">std::string <span class="title">isbn</span><span class="params">()</span> <span class="type">const</span> </span>&#123;<span class="keyword">return</span> bookNo;&#125;<span class="comment">// 返回给定书籍的销售总额</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">double</span> <span class="title">net_price</span><span class="params">(std::<span class="type">size_t</span> n)</span> <span class="type">const</span></span>&#123;<span class="comment">// 虚函数：派生类改写，使用不同的折扣计算方法</span></span><br><span class="line"><span class="keyword">return</span> n*price;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">virtual</span> ~<span class="built_in">Quote</span>()=<span class="keyword">default</span>;<span class="comment">// 对析构函数进行动态绑定</span></span><br><span class="line">  </span><br><span class="line">  <span class="keyword">private</span>:</span><br><span class="line">std::string bookNo;</span><br><span class="line"><span class="keyword">protected</span>:</span><br><span class="line"><span class="type">double</span> price=<span class="number">0.0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>为什么要将基类的析构函数定义为虚函数？解答：当派生类中需要回收内存时，如果析构函数不是virtual，则不会触发动态绑定，只会调用基类的析构函数（而非子类的析构函数）那么：子类资源无法正确释放，导致内存泄露</p></blockquote><h5 id="成员函数">成员函数</h5><p>基类定义成员函数时，需区分以下两种情况：</p><ol type="1"><li>派生类直接继承、不要改变的函数；（<strong>编译时</strong>解析，执行与派生类细节无关）</li><li>派生类进行覆盖的函数：定义为<strong>虚函数</strong></li></ol><ul><li><strong>运行时解析</strong>：使用基类指针/引用调用虚函数时，根据其绑定类型对象类型的不同，确定执行的版本。</li></ul><h5 id="访问权限">访问权限</h5><p>C++通过 public、protected、private三个关键字来控制成员变量和成员函数的访问权限，它们分别表示公有的、受保护的、私有的，被称为成员访问限定符。</p><ol type="1"><li><p><strong>类的内部</strong>：无论成员被声明为 public、protected还是 private，都是可以互相访问的，没有访问权限的限制。</p></li><li><p><strong>类的外部</strong>：只能通过对象访问public属性的成员，不能访问private,protected属性的成员。</p></li><li><p><strong>派生类</strong>：派生类可以访问基类的public,protected成员，不能访问private成员。</p></li></ol><h4 id="定义派生类">定义派生类</h4><h5 id="派生类构造函数">派生类构造函数</h5><p>派生类首先使用基类的构造函数，初始化其从基类继承的部分；然后按照声明的顺序，依次初始化派生类的成员。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">Bulk_quote</span>(<span class="type">const</span> std::string&amp; book, <span class="type">double</span> p, std::<span class="type">size_t</span> qty, <span class="type">double</span> disc):<span class="built_in">Quote</span>(book, p),<span class="built_in">min_qty</span>(qty), <span class="built_in">discount</span>(disc)&#123;&#125;</span><br></pre></td></tr></table></figure><p>如上例，将前两个参数传递给<code>Quote</code>的构造函数，由其初始化<code>Bulk_quote</code>的基类部分（<code>bookNo</code>和<code>price</code>两个成员）；再初始化由派生类直接定义的<code>min_qty</code>和<code>discount</code>成员。</p><h5 id="静态成员">静态成员</h5><p>如果基类定义了一个<strong>静态成员</strong>，则：整个继承体系中，<strong>只存在该成员的唯一定义</strong>；每个静态成员变量，只存在唯一实例。</p><h5 id="派生类的声明">派生类的声明</h5><p>声明包含类名，不包括派生列表（派生列表应该在定义中出现）：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Buik_quote</span>:<span class="keyword">public</span> Quote;<span class="comment">// 错误</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Bulk_quote</span>;<span class="comment">// 正确</span></span><br></pre></td></tr></table></figure><h5 id="防止继承的发生final">防止继承的发生：<code>final</code></h5><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">NoDerived</span> <span class="keyword">final</span> &#123;&#125;<span class="comment">// NoDerived不能作为基类</span></span><br></pre></td></tr></table></figure><h4 id="类型转换与继承">类型转换与继承</h4><h5 id="不存在下行的隐式类型转换但存在上行的类型转换">不存在下行的隐式类型转换（但存在上行的类型转换）</h5><ul><li>上行转换：把派⽣类的指针或引⽤，转换成基类表示</li><li>下行转换：把基类的指针或引⽤，转换为派⽣类表示</li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Quote base;</span><br><span class="line">Bulk_quote* bulkP=&amp;base;<span class="comment">// 错误</span></span><br><span class="line">Bulk_quote&amp; bulkRef=base;<span class="comment">// 错误</span></span><br></pre></td></tr></table></figure><p>即使基类指针绑定的是派生类对象，也不能执行从基类向派生类的转换：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Bulk_quote bulk;</span><br><span class="line">Quote *itemP=&amp;bulk;<span class="comment">// 基类指针绑定派生类对象</span></span><br><span class="line">Bulk_quote *bulkP=itemP;<span class="comment">//错误：也不能执行基类向派生类的转换</span></span><br></pre></td></tr></table></figure><blockquote><p>对比两种C++强制类型转换：</p><ol type="1"><li><code>static_cast</code>：<strong>没有运行时类型检查</strong><ul><li>上行转换（派生类转基类）安全</li><li>下行转换（基类转派生类）不安全：没有动态检查</li></ul></li><li><code>dynamic_cast</code>：下行转换时，具有类型检查（信息在虚函数中）的功能，⽐<code>static_cast</code>更安全。</li></ol></blockquote><h5 id="上行的自动类型转换只对指针或引用有效对对象无效">上行的自动类型转换，只对指针或引用有效（对对象无效）</h5><h3 id="虚函数">虚函数</h3><h4 id="虚函数性质">虚函数性质</h4><ol type="1"><li><p>基类声明的虚函数，在所有派生类中均为虚函数；</p></li><li><p>派生类中重写虚函数时：派生类中形参类型与该函数在基类中形参必须严格匹配。</p><blockquote><p>加了<code>override</code>说明符但形参列表不同：编译器报错</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">B</span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">f1</span><span class="params">(<span class="type">int</span>)</span> <span class="type">const</span></span>;</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">f2</span><span class="params">()</span></span>;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">f3</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">D1</span>:B&#123;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">f1</span><span class="params">(<span class="type">int</span>)</span> <span class="type">const</span> <span class="keyword">override</span></span>;<span class="comment">//正确：与B中f1匹配</span></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">f2</span><span class="params">(<span class="type">int</span>)</span> <span class="keyword">override</span></span>;<span class="comment">// 错误：形参不匹配</span></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">f3</span><span class="params">()</span> <span class="keyword">override</span></span>;<span class="comment">// 错误：f3不是虚函数</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>不加<code>override</code>说明符，函数名相同但形参列表不同：合法，不会覆盖基类中版本，视作两个独立的函数</p></blockquote></li><li><p>基类中声明为<code>final</code>的函数，派生类中不能重写：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">D2</span>:B&#123;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">f1</span><span class="params">(<span class="type">int</span>)</span> <span class="type">const</span> <span class="keyword">final</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">D3</span>:D2&#123;</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">f2</span><span class="params">()</span></span>;<span class="comment">// 正确：覆盖从B中继承的虚函数</span></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">f1</span><span class="params">(<span class="type">int</span>)</span> <span class="type">const</span></span>;<span class="comment">// 错误：D2中f1已声明为final</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>派生类强行调用基类中的虚函数版本：使用作用域运算符</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">double</span> undiscounted=baseP-&gt;Quote::<span class="built_in">net_price</span>(<span class="number">42</span>);</span><br><span class="line"><span class="comment">// 在编译时解析：无论baseP绑定的对象类型是什么，强行调用Quote的net_price版本</span></span><br></pre></td></tr></table></figure></li></ol><h4 id="虚函数的实现虚函数表">虚函数的实现：虚函数表</h4><ul><li><p><strong>虚函数表</strong>：每个类（包括抽象类）都有⼀个虚表，其中包含了该类的虚函数的地址。</p></li><li><p><strong>虚指针</strong>：每个对象都包含⼀个指向其类的虚表的指针，这个指针被称为虚指针（vptr）。</p></li></ul><p>当调⽤⼀个虚函数时，编译器会使⽤对象的虚指针查找虚表，并通过虚表中的函数地址来执⾏相应的虚函数。这就是为什么在运⾏时，可以根据实际对象类型来确定调⽤哪个函数的原因。</p><h4 id="多态的实现">多态的实现</h4><p>C++中的多态性通过虚函数（virtualfunction）和虚函数表（vtable）实现。多态性<strong>允许在基类类型的指针或引⽤上调⽤派⽣类对象的函数</strong>：调用虚函数时执行<strong>动态绑定</strong>：运行时解析，执行的函数版本与绑定对象匹配。</p><h6 id="基类声明虚函数">基类声明虚函数</h6><p>使⽤ <code>virtual</code> 关键字，以便派⽣类重写这些函数。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Shape</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line"> <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">draw</span><span class="params">()</span> <span class="type">const</span> </span>&#123;</span><br><span class="line"> <span class="comment">// 基类的默认实现</span></span><br><span class="line"> &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h6 id="派生类重写虚函数">派生类重写虚函数</h6><p>在派⽣类中重写基类中声明的虚函数，使⽤ <code>override</code>关键字。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Circle</span> : <span class="keyword">public</span> Shape &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line"> <span class="function"><span class="type">void</span> <span class="title">draw</span><span class="params">()</span> <span class="type">const</span> <span class="keyword">override</span> </span>&#123;</span><br><span class="line"> <span class="comment">// 派⽣类的实现</span></span><br><span class="line"> &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h6 id="使用基类指针或引用指向派生类对象">使用基类指针或引用，指向派生类对象</h6><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Shape* shapePtr = <span class="keyword">new</span> <span class="built_in">Circle</span>();</span><br></pre></td></tr></table></figure><h6 id="调用虚函数运行时解析">调用虚函数：运行时解析</h6><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shapePtr-&gt;<span class="built_in">draw</span>();</span><br></pre></td></tr></table></figure><blockquote><p>虚函数表：编译器在对象的内存布局中维护了⼀个虚函数表，其中存储了指向实际函数的指针。这个表在运⾏时⽤于动态查找调⽤的函数。</p></blockquote><h3 id="抽象基类不能被实例化的类">抽象基类：不能被实例化的类</h3><blockquote><p>类比Java中的abstrct类；纯虚函数类比Java中的abstract方法</p></blockquote><p>抽象类是不能被实例化的类，其主要⽬的是：<strong>提供⼀个接⼝，供派⽣类继承和实现</strong>。</p><p>抽象类中可以包含普通的成员函数、数据成员和构造函数，但它<strong>必须包含⾄少⼀个纯虚函数</strong>:即在声明中使⽤<code>virtual</code>关键字，并赋予函数⼀个 <code>= 0</code>的纯虚函数。</p><p><strong>派⽣类必须实现抽象类中的纯虚函数，否则它们也会成为抽象类。</strong></p><h4 id="纯虚函数">纯虚函数</h4><p>通过与虚函数的对比来说明。</p><ol type="1"><li><strong>没有实现</strong>：纯虚函数没有函数体，只有函数声明，无默认实现。<ul><li>虚函数<strong>有实现</strong>：有函数声明和实现，即在基类中可以提供默认实现。</li></ul></li><li><strong>强制覆盖</strong>：<strong>派⽣类必须提供纯虚函数的具体实现</strong>，否则它们也会成为抽象类。<ul><li>虚函数<strong>可选实现：</strong>派⽣类可以选择是否覆盖虚函数。如果派⽣类没有提供实现，将使⽤基类的默认实现。</li></ul></li><li><strong>禁止实例化</strong>：包含虚函数的类（即抽象基类）无法实例化。<ul><li>虚函数的类<strong>允许实例化</strong></li></ul></li><li><strong>用<code>=0</code>声明</strong>：<ul><li>虚函数用<strong>virtual声明</strong></li></ul></li><li><strong>为接口提供规范</strong>，供派生类具体实现。</li></ol><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">AbstractBase</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line"> <span class="comment">// 纯虚函数，没有具体实现</span></span><br><span class="line"> <span class="function"><span class="keyword">virtual</span> <span class="type">void</span> <span class="title">pureVirtualFunction</span><span class="params">()</span> </span>= <span class="number">0</span>;</span><br><span class="line"> <span class="comment">// 普通成员函数可以有具体实现</span></span><br><span class="line"> <span class="function"><span class="type">void</span> <span class="title">commonFunction</span><span class="params">()</span> </span>&#123;</span><br><span class="line"> <span class="comment">// 具体实现</span></span><br><span class="line"> &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="访问控制">访问控制</h3><h4 id="protected成员">protected成员</h4><p><code>protected</code>关键字，是介于<code>public</code>和<code>private</code>之间的产物。</p><ol type="1"><li><p>和<code>private</code>成员的相似点：<code>protected</code>和<code>private</code>成员，对于类的用户均为不可访问；</p></li><li><p>和<code>public</code>成员的相似点：（基类的）<code>protected</code>和<code>public</code>成员，<strong>对于派生类的成员和友元可访问</strong></p></li><li><p>派生类的成员和友元，<strong>只能通过派生类对象</strong>（不能通过基类对象），访问基类的<code>protected</code>成员。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Base</span>&#123;</span><br><span class="line"><span class="keyword">protected</span>:</span><br><span class="line">  <span class="type">int</span> prot_mem;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Sneaky</span>:<span class="keyword">public</span> Base&#123;</span><br><span class="line">  <span class="function"><span class="keyword">friend</span> <span class="type">void</span> <span class="title">clobber</span><span class="params">(Sneaky&amp;)</span></span>;<span class="comment">// 能访问Sneaky::prot_mem</span></span><br><span class="line">  <span class="function"><span class="keyword">friend</span> <span class="type">void</span> <span class="title">clobber</span><span class="params">(Base&amp;)</span></span>;<span class="comment">// 不能访问Base::prot_mem</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">clobber</span><span class="params">(Sneaky &amp;s)</span></span>&#123;s.j=s.prot_mem=<span class="number">0</span>;&#125;<span class="comment">// 正确</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">clobber</span><span class="params">(Base &amp;b)</span></span>&#123;b.prot_mem=<span class="number">0</span>;&#125;<span class="comment">// 错误</span></span><br></pre></td></tr></table></figure></li></ol><h4 id="public-private-protected继承">public, private,protected继承</h4><p>派生类对继承而得的成员的访问权限受两个因素影响：</p><ol type="1"><li><p>基类中<strong>该成员的访问说明符</strong>：影响<strong>派生类的成员和友元</strong>的访问权限</p><blockquote><p><strong>派生类的成员和友元</strong>的访问权限，只与基类中访问说明符有关，不受派生列表中访问说明符的影响：如下例中：<code>Priv_Derv</code>中可访问<code>prot_mem</code>（尽管派生列表中为<code>private</code>）</p></blockquote></li><li><p>派生列表中的访问说明符：影响派生类用户（包括派生类的派生类）的访问权限</p></li></ol><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Base</span>&#123;<span class="comment">// 基类</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">pub_mem</span><span class="params">()</span></span>;</span><br><span class="line"><span class="keyword">protected</span>:</span><br><span class="line">  <span class="type">int</span> prot_mem;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">  <span class="type">char</span> priv_mem;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 派生类</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Pub_Derv</span>:<span class="keyword">public</span> Base&#123;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">f</span><span class="params">()</span> </span>&#123;<span class="keyword">return</span> prot_mem;&#125;<span class="comment">//正确：派生类可访问基类的protected成员</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Priv_Derv</span>:<span class="keyword">private</span> Base&#123;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">f1</span><span class="params">()</span> <span class="type">const</span> </span>&#123;<span class="keyword">return</span> prot_mem;&#125;<span class="comment">// 正确：当前派生类不受派生列表中private的影响</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 派生类的用户</span></span><br><span class="line">Pub_Derv d1;</span><br><span class="line">d<span class="number">1.</span><span class="built_in">pub_mem</span>();<span class="comment">// 正确</span></span><br><span class="line">Priv_Derv d2;</span><br><span class="line">d<span class="number">2.</span><span class="built_in">pub_mem</span>();<span class="comment">// 错误：受Priv_Derv派生列表中private的影响，不能访问</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 派生类的派生类</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Derived_from_Public</span> : <span class="keyword">public</span> Pub_Derv&#123;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">use_base</span><span class="params">()</span> </span>&#123;<span class="keyword">return</span> prot_mem;&#125;<span class="comment">// 正确</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">Derived_from_Private</span> : <span class="keyword">public</span> Priv_Derv&#123;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">use_base</span><span class="params">()</span> </span>&#123;<span class="keyword">return</span> prot_mem;&#125;<span class="comment">// 错误：Base::prot_mem在Priv_Derv中是private的</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="3" type="1"><li><p>可通过<code>using</code>改变派生类继承的个别成员的可访问性：</p><ul><li><code>using</code>出现在类的<code>private</code>部分：能被类的成员、友元访问；</li><li><code>using</code>出现在类的<code>protected</code>部分：能被类的成员、友元和派生类访问；</li><li><code>using</code>出现在类的<code>public</code>部分：能被类的成员、友元、派生类和用户访问；</li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Derived</span> : <span class="keyword">private</span> Base&#123;</span><br><span class="line">  <span class="comment">// 使用private继承，所以默认情况下，继承来的pub_mem, prot_mem是Derived的private成员</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">  <span class="function"><span class="keyword">using</span> <span class="title">Base::pub_mem</span><span class="params">()</span></span>;</span><br><span class="line">  <span class="comment">// 使用using后：Derived的用户、派生类均可访问pub_mem</span></span><br><span class="line"><span class="keyword">protected</span>:</span><br><span class="line">  <span class="keyword">using</span> Base::prot_mem;<span class="comment">// 使用using后：Derived的</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h4 id="上行转换派生类向基类的可访问性">上行转换（派生类向基类）的可访问性</h4><ol type="1"><li>派生类的用户：当且仅当D对B<code>public</code>继承，才能进行上行转换；</li><li>派生类D的成员和友元：无论D对B的继承方式，均可上行转换；</li><li>派生类D的派生类E，其成员和友元：当且仅当D对B<code>public</code>或<code>protected</code>继承，才能上行转换。</li></ol><h4 id="友元与继承">友元与继承</h4><ul><li><p>友元关系不能传递和继承：对于友元的基类和派生类，不具备特殊访问能力。</p></li><li><p>每个类控制各自成员的访问权限：对基类的访问权限由基类本身控制，即使对于派生类的基类部分也是如此。</p></li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Base</span>&#123;</span><br><span class="line">  <span class="keyword">friend</span> <span class="keyword">class</span> <span class="title class_">Pal</span>;<span class="comment">// Base的友元</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Pal</span>&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">f</span><span class="params">(Base b)</span> </span>&#123;<span class="keyword">return</span> b.<span class="built_in">prot_mem</span>()&#125;;<span class="comment">// 正确：Pal是Base的友元</span></span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">f2</span><span class="params">(Sneaky s)</span> </span>&#123;<span class="keyword">return</span> s.prot_mem;&#125;<span class="comment">// 正确：Pal可访问派生类中，从Base继承的部分</span></span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">f3</span><span class="params">(Sneaky s)</span> </span>&#123;<span class="keyword">return</span> s.j;&#125;<span class="comment">// 错误：Pal不可访问派生类中，不属于基类的部分</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="struct和class默认继承保护级别"><code>struct</code>和<code>class</code>默认继承保护级别</h4><p>默认情况下，<code>class</code>定义的派生类采取<code>private</code>继承；<code>struct</code>定义的派生类采取<code>public</code>继承</p><h3 id="继承中的类作用域">继承中的类作用域</h3><p>派生类的作用域，<strong>嵌套在其基类的作用域之内</strong>：</p><ol type="1"><li><p>如果一个名字在派生类的作用域内无法解析，则<strong>编译器向其外层基类中，不断递归寻找</strong>该名字定义，直到继承链的顶端。&gt; 逻辑类似于：编译器在符号表中查找标识符。</p></li><li><p>名字冲突：若出现同名，定义在派生类的名字，将隐藏定义在基类中的名字（即使参数列表不同，也会隐藏掉）</p><blockquote><p>可通过作用域运算符，使用隐藏的基类成员，例如：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">Derived</span>:Base&#123;</span><br><span class="line">  <span class="function"><span class="type">int</span> <span class="title">get_base_num</span><span class="params">()</span> </span>&#123;<span class="keyword">return</span> Base::mem;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></blockquote></li></ol><h3 id="构造函数与拷贝控制">构造函数与拷贝控制</h3><h4 id="虚析构函数">虚析构函数</h4><p><strong>基类的析构函数必须定义为虚函数</strong>。</p><p>当<code>delete</code>一个动态分配对象的指针时，可能会出现：指针的静态类型与被删除对象的动态类型不符的情况（运行时多态）。因此需要定义为虚函数，实现虚构函数的动态绑定。</p><blockquote><p>如果基类的析构函数不是虚函数，则<code>delete</code>一个指向派生类对象的基类指针时，将产生未定义的行为。</p></blockquote><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Quote</span>&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">  <span class="keyword">virtual</span> ~<span class="built_in">Quote</span>()=<span class="keyword">default</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Quote *itemP=<span class="keyword">new</span> Quote;</span><br><span class="line"><span class="keyword">delete</span> itemP;<span class="comment">// 调用Quote的析构函数</span></span><br><span class="line">itemP=<span class="keyword">new</span> Bulk_quote;<span class="comment">// 静态类型与动态类型不一致</span></span><br><span class="line"><span class="keyword">delete</span> itemP;<span class="comment">// 调用Bulk_quote的析构函数</span></span><br></pre></td></tr></table></figure><h4 id="合成拷贝控制">合成拷贝控制</h4><p>未完待续...</p><h3 id="容器与继承">容器与继承</h3><p>当希望在容器中存放具有继承关系的对象时，可采用<strong>智能指针</strong>：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">vector&lt;shared_ptr&lt;Quote&gt;&gt; basket;</span><br><span class="line">basket.<span class="built_in">push_back</span>(<span class="built_in">make_shared</span>&lt;Quote&gt;(...));</span><br><span class="line">basket.<span class="built_in">push_back</span>(<span class="built_in">make_shared</span>&lt;Bulk_quote&gt;(...));</span><br><span class="line"></span><br><span class="line">cout&lt;&lt;basket.<span class="built_in">back</span>()-&gt;<span class="built_in">net_price</span>(<span class="number">15</span>)&lt;&lt;endl;</span><br><span class="line"><span class="comment">// basket存放的是shared_ptr，必须解引用才能获得运行net_price的对象</span></span><br></pre></td></tr></table></figure><blockquote><p>如果定义容器中直接存放基类对象，那么添加派生类时，其派生类部分将会被忽略掉。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> C++ Primer </category>
          
          <category> Class Design Techniques </category>
          
      </categories>
      
      
        <tags>
            
            <tag> C++ </tag>
            
            <tag> OOP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>BUAA-OS Lab1 实验笔记</title>
      <link href="/posts/48d27dfa.html"/>
      <url>/posts/48d27dfa.html</url>
      
        <content type="html"><![CDATA[<h1 id="总前言">总前言</h1><p>操作系统是大二下学期的一门核心专业课，实验部分分为6个实验（Lab1 ~Lab6）。采用增量式实验设计思想，每个实验包含的内核代码量在几百行左右，并提供了代码框架和代码示例，要求阅读源码、理解机制并补全核心代码。每个实验可以独立运行和评测，最后实现一个可以在MIPS平台上运行的小型操作系统。以此专题，纪念大二下的每个“备受折磨”的日夜，重温操作系统的核心理念。实验代码仓库位于<a href="https://github.com/WenLiuyi/OS_on_MIPS">OS_on_MIPS</a>.</p><p>总流程：实验编写的操作系统代码在Linux系统中，通过Makefile组织，通过交叉编译产生可执行文件；再使用QEMU模拟器运行该可执行文件，实现MOS操作系统的运行。</p><h2 id="内核与启动">内核与启动</h2><p><strong>内核</strong>是操作系统最核心的部分，负责与硬件直接交互，并为用户进程提供服务。在<strong>计算机启动时，内核需要被加载到内存中</strong>，但不宜放在磁盘（CPU无法直接从磁盘访问数据）或内存（易失性）中，因此放在一个<strong>非易失性存储器中（如ROM或FLASH）</strong>。不过，将操作系统直接放入ROM或FLASH会面临以下几个问题：1. <strong>存储空间限制</strong>：ROM或FLASH的存储空间有限，无法存放较大的内核; 2.<strong>只能启动一个操作系统</strong>：若操作系统内核直接从ROM或FLASH启动，无法实现多重启动。 3.<strong>移植性受限</strong>：将所有硬件相关代码放入内核中，不利于系统的移植。</p><h3 id="bootloader">Bootloader</h3><p>为了解决这些问题，设计者将<strong>硬件初始化工作独立为bootloader程序，并将其保存在ROM或FLASH中</strong>，而将操作系统内核保存在磁盘上。Bootloader工作分为两个阶段：1. Stage 1：硬件加电 -&gt; Stage 1 Bootloader（ROM/FLASH中） *硬件初始化（如时钟、中断、内存等）； * <strong>将Stage2的代码加载到RAM中，并跳转到Stage 2的入口点</strong>。</p><ol start="2" type="1"><li>Stage 2：Bootloader（RAM中）</li></ol><ul><li>初始化其他硬件设备</li><li>加载操作系统内核镜像到RAM</li><li>设置启动参数，并<strong>将控制权交给操作系统内核</strong></li></ul><ol start="3" type="1"><li>（不属于Bootloader）：</li></ol><p><img src="/posts/48d27dfa/image.png"></p><p>BootLoader的操作模式分为：<strong>启动加载模式</strong>（从本地存储器（如硬盘）加载内核镜像）和<strong>下载模式</strong>（通过串口或网络等方式下载远程内核镜像）。</p><p>总结：Bootloader是操作系统启动的第一步，负责<strong>硬件初始化和内核加载</strong>。</p><h3 id="qemu模拟器">QEMU模拟器</h3><p>在QEMU模拟环境中，由于QEMU模拟器提供bootloader的启动功能（模仿了YAMON的功能）；支持直接加载ELF内核的内存，因此上述都不是问题啦。我们的MOS操作系统，从跳转到内核入口开始的。&gt; 疑问：bootloader如何找到内核入口点呢？ &gt; &gt;解答：Bootloader中的引导加载程序，会解析内核映像的信息，找到<strong>内核入口点地址</strong>，将其写入某个寄存器（如跳转寄存器）；通过执行跳转命令，CPU从该寄存器中读取地址，从而跳转至内核入口。</p><h2 id="从零开始搭建mos">从零开始搭建MOS</h2><h3 id="构建内核从make开始">构建内核：从make开始</h3><h4 id="makefile为内核地图">Makefile为内核地图</h4><figure class="highlight make"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">include</span>.mk</span><br><span class="line"></span><br><span class="line">target_dir := target <span class="comment">#MOS构建目标所在目录</span></span><br><span class="line">mos_elf :=<span class="variable">$(target_dir)</span>/mos <span class="comment">#最终需要生成的ELF可执行文件</span></span><br><span class="line">user_disk := <span class="variable">$(target_dir)</span>/fs.img <span class="comment">#MOS文件系统使用的磁盘镜像文件</span></span><br><span class="line">link_script := kernel.lds</span><br><span class="line"></span><br><span class="line">modules :=libinit kern <span class="comment">#需要生成的子模块</span></span><br><span class="line">objects :=<span class="variable">$(<span class="built_in">addsuffix</span> /*.o,<span class="variable">$(modules)</span>)</span> <span class="comment">#要编译出内核所依赖的所有目标文件（*.o）</span></span><br><span class="line"></span><br><span class="line">QEMU_FLAGS :=-cpu4Kc-m64-nographic-Mmalta\</span><br><span class="line">            $(shell[-f&#x27;<span class="variable">$(user_disk)</span>&#x27;] &amp;&amp;\</span><br><span class="line">            echo&#x27;-driveid=ide,file=<span class="variable">$(user_disk)</span>,if=ide,format=raw&#x27;) \</span><br><span class="line">            -no-reboot <span class="comment">#QEMU运行参数</span></span><br><span class="line"></span><br><span class="line"><span class="meta"><span class="keyword">.PHONY</span>:all $(modules) clean</span></span><br></pre></td></tr></table></figure><p>在命令行执行<code>make</code>后，在<code>target</code>目录下生成内核镜像文件<code>mos</code>，步骤如下：<figure class="highlight make"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">targets:=<span class="variable">$(mos_elf)</span></span><br><span class="line"></span><br><span class="line"><span class="section">all:<span class="variable">$(targets)</span></span></span><br><span class="line"></span><br><span class="line"><span class="variable">$(modules)</span>:</span><br><span class="line">    <span class="variable">$(MAKE)</span>--directory=<span class="variable">$@</span></span><br><span class="line"></span><br><span class="line"><span class="variable">$(mos_elf)</span>: <span class="variable">$(modules)</span></span><br><span class="line">    <span class="variable">$(LD)</span> <span class="variable">$(LDFLAGS)</span>-o<span class="variable">$(mos_elf)</span>-N-T<span class="variable">$(link_script)</span> <span class="variable">$(objects)</span></span><br><span class="line">    <span class="comment"># 调用了链接器，将之前构建各模块产生的所有.o文件在linkerscript的指导下，链接到一起，产生最终的mos可执行文件</span></span><br></pre></td></tr></table></figure> ##### 构建MOS依赖项 1.执⾏<code>make</code>-&gt;构建⽬标<code>all</code>-&gt;构建<code>all</code>的依赖项<code>$(targets)</code>-&gt;构建<code>$(mos_elf)</code>-&gt;构建<code>$(modules)</code></p><ol start="2" type="1"><li>对 <code>$(modules)</code> 中的每个⽬录执⾏⼀次<code>$(MAKE) --directory=$@ .</code>，看⻅形如：<code>make[1]: Entering directory '/home/git/xxxxxxxx/init'</code>的输出。<code>$(modules)</code>包含的内容如下： <figure class="highlight make"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">modules :=lib init kern</span><br><span class="line">targets :=<span class="variable">$(mos_elf)</span></span><br><span class="line"></span><br><span class="line">lab-ge= <span class="variable">$(<span class="built_in">shell</span> [ <span class="string">&quot;$$(echo<span class="variable">$(lab)</span>_|cut-f1-d_)&quot;</span> -ge$(1)</span> ] &amp;&amp;echotrue)</span><br><span class="line"></span><br><span class="line"><span class="keyword">ifeq</span>($(calllab-ge,3),true)</span><br><span class="line">    user_modules +=user/bare</span><br><span class="line"><span class="keyword">endif</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">ifeq</span>($(calllab-ge,4),true)</span><br><span class="line">    user_modules +=user</span><br><span class="line"><span class="keyword">endif</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">ifeq</span>($(calllab-ge,5),true)</span><br><span class="line">    user_modules +=fs</span><br><span class="line">targets +=fs-image</span><br><span class="line"><span class="keyword">endif</span></span><br><span class="line"></span><br><span class="line">objects :=$(addsuffix/*.o, <span class="variable">$(modules)</span>)<span class="variable">$(<span class="built_in">addsuffix</span> /*.x,<span class="variable">$(user_modules)</span>)</span></span><br><span class="line">modules +=<span class="variable">$(user_modules)</span></span><br></pre></td></tr></table></figure><ul><li><code>$(modules)</code> 包含：<code>lib</code> ,<code>init</code>,<code>kern</code>这三个构建⽬标，分别对应依赖库、初始化代码和内核代码。</li><li><code>$(user_modules)</code>是一个可选的构建目标，它的构建取决于lab变量的值。</li></ul>将组合好的<code>$(modules)</code>和<code>$(user_modules)</code>的内容对应的生成文件，赋值给<code>$(objects)</code></li></ol><h5 id="构建mos">构建MOS</h5><ol start="3" type="1"><li><code>$(mos_elf)</code>构建：执⾏<code>$(LD) -o $(mos_elf) -N -T $(link_script) $(objects)</code><ul><li><code>-o --output</code> :设置输出⽂件名</li><li><code>-T --script</code> :读取链接脚本</li></ul>使⽤<code>$(link_script)</code> 将<code>$(objects)</code>链接，输出到<code>$(mos_elf)</code> 位置.</li><li>将组合好的 <code>$(modules)</code> 和<code>$(user_modules)</code>的内容对应的⽣成⽂件赋值给<code>$(objects)</code><ul><li><code>objects</code>:将⽤户程序和内核程序的⽬标⽂件，分为不同的后缀保存;</li><li><code>modules</code>: 设置<code>$(modules)</code>为所有需要依赖的构建⽬标</li></ul></li><li><code>$(mos_elf)</code> 下可查看内核⽂件</li></ol><h2 id="内核的入口">内核的入口</h2><p>QEMU模拟器在加载内核时：按照可执行文件中所记录的地址，将内核中的代码、数据，加载到相应的位置，并将CPU控制权移交给内核。那么抛出两个问题：1. 内核应该被放在哪里呢？ 2. 如何将内核加载到上述位置呢？</p><h3 id="寻找内核的正确位置mips内存布局">寻找内核的正确位置：MIPS内存布局</h3><p><strong>内核放在<code>kseg0</code></strong>.</p><p>MIPS 体系结构的虚拟地址空间大小为<code>4GB</code>，布局如下图： <img src="/posts/48d27dfa/image-1.png"></p><table><colgroup><col style="width: 6%"><col style="width: 6%"><col style="width: 56%"><col style="width: 30%"></colgroup><thead><tr><th>区域</th><th>可用性</th><th>地址映射</th><th>存取方式</th></tr></thead><tbody><tr><td>kuseg</td><td>用户态</td><td>唯一可MMU的TLB：虚拟地址 -&gt; 物理地址</td><td>通过cache</td></tr><tr><td>kseg0</td><td>内核态</td><td>MMU将虚拟地址最高位清零，得到物理地址（连续映射至物理地址低512MB空间）</td><td>通过cache</td></tr><tr><td>kseg1</td><td>内核态</td><td>MMU将虚拟地址高三位清零，得到物理地址（连续映射至物理地址低512MB空间）</td><td>不通过cache（使用MIMO访问外设）</td></tr><tr><td>kseg2</td><td>只能在内核态使用</td><td>MMU的TLB：虚拟地址 -&gt; 物理地址</td><td>通过cache</td></tr></tbody></table><h3 id="控制加载地址linker-script">控制加载地址：<code>Linker Script</code></h3><p>从上一节生成<code>MOS</code>的第3步中，可见：是使⽤<code>$(link_script)</code>将<code>$(objects)</code><strong>链接</strong>，生成可执行文件。这里的<code>$(link_script)</code>即<code>kernel.lds</code>，其中记录了各个节应该如何映射到段，以及各个段应该被加载到的位置。包括以下段：* <code>.text</code>：包含可执行文件中的代码 *<code>.data</code>：包含需要被初始化的全局变量和静态变量 *<code>.bss</code>：包含未初始化的全局变量和静态变量</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">OUTPUT_ARCH(mips)   // 架构：MIPS</span><br><span class="line">ENTRY(_start)       // 设置MOS内核入口地址为：_start</span><br><span class="line"></span><br><span class="line">SECTIONS &#123;</span><br><span class="line">. = 0x80000000;</span><br><span class="line">.tlb_miss_entry : &#123;*(.text.tlb_miss_entry)&#125;</span><br><span class="line"></span><br><span class="line">. = 0x80000180;</span><br><span class="line">.exc_gen_entry : &#123;*(.text.exc_gen_entry)&#125;</span><br><span class="line"></span><br><span class="line">. = 0x80020000;     // .text段的加载地址</span><br><span class="line"></span><br><span class="line">.text : &#123; *(.text) &#125;</span><br><span class="line"></span><br><span class="line">    .data : &#123; *(.data) &#125;</span><br><span class="line"></span><br><span class="line">bss_start = .;</span><br><span class="line">.bss : &#123; *(.bss) &#125;</span><br><span class="line">bss_end = .;</span><br><span class="line">. = 0x80400000;</span><br><span class="line">end = . ;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="mos内核入口_start">MOS内核入口：_start</h3><p>从上一小节可知：<code>kernel.lds</code>中设置了MOS内核入口<code>ENTRY(_start)</code>，对应<code>init/start.S</code>中的<code>_start</code>函数，如下：<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;asm/asm.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;mmu.h&gt;</span></span></span><br><span class="line"></span><br><span class="line">.text</span><br><span class="line"><span class="title function_">EXPORT</span><span class="params">(_start)</span></span><br><span class="line">.<span class="built_in">set</span> at</span><br><span class="line">.<span class="built_in">set</span> reorder    <span class="comment">// 启用指令重排：MIPS编译器自动重排指令以优化性能，减少流水线阻塞</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* 清空 .bss 段：清零后跳转至clear_bss_done */</span></span><br><span class="line">la      v0, bss_start</span><br><span class="line">la      v1, bss_end</span><br><span class="line">clear_bss_loop:</span><br><span class="line">beq     v0, v1, clear_bss_done</span><br><span class="line">sb      zero, 0<span class="params">(v0)</span></span><br><span class="line">addiu   v0, v0, 1</span><br><span class="line">j       clear_bss_loop</span><br><span class="line"></span><br><span class="line">clear_bss_done:</span><br><span class="line"><span class="comment">/* 禁用中断 */</span></span><br><span class="line">mtc0    zero, CP0_STATUS</span><br><span class="line"></span><br><span class="line"><span class="comment">/* 将sp寄存器设置到：内核栈的起始地址 */</span></span><br><span class="line">       lasp, 0x80400000</span><br><span class="line"></span><br><span class="line"><span class="comment">/* 跳转到 mips_init：内核初始化的入口点，执行内核的后续初始化工作 */</span></span><br><span class="line">jmips_init</span><br></pre></td></tr></table></figure> &gt; 注： &gt; 1.栈由高地址向低地址方向增长，<code>sp</code>应设置到栈底（即“顶”）； &gt;2.<code>j mips_init</code>采用<code>j</code>而非<code>jal</code>，是因为不存在返回的情况。</p><h2 id="内核初始化mips_init函数">内核初始化：mips_init函数</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">ifdef</span> MOS_INIT_OVERRIDDEN</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;generated/init_override.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line"><span class="type">void</span> <span class="title function_">mips_init</span><span class="params">(u_int argc, <span class="type">char</span> **argv, <span class="type">char</span> **penv, u_int ram_low_size)</span> &#123;</span><br><span class="line">printk(<span class="string">&quot;init.c:\tmips_init() is called\n&quot;</span>);</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br></pre></td></tr></table></figure><h2 id="结尾">结尾</h2><p>经过以上步骤，命令行执行<code>make run</code>，编译运行内核，MOS操作系统可以正常运行起来啦！</p><p>下一个Lab，将进入MIPS4Kc的访存流程与内存映射布局，深入物理内存、虚拟内存的管理办法，以及TLB的清除与重填流程。</p>]]></content>
      
      
      <categories>
          
          <category> OS </category>
          
          <category> BUAA OS lab </category>
          
      </categories>
      
      
        <tags>
            
            <tag> C </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>C++标准库：容器、动态内存、同步原语</title>
      <link href="/posts/b93a17fc.html"/>
      <url>/posts/b93a17fc.html</url>
      
        <content type="html"><![CDATA[<p>接上一篇知识。</p><h2 id="c标准库容器">C++标准库容器</h2><h3 id="stdvector"><code>std::vector</code></h3><ul><li><code>std::vector</code>是一种动态数组，可以根据需要自动调整大小，能够存储任意类型的元素。</li></ul><h4 id="向向量中添加元素">向向量中添加元素</h4><ul><li><code>push_back</code> 和 <code>emplace_back</code>都用于向向量中添加元素。<ul><li><code>emplace_back</code> 通常比 <code>push_back</code>更高效，因为它直接在内存中创建元素，而不需要先构造一个临时对象然后再移动。<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">point_vector.<span class="built_in">push_back</span>(<span class="built_in">Point</span>(<span class="number">35</span>, <span class="number">36</span>));  <span class="comment">// 使用 push_back 添加元素</span></span><br><span class="line">point_vector.<span class="built_in">emplace_back</span>(<span class="number">37</span>, <span class="number">38</span>);  <span class="comment">// 使用 emplace_back 添加元素</span></span><br></pre></td></tr></table></figure></li></ul></li></ul><h4 id="遍历向量">遍历向量</h4><ul><li>直接/<strong>用下标</strong>遍历元素 <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">std::cout &lt;&lt; <span class="string">&quot;Printing the items in point_vector:\n&quot;</span>;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; point_vector.<span class="built_in">size</span>(); ++i) &#123;</span><br><span class="line">  point_vector[i].<span class="built_in">PrintPoint</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></li></ul><h4 id="删除向量中的元素">删除向量中的元素</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">int_vector.<span class="built_in">erase</span>(int_vector.<span class="built_in">begin</span>() + <span class="number">2</span>);  <span class="comment">// 删除索引为 2 的元素</span></span><br><span class="line">int_vector.<span class="built_in">erase</span>(int_vector.<span class="built_in">begin</span>() + <span class="number">1</span>, int_vector.<span class="built_in">end</span>());  <span class="comment">// 删除索引从 1 到末尾的元素</span></span><br></pre></td></tr></table></figure><h4 id="使用-stdremove_if-删除符合条件的元素">使用<code>std::remove_if</code> 删除符合条件的元素</h4><ul><li><code>remove_if</code>会将符合条件的元素移动到容器末尾，返回一个指向第一个符合条件元素的迭代器，然后通过<code>erase</code> 实际删除这些元素。 <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">point_vector.<span class="built_in">erase</span>(</span><br><span class="line">    std::<span class="built_in">remove_if</span>(point_vector.<span class="built_in">begin</span>(), point_vector.<span class="built_in">end</span>(),</span><br><span class="line">                   [](<span class="type">const</span> Point &amp;point) &#123; <span class="keyword">return</span> point.<span class="built_in">GetX</span>() == <span class="number">37</span>; &#125;),</span><br><span class="line">    point_vector.<span class="built_in">end</span>());</span><br></pre></td></tr></table></figure></li></ul><h3 id="stdset"><code>std::set</code></h3><ul><li><code>std::set</code>是一个存储<strong>唯一元素</strong>的容器，且元素会自动按顺序排列。通常，<code>std::set</code>使用<strong>红黑树</strong>来实现，确保元素在插入时能够保持<strong>有序</strong>。</li><li>支持插入、查找、删除等基本操作；</li><li><strong>不支持按索引访问，只能通过迭代器遍历</strong></li></ul><h4 id="插入元素">插入元素</h4><ul><li>通过 <code>insert</code> 和 <code>emplace</code> 两种方式向<code>int_set</code> 集合中插入元素。<ul><li>其中 emplace 允许直接构造对象，而不需要先创建临时对象。<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 使用 insert 插入元素 1 到 5</span></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt;= <span class="number">5</span>; ++i) &#123;</span><br><span class="line">  int_set.<span class="built_in">insert</span>(i);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用 emplace 插入元素 6 到 10</span></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">6</span>; i &lt;= <span class="number">10</span>; ++i) &#123;</span><br><span class="line">  int_set.<span class="built_in">emplace</span>(i);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul></li></ul><h4 id="查找元素">查找元素</h4><ul><li>使用 <code>find</code>函数查找元素，返回的是一个迭代器：如果找到了元素，返回的迭代器不等于<code>end()</code>，否则等于 <code>end()</code>。 <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">std::set&lt;<span class="type">int</span>&gt;::iterator search = int_set.<span class="built_in">find</span>(<span class="number">2</span>);</span><br><span class="line"><span class="keyword">if</span> (search != int_set.<span class="built_in">end</span>()) &#123;</span><br><span class="line">  std::cout &lt;&lt; <span class="string">&quot;Element 2 is in int_set.\n&quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h4 id="计数元素">计数元素</h4><ul><li><code>count</code> 函数用于查找某个元素的个数，在<code>std::set</code> 中，每个元素最多只能出现一次，所以返回值要么是0（元素不存在），要么是 1（元素存在）。</li></ul><h4 id="删除元素">删除元素</h4><p><code>erase(int_set.find(9), int_set.end())</code> 用于删除从元素 9开始直到集合末尾的所有元素。 *由于<code>set</code>有序，即为：删除大于等于9的元素</p><h4 id="遍历集合">遍历集合</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (std::set&lt;<span class="type">int</span>&gt;::iterator it = int_set.<span class="built_in">begin</span>(); it != int_set.<span class="built_in">end</span>(); ++it) &#123;</span><br><span class="line">  std::cout &lt;&lt; *it &lt;&lt; <span class="string">&quot; &quot;</span>;  <span class="comment">// 通过解引用迭代器访问元素</span></span><br><span class="line">&#125;</span><br><span class="line">std::cout &lt;&lt; <span class="string">&quot;\n&quot;</span>;</span><br><span class="line"></span><br><span class="line">std::cout &lt;&lt; <span class="string">&quot;Printing the elements of the iterator with a for-each loop:\n&quot;</span>;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">const</span> <span class="type">int</span> &amp;elem : int_set) &#123;</span><br><span class="line">  std::cout &lt;&lt; elem &lt;&lt; <span class="string">&quot; &quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="stdunordered_map"><code>std::unordered_map</code></h3><ul><li><code>std::unordered_map</code>是一个<strong>哈希表</strong>实现的容器，用于存储键值对；每个键是唯一的；且容器中的元素不保证按任何特定顺序排列，而是根据哈希值分布存储。<ul><li>查找、插入和删除操作的平均时间复杂度为常数级别</li></ul></li><li>支持插入、查找、删除和<strong>迭代</strong>操作 <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span>   <span class="comment">// 用于输出（打印）</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unordered_map&gt;</span>  <span class="comment">// 包含 std::unordered_map 容器的头文件</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string&gt;</span>     <span class="comment">// 包含 std::string 类型的头文件</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;utility&gt;</span>    <span class="comment">// 包含 std::make_pair 等实用功能的头文件</span></span></span><br></pre></td></tr></table></figure></li></ul><h4 id="插入元素-1">插入元素</h4><ul><li><code>std::make_pair</code> 用于创建一个键值对。 <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">map.<span class="built_in">insert</span>(&#123;<span class="string">&quot;foo&quot;</span>, <span class="number">2</span>&#125;);  </span><br><span class="line">map.<span class="built_in">insert</span>(std::<span class="built_in">make_pair</span>(<span class="string">&quot;jignesh&quot;</span>, <span class="number">445</span>));  </span><br><span class="line">map.<span class="built_in">insert</span>(&#123;&#123;<span class="string">&quot;spam&quot;</span>, <span class="number">1</span>&#125;, &#123;<span class="string">&quot;eggs&quot;</span>, <span class="number">2</span>&#125;, &#123;<span class="string">&quot;garlic rice&quot;</span>, <span class="number">3</span>&#125;&#125;);  <span class="comment">// 批量插入多个键值对</span></span><br><span class="line">map[<span class="string">&quot;bacon&quot;</span>] = <span class="number">5</span>;  <span class="comment">// 通过下标语法插入 &quot;bacon&quot; 键和 5 值</span></span><br></pre></td></tr></table></figure></li></ul><h4 id="查找元素-1">查找元素</h4><ul><li>通过迭代器可以访问到键值对，<code>result-&gt;first</code>获取键，<code>result-&gt;second</code> 获取值 <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">std::unordered_map&lt;std::string, <span class="type">int</span>&gt;::iterator result = map.<span class="built_in">find</span>(<span class="string">&quot;jignesh&quot;</span>);</span><br><span class="line"><span class="keyword">if</span> (result != map.<span class="built_in">end</span>()) &#123;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Found key &quot;</span> &lt;&lt; result-&gt;first &lt;&lt; <span class="string">&quot; with value &quot;</span> &lt;&lt; result-&gt;second &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h3 id="使用auto关键字">使用<code>auto</code>关键字</h3><ul><li><code>auto</code>关键字用于告诉编译器<strong>根据变量的初始化表达式来推断变量的类型</strong>。这样，开发者不需要显式地指定类型，编译器会根据右侧的赋值表达式自动推导类型。这对于复杂的类型声明，尤其是模板类或容器类型，非常有用。</li></ul><h4 id="复杂类型的推导示例">复杂类型的推导示例</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 定义一个模板类，它的名称非常长。</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T, <span class="keyword">typename</span> U&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Abcdefghijklmnopqrstuvwxyz</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">  <span class="built_in">Abcdefghijklmnopqrstuvwxyz</span>(T instance1, U instance2)</span><br><span class="line">      : <span class="built_in">instance1_</span>(instance1), <span class="built_in">instance2_</span>(instance2) &#123;&#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">print</span><span class="params">()</span> <span class="type">const</span> </span>&#123;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;(&quot;</span> &lt;&lt; instance1_ &lt;&lt; <span class="string">&quot;,&quot;</span> &lt;&lt; instance2_ &lt;&lt; <span class="string">&quot;)\n&quot;</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">  T instance1_;</span><br><span class="line">  U instance2_;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 返回一个模板类实例的函数</span></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="function">Abcdefghijklmnopqrstuvwxyz&lt;T, T&gt; <span class="title">construct_obj</span><span class="params">(T instance)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">Abcdefghijklmnopqrstuvwxyz</span>&lt;T, T&gt;(instance, instance);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  Abcdefghijklmnopqrstuvwxyz&lt;<span class="type">int</span>, <span class="type">int</span>&gt; obj = <span class="built_in">construct_obj</span>&lt;<span class="type">int</span>&gt;(<span class="number">2</span>);</span><br><span class="line">  <span class="keyword">auto</span> obj1 = <span class="built_in">construct_obj</span>&lt;<span class="type">int</span>&gt;(<span class="number">2</span>);  <span class="comment">// 使用 auto 推导类型，无需写出长类名</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="复制与引用">复制与引用</h4><ul><li><code>auto</code> <strong>默认会进行深拷贝</strong><ul><li>在此例中，<code>copy_int_values</code> 是 <code>int_values</code>的一个副本，修改 <code>copy_int_values</code> 不会影响<code>int_values</code></li><li>如果希望避免深拷贝，可以使用 <code>auto&amp;</code>来创建一个引用，这样对 <code>ref_int_values</code> 的修改将直接影响<code>int_values</code> <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">std::vector&lt;<span class="type">int</span>&gt; int_values = &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>&#125;;</span><br><span class="line"><span class="comment">// auto 会创建一个副本</span></span><br><span class="line"><span class="keyword">auto</span> copy_int_values = int_values;  <span class="comment">// 深拷贝 int_values</span></span><br><span class="line"><span class="comment">// 使用 auto&amp; 创建引用，避免深拷贝</span></span><br><span class="line"><span class="keyword">auto</span>&amp; ref_int_values = int_values;  <span class="comment">// 引用 int_values</span></span><br></pre></td></tr></table></figure></li></ul></li></ul><h4 id="用于迭代容器">用于迭代容器</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 使用 auto 推导迭代器类型</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">auto</span> it = map.<span class="built_in">begin</span>(); it != map.<span class="built_in">end</span>(); ++it) &#123;</span><br><span class="line">  std::cout &lt;&lt; <span class="string">&quot;(&quot;</span> &lt;&lt; it-&gt;first &lt;&lt; <span class="string">&quot;,&quot;</span> &lt;&lt; it-&gt;second &lt;&lt; <span class="string">&quot;) &quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="c标准库动态内存">C++标准库动态内存</h2><p>智能指针：是用于内存管理的一个数据结构，尤其是在没有内存管理内建机制（如垃圾回收）的语言中（例如C++）。智能指针的主要功能是<strong>自动处理内存的分配与释放</strong>。在现代C++ 标准库中，常用的智能指针有 <code>std::unique_ptr</code> 和<code>std::shared_ptr</code>，它们都在内部封装了原始指针，自动管理内存。</p><h3 id="stdunique_ptr"><code>std::unique_ptr</code></h3><ul><li>具有<strong>唯一所有权</strong>的特性。即同一个对象只能被一个<code>std::unique_ptr</code> 管理，不能共享对象的所有权。</li><li>它<strong>无法进行拷贝</strong>，但可以通过 <code>std::move</code>转移所有权。</li><li>当 <code>std::unique_ptr</code>离开作用域时，它所管理的对象会被自动释放。这避免了手动释放内存时可能出现的错误（如内存泄漏）。</li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;memory&gt;</span> <span class="comment">// 引入 unique_ptr 功能</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string&gt;</span> <span class="comment">// 用于打印的字符串库</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;utility&gt;</span> <span class="comment">// 引入 std::move</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Point</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">  <span class="built_in">Point</span>() : <span class="built_in">x_</span>(<span class="number">0</span>), <span class="built_in">y_</span>(<span class="number">0</span>) &#123;&#125;</span><br><span class="line">  <span class="built_in">Point</span>(<span class="type">int</span> x, <span class="type">int</span> y) : <span class="built_in">x_</span>(x), <span class="built_in">y_</span>(y) &#123;&#125;</span><br><span class="line">  <span class="function"><span class="keyword">inline</span> <span class="type">int</span> <span class="title">GetX</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> x_; &#125;</span><br><span class="line">  <span class="function"><span class="keyword">inline</span> <span class="type">int</span> <span class="title">GetY</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> y_; &#125;</span><br><span class="line">  <span class="function"><span class="keyword">inline</span> <span class="type">void</span> <span class="title">SetX</span><span class="params">(<span class="type">int</span> x)</span> </span>&#123; x_ = x; &#125;</span><br><span class="line">  <span class="function"><span class="keyword">inline</span> <span class="type">void</span> <span class="title">SetY</span><span class="params">(<span class="type">int</span> y)</span> </span>&#123; y_ = y; &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">  <span class="type">int</span> x_;</span><br><span class="line">  <span class="type">int</span> y_;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">SetXTo445</span><span class="params">(std::unique_ptr&lt;Point&gt;&amp; ptr)</span> </span>&#123;</span><br><span class="line">  ptr-&gt;<span class="built_in">SetX</span>(<span class="number">445</span>); <span class="comment">// 修改唯一指针指向的对象的 x 值</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 初始化 unique_ptr</span></span><br><span class="line">  std::unique_ptr&lt;Point&gt; u1; <span class="comment">// 空指针</span></span><br><span class="line">  std::unique_ptr&lt;Point&gt; u2 = std::<span class="built_in">make_unique</span>&lt;Point&gt;(); <span class="comment">// 默认构造函数</span></span><br><span class="line">  std::unique_ptr&lt;Point&gt; u3 = std::<span class="built_in">make_unique</span>&lt;Point&gt;(<span class="number">2</span>, <span class="number">3</span>); <span class="comment">// 自定义构造函数</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 判断 unique_ptr 是否为空</span></span><br><span class="line">  <span class="keyword">if</span> (u1) &#123;</span><br><span class="line">    <span class="comment">// 这个条件不会成立，因为 u1 是空的</span></span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;u1&#x27;s value of x is &quot;</span> &lt;&lt; u1-&gt;<span class="built_in">GetX</span>() &lt;&lt; std::endl;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (u2) &#123;</span><br><span class="line">    <span class="comment">// 这个条件会成立，因为 u2 包含一个有效的 Point 实例</span></span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;u2&#x27;s value of x is &quot;</span> &lt;&lt; u2-&gt;<span class="built_in">GetX</span>() &lt;&lt; std::endl;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 打印 unique_ptr 是否为空</span></span><br><span class="line">  std::cout &lt;&lt; <span class="string">&quot;Pointer u1 is &quot;</span> &lt;&lt; (u1 ? <span class="string">&quot;not empty&quot;</span> : <span class="string">&quot;empty&quot;</span>) &lt;&lt; std::endl;</span><br><span class="line">  std::cout &lt;&lt; <span class="string">&quot;Pointer u2 is &quot;</span> &lt;&lt; (u2 ? <span class="string">&quot;not empty&quot;</span> : <span class="string">&quot;empty&quot;</span>) &lt;&lt; std::endl;</span><br><span class="line">  std::cout &lt;&lt; <span class="string">&quot;Pointer u3 is &quot;</span> &lt;&lt; (u3 ? <span class="string">&quot;not empty&quot;</span> : <span class="string">&quot;empty&quot;</span>) &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// unique_ptr 不能被拷贝（没有拷贝构造函数），因此以下代码不能编译：</span></span><br><span class="line">  <span class="comment">// std::unique_ptr&lt;Point&gt; u4 = u3;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 但是可以通过 std::move 转移所有权</span></span><br><span class="line">  std::unique_ptr&lt;Point&gt; u4 = std::<span class="built_in">move</span>(u3);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 因为所有权已经转移到 u4，u3 现在为空</span></span><br><span class="line">  std::cout &lt;&lt; <span class="string">&quot;Pointer u3 is &quot;</span> &lt;&lt; (u3 ? <span class="string">&quot;not empty&quot;</span> : <span class="string">&quot;empty&quot;</span>) &lt;&lt; std::endl;</span><br><span class="line">  std::cout &lt;&lt; <span class="string">&quot;Pointer u4 is &quot;</span> &lt;&lt; (u4 ? <span class="string">&quot;not empty&quot;</span> : <span class="string">&quot;empty&quot;</span>) &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 传递 unique_ptr 给函数</span></span><br><span class="line">  <span class="built_in">SetXTo445</span>(u4);  <span class="comment">// 通过引用传递，确保所有权没有改变</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 打印 u4 的 x 值，确认所有权未变且对象已被修改</span></span><br><span class="line">  std::cout &lt;&lt; <span class="string">&quot;Pointer u4&#x27;s x value is &quot;</span> &lt;&lt; u4-&gt;<span class="built_in">GetX</span>() &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="stdshared_ptr"><code>std::shared_ptr</code></h3><p><code>std::shared_ptr</code>实现了<strong>共享所有权</strong>的机制，这意味着多个<code>shared_ptr</code> 实例可以指向同一个对象，且每个<code>shared_ptr</code> 的析构都会降低对象的引用计数。当引用计数降至 0时，所管理的对象会被自动销毁。 *<strong>拷贝构造与赋值</strong>：<code>std::shared_ptr</code>支持拷贝构造和赋值操作符。这些操作会导致引用计数（<code>use_count</code>）增加。* <strong>转移所有权</strong>：可以通过 <code>std::move</code> 转移<code>shared_ptr</code> 的所有权，使得原来的 <code>shared_ptr</code>成为“空”指针，而新的 <code>shared_ptr</code> 会接管原来的对象。</p><h4 id="创建和初始化shared_ptr">创建和初始化<code>shared_ptr</code></h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">std::shared_ptr&lt;Point&gt; s1;</span><br><span class="line">std::shared_ptr&lt;Point&gt; s2 = std::<span class="built_in">make_shared</span>&lt;Point&gt;();</span><br><span class="line">std::shared_ptr&lt;Point&gt; s3 = std::<span class="built_in">make_shared</span>&lt;Point&gt;(<span class="number">2</span>, <span class="number">3</span>);</span><br></pre></td></tr></table></figure><h4 id="引用计数与拷贝构造">引用计数与拷贝构造</h4><ul><li>初始时，<code>s3</code> 是唯一一个指向 <code>Point</code>对象的指针，因此引用计数为 1；将 <code>s3</code> 拷贝给 <code>s4</code>后，引用计数增加到 2，表示 <code>s3</code> 和 <code>s4</code>都指向同一块内存。<ul><li>修改 <code>s3</code> 的数据会影响<code>s4</code>，因为它们共享同一个对象。<strong><code>shared_ptr</code>确保当任何一个指针修改对象时，所有的共享指针都会看到这个变化</strong>。<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">std::cout &lt;&lt; <span class="string">&quot;s3 use_count: &quot;</span> &lt;&lt; s<span class="number">3.</span><span class="built_in">use_count</span>() &lt;&lt; std::endl;  <span class="comment">// 输出 1</span></span><br><span class="line">std::shared_ptr&lt;Point&gt; s4 = s3;</span><br><span class="line">std::cout &lt;&lt; <span class="string">&quot;s3 use_count after copy: &quot;</span> &lt;&lt; s<span class="number">3.</span><span class="built_in">use_count</span>() &lt;&lt; std::endl;  <span class="comment">// 输出 2</span></span><br></pre></td></tr></table></figure></li></ul></li></ul><h4 id="转移所有权">转移所有权</h4><ul><li>使用 <code>std::move</code> 可以将 <code>s5</code> 的所有权转移到<code>s6</code>。此时，<code>s5</code> 变为空指针，而 <code>s6</code>接管了原来 <code>s5</code> 所指向的对象。 <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">std::shared_ptr&lt;Point&gt; s6 = std::<span class="built_in">move</span>(s5);</span><br></pre></td></tr></table></figure></li></ul><h4 id="通过引用和右值引用传递shared_ptr">通过引用和右值引用传递<code>shared_ptr</code></h4><ul><li>通过<strong>引用</strong>传递时，原始的 <code>shared_ptr</code>仍然<strong>保持所有权</strong>；</li><li>通过<strong>右值引用</strong>传递时，<strong>所有权会转移到函数内的指针</strong>。<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">modify_ptr_via_ref</span><span class="params">(std::shared_ptr&lt;Point&gt; &amp;point)</span> </span>&#123; point-&gt;<span class="built_in">SetX</span>(<span class="number">15</span>); &#125;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">modify_ptr_via_rvalue_ref</span><span class="params">(std::shared_ptr&lt;Point&gt; &amp;&amp;point)</span> </span>&#123;point-&gt;<span class="built_in">SetY</span>(<span class="number">645</span>);&#125;</span><br></pre></td></tr></table></figure></li></ul><h2 id="c标准库同步原语">C++标准库同步原语</h2><p>在并发编程中，同步原语用于管理线程之间的访问顺序、共享资源的访问权限以及防止数据竞争。在C++标准库（STL）中，提供了一些同步原语，用于实现线程安全和协调多个线程的执行。以下是STL 中常见的同步原语及其说明。</p><h3 id="stdmutex"><code>std::mutex</code></h3><ul><li><code>std::mutex</code>提供了基本的互斥锁功能，保证在<strong>同一时刻只有一个线程可以访问</strong>共享资源。<ul><li><code>lock()</code> 和 <code>unlock()</code>用于手动获取和释放锁，确保线程在访问共享资源时是独占的。</li><li>C++11 引入了 <code>std::lock_guard</code> 和<code>std::unique_lock</code> 等工具，这些工具通过RAII（资源获取即初始化）模式简化了锁的管理，自动管理锁的获取和释放。</li></ul></li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span> <span class="comment">// 包含 std::cout 用于打印输出</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;mutex&gt;</span>    <span class="comment">// 包含 std::mutex 库</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thread&gt;</span>   <span class="comment">// 包含 std::thread 库，用于创建线程</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 定义一个全局计数变量和一个 mutex 互斥锁</span></span><br><span class="line"><span class="type">int</span> count = <span class="number">0</span>;</span><br><span class="line">std::mutex m;  <span class="comment">// 声明并默认初始化一个互斥锁 m</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// add_count 函数允许线程原子性地将 count 增加 1</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">add_count</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 在访问共享资源 count 之前，首先获取锁</span></span><br><span class="line">  m.<span class="built_in">lock</span>();</span><br><span class="line">  count += <span class="number">1</span>;</span><br><span class="line">  <span class="comment">// 操作完成后，释放锁</span></span><br><span class="line">  m.<span class="built_in">unlock</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 创建两个线程，分别运行 add_count 函数</span></span><br><span class="line">  <span class="function">std::thread <span class="title">t1</span><span class="params">(add_count)</span></span>;</span><br><span class="line">  <span class="function">std::thread <span class="title">t2</span><span class="params">(add_count)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 等待两个线程完成执行</span></span><br><span class="line">  t<span class="number">1.</span><span class="built_in">join</span>();</span><br><span class="line">  t<span class="number">2.</span><span class="built_in">join</span>();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 打印 count 的最终值</span></span><br><span class="line">  std::cout &lt;&lt; <span class="string">&quot;Printing count: &quot;</span> &lt;&lt; count &lt;&lt; std::endl;</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="stdscoped_lock"><code>std::scoped_lock</code></h3><ul><li><code>std::scoped_lock</code> 是 C++11引入的一个新的互斥锁包装类，它遵循 RAII（资源获取即初始化）范式。在构造<code>std::scoped_lock</code>对象时，它会<strong>自动获取指定的互斥锁，并在作用域结束时自动释放锁</strong>。<ul><li>这使得锁的管理变得更加简洁和安全，避免了手动调用 <code>lock()</code>和 <code>unlock()</code> 的错误;</li><li>它确保互斥锁会被自动释放，无论函数如何退出（正常结束或抛出异常）;</li><li><code>std::scoped_lock</code>会<strong>按传递顺序</strong>自动获取多个锁：如果需要在同一作用域中锁定多个互斥锁，可以使用<code>std::scoped_lock</code>来确保按正确的顺序获取锁，避免死锁问题。</li></ul></li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span> <span class="comment">// 包含 std::cout 用于打印输出</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;mutex&gt;</span>    <span class="comment">// 包含 std::mutex 库</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thread&gt;</span>   <span class="comment">// 包含 std::thread 库，用于创建线程</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 定义一个全局计数变量和一个互斥锁</span></span><br><span class="line"><span class="type">int</span> count = <span class="number">0</span>;</span><br><span class="line">std::mutex m;  <span class="comment">// 声明并默认初始化一个互斥锁 m</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// add_count 函数允许线程原子性地将 count 增加 1</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">add_count</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 使用 std::scoped_lock 自动获取互斥锁 m</span></span><br><span class="line">  <span class="function">std::scoped_lock <span class="title">slk</span><span class="params">(m)</span></span>;  <span class="comment">// 锁 m，作用范围在 slk 对象的生命周期内</span></span><br><span class="line">  count += <span class="number">1</span>;</span><br><span class="line">  <span class="comment">// 在函数结束时，slk 销毁，mutex m 被自动释放</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 创建两个线程，分别运行 add_count 函数</span></span><br><span class="line">  <span class="function">std::thread <span class="title">t1</span><span class="params">(add_count)</span></span>;</span><br><span class="line">  <span class="function">std::thread <span class="title">t2</span><span class="params">(add_count)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 等待两个线程完成执行</span></span><br><span class="line">  t<span class="number">1.</span><span class="built_in">join</span>();</span><br><span class="line">  t<span class="number">2.</span><span class="built_in">join</span>();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 打印 count 的最终值</span></span><br><span class="line">  std::cout &lt;&lt; <span class="string">&quot;Printing count: &quot;</span> &lt;&lt; count &lt;&lt; std::endl;</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="条件变量stdcondition_variable">条件变量<code>std::condition_variable</code></h3><h4 id="主要功能">主要功能</h4><ul><li>条件变量使得线程可以在满足某个条件之前挂起（等待）；</li><li>通知机制：线程可以<strong>通过条件变量，通知等待线程某个条件的改变</strong>（例如，条件变为true）；</li></ul><h4 id="关键组件">关键组件</h4><ol type="1"><li><code>std::mutex</code>：用于保护共享资源，防止数据竞争；</li><li><code>std::condition_variable</code>：用于实现条件同步；</li><li><code>std::unique_lock</code>：配合条件变量使用，允许线程在等待期间释放锁，以便其他线程可以访问共享资源；当条件满足时，<code>unique_lock</code>会重新获得锁。</li></ol><ul><li><code>cv.wait(lk, pred)</code>：该函数<strong>使线程阻塞，直到<code>pred</code> 条件返回<code>true</code></strong>。在等待期间，线程会释放锁，当条件成立时会重新获取锁。</li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;condition_variable&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;mutex&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thread&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> count = <span class="number">0</span>;                    <span class="comment">// 全局计数器</span></span><br><span class="line">std::mutex m;                     <span class="comment">// 互斥锁，用于同步对 count 的访问</span></span><br><span class="line">std::condition_variable cv;       <span class="comment">// 条件变量，用于线程间同步</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 函数用于增加 count 值并在 count == 2 时通知等待线程</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">add_count_and_notify</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="function">std::scoped_lock <span class="title">slk</span><span class="params">(m)</span></span>;        <span class="comment">// 自动加锁和解锁</span></span><br><span class="line">  count += <span class="number">1</span>;</span><br><span class="line">  <span class="keyword">if</span> (count == <span class="number">2</span>) &#123;</span><br><span class="line">    cv.<span class="built_in">notify_one</span>();              <span class="comment">// 如果 count 达到 2，通知一个等待线程</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 等待线程函数，等待 count == 2 时继续执行</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">waiter_thread</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="function">std::unique_lock <span class="title">lk</span><span class="params">(m)</span></span>;         <span class="comment">// 使用 unique_lock 管理锁</span></span><br><span class="line">  cv.<span class="built_in">wait</span>(lk, []&#123; <span class="keyword">return</span> count == <span class="number">2</span>; &#125;);  <span class="comment">// 等待条件成立，count == 2</span></span><br><span class="line">  std::cout &lt;&lt; <span class="string">&quot;Printing count: &quot;</span> &lt;&lt; count &lt;&lt; std::endl; <span class="comment">// 打印 count 值</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 创建三个线程，t1 和 t2 会运行 add_count_and_notify，t3 运行 waiter_thread</span></span><br><span class="line">  <span class="function">std::thread <span class="title">t1</span><span class="params">(add_count_and_notify)</span></span>;</span><br><span class="line">  <span class="function">std::thread <span class="title">t2</span><span class="params">(add_count_and_notify)</span></span>;</span><br><span class="line">  <span class="function">std::thread <span class="title">t3</span><span class="params">(waiter_thread)</span></span>;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 等待线程执行完成</span></span><br><span class="line">  t<span class="number">1.</span><span class="built_in">join</span>();</span><br><span class="line">  t<span class="number">2.</span><span class="built_in">join</span>();</span><br><span class="line">  t<span class="number">3.</span><span class="built_in">join</span>();</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="c-stl-示例读写锁rwlock模拟">C++ STL示例：读写锁（RWLock）模拟</h3><p>C++ 标准库（STL）并没有直接提供读写锁（Reader-WriterLock）的实现，但可以通过<code>std::shared_mutex</code>、<code>std::shared_lock</code> 和<code>std::unique_lock</code> 来模拟读写锁的行为。</p><h4 id="关键组件-1">关键组件</h4><ol type="1"><li><code>std::shared_mutex m</code>：共享互斥锁，保护对<code>count</code> 变量的访问</li><li>共享锁（<code>std::shared_lock</code>）：在<code>read_value()</code> 中，<code>std::shared_lock</code>允许多个线程同时读取 <code>count</code>，但不能同时进行写入操作。</li><li>独占锁（<code>std::unique_lock</code>）：在<code>write_value()</code> 中，<code>std::unique_lock</code>确保每次只有一个线程可以修改<code>count</code>，从而避免了数据竞争。</li></ol><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;mutex&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;shared_mutex&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;thread&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 全局变量 count 和共享互斥锁 m，用于保护 count</span></span><br><span class="line"><span class="type">int</span> count = <span class="number">0</span>;</span><br><span class="line">std::shared_mutex m;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 读取值的函数，使用 std::shared_lock 获取共享锁，表示读操作</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">read_value</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="function">std::shared_lock <span class="title">lk</span><span class="params">(m)</span></span>;  <span class="comment">// 获取共享锁</span></span><br><span class="line">  std::cout &lt;&lt; <span class="string">&quot;Reading value &quot;</span> + std::<span class="built_in">to_string</span>(count) + <span class="string">&quot;\n&quot;</span> &lt;&lt; std::flush;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 写入值的函数，使用 std::unique_lock 获取独占锁，表示写操作</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">write_value</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="function">std::unique_lock <span class="title">lk</span><span class="params">(m)</span></span>;  <span class="comment">// 获取独占锁</span></span><br><span class="line">  count += <span class="number">3</span>;  <span class="comment">// 对 count 进行修改</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 创建六个线程，两个执行写操作，四个执行读操作</span></span><br><span class="line">  <span class="function">std::thread <span class="title">t1</span><span class="params">(read_value)</span></span>;  <span class="comment">// 读取操作</span></span><br><span class="line">  <span class="function">std::thread <span class="title">t2</span><span class="params">(write_value)</span></span>; <span class="comment">// 写入操作</span></span><br><span class="line">  <span class="function">std::thread <span class="title">t3</span><span class="params">(read_value)</span></span>;  <span class="comment">// 读取操作</span></span><br><span class="line">  <span class="function">std::thread <span class="title">t4</span><span class="params">(read_value)</span></span>;  <span class="comment">// 读取操作</span></span><br><span class="line">  <span class="function">std::thread <span class="title">t5</span><span class="params">(write_value)</span></span>; <span class="comment">// 写入操作</span></span><br><span class="line">  <span class="function">std::thread <span class="title">t6</span><span class="params">(read_value)</span></span>;  <span class="comment">// 读取操作</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 等待所有线程完成</span></span><br><span class="line">  t<span class="number">1.</span><span class="built_in">join</span>();</span><br><span class="line">  t<span class="number">2.</span><span class="built_in">join</span>();</span><br><span class="line">  t<span class="number">3.</span><span class="built_in">join</span>();</span><br><span class="line">  t<span class="number">4.</span><span class="built_in">join</span>();</span><br><span class="line">  t<span class="number">5.</span><span class="built_in">join</span>();</span><br><span class="line">  t<span class="number">6.</span><span class="built_in">join</span>();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> C++ Primer </category>
          
      </categories>
      
      
        <tags>
            
            <tag> C++ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello，world！C++中的引用、移动语义、模板、包装类、迭代器和命名空间</title>
      <link href="/posts/73de9bd.html"/>
      <url>/posts/73de9bd.html</url>
      
        <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>Hello，world！今天是2025年3月12日，这是本站的第一篇博客，也是我重新踏上自学CS之路的起点！</p><p>回想已流逝的两年半多本科时光，很多课程因为时间紧、任务重，学得像个“快餐式”程序员——知识点匆匆下肚，消化得却不咋样；ppt上的知识点背了一打，实践起来“一问三不知”。猛然发现，自己像个“半成品”，代码写得像“面条”，bug多得像“打地鼠”。</p><p>恰逢找到第一个日常实习，初尝真实的工作环境。实习之余决定重启学习，重新修炼“代码内功”。</p><p>从哪里开始呢？第一站是C++的基本语法。之前刷算法题时用过C++，每次没有类、没有封装、没有unit test、没有 Makefile、没有Git，唯一的优点是它确实能跑，缺点是“能跑”的补集；大三上做过一个4000行代码的Qt小项目，实现简单图像识别与参量的自动化计算（可见：<a href="https://github.com/WenLiuyi/fiber_Analysis">https://github.com/WenLiuyi/fiber_Analysis</a>）现已经成功打包成exe文件，可在Windows系统执行。但那过程简直像“渡劫”——装了几十个G 的 Visual Studio，每次打开那笨重的IDE，配置环境像“解谜游戏”，编译错误像“天书”，代码结构像“迷宫”。每次debug都像在玩“找茬”，头大得能顶个西瓜！但这些“坑”让我明白，自己的知识储备还像个“小池塘”，远远不够用。</p><p>这条路不会像“Hello,world!”那么简单，但最好的时机，就是现在！从“零”开始，走向“无穷大”！（超级感谢<a href="https://csdiy.wiki/">CS自学指南</a>）</p><h1 id="c预备知识">C++预备知识</h1><ul><li><a href="https://en.cppreference.com/w/cpp/language/reference">References</a></li><li><a href="https://en.cppreference.com/w/cpp/utility/move">std::move</a></li><li><a href="https://en.cppreference.com/w/cpp/language/move_constructor">MoveConstructors</a>和<a href="https://en.cppreference.com/w/cpp/language/move_assignment">MoveAssignment Operators</a></li></ul><h2 id="引用和移动">引用和移动</h2><h3 id="引用">引用</h3><h4 id="概述">概述</h4><p>引用是 C++中的一种机制，用来创建变量的别名。通过引用，<strong>多个名字可以指向同一块内存区域</strong>。引用通常用于函数参数的传递、改动数据的追踪以及提升性能等场景。*初始化：引用必须在声明时初始化，并且一旦绑定到一个变量后不能改变指向另一个变量。* 参考传递（Pass byReference）：引用是一种传递方式，允许函数修改调用者的变量值。 *性能优化：通过引用避免了数据的复制，提高了效率，尤其是在传递大数据结构时。</p><h4 id="引用的声明">引用的声明</h4><p>引用的声明使用的是单个 &amp; 符号。例如： <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> a = <span class="number">10</span>;</span><br><span class="line"><span class="type">int</span> &amp;b = a;  <span class="comment">// b 是 a 的引用</span></span><br></pre></td></tr></table></figure> 这意味着 b只是 a 的另一个名字，a 和 b 都指向同一个内存位置。如果我们修改b，实际上就是修改 a 的值。</p><h4 id="示例代码">示例代码</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 一个接受 int 引用并将其值增加 3 的函数</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">add_three</span><span class="params">(<span class="type">int</span> &amp;a)</span> </span>&#123; </span><br><span class="line">    a = a + <span class="number">3</span>; </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> a = <span class="number">10</span>;   <span class="comment">// 定义一个整型变量 a</span></span><br><span class="line">    <span class="type">int</span> &amp;b = a;   <span class="comment">// b 是 a 的引用，它指向 a</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 输出 b 的值，此时 b 的值为 10</span></span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;b is &quot;</span> &lt;&lt; b &lt;&lt; std::endl;  </span><br><span class="line"></span><br><span class="line">    <span class="comment">// 调用 add_three 函数，传入 a 的引用，a 的值将被修改</span></span><br><span class="line">    <span class="built_in">add_three</span>(a);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 输出 a 的新值，add_three 函数已将 a 增加了 3</span></span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;a is &quot;</span> &lt;&lt; a &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="c移动语义">C++移动语义</h3><h4 id="概述-1">概述</h4><p>移动语义是 C++中的一种重要特性，旨在提高程序的性能，特别是在处理大型数据结构时。移动语义通过避免不必要的深拷贝，使得对象之间的数据转移更加高效。与传统的拷贝操作不同，移动操作<strong>通过“转移所有权”的方式，使得对象的资源能够直接从一个对象转移到另一个对象，而不是复制数据</strong>。移动语义的核心概念在于区分 左值（lvalue） 和 右值（rvalue）： *左值（lvalue）：是指向<strong>内存中某个位置的对象</strong>，可以持久存在。 *右值（rvalue）是<strong>临时对象</strong>，通常用于表示临时的、不再需要的对象。 *性能提升：使用 <code>std::move</code>可以避免不必要的深拷贝。特别是当我们操作如<code>std::vector</code>、<code>std::string</code>等需要大量内存的容器时，移动比拷贝要高效得多。</p><h4 id="主要概念">主要概念</h4><ol type="1"><li><code>std::move</code>： <code>std::move</code>不是“移动”操作本身，而是将一个对象标记为可以被移动的状态，实际上它只是一个类型转换操作，<strong>将左值转换为右值</strong>。之后，移动构造函数或移动赋值操作符会将对象的所有权，从一个对象转移到另一个对象。</li><li>右值引用（Rvalue Reference）： 右值引用是使用<code>&amp;&amp;</code>语法声明的引用，它绑定到一个右值上。通过右值引用，我们可以通过移动语义避免不必要的拷贝。</li></ol><h4 id="示例代码-1">示例代码</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;utility&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 一个接收右值引用作为参数的函数</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">move_add_three_and_print</span><span class="params">(std::vector&lt;<span class="type">int</span>&gt; &amp;&amp;vec)</span> </span>&#123;</span><br><span class="line">  std::vector&lt;<span class="type">int</span>&gt; vec1 = std::<span class="built_in">move</span>(vec);  <span class="comment">// 使用 std::move 转移 vec 的所有权</span></span><br><span class="line">  vec<span class="number">1.</span><span class="built_in">push_back</span>(<span class="number">3</span>);  <span class="comment">// 向 vec1 添加一个元素</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="type">const</span> <span class="type">int</span> &amp;item : vec1) &#123;</span><br><span class="line">    std::cout &lt;&lt; item &lt;&lt; <span class="string">&quot; &quot;</span>;  <span class="comment">// 打印 vec1 中的元素</span></span><br><span class="line">  &#125;</span><br><span class="line">  std::cout &lt;&lt; <span class="string">&quot;\n&quot;</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 一个接收右值引用的函数，但不获取所有权，仅修改数据</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">add_three_and_print</span><span class="params">(std::vector&lt;<span class="type">int</span>&gt; &amp;&amp;vec)</span> </span>&#123;</span><br><span class="line">  vec.<span class="built_in">push_back</span>(<span class="number">3</span>);</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">const</span> <span class="type">int</span> &amp;item : vec) &#123;</span><br><span class="line">    std::cout &lt;&lt; item &lt;&lt; <span class="string">&quot; &quot;</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  std::cout &lt;&lt; <span class="string">&quot;\n&quot;</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="type">int</span> a = <span class="number">10</span>;  <span class="comment">// &#x27;a&#x27; 是左值</span></span><br><span class="line"></span><br><span class="line">  std::vector&lt;<span class="type">int</span>&gt; int_array = &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>&#125;;  <span class="comment">// 定义一个整数向量</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 将 int_array 的数据转移到另一个向量</span></span><br><span class="line">  std::vector&lt;<span class="type">int</span>&gt; stealing_ints = std::<span class="built_in">move</span>(int_array);  <span class="comment">// 通过 std::move 将所有权转移</span></span><br><span class="line"></span><br><span class="line">  std::vector&lt;<span class="type">int</span>&gt; &amp;&amp;rvalue_stealing_ints = std::<span class="built_in">move</span>(stealing_ints);  <span class="comment">// 使用右值引用</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 虽然所有权已转移，但仍然可以访问原来数据（不过此时的行为不可预测）</span></span><br><span class="line">  std::cout &lt;&lt; <span class="string">&quot;Printing from stealing_ints: &quot;</span> &lt;&lt; stealing_ints[<span class="number">1</span>] &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 将右值引用传入函数，转移所有权</span></span><br><span class="line">  std::vector&lt;<span class="type">int</span>&gt; int_array2 = &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>&#125;;</span><br><span class="line">  std::cout &lt;&lt; <span class="string">&quot;Calling move_add_three_and_print...\n&quot;</span>;</span><br><span class="line">  <span class="built_in">move_add_three_and_print</span>(std::<span class="built_in">move</span>(int_array2));  <span class="comment">// 使用 std::move 转移 int_array2 的所有权</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 注意：一旦调用了 move_add_three_and_print，int_array2 中的数据就不再属于它，不能再访问</span></span><br><span class="line">  <span class="comment">// std::cout &lt;&lt; int_array2[1] &lt;&lt; std::endl;  // 访问已转移数据的行为未定义（可能崩溃）</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 另一种情况，使用右值引用，但不获取所有权</span></span><br><span class="line">  std::vector&lt;<span class="type">int</span>&gt; int_array3 = &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>&#125;;</span><br><span class="line">  std::cout &lt;&lt; <span class="string">&quot;Calling add_three_and_print...\n&quot;</span>;</span><br><span class="line">  <span class="built_in">add_three_and_print</span>(std::<span class="built_in">move</span>(int_array3));  <span class="comment">// 这里只是修改数据，不转移所有权</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 由于没有转移所有权，int_array3 仍然有效</span></span><br><span class="line">  std::cout &lt;&lt; <span class="string">&quot;Printing from int_array3: &quot;</span> &lt;&lt; int_array3[<span class="number">1</span>] &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="移动构造函数和移动赋值运算符">移动构造函数和移动赋值运算符</h3><h4 id="移动构造函数">移动构造函数</h4><p>移动构造函数用于在<strong>创建新对象</strong>时，将一个已有对象的资源从源对象“移动”到目标对象。通过std::move，源对象的资源将被转移给新对象，而源对象的状态会被置为无效。</p><h4 id="移动赋值运算符">移动赋值运算符</h4><p>移动赋值运算符用于将一个已有对象的资源从一个对象转移到另一个<strong>已存在的对象</strong>中。在此过程中，目标对象会接管源对象的资源，而源对象则失去对这些资源的所有权。</p><h4 id="示例代码-2">示例代码</h4><ol type="1"><li><code>Person</code>类包含3个构造函数：一个默认构造函数；一个带有右值引用参数的构造函数用于通过移动资源来初始化对象；一个移动构造函数</li><li>移动构造函数<code>Person(Person &amp;&amp;person)</code>：接受一个右值引用<code>Person &amp;&amp;person</code>，通过 <code>std::move</code> 转移<code>nicknames_</code> 和 <code>age_</code> 的所有权来创建新对象；</li><li>移动赋值运算符<code>Person &amp;operator=(Person &amp;&amp;other)</code>：将<code>other</code> 对象的资源转移到当前对象</li></ol><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;utility&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdint&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Person</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">  <span class="built_in">Person</span>() : <span class="built_in">age_</span>(<span class="number">0</span>), <span class="built_in">nicknames_</span>(&#123;&#125;), <span class="built_in">valid_</span>(<span class="literal">true</span>) &#123;&#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 移动构造函数：接受右值引用，转移资源</span></span><br><span class="line">  <span class="built_in">Person</span>(<span class="type">uint32_t</span> age, std::vector&lt;std::string&gt; &amp;&amp;nicknames)</span><br><span class="line">      : <span class="built_in">age_</span>(age), <span class="built_in">nicknames_</span>(std::<span class="built_in">move</span>(nicknames)), <span class="built_in">valid_</span>(<span class="literal">true</span>) &#123;&#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 复制构造函数已删除，不允许复制</span></span><br><span class="line">  <span class="built_in">Person</span>(<span class="type">const</span> Person &amp;) = <span class="keyword">delete</span>;</span><br><span class="line">  Person &amp;<span class="keyword">operator</span>=(<span class="type">const</span> Person &amp;) = <span class="keyword">delete</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 移动构造函数：从另一个 Person 对象移动资源</span></span><br><span class="line">  <span class="built_in">Person</span>(Person &amp;&amp;person)</span><br><span class="line">      : <span class="built_in">age_</span>(person.age_), <span class="built_in">nicknames_</span>(std::<span class="built_in">move</span>(person.nicknames_)),</span><br><span class="line">        <span class="built_in">valid_</span>(<span class="literal">true</span>) &#123;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;调用 Person 类的移动构造函数。\n&quot;</span>;</span><br><span class="line">    person.valid_ = <span class="literal">false</span>; <span class="comment">// 移动后，源对象的状态变为无效</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 移动赋值运算符：转移资源</span></span><br><span class="line">  Person &amp;<span class="keyword">operator</span>=(Person &amp;&amp;other) &#123;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;调用 Person 类的移动赋值运算符。\n&quot;</span>;</span><br><span class="line">    age_ = other.age_;</span><br><span class="line">    nicknames_ = std::<span class="built_in">move</span>(other.nicknames_);</span><br><span class="line">    valid_ = <span class="literal">true</span>;</span><br><span class="line">    other.valid_ = <span class="literal">false</span>; <span class="comment">// 源对象的状态变为无效</span></span><br><span class="line">    <span class="keyword">return</span> *<span class="keyword">this</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">uint32_t</span> <span class="title">GetAge</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> age_; &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 返回 nicknames_ 中的某个字符串的引用</span></span><br><span class="line">  <span class="function">std::string &amp;<span class="title">GetNicknameAtI</span><span class="params">(<span class="type">size_t</span> i)</span> </span>&#123; <span class="keyword">return</span> nicknames_[i]; &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">PrintValid</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (valid_) &#123;</span><br><span class="line">      std::cout &lt;&lt; <span class="string">&quot;对象有效。\n&quot;</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      std::cout &lt;&lt; <span class="string">&quot;对象无效。\n&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">  <span class="type">uint32_t</span> age_;</span><br><span class="line">  std::vector&lt;std::string&gt; nicknames_;</span><br><span class="line">  <span class="type">bool</span> valid_; <span class="comment">// 追踪对象的有效性</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 创建一个 Person 对象 andy，并初始化其昵称和年龄</span></span><br><span class="line">  <span class="function">Person <span class="title">andy</span><span class="params">(<span class="number">15445</span>, &#123;<span class="string">&quot;andy&quot;</span>, <span class="string">&quot;pavlo&quot;</span>&#125;)</span></span>;</span><br><span class="line">  std::cout &lt;&lt; <span class="string">&quot;打印 andy 的有效性: &quot;</span>;</span><br><span class="line">  andy.<span class="built_in">PrintValid</span>();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 使用 std::move 调用移动赋值运算符，将 andy 的内容转移到 andy1</span></span><br><span class="line">  Person andy1;</span><br><span class="line">  andy1 = std::<span class="built_in">move</span>(andy);  <span class="comment">// 调用移动赋值运算符</span></span><br><span class="line"></span><br><span class="line">  std::cout &lt;&lt; <span class="string">&quot;打印 andy1 的有效性: &quot;</span>;</span><br><span class="line">  andy<span class="number">1.</span><span class="built_in">PrintValid</span>();</span><br><span class="line">  std::cout &lt;&lt; <span class="string">&quot;打印 andy 的有效性: &quot;</span>;</span><br><span class="line">  andy.<span class="built_in">PrintValid</span>();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 使用 std::move 调用移动构造函数，将 andy1 的内容转移到 andy2</span></span><br><span class="line">  <span class="function">Person <span class="title">andy2</span><span class="params">(std::move(andy1))</span></span>;  <span class="comment">// 调用移动构造函数</span></span><br><span class="line"></span><br><span class="line">  std::cout &lt;&lt; <span class="string">&quot;打印 andy2 的有效性: &quot;</span>;</span><br><span class="line">  andy<span class="number">2.</span><span class="built_in">PrintValid</span>();</span><br><span class="line">  std::cout &lt;&lt; <span class="string">&quot;打印 andy1 的有效性: &quot;</span>;</span><br><span class="line">  andy<span class="number">1.</span><span class="built_in">PrintValid</span>();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 以下代码会因为复制构造函数被删除而无法编译</span></span><br><span class="line">  <span class="comment">// Person andy3;</span></span><br><span class="line">  <span class="comment">// andy3 = andy2;  // 编译错误，不能使用复制赋值运算符</span></span><br><span class="line">  <span class="comment">// Person andy4(andy2);  // 编译错误，不能使用复制构造函数</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="模板">模板</h2><p>模板是C++中的一种语言特性，它允许你编写可以与多种数据类型一起工作的代码，而无需指定具体的类型。C++中既可以创建模板函数，也可以创建模板类。</p><h3 id="模板类">模板类</h3><ul><li>模板类使得类能够与不同的数据类型一起工作，而不需要为每个数据类型编写不同的类实现。</li></ul><h4 id="基本模板类">基本模板类</h4><p>下面是一个基本的模板类 Foo，它可以存储一个模板类型的元素，并在调用print 函数时打印该元素的值： * T 是模板参数，表示类 Foo可以存储任何类型的值。var_ 是存储该值的成员变量，print函数用来打印该值。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Foo</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">Foo</span>(T var) : <span class="built_in">var_</span>(var) &#123;&#125;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">print</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        std::cout &lt;&lt; var_ &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    T var_;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h4 id="使用多个模板参数">使用多个模板参数</h4><p>模板类不仅支持单一模板参数，还可以支持多个模板参数。以下是一个接受两个不同类型参数的模板类Foo2： * Foo2 类存储了两个不同类型的元素 var1_ 和 var2_，并在 print函数中打印它们。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T, <span class="keyword">typename</span> U&gt; </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Foo2</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">Foo2</span>(T var1, U var2) : <span class="built_in">var1_</span>(var1), <span class="built_in">var2_</span>(var2) &#123;&#125;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">print</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        std::cout &lt;&lt; var1_ &lt;&lt; <span class="string">&quot; and &quot;</span> &lt;&lt; var2_ &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    T var1_;</span><br><span class="line">    U var2_;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h4 id="特化模板类">特化模板类</h4><p>C++允许为特定类型提供模板类的专门实现，这称为模板类特化。以下是一个模板类<code>FooSpecial</code>，它的 <code>print</code>函数根据模板参数类型的不同执行不同的操作： *在这个例子中，<code>FooSpecial</code> 是一个模板类，当它的类型是<code>float</code> 时，<code>print</code> 函数会输出不同的信息（"hellofloat!"），而其他类型则按照常规输出存储的值。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FooSpecial</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">FooSpecial</span>(T var) : <span class="built_in">var_</span>(var) &#123;&#125;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">print</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        std::cout &lt;&lt; var_ &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    T var_;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="comment">// 针对float类型的模板特化</span></span><br><span class="line"><span class="keyword">template</span>&lt;&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FooSpecial</span>&lt;<span class="type">float</span>&gt; &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">FooSpecial</span>(<span class="type">float</span> var) : <span class="built_in">var_</span>(var) &#123;&#125;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">print</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;hello float! &quot;</span> &lt;&lt; var_ &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="type">float</span> var_;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h4 id="使用非类型模板参数">使用非类型模板参数</h4><p>除了类型作为模板参数外，还可以使用常量（如整数）作为模板参数。以下是一个例子，其中<code>Bar</code> 类接受一个整数作为模板参数： * <code>Bar</code>类接受一个整数模板参数 T，并在 <code>print_int</code>函数中输出该常量值。 <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="type">int</span> T&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Bar</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">Bar</span>() &#123;&#125;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">print_int</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;print int: &quot;</span> &lt;&lt; T &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure> #### 示例 <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 使用模板类型 int 实例化 Foo 类</span></span><br><span class="line"><span class="function">Foo&lt;<span class="type">int</span>&gt; <span class="title">a</span><span class="params">(<span class="number">3</span>)</span></span>;</span><br><span class="line">std::cout &lt;&lt; <span class="string">&quot;Calling print on Foo&lt;int&gt; a(3): &quot;</span>;</span><br><span class="line">a.<span class="built_in">print</span>();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用模板类型 float 实例化 Foo 类</span></span><br><span class="line"><span class="function">Foo <span class="title">b</span><span class="params">(<span class="number">3.4f</span>)</span></span>;</span><br><span class="line">std::cout &lt;&lt; <span class="string">&quot;Calling print on Foo b(3.4f): &quot;</span>;</span><br><span class="line">b.<span class="built_in">print</span>();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用两个不同模板类型实例化 Foo2 类</span></span><br><span class="line"><span class="function">Foo2&lt;<span class="type">int</span>, <span class="type">float</span>&gt; <span class="title">c</span><span class="params">(<span class="number">3</span>, <span class="number">3.2f</span>)</span></span>;</span><br><span class="line">std::cout &lt;&lt; <span class="string">&quot;Calling print on Foo2&lt;int, float&gt; c(3, 3.2f): &quot;</span>;</span><br><span class="line">c.<span class="built_in">print</span>();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 实例化 FooSpecial 类，分别使用 int 和 float 类型</span></span><br><span class="line"><span class="function">FooSpecial&lt;<span class="type">int</span>&gt; <span class="title">d</span><span class="params">(<span class="number">5</span>)</span></span>;</span><br><span class="line">std::cout &lt;&lt; <span class="string">&quot;Calling print on FooSpecial&lt;int&gt; d(5): &quot;</span>;</span><br><span class="line">d.<span class="built_in">print</span>();</span><br><span class="line"></span><br><span class="line"><span class="function">FooSpecial&lt;<span class="type">float</span>&gt; <span class="title">e</span><span class="params">(<span class="number">4.5</span>)</span></span>;</span><br><span class="line">std::cout &lt;&lt; <span class="string">&quot;Calling print on FooSpecial&lt;float&gt; e(4.5): &quot;</span>;</span><br><span class="line">e.<span class="built_in">print</span>();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用非类型模板参数实例化 Bar 类</span></span><br><span class="line">Bar&lt;<span class="number">150</span>&gt; f;</span><br><span class="line">std::cout &lt;&lt; <span class="string">&quot;Calling print_int on Bar&lt;150&gt; f: &quot;</span>;</span><br><span class="line">f.<span class="built_in">print_int</span>();</span><br></pre></td></tr></table></figure></p><h3 id="模板函数">模板函数</h3><h4 id="基本模板函数">基本模板函数</h4><p>C++模板函数的语法允许函数接受<strong>任何类型的数据</strong>作为参数，而不需要显式地定义数据类型。可以使用<code>template</code> 关键字来定义模板函数： <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt; </span><br><span class="line"><span class="function">T <span class="title">add</span><span class="params">(T a, T b)</span> </span>&#123; </span><br><span class="line">    <span class="keyword">return</span> a + b; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>这个函数接受两种相同类型的参数，返回它们的和。<code>typename T</code>是模板参数，表示函数可以接受任意类型的数据。</p><h4 id="多个模板参数">多个模板参数</h4><p>模板函数可以接受多个模板参数。例如，下面的<code>print_two_values</code> 函数接受两种不同类型的参数：<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T, <span class="keyword">typename</span> U&gt;</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">print_two_values</span><span class="params">(T a, U b)</span> </span>&#123;</span><br><span class="line">    std::cout &lt;&lt; a &lt;&lt; <span class="string">&quot; and &quot;</span> &lt;&lt; b &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure> 该函数输出两个不同类型的参数。</p><h4 id="特化模板函数">特化模板函数</h4><p>C++允许<strong>为特定类型提供模板函数的专门实现</strong>，这称为模板特化。在下面的例子中，<code>print_msg</code>函数通常打印“Hello world!”，但当类型为 <code>float</code>时，打印不同的信息： <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt; </span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">print_msg</span><span class="params">()</span> </span>&#123; </span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Hello world!\n&quot;</span>; </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 针对float类型的模板特化</span></span><br><span class="line"><span class="keyword">template</span> &lt;&gt; </span><br><span class="line"><span class="type">void</span> <span class="built_in">print_msg</span>&lt;<span class="type">float</span>&gt;() &#123;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;print_msg called with float type!\n&quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h4 id="使用非类模板参数">使用非类模板参数</h4><p>模板的参数不一定非要是类型。你也可以使用常量表达式作为模板参数，例如下面的add3 函数，它根据传入的布尔值决定如何修改参数： <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="type">bool</span> T&gt; </span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">add3</span><span class="params">(<span class="type">int</span> a)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (T) &#123;</span><br><span class="line">        <span class="keyword">return</span> a + <span class="number">3</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> a;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>这个函数通过模板参数 T 决定是将 a 加上3还是不变。</p><h4 id="调用模板函数">调用模板函数</h4><p>下面是如何调用模板函数的示例： <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 调用 add&lt;int&gt; 和 add&lt;float&gt;</span></span><br><span class="line">std::cout &lt;&lt; <span class="string">&quot;Printing add&lt;int&gt;(3, 5): &quot;</span> &lt;&lt; <span class="built_in">add</span>&lt;<span class="type">int</span>&gt;(<span class="number">3</span>, <span class="number">5</span>) &lt;&lt; std::endl;</span><br><span class="line">std::cout &lt;&lt; <span class="string">&quot;Printing add&lt;float&gt;(2.8, 3.7): &quot;</span> &lt;&lt; <span class="built_in">add</span>&lt;<span class="type">float</span>&gt;(<span class="number">2.8</span>, <span class="number">3.7</span>) &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 类型推断（函数根据传入的参数类型推断模板类型）</span></span><br><span class="line">std::cout &lt;&lt; <span class="string">&quot;Printing add(3, 5): &quot;</span> &lt;&lt; <span class="built_in">add</span>(<span class="number">3</span>, <span class="number">5</span>) &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 调用 print_two_values</span></span><br><span class="line">std::cout &lt;&lt; <span class="string">&quot;Printing print_two_values&lt;int, float&gt;(3, 3.2): &quot;</span>;</span><br><span class="line"><span class="built_in">print_two_values</span>&lt;<span class="type">int</span>, <span class="type">float</span>&gt;(<span class="number">3</span>, <span class="number">3.2</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 调用 print_msg</span></span><br><span class="line">std::cout &lt;&lt; <span class="string">&quot;Calling print_msg&lt;int&gt;(): &quot;</span>;</span><br><span class="line"><span class="built_in">print_msg</span>&lt;<span class="type">int</span>&gt;();</span><br><span class="line">std::cout &lt;&lt; <span class="string">&quot;Calling print_msg&lt;float&gt;(): &quot;</span>;</span><br><span class="line"><span class="built_in">print_msg</span>&lt;<span class="type">float</span>&gt;();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 调用 add3</span></span><br><span class="line">std::cout &lt;&lt; <span class="string">&quot;Printing add3&lt;true&gt;(3): &quot;</span> &lt;&lt; <span class="built_in">add3</span>&lt;<span class="literal">true</span>&gt;(<span class="number">3</span>) &lt;&lt; std::endl;</span><br><span class="line">std::cout &lt;&lt; <span class="string">&quot;Printing add3&lt;false&gt;(3): &quot;</span> &lt;&lt; <span class="built_in">add3</span>&lt;<span class="literal">false</span>&gt;(<span class="number">3</span>) &lt;&lt; std::endl;</span><br><span class="line"></span><br></pre></td></tr></table></figure></p><h2 id="包装类">包装类</h2><p>在C++中，包装类是一种<strong>管理资源的类</strong>。资源可以是内存、文件句柄、网络连接等。包装类通常采用RAII（ResourceAcquisition IsInitialization，资源获取即初始化）编程技巧，这意味着<strong>资源的生命周期与类实例的生命周期绑定</strong>。当包装类的实例被构造时，它会获取相应的资源；而当实例被销毁时，资源会被释放。</p><h3 id="intptrmanager实现"><code>IntPtrManager</code>实现</h3><h4 id="构造函数">构造函数</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">IntPtrManager</span>() &#123;</span><br><span class="line">  ptr_ = <span class="keyword">new</span> <span class="type">int</span>;   <span class="comment">// 分配内存</span></span><br><span class="line">  *ptr_ = <span class="number">0</span>;        <span class="comment">// 初始化值为 0</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">IntPtrManager</span>(<span class="type">int</span> val) &#123;</span><br><span class="line">  ptr_ = <span class="keyword">new</span> <span class="type">int</span>;   <span class="comment">// 分配内存</span></span><br><span class="line">  *ptr_ = val;      <span class="comment">// 初始化为给定的值</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="析构函数">析构函数</h4><ul><li>析构函数通过 <code>delete</code> 释放 <code>ptr_</code>指向的内存。为了防止在移动语义中出现悬挂指针，它会检查<code>ptr_</code>是否为 <code>nullptr</code>。 <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">~<span class="built_in">IntPtrManager</span>() &#123;</span><br><span class="line">  <span class="keyword">if</span> (ptr_) &#123;</span><br><span class="line">    <span class="keyword">delete</span> ptr_;  <span class="comment">// 释放资源</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h4 id="移动构造函数和移动赋值操作符">移动构造函数和移动赋值操作符</h4><ul><li>由于<strong>包装类通常不允许复制</strong>，因为复制可能会导致双重删除资源（即两个对象管理同一资源），因此：删除了拷贝构造函数和拷贝赋值操作符，并实现了移动构造函数和移动赋值操作符。</li><li>移动构造函数： <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">IntPtrManager</span>(IntPtrManager&amp;&amp; other) &#123;</span><br><span class="line">  ptr_ = other.ptr_;  <span class="comment">// 转移资源</span></span><br><span class="line">  other.ptr_ = <span class="literal">nullptr</span>;  <span class="comment">// 设置源对象为无效状态</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li>移动赋值操作符： <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">IntPtrManager &amp;<span class="keyword">operator</span>=(IntPtrManager&amp;&amp; other) &#123;</span><br><span class="line">  <span class="keyword">if</span> (ptr_ == other.ptr_) &#123;</span><br><span class="line">    <span class="keyword">return</span> *<span class="keyword">this</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (ptr_) &#123;</span><br><span class="line">    <span class="keyword">delete</span> ptr_;  <span class="comment">// 释放当前资源</span></span><br><span class="line">  &#125;</span><br><span class="line">  ptr_ = other.ptr_;  <span class="comment">// 转移资源</span></span><br><span class="line">  other.ptr_ = <span class="literal">nullptr</span>;  <span class="comment">// 设置源对象为无效状态</span></span><br><span class="line">  <span class="keyword">return</span> *<span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h4 id="删除拷贝构造函数和拷贝赋值操作符">删除拷贝构造函数和拷贝赋值操作符</h4><ul><li>为了避免两个对象管理同一资源，IntPtrManager类的拷贝构造函数和拷贝赋值操作符被删除： <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">IntPtrManager</span>(<span class="type">const</span> IntPtrManager&amp;) = <span class="keyword">delete</span>;  <span class="comment">// 禁止拷贝构造</span></span><br><span class="line">IntPtrManager&amp; <span class="keyword">operator</span>=(<span class="type">const</span> IntPtrManager&amp;) = <span class="keyword">delete</span>;  <span class="comment">// 禁止拷贝赋值</span></span><br></pre></td></tr></table></figure></li></ul><h2 id="迭代器iterator">迭代器(Iterator)</h2><p>C++迭代器是<strong>指向容器中元素的对象</strong>，可以用来遍历容器中的元素。迭代器在C++ STL中被广泛使用，通常用来访问和修改容器中的元素。指针就是一种常见的迭代器，它可以用来遍历C 风格数组。</p><h3 id="基本操作">基本操作</h3><ol type="1"><li>**解引用运算符（*）**：返回当前迭代器指向元素的值；</li><li><strong>自增运算符（++）</strong>：将迭代器指向下一个元素。 STL中的容器（如 vector, set, unordered_map）都支持迭代器。</li></ol><h3 id="自定义迭代器">自定义迭代器</h3><p>实现自定义双向链表（DLL）迭代器的示例。 1.双向链表节点（<code>Node</code>） 定义一个节点结构体Node，它包含指向前一个节点和后一个节点的指针，以及存储的值。<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">Node</span> &#123;</span><br><span class="line">  <span class="built_in">Node</span>(<span class="type">int</span> val) </span><br><span class="line">    : <span class="built_in">next_</span>(<span class="literal">nullptr</span>), <span class="built_in">prev_</span>(<span class="literal">nullptr</span>), <span class="built_in">value_</span>(val) &#123;&#125;</span><br><span class="line">  Node* next_;</span><br><span class="line">  Node* prev_;</span><br><span class="line">  <span class="type">int</span> value_;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure> 2. 自定义迭代器（<code>DLLIterator</code>）实现自定义迭代器，用于遍历双向链表。该迭代器类实现了以下操作符：</p><ul><li>前缀自增运算符 <code>++iter</code>：将迭代器指向下一个节点。</li><li>后缀自增运算符<code>iter++</code>：类似于前缀自增运算符，但<strong>返回值是递增前的迭代器</strong>。</li><li>等于运算符 <code>==</code> 和不等于运算符<code>!=</code>：判断两个迭代器是否指向同一个节点。</li><li>解引用运算符 <code>*</code>：返回当前节点的值。</li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">DLLIterator</span> &#123;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">DLLIterator</span>(Node* head) </span><br><span class="line">      : <span class="built_in">curr_</span>(head) &#123;&#125;</span><br><span class="line"></span><br><span class="line">    DLLIterator&amp; <span class="keyword">operator</span>++() &#123;     <span class="comment">// 前缀自增</span></span><br><span class="line">      curr_ = curr_-&gt;next_;</span><br><span class="line">      <span class="keyword">return</span> *<span class="keyword">this</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    DLLIterator <span class="keyword">operator</span>++(<span class="type">int</span>) &#123;    <span class="comment">// 后缀自增</span></span><br><span class="line">      DLLIterator temp = *<span class="keyword">this</span>;</span><br><span class="line">      ++*<span class="keyword">this</span>;</span><br><span class="line">      <span class="keyword">return</span> temp;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">bool</span> <span class="keyword">operator</span>==(<span class="type">const</span> DLLIterator &amp;itr) <span class="type">const</span> &#123;</span><br><span class="line">      <span class="keyword">return</span> itr.curr_ == <span class="keyword">this</span>-&gt;curr_;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">bool</span> <span class="keyword">operator</span>!=(<span class="type">const</span> DLLIterator &amp;itr) <span class="type">const</span> &#123;</span><br><span class="line">      <span class="keyword">return</span> itr.curr_ != <span class="keyword">this</span>-&gt;curr_;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> <span class="keyword">operator</span>*() &#123;</span><br><span class="line">      <span class="keyword">return</span> curr_-&gt;value_;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span>:</span><br><span class="line">    Node* curr_;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><ol start="3" type="1"><li>双向链表（<code>DLL</code>）</li></ol><ul><li><code>DLL</code> 类实现了一个基本的双向链表，并且提供了<code>Begin</code> 和 <code>End</code> 函数返回迭代器，用于遍历链表。<code>Begin()</code> 返回指向链表头部的迭代器。 <code>End()</code>返回指向链表末尾之后位置的迭代器（即 <code>nullptr</code>）。</li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">DLL</span> &#123;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">DLL</span>() : <span class="built_in">head_</span>(<span class="literal">nullptr</span>), <span class="built_in">size_</span>(<span class="number">0</span>) &#123;&#125;</span><br><span class="line"></span><br><span class="line">    ~<span class="built_in">DLL</span>() &#123;      <span class="comment">// 析构函数</span></span><br><span class="line">      Node *current = head_;</span><br><span class="line">      <span class="keyword">while</span>(current != <span class="literal">nullptr</span>) &#123;</span><br><span class="line">        Node *next = current-&gt;next_;</span><br><span class="line">        <span class="keyword">delete</span> current;</span><br><span class="line">        current = next;</span><br><span class="line">      &#125;</span><br><span class="line">      head_ = <span class="literal">nullptr</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">InsertAtHead</span><span class="params">(<span class="type">int</span> val)</span> </span>&#123;</span><br><span class="line">      Node *new_node = <span class="keyword">new</span> <span class="built_in">Node</span>(val);</span><br><span class="line">      new_node-&gt;next_ = head_;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (head_ != <span class="literal">nullptr</span>) &#123;</span><br><span class="line">        head_-&gt;prev_ = new_node;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      head_ = new_node;</span><br><span class="line">      size_ += <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function">DLLIterator <span class="title">Begin</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="built_in">DLLIterator</span>(head_);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function">DLLIterator <span class="title">End</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="built_in">DLLIterator</span>(<span class="literal">nullptr</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    Node* head_;</span><br><span class="line">    <span class="type">size_t</span> size_;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><ol start="4" type="1"><li>使用迭代器遍历双向链表</li></ol><ul><li>在 <code>main</code>函数中，我们演示了如何使用自定义的双向链表迭代器来遍历链表。<ul><li>插入元素：通过 <code>InsertAtHead</code> 插入元素。</li><li>遍历链表：通过前缀和后缀自增运算符来遍历链表。</li></ul></li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  DLL dll;</span><br><span class="line">  dll.<span class="built_in">InsertAtHead</span>(<span class="number">6</span>);</span><br><span class="line">  dll.<span class="built_in">InsertAtHead</span>(<span class="number">5</span>);</span><br><span class="line">  dll.<span class="built_in">InsertAtHead</span>(<span class="number">4</span>);</span><br><span class="line">  dll.<span class="built_in">InsertAtHead</span>(<span class="number">3</span>);</span><br><span class="line">  dll.<span class="built_in">InsertAtHead</span>(<span class="number">2</span>);</span><br><span class="line">  dll.<span class="built_in">InsertAtHead</span>(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 使用前缀自增运算符遍历</span></span><br><span class="line">  std::cout &lt;&lt; <span class="string">&quot;Printing elements of the DLL dll via prefix increment operator\n&quot;</span>;</span><br><span class="line">  <span class="keyword">for</span> (DLLIterator iter = dll.<span class="built_in">Begin</span>(); iter != dll.<span class="built_in">End</span>(); ++iter) &#123;</span><br><span class="line">    std::cout &lt;&lt; *iter &lt;&lt; <span class="string">&quot; &quot;</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  std::cout &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 使用后缀自增运算符遍历</span></span><br><span class="line">  std::cout &lt;&lt; <span class="string">&quot;Printing elements of the DLL dll via postfix increment operator\n&quot;</span>;</span><br><span class="line">  <span class="keyword">for</span> (DLLIterator iter = dll.<span class="built_in">Begin</span>(); iter != dll.<span class="built_in">End</span>(); iter++) &#123;</span><br><span class="line">    std::cout &lt;&lt; *iter &lt;&lt; <span class="string">&quot; &quot;</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  std::cout &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="命名空间">命名空间</h2><p>命名空间（namespace）用于将标识符（如函数、类型、变量等）组织成逻辑上的组，并避免不同标识符之间的命名冲突。命名空间通过<strong>限定作用域</strong>，防止命名冲突。例如，C++标准库使用 std 命名空间，因此我们通过 std::cout 来访问输出流对象cout。:: 操作符用于指定作用域，帮助区分不同命名空间中的标识符。</p><h3 id="函数调用">函数调用</h3><ul><li>若在同一命名空间中调用，可以直接使用函数名；而如果在其他命名空间中调用，需要通过作用域解析运算符<code>::</code> 指定完整的命名空间路径。 <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">namespace</span> ABC &#123;</span><br><span class="line">  <span class="keyword">namespace</span> DEF &#123;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">uses_spam</span><span class="params">(<span class="type">int</span> a)</span> </span>&#123;</span><br><span class="line">      std::cout &lt;&lt; <span class="string">&quot;Hello from uses_spam: &quot;</span>;</span><br><span class="line">      ABC::<span class="built_in">spam</span>(a);  <span class="comment">// 必须通过 ABC::spam 来调用</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h3 id="命名空间冲突">命名空间冲突</h3><ul><li>如果多个命名空间中有相同名字的函数或变量，它们依然可以共存，因为它们的全名（即带有命名空间的名字）是不同的。</li></ul><h3 id="using-关键字的使用">using 关键字的使用</h3><p><code>using</code>关键字可以将命名空间或命名空间中的特定成员引入当前作用域。它有两个常见用法：*<strong>引入整个命名空间</strong>：使得命名空间中的所有成员在当前作用域内可以直接使用，而不需要指定命名空间名。*<strong>引入特定成员</strong>：仅将命名空间中的某个成员引入当前作用域。<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> B;  <span class="comment">// 引入整个 B 命名空间</span></span><br><span class="line"><span class="keyword">using</span> C::eggs;  <span class="comment">// 引入 C 命名空间中的 eggs 函数</span></span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> C++ Primer </category>
          
      </categories>
      
      
        <tags>
            
            <tag> C++ </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
